{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import os, sys\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "home_dir = os.path.abspath(os.getcwd())\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "from utils.arguments import load_vcoco_opt_command\n",
    "from utils.distributed import init_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, cmdline_args = load_vcoco_opt_command(home_dir)\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/ADE20K_2021_17_01/images_detectron2/training\n",
      "datasets/ADE20K_2021_17_01/images_detectron2/validation\n"
     ]
    }
   ],
   "source": [
    "from datasets.registration.register_vcoco_dataset import register_all_vcoco\n",
    "_root = os.getenv(\"DATASET\", \"../datasets\")\n",
    "register_all_vcoco(_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_mappers import VCOCODatasetMapper\n",
    "from datasets.build import build_detection_train_loader\n",
    "from datasets.build import _train_loader_from_config\n",
    "from xdecoder.utils import configurable\n",
    "from detectron2.data.common import DatasetFromList, MapDataset\n",
    "from detectron2.data.samplers import TrainingSampler\n",
    "from detectron2.data.build import build_batch_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@configurable(from_config=_train_loader_from_config)\n",
    "def build_hoi_train_loader(\n",
    "    dataset, *, mapper, sampler=None, total_batch_size, aspect_ratio_grouping=True, num_workers=0\n",
    "):\n",
    "    if isinstance(dataset, list):\n",
    "        dataset = DatasetFromList(dataset, copy=False)\n",
    "    if mapper is not None:\n",
    "        dataset = MapDataset(dataset, mapper)\n",
    "    if sampler is None:\n",
    "        sampler = TrainingSampler(len(dataset))\n",
    "    assert isinstance(sampler, torch.utils.data.sampler.Sampler)\n",
    "    return build_batch_data_loader(\n",
    "        dataset,\n",
    "        sampler,\n",
    "        total_batch_size,\n",
    "        aspect_ratio_grouping=aspect_ratio_grouping,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/12 17:56:48 d2.data.common]: Serializing 5400 elements to byte tensors and concatenating them all ...\n",
      "[07/12 17:56:48 d2.data.common]: Serialized dataset takes 3.62 MiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7f3dda98ffa0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['DATASETS']['Train'] = ['vcoco_train']\n",
    "dataset_names = opt['DATASETS']['Train']\n",
    "opt.update(opt['VCOCO'])\n",
    "mapper = VCOCODatasetMapper(opt, True)\n",
    "dataloaders = [build_hoi_train_loader(opt, dataset_names, mapper=mapper)]\n",
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.build import build_train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/12 18:08:59 d2.data.common]: Serializing 5400 elements to byte tensors and concatenating them all ...\n",
      "[07/12 18:08:59 d2.data.common]: Serialized dataset takes 3.62 MiB\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = [build_train_dataloader(opt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m dataloader, dataset_name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(train_data_loader, dataset_names):\n\u001b[0;32m----> 6\u001b[0m     dataloader \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(dataloader)\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(dataloader))\n\u001b[1;32m      8\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:34\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     33\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     35\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/detectron2/data/common.py:202\u001b[0m, in \u001b[0;36mToIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m     sampler \u001b[39m=\u001b[39m _shard_iterator_dataloader_worker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler)\n\u001b[1;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m sampler:\n\u001b[0;32m--> 202\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/detectron2/data/common.py:91\u001b[0m, in \u001b[0;36mMapDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     88\u001b[0m cur_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(idx)\n\u001b[1;32m     90\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[cur_idx])\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fallback_candidates\u001b[39m.\u001b[39madd(cur_idx)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/detectron2/utils/serialize.py:26\u001b[0m, in \u001b[0;36mPicklableWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/datasets/dataset_mappers/vcoco_dataset_mapper.py:145\u001b[0m, in \u001b[0;36mVCOCODatasetMapper.__call__\u001b[0;34m(self, dataset_dict)\u001b[0m\n\u001b[1;32m    142\u001b[0m target[\u001b[39m'\u001b[39m\u001b[39marea\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (boxes[:, \u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m boxes[:, \u001b[39m0\u001b[39m]) \u001b[39m*\u001b[39m (boxes[:, \u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m boxes[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transforms \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transforms(img, target)\n\u001b[1;32m    147\u001b[0m kept_box_indices \u001b[39m=\u001b[39m [label[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m target[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m    149\u001b[0m target[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m target[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/datasets/utils/transforms.py:254\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, image, target)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, image, target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    253\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m--> 254\u001b[0m         image, target \u001b[39m=\u001b[39m t(image, target)\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m image, target\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/datasets/utils/transforms.py:212\u001b[0m, in \u001b[0;36mRandomSelect.__call__\u001b[0;34m(self, img, target)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img, target):\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp:\n\u001b[0;32m--> 212\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms1(img, target)\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms2(img, target)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/datasets/utils/transforms.py:191\u001b[0m, in \u001b[0;36mRandomResize.__call__\u001b[0;34m(self, img, target)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img, target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    190\u001b[0m     size \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msizes)\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m resize(img, target, size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_size)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/datasets/utils/transforms.py:97\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, target, size, max_size)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[39mreturn\u001b[39;00m get_size_with_aspect_ratio(image_size, size, max_size)\n\u001b[1;32m     96\u001b[0m size \u001b[39m=\u001b[39m get_size(image\u001b[39m.\u001b[39msize, size, max_size)\n\u001b[0;32m---> 97\u001b[0m rescaled_image \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mresize(image, size)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m rescaled_image, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/torchvision/transforms/functional.py:474\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    472\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 474\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49moutput_size, interpolation\u001b[39m=\u001b[39;49mpil_interpolation)\n\u001b[1;32m    476\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39moutput_size, interpolation\u001b[39m=\u001b[39minterpolation\u001b[39m.\u001b[39mvalue, antialias\u001b[39m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py:252\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(size, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(size) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot inappropriate size arg: \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mresize(\u001b[39mtuple\u001b[39;49m(size[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]), interpolation)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/PIL/Image.py:2193\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[1;32m   2186\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[1;32m   2187\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   2188\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   2189\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   2190\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   2191\u001b[0m         )\n\u001b[0;32m-> 2193\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from datasets.utils.vcoco_utils import valid_obj_ids, get_coco_instance_ID_to_name, random_color\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for dataloader, dataset_name in zip(train_data_loader, dataset_names):\n",
    "    dataloader = list(dataloader)\n",
    "    print(len(dataloader))\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            if idx == 3:\n",
    "                break\n",
    "            for test in batch:\n",
    "                target_img = test[\"image\"]\n",
    "                target = test[\"instances\"]\n",
    "                img = target_img.permute(1, 2, 0).detach().cpu().numpy()\n",
    "                hh, ww = img.shape[0], img.shape[1]\n",
    "                # print(hh, ww)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                obj_labels = []\n",
    "                labels = []\n",
    "                verb_names = []\n",
    "                ob_boxes = []\n",
    "                sub_boxes = []\n",
    "\n",
    "                obj_boxes = target['boxes']\n",
    "                for test in range(obj_boxes.shape[0]):\n",
    "                    cx, cy, w, h = obj_boxes[test]\n",
    "                    color = random_color()\n",
    "                    cx, cy, w, h = cx * ww, cy * hh, w * ww, h * hh\n",
    "                    n_box = list(map(int, [cx - 0.5 * w, cy - 0.5 * h, cx + 0.5 * w, cy + 0.5 * h]))\n",
    "                    x1, y1, x2, y2 = n_box\n",
    "                    ob_boxes.append(n_box)\n",
    "\n",
    "                for idx in target['labels']:\n",
    "                    label_name = get_coco_instance_ID_to_name(valid_obj_ids[idx])\n",
    "                    labels.append(label_name)\n",
    "\n",
    "                for label, box in zip(labels, ob_boxes):\n",
    "                    color = random_color()\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                    x = (x1 + x2) / 2\n",
    "                    y = (y1 + y2) / 2\n",
    "\n",
    "                    plt.scatter(x, y, 30, color=[i/255 for i in color])\n",
    "                    plt.text(\n",
    "                        x + 5,\n",
    "                        y + 5,\n",
    "                        label,\n",
    "                        fontsize=10,\n",
    "                        bbox=dict(facecolor=[i/255 for i in color], alpha=0.5),\n",
    "                        )\n",
    "\n",
    "                plt.imshow(img)\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
