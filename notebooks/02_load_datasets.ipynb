{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/ADE20K_2021_17_01/images_detectron2/training\n",
      "datasets/ADE20K_2021_17_01/images_detectron2/validation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "home_dir = os.path.abspath(os.getcwd())\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "from pprint import pprint\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "\n",
    "from utils.arguments import load_opt_command\n",
    "from utils.distributed import init_distributed, is_main_process, apply_distributed, synchronize\n",
    "from utils.misc import hook_metadata, hook_switcher, hook_opt\n",
    "from datasets import build_evaluator, build_eval_dataloader\n",
    "from xdecoder import build_model\n",
    "from xdecoder.BaseModel import BaseModel\n",
    "from xdecoder.utils import get_class_names\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WEIGHT', '../checkpoints/xdecoder_focalt_best_openseg.pt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Pretrain or fine-tune models for NLP tasks.')\n",
    "parser.add_argument('--command', default=\"evaluate\", help='Command: train/evaluate/train-and-evaluate')\n",
    "parser.add_argument('--conf_files', nargs='+', help='Path(s) to the config file(s).')\n",
    "parser.add_argument('--user_dir', help='Path to the user defined module for tasks (models, criteria), optimizers, and lr schedulers.')\n",
    "parser.add_argument('--config_overrides', nargs='*', help='Override parameters on config with a json style string, e.g. {\"<PARAM_NAME_1>\": <PARAM_VALUE_1>, \"<PARAM_GROUP_2>.<PARAM_SUBGROUP_2>.<PARAM_2>\": <PARAM_VALUE_2>}. A key with \".\" updates the object in the corresponding nested dict. Remember to escape \" in command line.')\n",
    "parser.add_argument('--overrides', help='arguments that used to override the config file in cmdline', nargs=argparse.REMAINDER)\n",
    "\n",
    "cmdline_args = parser.parse_args('')\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"../configs/xdecoder/svlp_focalt_lang.yaml\")]\n",
    "cmdline_args.overrides = ['WEIGHT', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "cmdline_args.overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = load_opt_from_config_files(cmdline_args.conf_files)\n",
    "\n",
    "keys = [cmdline_args.overrides[idx*2] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [cmdline_args.overrides[idx*2+1] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [val.replace('false', '').replace('False','') if len(val.replace(' ', '')) == 5 else val for val in vals]\n",
    "types = []\n",
    "for key in keys:\n",
    "    key = key.split('.')\n",
    "    ele = opt.copy()\n",
    "    while len(key) > 0:\n",
    "        ele = ele[key.pop(0)]\n",
    "    types.append(type(ele))\n",
    "\n",
    "config_dict = {x:z(y) for x,y,z in zip(keys, vals, types)}\n",
    "config_dict\n",
    "\n",
    "load_config_dict_to_opt(opt, config_dict)\n",
    "for key, val in cmdline_args.__dict__.items():\n",
    "    if val is not None:\n",
    "        opt[key] = val\n",
    "\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADE20K': {'DATASET': {'DATASET': 'ade'},\n",
      "            'INPUT': {'COLOR_AUG_SSD': True,\n",
      "                      'CROP': {'ENABLED': True,\n",
      "                               'SINGLE_CATEGORY_MAX_AREA': 1.0,\n",
      "                               'SIZE': '(640, 640)',\n",
      "                               'TYPE': 'absolute'},\n",
      "                      'DATASET_MAPPER_NAME': 'mask_former_panoptic',\n",
      "                      'FORMAT': 'RGB',\n",
      "                      'MASK_FORMAT': 'polygon',\n",
      "                      'MAX_SIZE_TEST': 200,\n",
      "                      'MAX_SIZE_TRAIN': 200,\n",
      "                      'MIN_SIZE_TEST': 640,\n",
      "                      'MIN_SIZE_TRAIN': 640,\n",
      "                      'MIN_SIZE_TRAIN_SAMPLING': 'choice',\n",
      "                      'SIZE_DIVISIBILITY': 640},\n",
      "            'TEST': {'BATCH_SIZE_TOTAL': 4}},\n",
      " 'BDD': {'DATALOADER': {'ASPECT_RATIO_GROUPING': False,\n",
      "                        'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                        'LOAD_PROPOSALS': False,\n",
      "                        'NUM_WORKERS': 0,\n",
      "                        'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "         'INPUT': {'MAX_SIZE_TEST': 1333,\n",
      "                   'MIN_SIZE_TEST': 800,\n",
      "                   'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "                   'PIXEL_STD': [58.395, 57.12, 57.375]},\n",
      "         'TEST': {'BATCH_SIZE_TOTAL': 8}},\n",
      " 'CITY': {'DATALOADER': {'FILTER_EMPTY_ANNOTATIONS': True, 'NUM_WORKERS': 4},\n",
      "          'INPUT': {'COLOR_AUG_SSD': True,\n",
      "                    'CROP': {'ENABLED': True,\n",
      "                             'SINGLE_CATEGORY_MAX_AREA': 1.0,\n",
      "                             'SIZE': '(512, 1024)',\n",
      "                             'TYPE': 'absolute'},\n",
      "                    'DATASET_MAPPER_NAME': 'mask_former_panoptic',\n",
      "                    'FORMAT': 'RGB',\n",
      "                    'MASK_FORMAT': 'polygon',\n",
      "                    'MAX_SIZE_TEST': 2048,\n",
      "                    'MAX_SIZE_TRAIN': 4096,\n",
      "                    'MIN_SIZE_TEST': 1024,\n",
      "                    'MIN_SIZE_TRAIN': 1024,\n",
      "                    'MIN_SIZE_TRAIN_SAMPLING': 'choice',\n",
      "                    'SIZE_DIVISIBILITY': -1},\n",
      "          'TEST': {'AUG': {'ENABLED': False,\n",
      "                           'FLIP': True,\n",
      "                           'MAX_SIZE': 4096,\n",
      "                           'MIN_SIZES': [512, 768, 1024, 1280, 1536, 1792]},\n",
      "                   'BATCH_SIZE_TOTAL': 8,\n",
      "                   'EVAL_PERIOD': 5000}},\n",
      " 'COCO': {'DATALOADER': {'ASPECT_RATIO_GROUPING': True,\n",
      "                         'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                         'LOAD_PROPOSALS': False,\n",
      "                         'NUM_WORKERS': 2,\n",
      "                         'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "          'DATASET': {'DATASET': 'coco'},\n",
      "          'INPUT': {'COLOR_AUG_SSD': False,\n",
      "                    'CROP': {'ENABLED': True},\n",
      "                    'DATASET_MAPPER_NAME': 'coco_panoptic_lsj',\n",
      "                    'FORMAT': 'RGB',\n",
      "                    'IGNORE_VALUE': 255,\n",
      "                    'IMAGE_SIZE': 1024,\n",
      "                    'MASK_FORMAT': 'polygon',\n",
      "                    'MAX_SCALE': 2.0,\n",
      "                    'MAX_SIZE_TEST': 1333,\n",
      "                    'MIN_SCALE': 0.1,\n",
      "                    'MIN_SIZE_TEST': 800,\n",
      "                    'RANDOM_FLIP': 'horizontal',\n",
      "                    'SIZE_DIVISIBILITY': 32},\n",
      "          'TEST': {'AUG': {'ENABLED': False},\n",
      "                   'BATCH_SIZE_TOTAL': 8,\n",
      "                   'DETECTIONS_PER_IMAGE': 100,\n",
      "                   'IOU_TYPE': ['bbox', 'segm'],\n",
      "                   'MODEL_FILE': '',\n",
      "                   'NAME': 'coco_eval',\n",
      "                   'USE_MULTISCALE': False}},\n",
      " 'CUDA': True,\n",
      " 'DATALOADER': {'ASPECT_RATIO_GROUPING': True,\n",
      "                'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                'LOAD_PROPOSALS': False,\n",
      "                'NUM_WORKERS': 16,\n",
      "                'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      " 'DATASETS': {'CLASS_CONCAT': False,\n",
      "              'PROPOSAL_FILES_TRAIN': [],\n",
      "              'SIZE_DIVISIBILITY': 32,\n",
      "              'TEST': ['ade20k_panoptic_val']},\n",
      " 'INPUT': {'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "           'PIXEL_STD': [58.395, 57.12, 57.375]},\n",
      " 'MODEL': {'BACKBONE': {'FOCAL': {'DEPTHS': [2, 2, 6, 2],\n",
      "                                  'DROP_PATH_RATE': 0.3,\n",
      "                                  'DROP_RATE': 0.0,\n",
      "                                  'EMBED_DIM': 96,\n",
      "                                  'FOCAL_LEVELS': [3, 3, 3, 3],\n",
      "                                  'FOCAL_WINDOWS': [3, 3, 3, 3],\n",
      "                                  'MLP_RATIO': 4.0,\n",
      "                                  'OUT_FEATURES': ['res2',\n",
      "                                                   'res3',\n",
      "                                                   'res4',\n",
      "                                                   'res5'],\n",
      "                                  'OUT_INDICES': [0, 1, 2, 3],\n",
      "                                  'PATCH_NORM': True,\n",
      "                                  'PATCH_SIZE': 4,\n",
      "                                  'PRETRAIN_IMG_SIZE': 224,\n",
      "                                  'SCALING_MODULATOR': True,\n",
      "                                  'USE_CHECKPOINT': False,\n",
      "                                  'USE_CONV_EMBED': True,\n",
      "                                  'USE_LAYERSCALE': True,\n",
      "                                  'USE_POSTLN': True,\n",
      "                                  'USE_POSTLN_IN_MODULATION': False},\n",
      "                        'LOAD_PRETRAINED': False,\n",
      "                        'NAME': 'focal_dw',\n",
      "                        'PRETRAINED': ''},\n",
      "           'BACKBONE_DIM': 768,\n",
      "           'DECODER': {'CAPTION': {'ENABLED': True,\n",
      "                                   'PHRASE_PROB': 0.0,\n",
      "                                   'SIM_THRES': 0.95},\n",
      "                       'CAPTIONING': {'ENABLED': True, 'STEP': 50},\n",
      "                       'DEC_LAYERS': 10,\n",
      "                       'DETECTION': False,\n",
      "                       'DIM_FEEDFORWARD': 2048,\n",
      "                       'DROPOUT': 0.0,\n",
      "                       'ENFORCE_INPUT_PROJ': False,\n",
      "                       'GROUNDING': {'CLASS_WEIGHT': 0.5,\n",
      "                                     'ENABLED': True,\n",
      "                                     'MAX_LEN': 5,\n",
      "                                     'TEXT_WEIGHT': 2.0},\n",
      "                       'HIDDEN_DIM': 512,\n",
      "                       'IMPORTANCE_SAMPLE_RATIO': 0.75,\n",
      "                       'MASK': True,\n",
      "                       'NAME': 'xdecoder',\n",
      "                       'NHEADS': 8,\n",
      "                       'NUM_OBJECT_QUERIES': 101,\n",
      "                       'OVERSAMPLE_RATIO': 3.0,\n",
      "                       'PRE_NORM': False,\n",
      "                       'RETRIEVAL': {'DIM_IMG': 768,\n",
      "                                     'ENABLED': True,\n",
      "                                     'ENSEMBLE': True},\n",
      "                       'SIZE_DIVISIBILITY': 32,\n",
      "                       'TEST': {'INSTANCE_ON': True,\n",
      "                                'OBJECT_MASK_THRESHOLD': 0.8,\n",
      "                                'OVERLAP_THRESHOLD': 0.8,\n",
      "                                'PANOPTIC_ON': True,\n",
      "                                'SEMANTIC_ON': True,\n",
      "                                'SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE': False},\n",
      "                       'TOP_CAPTIONING_LAYERS': 3,\n",
      "                       'TOP_CAPTION_LAYERS': 3,\n",
      "                       'TOP_GROUNDING_LAYERS': 3,\n",
      "                       'TOP_RETRIEVAL_LAYERS': 3,\n",
      "                       'TRAIN_NUM_POINTS': 12544,\n",
      "                       'TRANSFORMER_IN_FEATURE': 'multi_scale_pixel_decoder'},\n",
      "           'DIM_PROJ': 512,\n",
      "           'ENCODER': {'COMMON_STRIDE': 4,\n",
      "                       'CONVS_DIM': 512,\n",
      "                       'DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES': ['res3',\n",
      "                                                                      'res4',\n",
      "                                                                      'res5'],\n",
      "                       'IGNORE_VALUE': 255,\n",
      "                       'IN_FEATURES': ['res2', 'res3', 'res4', 'res5'],\n",
      "                       'LOSS_WEIGHT': 1.0,\n",
      "                       'MASK_DIM': 512,\n",
      "                       'NAME': 'transformer_encoder_fpn',\n",
      "                       'NORM': 'GN',\n",
      "                       'NUM_CLASSES': 133,\n",
      "                       'TRANSFORMER_ENC_LAYERS': 6},\n",
      "           'HEAD': 'xdecoder_head',\n",
      "           'KEYPOINT_ON': False,\n",
      "           'LOAD_PROPOSALS': False,\n",
      "           'MASK_ON': False,\n",
      "           'NAME': 'xdecoder_model',\n",
      "           'TEXT': {'ARCH': 'vlpencoder',\n",
      "                    'AUTOGRESSIVE': True,\n",
      "                    'CONTEXT_LENGTH': 77,\n",
      "                    'HEADS': 8,\n",
      "                    'LAYERS': 12,\n",
      "                    'NAME': 'transformer',\n",
      "                    'TOKENIZER': 'clip',\n",
      "                    'WIDTH': 512}},\n",
      " 'PORT': 53711,\n",
      " 'REF': {'DATALOADER': {'ASPECT_RATIO_GROUPING': False,\n",
      "                        'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                        'LOAD_PROPOSALS': False,\n",
      "                        'NUM_WORKERS': 0,\n",
      "                        'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "         'INPUT': {'FORMAT': 'RGB',\n",
      "                   'MAX_SIZE_TEST': 1024,\n",
      "                   'MIN_SIZE_TEST': 512,\n",
      "                   'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "                   'PIXEL_STD': [58.395, 57.12, 57.375]},\n",
      "         'TEST': {'BATCH_SIZE_TOTAL': 8}},\n",
      " 'SAVE_DIR': '../../data/output/test',\n",
      " 'SCAN': {'DATALOADER': {'ASPECT_RATIO_GROUPING': False,\n",
      "                         'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                         'LOAD_PROPOSALS': False,\n",
      "                         'NUM_WORKERS': 0,\n",
      "                         'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "          'INPUT': {'MAX_SIZE_TEST': 1024,\n",
      "                    'MIN_SIZE_TEST': 512,\n",
      "                    'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "                    'PIXEL_STD': [58.395, 57.12, 57.375]},\n",
      "          'TEST': {'BATCH_SIZE_TOTAL': 8}},\n",
      " 'SUN': {'DATALOADER': {'ASPECT_RATIO_GROUPING': False,\n",
      "                        'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                        'LOAD_PROPOSALS': False,\n",
      "                        'NUM_WORKERS': 0,\n",
      "                        'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "         'INPUT': {'MAX_SIZE_TEST': 1024,\n",
      "                   'MIN_SIZE_TEST': 512,\n",
      "                   'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "                   'PIXEL_STD': [58.395, 57.12, 57.375]},\n",
      "         'TEST': {'BATCH_SIZE_TOTAL': 8}},\n",
      " 'VERBOSE': True,\n",
      " 'VLP': {'DATALOADER': {'ASPECT_RATIO_GROUPING': True,\n",
      "                        'FILTER_EMPTY_ANNOTATIONS': False,\n",
      "                        'LOAD_PROPOSALS': False,\n",
      "                        'NUM_WORKERS': 16,\n",
      "                        'SAMPLER_TRAIN': 'TrainingSampler'},\n",
      "         'INPUT': {'COLOR_AUG_SSD': False,\n",
      "                   'CROP': {'ENABLED': True},\n",
      "                   'DATASET_MAPPER_NAME': 'vlpretrain',\n",
      "                   'FORMAT': 'RGB',\n",
      "                   'IGNORE_VALUE': 255,\n",
      "                   'IMAGE_SIZE': 224,\n",
      "                   'MASK_FORMAT': 'polygon',\n",
      "                   'SIZE_DIVISIBILITY': 32},\n",
      "         'TEST': {'BATCH_SIZE_TOTAL': 64},\n",
      "         'TRAIN': {'BATCH_SIZE_PER_GPU': 2, 'BATCH_SIZE_TOTAL': 2}},\n",
      " 'WEIGHT': '../checkpoints/xdecoder_focalt_best_openseg.pt',\n",
      " 'command': 'evaluate',\n",
      " 'conf_files': ['/home/djjin/Mygit/X-Decoder/notebooks/../configs/xdecoder/svlp_focalt_lang.yaml'],\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'env_info': 'no MPI',\n",
      " 'local_rank': 0,\n",
      " 'local_size': 1,\n",
      " 'master_address': '127.0.0.1',\n",
      " 'master_port': '8673',\n",
      " 'overrides': ['WEIGHT', '../checkpoints/xdecoder_focalt_best_openseg.pt'],\n",
      " 'rank': 0,\n",
      " 'world_size': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*UNLOADED* sem_seg_head.predictor.pos_embed_caping.weight, Model Shape: torch.Size([77, 512])\n",
      "$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])\n",
      "$UNUSED$ sem_seg_head.predictor.query_feat_caping.weight, Ckpt Shape: torch.Size([77, 512])\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(opt, build_model(opt)).from_pretrained(opt['WEIGHT']).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = build_eval_dataloader(opt)\n",
    "dataset_names = opt['DATASETS']['TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m evaluator\u001b[39m.\u001b[39mreset()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(batch))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# with torch.autocast(device_type='cuda', dtype=torch.float16):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m#     outputs = model(batch, mode=eval_type)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/djjin/Mygit/X-Decoder/notebooks/02_load_datasets.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m# print(outputs)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_Decoder/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_Decoder/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_Decoder/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_Decoder/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_X_Decoder/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataloader, dataset_name in zip(dataloaders, dataset_names):\n",
    "    # build evaluator\n",
    "    evaluator = build_evaluator(opt, dataset_name, opt['SAVE_DIR'])\n",
    "    evaluator.reset()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            print(len(batch))\n",
    "            # forward\n",
    "            # with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            #     outputs = model(batch, mode=eval_type)\n",
    "            # print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
