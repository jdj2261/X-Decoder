{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.colormap import random_color\n",
    "from detectron2.structures import Boxes, ImageList, Instances, BitMasks, BoxMode\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "\n",
    "from utils.arguments import load_opt_command\n",
    "from utils.misc import hook_metadata, hook_switcher, hook_opt\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Pretrain or fine-tune models for NLP tasks.')\n",
    "parser.add_argument('--command', default=\"evaluate\", help='Command: train/evaluate/train-and-evaluate')\n",
    "parser.add_argument('--conf_files', nargs='+', help='Path(s) to the config file(s).')\n",
    "parser.add_argument('--user_dir', help='Path to the user defined module for tasks (models, criteria), optimizers, and lr schedulers.')\n",
    "parser.add_argument('--config_overrides', nargs='*', help='Override parameters on config with a json style string, e.g. {\"<PARAM_NAME_1>\": <PARAM_VALUE_1>, \"<PARAM_GROUP_2>.<PARAM_SUBGROUP_2>.<PARAM_2>\": <PARAM_VALUE_2>}. A key with \".\" updates the object in the corresponding nested dict. Remember to escape \" in command line.')\n",
    "parser.add_argument('--overrides', help='arguments that used to override the config file in cmdline', nargs=argparse.REMAINDER)\n",
    "\n",
    "cmdline_args = parser.parse_args('')\n",
    "# cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/svlp_focalt_lang.yaml\")]\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco.yaml\")]\n",
    "cmdline_args.overrides = ['WEIGHT', 'true', 'RESUME_FROM', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "\n",
    "opt = load_opt_from_config_files(cmdline_args.conf_files)\n",
    "opt[\"base_path\"] = \"../\"\n",
    "\n",
    "keys = [cmdline_args.overrides[idx*2] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [cmdline_args.overrides[idx*2+1] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [val.replace('false', '').replace('False','') if len(val.replace(' ', '')) == 5 else val for val in vals]\n",
    "types = []\n",
    "for key in keys:\n",
    "    key = key.split('.')\n",
    "    ele = opt.copy()\n",
    "    while len(key) > 0:\n",
    "        ele = ele[key.pop(0)]\n",
    "    types.append(type(ele))\n",
    "\n",
    "config_dict = {x:z(y) for x,y,z in zip(keys, vals, types)}\n",
    "\n",
    "load_config_dict_to_opt(opt, config_dict)\n",
    "for key, val in cmdline_args.__dict__.items():\n",
    "    if val is not None:\n",
    "        opt[key] = val\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': True, 'encoder': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"WANDB\"] = False\n",
    "fix_param = opt['SOLVER'].get('FIX_PARAM',{})\n",
    "fix_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as data/output/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to data/output/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-------------------------------------------------------\n",
      "INFO:trainer.default_trainer:Training on rank: 0\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.136)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.191)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.218)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.245)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.273)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-5): 6 x TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-2): 3 x TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): PostProcessHOI()\n",
      ")\n",
      "INFO:datasets.build:Using training sampler TrainingSampler\n",
      "INFO:detectron2.data.common:Serializing 5400 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.62 MiB\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:num of train samples: 2700\n",
      "INFO:trainer.hdecoder_trainer:Calculate MAX_ITER @ 24300000 and STEPS @ [21600027, 23399928]\n",
      "INFO:trainer.hdecoder_trainer:Total number of parameters in default module (on each GPU): 85407335\n",
      "INFO:trainer.hdecoder_trainer:Number of trainable parameters in default module (on each GPU): 26389111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 5400\n",
      "num of train samples: 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512])\n",
      "WARNING:utils.model:$UNUSED$ backbone_proj, Ckpt Shape: torch.Size([768, 512])\n",
      "WARNING:utils.model:$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.pixel_decoder.layer_4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.pixel_decoder.layer_4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.pixel_decoder.layer_4.weight, Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.caping_embed, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.class_embed, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.decoder_norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.decoder_norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([77, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Ckpt Shape: torch.Size([49408, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_proj, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.logit_scale, Ckpt Shape: torch.Size([])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.level_embed.weight, Ckpt Shape: torch.Size([3, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.0.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.0.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.1.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.2.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_embed.weight, Ckpt Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_feat.weight, Ckpt Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_feat_caping.weight, Ckpt Shape: torch.Size([77, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.self_attn_mask, Ckpt Shape: torch.Size([1, 178, 178])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNMATCHED* criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([134])\n",
      "WARNING:trainer.utils_trainer:Load weights from ../checkpoints/xdecoder_focalt_best_openseg.pt...\n",
      "INFO:trainer.default_trainer:***** Running training *****\n",
      "INFO:trainer.default_trainer:  Num of GPUs = 1\n",
      "INFO:trainer.default_trainer:  Num Epochs = 90\n",
      "INFO:trainer.default_trainer:  Num of Mini Batches per Epoch = 2700\n",
      "INFO:trainer.default_trainer:  Total train batch size (w. parallel, distributed & accumulation) = 243000\n",
      "INFO:trainer.default_trainer:  Gradient Accumulation steps = 1\n",
      "INFO:trainer.default_trainer:  Total optimization steps = 243000\n",
      "INFO:trainer.default_trainer:Start epoch: 0 training.\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 526.80597/526.80597, loss_obj_ce: 4.95657/4.95657, obj_class_error: 100.00000/100.00000, loss_verb_ce: 80.34808/80.34808, loss_sub_bbox: 1.11321/1.11321, loss_obj_bbox: 0.98606/0.98606, loss_sub_giou: 1.18159/1.18159, loss_obj_giou: 0.94380/0.94380, obj_cardinality_error: 97.00000/97.00000, loss_obj_ce_0: 4.84742/4.84742, loss_verb_ce_0: 82.66903/82.66903, loss_sub_bbox_0: 1.10058/1.10058, loss_obj_bbox_0: 0.97235/0.97235, loss_sub_giou_0: 1.16676/1.16676, loss_obj_giou_0: 0.95763/0.95763, obj_cardinality_error_0: 97.00000/97.00000, loss_obj_ce_1: 4.88207/4.88207, loss_verb_ce_1: 82.04111/82.04111, loss_sub_bbox_1: 1.10206/1.10206, loss_obj_bbox_1: 0.97716/0.97716, loss_sub_giou_1: 1.17208/1.17208, loss_obj_giou_1: 0.95303/0.95303, obj_cardinality_error_1: 97.00000/97.00000] items per batch[1] items per second[0.79] total items[1] mini batches[     1] memory[965] epoch remaining[0:56:43]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 193.60846/360.20721, loss_obj_ce: 4.17506/4.56581, obj_class_error: 100.00000/100.00000, loss_verb_ce: 26.41810/53.38309, loss_sub_bbox: 0.45373/0.78347, loss_obj_bbox: 0.95063/0.96834, loss_sub_giou: 0.78338/0.98249, loss_obj_giou: 0.95427/0.94903, obj_cardinality_error: 97.00000/97.00000, loss_obj_ce_0: 4.06032/4.45387, loss_verb_ce_0: 29.16749/55.91826, loss_sub_bbox_0: 0.45563/0.77811, loss_obj_bbox_0: 0.93319/0.95277, loss_sub_giou_0: 0.77562/0.97119, loss_obj_giou_0: 0.96678/0.96220, obj_cardinality_error_0: 96.50000/96.75000, loss_obj_ce_1: 4.06296/4.47252, loss_verb_ce_1: 27.21540/54.62826, loss_sub_bbox_1: 0.46085/0.78145, loss_obj_bbox_1: 0.94196/0.95956, loss_sub_giou_1: 0.78247/0.97728, loss_obj_giou_1: 0.95566/0.95435, obj_cardinality_error_1: 97.00000/97.00000] items per batch[1] items per second[9.32] total items[2] mini batches[     2] memory[965] epoch remaining[0:30:45]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[3/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 250.25275/323.55573, loss_obj_ce: 3.67805/4.26989, obj_class_error: 100.00000/100.00000, loss_verb_ce: 36.59058/47.78559, loss_sub_bbox: 0.66411/0.74368, loss_obj_bbox: 1.11827/1.01832, loss_sub_giou: 0.69572/0.88690, loss_obj_giou: 1.41902/1.10569, obj_cardinality_error: 95.50000/96.50000, loss_obj_ce_0: 3.49418/4.13397, loss_verb_ce_0: 38.47341/50.10331, loss_sub_bbox_0: 0.65056/0.73559, loss_obj_bbox_0: 1.09173/0.99909, loss_sub_giou_0: 0.68663/0.87634, loss_obj_giou_0: 1.40839/1.11093, obj_cardinality_error_0: 65.50000/86.33333, loss_obj_ce_1: 3.46532/4.13679, loss_verb_ce_1: 34.98378/48.08010, loss_sub_bbox_1: 0.65939/0.74077, loss_obj_bbox_1: 1.10094/1.00668, loss_sub_giou_1: 0.68187/0.87881, loss_obj_giou_1: 1.41550/1.10807, obj_cardinality_error_1: 57.00000/83.66667] items per batch[1] items per second[10.81] total items[3] mini batches[     3] memory[965] epoch remaining[0:21:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[4/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 80.25570/262.73072, loss_obj_ce: 3.05387/3.96589, obj_class_error: 100.00000/100.00000, loss_verb_ce: 9.93696/38.32343, loss_sub_bbox: 0.59940/0.70761, loss_obj_bbox: 0.61290/0.91696, loss_sub_giou: 0.63869/0.82484, loss_obj_giou: 0.84630/1.04085, obj_cardinality_error: 4.50000/73.50000, loss_obj_ce_0: 2.54542/3.73683, loss_verb_ce_0: 10.24567/40.13890, loss_sub_bbox_0: 0.59350/0.70007, loss_obj_bbox_0: 0.61503/0.90308, loss_sub_giou_0: 0.63176/0.81519, loss_obj_giou_0: 0.84622/1.04475, obj_cardinality_error_0: 1.50000/65.12500, loss_obj_ce_1: 2.60802/3.75459, loss_verb_ce_1: 9.10719/38.33687, loss_sub_bbox_1: 0.58664/0.70224, loss_obj_bbox_1: 0.60393/0.90600, loss_sub_giou_1: 0.63395/0.81759, loss_obj_giou_1: 0.84332/1.04188, obj_cardinality_error_1: 1.50000/63.12500] items per batch[1] items per second[7.05] total items[4] mini batches[     4] memory[1058] epoch remaining[0:18:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[5/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 44.49701/219.08398, loss_obj_ce: 2.38701/3.65011, obj_class_error: 100.00000/100.00000, loss_verb_ce: 4.21557/31.50186, loss_sub_bbox: 0.55504/0.67710, loss_obj_bbox: 0.68101/0.86977, loss_sub_giou: 0.66341/0.79256, loss_obj_giou: 0.77517/0.98771, obj_cardinality_error: 3.50000/59.50000, loss_obj_ce_0: 2.03883/3.39723, loss_verb_ce_0: 4.19678/32.95048, loss_sub_bbox_0: 0.54836/0.66973, loss_obj_bbox_0: 0.66739/0.85594, loss_sub_giou_0: 0.65687/0.78353, loss_obj_giou_0: 0.76527/0.98886, obj_cardinality_error_0: 3.50000/52.80000, loss_obj_ce_1: 2.02926/3.40953, loss_verb_ce_1: 3.87034/31.44356, loss_sub_bbox_1: 0.55063/0.67192, loss_obj_bbox_1: 0.67392/0.85958, loss_sub_giou_1: 0.65302/0.78468, loss_obj_giou_1: 0.77191/0.98789, obj_cardinality_error_1: 3.50000/51.20000] items per batch[1] items per second[11.03] total items[5] mini batches[     5] memory[1058] epoch remaining[0:15:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[6/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 56.90778/192.05461, loss_obj_ce: 1.31857/3.26152, obj_class_error: 100.00000/100.00000, loss_verb_ce: 6.07058/27.26331, loss_sub_bbox: 0.84083/0.70439, loss_obj_bbox: 0.75206/0.85015, loss_sub_giou: 0.87595/0.80646, loss_obj_giou: 0.86778/0.96772, obj_cardinality_error: 1.00000/49.75000, loss_obj_ce_0: 0.95843/2.99077, loss_verb_ce_0: 6.39563/28.52467, loss_sub_bbox_0: 0.83957/0.69803, loss_obj_bbox_0: 0.77421/0.84232, loss_sub_giou_0: 0.88892/0.80109, loss_obj_giou_0: 0.86936/0.96894, obj_cardinality_error_0: 1.00000/44.16667, loss_obj_ce_1: 0.97534/3.00383, loss_verb_ce_1: 5.70850/27.15439, loss_sub_bbox_1: 0.83873/0.69972, loss_obj_bbox_1: 0.77791/0.84597, loss_sub_giou_1: 0.87393/0.79955, loss_obj_giou_1: 0.87180/0.96854, obj_cardinality_error_1: 1.00000/42.83333] items per batch[1] items per second[9.58] total items[6] mini batches[     6] memory[1058] epoch remaining[0:13:27]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[7/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 35.62868/169.70805, loss_obj_ce: 2.29422/3.12333, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.58007/23.59428, loss_sub_bbox: 0.90614/0.73321, loss_obj_bbox: 0.69066/0.82737, loss_sub_giou: 1.19254/0.86161, loss_obj_giou: 1.15358/0.99427, obj_cardinality_error: 5.00000/43.35714, loss_obj_ce_0: 2.45347/2.91401, loss_verb_ce_0: 1.58448/24.67607, loss_sub_bbox_0: 0.89264/0.72584, loss_obj_bbox_0: 0.71360/0.82393, loss_sub_giou_0: 1.20060/0.85817, loss_obj_giou_0: 1.16978/0.99763, obj_cardinality_error_0: 5.00000/38.57143, loss_obj_ce_1: 2.36004/2.91186, loss_verb_ce_1: 1.54470/23.49586, loss_sub_bbox_1: 0.90237/0.72867, loss_obj_bbox_1: 0.70653/0.82605, loss_sub_giou_1: 1.19260/0.85570, loss_obj_giou_1: 1.16347/0.99639, obj_cardinality_error_1: 5.00000/37.42857] items per batch[1] items per second[10.61] total items[7] mini batches[     7] memory[1058] epoch remaining[0:12:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[8/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 34.01704/152.74667, loss_obj_ce: 0.92634/2.84871, obj_class_error: 100.00000/100.00000, loss_verb_ce: 3.08457/21.03056, loss_sub_bbox: 0.46602/0.69981, loss_obj_bbox: 0.61932/0.80136, loss_sub_giou: 0.73908/0.84630, loss_obj_giou: 0.88019/0.98001, obj_cardinality_error: 1.50000/38.12500, loss_obj_ce_0: 0.87261/2.65883, loss_verb_ce_0: 3.27256/22.00063, loss_sub_bbox_0: 0.45878/0.69245, loss_obj_bbox_0: 0.57304/0.79257, loss_sub_giou_0: 0.73461/0.84272, loss_obj_giou_0: 0.87698/0.98255, obj_cardinality_error_0: 1.50000/33.93750, loss_obj_ce_1: 0.88603/2.65863, loss_verb_ce_1: 2.91219/20.92290, loss_sub_bbox_1: 0.47001/0.69634, loss_obj_bbox_1: 0.59066/0.79663, loss_sub_giou_1: 0.73895/0.84111, loss_obj_giou_1: 0.87902/0.98171, obj_cardinality_error_1: 1.50000/32.93750] items per batch[1] items per second[7.97] total items[8] mini batches[     8] memory[1058] epoch remaining[0:11:18]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[9/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 35.76548/139.74876, loss_obj_ce: 0.91506/2.63386, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.69521/18.88219, loss_sub_bbox: 0.77090/0.70771, loss_obj_bbox: 1.31190/0.85809, loss_sub_giou: 0.90687/0.85303, loss_obj_giou: 1.49974/1.03776, obj_cardinality_error: 1.50000/34.05556, loss_obj_ce_0: 0.91319/2.46487, loss_verb_ce_0: 1.81090/19.75733, loss_sub_bbox_0: 0.74787/0.69861, loss_obj_bbox_0: 1.28253/0.84701, loss_sub_giou_0: 0.89924/0.84900, loss_obj_giou_0: 1.50190/1.04025, obj_cardinality_error_0: 1.50000/30.33333, loss_obj_ce_1: 0.88800/2.46189, loss_verb_ce_1: 1.67798/18.78458, loss_sub_bbox_1: 0.77204/0.70475, loss_obj_bbox_1: 1.29744/0.85227, loss_sub_giou_1: 0.91678/0.84952, loss_obj_giou_1: 1.49983/1.03928, obj_cardinality_error_1: 1.50000/29.44444] items per batch[1] items per second[7.25] total items[9] mini batches[     9] memory[1058] epoch remaining[0:10:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[10/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 28.29085/128.60297, loss_obj_ce: 1.48538/2.51901, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.26260/17.12023, loss_sub_bbox: 0.52266/0.68921, loss_obj_bbox: 0.84853/0.85713, loss_sub_giou: 0.83639/0.85136, loss_obj_giou: 1.19635/1.05362, obj_cardinality_error: 3.50000/31.00000, loss_obj_ce_0: 1.53660/2.37205, loss_verb_ce_0: 1.24762/17.90636, loss_sub_bbox_0: 0.51813/0.68056, loss_obj_bbox_0: 0.82362/0.84467, loss_sub_giou_0: 0.84002/0.84810, loss_obj_giou_0: 1.19244/1.05547, obj_cardinality_error_0: 3.50000/27.65000, loss_obj_ce_1: 1.52274/2.36798, loss_verb_ce_1: 1.23569/17.02969, loss_sub_bbox_1: 0.52130/0.68640, loss_obj_bbox_1: 0.82383/0.84943, loss_sub_giou_1: 0.84328/0.84889, loss_obj_giou_1: 1.20068/1.05542, obj_cardinality_error_1: 3.50000/26.85000] items per batch[1] items per second[7.34] total items[10] mini batches[    10] memory[1058] epoch remaining[0:10:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[20/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.24664/79.15897, loss_obj_ce: 0.93041/1.85182, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.21028/9.24685, loss_sub_bbox: 0.74221/0.74139, loss_obj_bbox: 0.56533/0.82297, loss_sub_giou: 0.80034/0.93124, loss_obj_giou: 0.76904/1.04625, obj_cardinality_error: 1.50000/16.85000, loss_obj_ce_0: 0.90673/1.78182, loss_verb_ce_0: 1.16016/9.63864, loss_sub_bbox_0: 0.75844/0.73337, loss_obj_bbox_0: 0.52522/0.81186, loss_sub_giou_0: 0.79750/0.93258, loss_obj_giou_0: 0.74465/1.04218, obj_cardinality_error_0: 1.50000/15.17500, loss_obj_ce_1: 0.94758/1.77497, loss_verb_ce_1: 1.17308/9.19468, loss_sub_bbox_1: 0.75257/0.73931, loss_obj_bbox_1: 0.53885/0.81490, loss_sub_giou_1: 0.80225/0.93400, loss_obj_giou_1: 0.75451/1.04427, obj_cardinality_error_1: 1.50000/14.77500] items per batch[1] items per second[0.80] total items[20] mini batches[    20] memory[1058] epoch remaining[0:07:54]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[30/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 31.08452/61.81045, loss_obj_ce: 1.43475/1.60532, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.17228/6.59716, loss_sub_bbox: 0.82697/0.71744, loss_obj_bbox: 0.97635/0.78765, loss_sub_giou: 0.86960/0.90755, loss_obj_giou: 1.20363/1.05210, obj_cardinality_error: 4.00000/12.15000, loss_obj_ce_0: 1.44434/1.56615, loss_verb_ce_0: 1.10860/6.84002, loss_sub_bbox_0: 0.86121/0.70698, loss_obj_bbox_0: 0.95620/0.77805, loss_sub_giou_0: 0.89141/0.91291, loss_obj_giou_0: 1.18657/1.04716, obj_cardinality_error_0: 4.00000/11.03333, loss_obj_ce_1: 1.46459/1.55623, loss_verb_ce_1: 1.15780/6.55499, loss_sub_bbox_1: 0.85249/0.71422, loss_obj_bbox_1: 0.97259/0.78131, loss_sub_giou_1: 0.88827/0.91241, loss_obj_giou_1: 1.20948/1.05216, obj_cardinality_error_1: 4.00000/10.76667] items per batch[1] items per second[0.78] total items[30] mini batches[    30] memory[1144] epoch remaining[0:07:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[40/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 29.17415/53.09764, loss_obj_ce: 0.66624/1.43170, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.16123/5.25118, loss_sub_bbox: 0.87454/0.70550, loss_obj_bbox: 0.72045/0.75880, loss_sub_giou: 1.19906/0.89864, loss_obj_giou: 1.58852/1.14486, obj_cardinality_error: 1.50000/9.66250, loss_obj_ce_0: 0.66678/1.39982, loss_verb_ce_0: 1.16603/5.43630, loss_sub_bbox_0: 0.85538/0.69612, loss_obj_bbox_0: 0.70379/0.74982, loss_sub_giou_0: 1.19361/0.90262, loss_obj_giou_0: 1.59414/1.13990, obj_cardinality_error_0: 1.50000/8.82500, loss_obj_ce_1: 0.66732/1.39271, loss_verb_ce_1: 1.17910/5.22438, loss_sub_bbox_1: 0.86120/0.70246, loss_obj_bbox_1: 0.71372/0.75314, loss_sub_giou_1: 1.19140/0.90180, loss_obj_giou_1: 1.57169/1.14729, obj_cardinality_error_1: 1.50000/8.62500] items per batch[1] items per second[0.87] total items[40] mini batches[    40] memory[1144] epoch remaining[0:06:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[50/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.84837/47.67582, loss_obj_ce: 0.81351/1.31303, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.18419/4.44678, loss_sub_bbox: 0.69046/0.69397, loss_obj_bbox: 0.56350/0.74882, loss_sub_giou: 0.73785/0.87196, loss_obj_giou: 1.17104/1.15523, obj_cardinality_error: 2.00000/8.11000, loss_obj_ce_0: 0.87918/1.29075, loss_verb_ce_0: 1.19408/4.59617, loss_sub_bbox_0: 0.68715/0.68601, loss_obj_bbox_0: 0.56022/0.73893, loss_sub_giou_0: 0.74542/0.87501, loss_obj_giou_0: 1.19816/1.15124, obj_cardinality_error_0: 2.00000/7.44000, loss_obj_ce_1: 0.82201/1.28232, loss_verb_ce_1: 1.21861/4.43056, loss_sub_bbox_1: 0.68645/0.69105, loss_obj_bbox_1: 0.56013/0.74358, loss_sub_giou_1: 0.74079/0.87419, loss_obj_giou_1: 1.17688/1.15913, obj_cardinality_error_1: 2.00000/7.28000] items per batch[1] items per second[0.82] total items[50] mini batches[    50] memory[1144] epoch remaining[0:06:21]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[60/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 29.25603/44.18180, loss_obj_ce: 1.40854/1.26956, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.25401/3.90563, loss_sub_bbox: 0.67565/0.69382, loss_obj_bbox: 0.81885/0.73768, loss_sub_giou: 0.83132/0.85687, loss_obj_giou: 1.29802/1.17726, obj_cardinality_error: 2.50000/7.15833, loss_obj_ce_0: 1.38511/1.25186, loss_verb_ce_0: 1.27600/4.02702, loss_sub_bbox_0: 0.68057/0.68623, loss_obj_bbox_0: 0.80308/0.72592, loss_sub_giou_0: 0.83497/0.86038, loss_obj_giou_0: 1.27611/1.17408, obj_cardinality_error_0: 2.50000/6.60000, loss_obj_ce_1: 1.39989/1.24417, loss_verb_ce_1: 1.24193/3.88751, loss_sub_bbox_1: 0.67116/0.69162, loss_obj_bbox_1: 0.82131/0.73138, loss_sub_giou_1: 0.81450/0.85854, loss_obj_giou_1: 1.28715/1.18211, obj_cardinality_error_1: 2.50000/6.46667] items per batch[1] items per second[0.81] total items[60] mini batches[    60] memory[1144] epoch remaining[0:06:10]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[70/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 25.22483/41.49804, loss_obj_ce: 1.57912/1.26330, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.11177/3.51539, loss_sub_bbox: 0.40789/0.66851, loss_obj_bbox: 0.66278/0.72728, loss_sub_giou: 0.73371/0.83734, loss_obj_giou: 1.15984/1.18456, obj_cardinality_error: 4.00000/6.55714, loss_obj_ce_0: 1.60148/1.24721, loss_verb_ce_0: 1.12024/3.61689, loss_sub_bbox_0: 0.40615/0.66284, loss_obj_bbox_0: 0.64536/0.71613, loss_sub_giou_0: 0.73060/0.83929, loss_obj_giou_0: 1.15862/1.18303, obj_cardinality_error_0: 4.00000/6.07857, loss_obj_ce_1: 1.60871/1.24277, loss_verb_ce_1: 1.15586/3.49967, loss_sub_bbox_1: 0.41587/0.66701, loss_obj_bbox_1: 0.65966/0.72153, loss_sub_giou_1: 0.72658/0.83808, loss_obj_giou_1: 1.15616/1.19034, obj_cardinality_error_1: 4.00000/5.96429] items per batch[1] items per second[0.83] total items[70] mini batches[    70] memory[1144] epoch remaining[0:06:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[80/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 26.32196/39.63641, loss_obj_ce: 1.38739/1.24676, obj_class_error: 100.00000/100.00000, loss_verb_ce: 0.95243/3.21767, loss_sub_bbox: 0.55462/0.66139, loss_obj_bbox: 0.63445/0.72628, loss_sub_giou: 1.03004/0.84033, loss_obj_giou: 1.44972/1.19702, obj_cardinality_error: 5.00000/6.10000, loss_obj_ce_0: 1.43088/1.23522, loss_verb_ce_0: 0.96947/3.30585, loss_sub_bbox_0: 0.55740/0.65670, loss_obj_bbox_0: 0.61716/0.71515, loss_sub_giou_0: 1.03438/0.84245, loss_obj_giou_0: 1.45760/1.19764, obj_cardinality_error_0: 5.00000/5.68125, loss_obj_ce_1: 1.42168/1.23019, loss_verb_ce_1: 0.94890/3.20310, loss_sub_bbox_1: 0.55955/0.65998, loss_obj_bbox_1: 0.61826/0.71992, loss_sub_giou_1: 1.04174/0.84115, loss_obj_giou_1: 1.47332/1.20387, obj_cardinality_error_1: 5.00000/5.58125] items per batch[1] items per second[0.80] total items[80] mini batches[    80] memory[1144] epoch remaining[0:05:56]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[90/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.84804/37.95150, loss_obj_ce: 0.56932/1.21586, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.41479/2.98954, loss_sub_bbox: 0.76375/0.65008, loss_obj_bbox: 0.27150/0.70651, loss_sub_giou: 0.86017/0.83531, loss_obj_giou: 0.84435/1.20852, obj_cardinality_error: 1.50000/5.71667, loss_obj_ce_0: 0.57631/1.20559, loss_verb_ce_0: 1.32944/3.06844, loss_sub_bbox_0: 0.73640/0.64564, loss_obj_bbox_0: 0.28051/0.69584, loss_sub_giou_0: 0.85544/0.83756, loss_obj_giou_0: 0.89780/1.20956, obj_cardinality_error_0: 1.50000/5.34444, loss_obj_ce_1: 0.55707/1.20106, loss_verb_ce_1: 1.41742/2.97606, loss_sub_bbox_1: 0.74208/0.64894, loss_obj_bbox_1: 0.27167/0.70050, loss_sub_giou_1: 0.85367/0.83624, loss_obj_giou_1: 0.84584/1.21495, obj_cardinality_error_1: 1.50000/5.25556] items per batch[1] items per second[0.90] total items[90] mini batches[    90] memory[1144] epoch remaining[0:05:47]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[100/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.28358/36.65034, loss_obj_ce: 1.36837/1.21652, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.17007/2.80330, loss_sub_bbox: 0.19541/0.64062, loss_obj_bbox: 0.62197/0.69609, loss_sub_giou: 0.29966/0.82228, loss_obj_giou: 1.38465/1.21270, obj_cardinality_error: 3.00000/5.45500, loss_obj_ce_0: 1.38496/1.20712, loss_verb_ce_0: 1.16922/2.87312, loss_sub_bbox_0: 0.17755/0.63651, loss_obj_bbox_0: 0.60266/0.68574, loss_sub_giou_0: 0.31599/0.82536, loss_obj_giou_0: 1.37972/1.21418, obj_cardinality_error_0: 3.00000/5.12000, loss_obj_ce_1: 1.37692/1.20425, loss_verb_ce_1: 1.17207/2.79081, loss_sub_bbox_1: 0.21049/0.63984, loss_obj_bbox_1: 0.61409/0.68996, loss_sub_giou_1: 0.31574/0.82286, loss_obj_giou_1: 1.37944/1.21869, obj_cardinality_error_1: 3.00000/5.04000] items per batch[1] items per second[0.78] total items[100] mini batches[   100] memory[1162] epoch remaining[0:05:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[110/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 27.14257/35.64759, loss_obj_ce: 0.62159/1.20584, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.59390/2.65632, loss_sub_bbox: 0.59776/0.63112, loss_obj_bbox: 0.70587/0.69517, loss_sub_giou: 0.54888/0.81685, loss_obj_giou: 1.47891/1.22163, obj_cardinality_error: 1.00000/5.20000, loss_obj_ce_0: 0.61435/1.19609, loss_verb_ce_0: 1.62152/2.71957, loss_sub_bbox_0: 0.59109/0.62592, loss_obj_bbox_0: 0.68082/0.68467, loss_sub_giou_0: 0.56804/0.81729, loss_obj_giou_0: 1.43612/1.22354, obj_cardinality_error_0: 1.00000/4.89545, loss_obj_ce_1: 0.59270/1.19412, loss_verb_ce_1: 1.61143/2.64402, loss_sub_bbox_1: 0.59551/0.63032, loss_obj_bbox_1: 0.68350/0.68867, loss_sub_giou_1: 0.56441/0.81634, loss_obj_giou_1: 1.42751/1.22638, obj_cardinality_error_1: 1.00000/4.82273] items per batch[1] items per second[0.79] total items[110] mini batches[   110] memory[1203] epoch remaining[0:05:42]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[120/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.26718/34.69287, loss_obj_ce: 1.38090/1.18862, obj_class_error: 100.00000/100.00000, loss_verb_ce: 0.87248/2.52639, loss_sub_bbox: 0.44952/0.62018, loss_obj_bbox: 0.58281/0.68890, loss_sub_giou: 0.92191/0.81613, loss_obj_giou: 1.51249/1.22644, obj_cardinality_error: 5.50000/5.02083, loss_obj_ce_0: 1.42394/1.18127, loss_verb_ce_0: 0.91087/2.58477, loss_sub_bbox_0: 0.42369/0.61474, loss_obj_bbox_0: 0.56185/0.67902, loss_sub_giou_0: 0.92288/0.81585, loss_obj_giou_0: 1.49580/1.22689, obj_cardinality_error_0: 5.50000/4.74167, loss_obj_ce_1: 1.36720/1.17905, loss_verb_ce_1: 0.88838/2.51494, loss_sub_bbox_1: 0.39658/0.61892, loss_obj_bbox_1: 0.56635/0.68271, loss_sub_giou_1: 0.92166/0.81514, loss_obj_giou_1: 1.52493/1.23009, obj_cardinality_error_1: 5.50000/4.67500] items per batch[1] items per second[0.76] total items[120] mini batches[   120] memory[1203] epoch remaining[0:05:40]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[130/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.64496/33.92478, loss_obj_ce: 0.82166/1.17274, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.10269/2.42168, loss_sub_bbox: 0.30816/0.61324, loss_obj_bbox: 0.40071/0.68541, loss_sub_giou: 0.79786/0.81760, loss_obj_giou: 1.19993/1.22086, obj_cardinality_error: 2.00000/4.81154, loss_obj_ce_0: 0.86667/1.16610, loss_verb_ce_0: 1.12887/2.47700, loss_sub_bbox_0: 0.30896/0.60655, loss_obj_bbox_0: 0.44580/0.67696, loss_sub_giou_0: 0.77753/0.81725, loss_obj_giou_0: 1.18881/1.22233, obj_cardinality_error_0: 2.00000/4.55385, loss_obj_ce_1: 0.85182/1.16417, loss_verb_ce_1: 1.11083/2.41091, loss_sub_bbox_1: 0.30336/0.61135, loss_obj_bbox_1: 0.42336/0.67967, loss_sub_giou_1: 0.77735/0.81686, loss_obj_giou_1: 1.20267/1.22473, obj_cardinality_error_1: 2.00000/4.49231] items per batch[1] items per second[0.75] total items[130] mini batches[   130] memory[1258] epoch remaining[0:05:39]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[140/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.46830/33.18683, loss_obj_ce: 1.19075/1.16386, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.07793/2.32640, loss_sub_bbox: 0.33862/0.59956, loss_obj_bbox: 0.62534/0.67756, loss_sub_giou: 0.79432/0.81775, loss_obj_giou: 1.50703/1.22541, obj_cardinality_error: 3.00000/4.69643, loss_obj_ce_0: 1.23289/1.15805, loss_verb_ce_0: 1.12823/2.37872, loss_sub_bbox_0: 0.37290/0.59444, loss_obj_bbox_0: 0.60280/0.67026, loss_sub_giou_0: 0.84724/0.81719, loss_obj_giou_0: 1.54164/1.22600, obj_cardinality_error_0: 3.00000/4.45714, loss_obj_ce_1: 1.19688/1.15620, loss_verb_ce_1: 1.07635/2.31647, loss_sub_bbox_1: 0.33971/0.59795, loss_obj_bbox_1: 0.60757/0.67284, loss_sub_giou_1: 0.82807/0.81775, loss_obj_giou_1: 1.54710/1.22994, obj_cardinality_error_1: 3.00000/4.40000] items per batch[1] items per second[0.82] total items[140] mini batches[   140] memory[1258] epoch remaining[0:05:36]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[150/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 25.24934/32.65261, loss_obj_ce: 0.50771/1.14440, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.59597/2.24770, loss_sub_bbox: 0.56857/0.59366, loss_obj_bbox: 0.84559/0.67815, loss_sub_giou: 0.53388/0.81607, loss_obj_giou: 0.72079/1.23953, obj_cardinality_error: 1.00000/4.54333, loss_obj_ce_0: 0.51086/1.13893, loss_verb_ce_0: 1.55795/2.29696, loss_sub_bbox_0: 0.57665/0.58813, loss_obj_bbox_0: 0.89087/0.67129, loss_sub_giou_0: 0.57477/0.81577, loss_obj_giou_0: 0.73821/1.24138, obj_cardinality_error_0: 1.00000/4.31667, loss_obj_ce_1: 0.47012/1.13670, loss_verb_ce_1: 1.47436/2.23868, loss_sub_bbox_1: 0.60687/0.59218, loss_obj_bbox_1: 0.79917/0.67314, loss_sub_giou_1: 0.52213/0.81671, loss_obj_giou_1: 0.69502/1.24505, obj_cardinality_error_1: 1.00000/4.26333] items per batch[1] items per second[0.91] total items[150] mini batches[   150] memory[1258] epoch remaining[0:05:31]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[160/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.69944/32.10981, loss_obj_ce: 0.65001/1.13334, obj_class_error: 100.00000/100.00000, loss_verb_ce: 1.21758/2.17623, loss_sub_bbox: 0.47881/0.58731, loss_obj_bbox: 0.56438/0.67021, loss_sub_giou: 0.91993/0.82276, loss_obj_giou: 1.34364/1.24367, obj_cardinality_error: 2.00000/4.42188, loss_obj_ce_0: 0.69956/1.12966, loss_verb_ce_0: 1.18208/2.22194, loss_sub_bbox_0: 0.46433/0.58271, loss_obj_bbox_0: 0.53297/0.66214, loss_sub_giou_0: 0.82490/0.82172, loss_obj_giou_0: 1.45053/1.24504, obj_cardinality_error_0: 2.00000/4.20312, loss_obj_ce_1: 0.65608/1.12581, loss_verb_ce_1: 1.21485/2.16783, loss_sub_bbox_1: 0.48591/0.58641, loss_obj_bbox_1: 0.54487/0.66473, loss_sub_giou_1: 0.88323/0.82299, loss_obj_giou_1: 1.36435/1.24907, obj_cardinality_error_1: 2.00000/4.15313] items per batch[1] items per second[0.85] total items[160] mini batches[   160] memory[1258] epoch remaining[0:05:28]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[170/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.97195/31.69466, loss_obj_ce: 0.70152/1.12826, obj_class_error: 100.00000/99.55882, loss_verb_ce: 1.13489/2.11097, loss_sub_bbox: 0.60602/0.58429, loss_obj_bbox: 0.52938/0.66783, loss_sub_giou: 1.24034/0.83516, loss_obj_giou: 0.98402/1.24366, obj_cardinality_error: 2.00000/4.33824, loss_obj_ce_0: 0.78825/1.12643, loss_verb_ce_0: 1.11056/2.15462, loss_sub_bbox_0: 0.59096/0.57946, loss_obj_bbox_0: 0.49308/0.65932, loss_sub_giou_0: 1.17772/0.83206, loss_obj_giou_0: 1.00660/1.24440, obj_cardinality_error_0: 2.00000/4.14706, loss_obj_ce_1: 0.71653/1.12173, loss_verb_ce_1: 1.15956/2.10299, loss_sub_bbox_1: 0.59872/0.58341, loss_obj_bbox_1: 0.52486/0.66254, loss_sub_giou_1: 1.22120/0.83487, loss_obj_giou_1: 0.96824/1.24881, obj_cardinality_error_1: 2.00000/4.08824] items per batch[1] items per second[0.88] total items[170] mini batches[   170] memory[1258] epoch remaining[0:05:24]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[180/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.42056/31.22522, loss_obj_ce: 0.48571/1.11697, obj_class_error: 100.00000/99.42460, loss_verb_ce: 1.29696/2.05516, loss_sub_bbox: 0.17663/0.57883, loss_obj_bbox: 0.33725/0.66406, loss_sub_giou: 0.29087/0.83275, loss_obj_giou: 1.26598/1.23710, obj_cardinality_error: 1.00000/4.22500, loss_obj_ce_0: 0.45520/1.11490, loss_verb_ce_0: 1.42981/2.09745, loss_sub_bbox_0: 0.20542/0.57412, loss_obj_bbox_0: 0.38564/0.65447, loss_sub_giou_0: 0.36664/0.82880, loss_obj_giou_0: 1.19276/1.23778, obj_cardinality_error_0: 1.00000/4.06667, loss_obj_ce_1: 0.49967/1.11085, loss_verb_ce_1: 1.35973/2.04892, loss_sub_bbox_1: 0.19548/0.57796, loss_obj_bbox_1: 0.32630/0.65805, loss_sub_giou_1: 0.37369/0.83218, loss_obj_giou_1: 1.25023/1.24207, obj_cardinality_error_1: 1.00000/4.00000] items per batch[1] items per second[0.86] total items[180] mini batches[   180] memory[1258] epoch remaining[0:05:21]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[190/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 25.65070/30.82944, loss_obj_ce: 1.55082/1.11414, obj_class_error: 100.00000/99.28383, loss_verb_ce: 0.92487/2.00670, loss_sub_bbox: 0.55495/0.57193, loss_obj_bbox: 0.56156/0.65925, loss_sub_giou: 1.00257/0.83383, loss_obj_giou: 1.34501/1.23166, obj_cardinality_error: 3.50000/4.13158, loss_obj_ce_0: 1.58820/1.11369, loss_verb_ce_0: 0.95806/2.04796, loss_sub_bbox_0: 0.52083/0.56777, loss_obj_bbox_0: 0.59686/0.65052, loss_sub_giou_0: 0.96703/0.82943, loss_obj_giou_0: 1.31358/1.23132, obj_cardinality_error_0: 2.50000/3.97632, loss_obj_ce_1: 1.58243/1.10907, loss_verb_ce_1: 0.93458/2.00176, loss_sub_bbox_1: 0.54379/0.57088, loss_obj_bbox_1: 0.57938/0.65352, loss_sub_giou_1: 0.95744/0.83259, loss_obj_giou_1: 1.31518/1.23621, obj_cardinality_error_1: 3.50000/3.92632] items per batch[1] items per second[0.79] total items[190] mini batches[   190] memory[1258] epoch remaining[0:05:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[200/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.04787/30.36570, loss_obj_ce: 0.76068/1.10518, obj_class_error: 100.00000/99.26964, loss_verb_ce: 1.26120/1.95894, loss_sub_bbox: 0.33767/0.56368, loss_obj_bbox: 0.36252/0.64985, loss_sub_giou: 0.90767/0.83303, loss_obj_giou: 1.16541/1.22361, obj_cardinality_error: 2.00000/4.05250, loss_obj_ce_0: 0.77369/1.10834, loss_verb_ce_0: 1.26613/1.99844, loss_sub_bbox_0: 0.32188/0.56029, loss_obj_bbox_0: 0.32678/0.64215, loss_sub_giou_0: 0.87057/0.82916, loss_obj_giou_0: 1.10195/1.22278, obj_cardinality_error_0: 2.00000/3.91750, loss_obj_ce_1: 0.78873/1.10235, loss_verb_ce_1: 1.26447/1.95481, loss_sub_bbox_1: 0.32902/0.56246, loss_obj_bbox_1: 0.34903/0.64450, loss_sub_giou_1: 0.88920/0.83134, loss_obj_giou_1: 1.13912/1.22820, obj_cardinality_error_1: 2.00000/3.85750] items per batch[1] items per second[0.75] total items[200] mini batches[   200] memory[1258] epoch remaining[0:05:19]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[210/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.91233/30.04863, loss_obj_ce: 0.60276/1.09347, obj_class_error: 75.00000/98.84146, loss_verb_ce: 1.08634/1.91492, loss_sub_bbox: 0.46557/0.56251, loss_obj_bbox: 0.54200/0.64557, loss_sub_giou: 0.74110/0.83551, loss_obj_giou: 1.58670/1.22840, obj_cardinality_error: 1.00000/3.96667, loss_obj_ce_0: 0.67880/1.09995, loss_verb_ce_0: 1.05575/1.95327, loss_sub_bbox_0: 0.43405/0.55859, loss_obj_bbox_0: 0.57304/0.63781, loss_sub_giou_0: 0.74168/0.83085, loss_obj_giou_0: 1.61881/1.22824, obj_cardinality_error_0: 2.00000/3.84524, loss_obj_ce_1: 0.63599/1.09233, loss_verb_ce_1: 1.05645/1.91149, loss_sub_bbox_1: 0.44196/0.56087, loss_obj_bbox_1: 0.55715/0.64037, loss_sub_giou_1: 0.76369/0.83302, loss_obj_giou_1: 1.61129/1.23319, obj_cardinality_error_1: 2.00000/3.78333] items per batch[1] items per second[0.88] total items[210] mini batches[   210] memory[1258] epoch remaining[0:05:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[220/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.11276/29.67369, loss_obj_ce: 0.69476/1.08447, obj_class_error: 83.33334/98.54058, loss_verb_ce: 1.14589/1.87732, loss_sub_bbox: 0.29591/0.55373, loss_obj_bbox: 0.37559/0.64039, loss_sub_giou: 0.83128/0.83150, loss_obj_giou: 1.43639/1.22448, obj_cardinality_error: 2.50000/3.87955, loss_obj_ce_0: 0.84033/1.09477, loss_verb_ce_0: 1.08093/1.91411, loss_sub_bbox_0: 0.28169/0.55082, loss_obj_bbox_0: 0.45478/0.63261, loss_sub_giou_0: 0.80923/0.82800, loss_obj_giou_0: 1.41965/1.22318, obj_cardinality_error_0: 3.00000/3.79318, loss_obj_ce_1: 0.79783/1.08490, loss_verb_ce_1: 1.13934/1.87434, loss_sub_bbox_1: 0.29447/0.55236, loss_obj_bbox_1: 0.40561/0.63536, loss_sub_giou_1: 0.85906/0.82973, loss_obj_giou_1: 1.42181/1.22794, obj_cardinality_error_1: 3.00000/3.72955] items per batch[1] items per second[0.79] total items[220] mini batches[   220] memory[1297] epoch remaining[0:05:15]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[230/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.31214/29.38969, loss_obj_ce: 1.02345/1.07886, obj_class_error: 85.71429/98.34006, loss_verb_ce: 0.97089/1.84193, loss_sub_bbox: 0.53480/0.55348, loss_obj_bbox: 0.54248/0.63481, loss_sub_giou: 0.89778/0.82961, loss_obj_giou: 1.54447/1.22476, obj_cardinality_error: 2.50000/3.82174, loss_obj_ce_0: 1.18722/1.09377, loss_verb_ce_0: 1.02228/1.87710, loss_sub_bbox_0: 0.50771/0.54954, loss_obj_bbox_0: 0.47179/0.62609, loss_sub_giou_0: 0.92656/0.82616, loss_obj_giou_0: 1.46428/1.22270, obj_cardinality_error_0: 3.50000/3.76304, loss_obj_ce_1: 1.16642/1.08243, loss_verb_ce_1: 0.97342/1.83869, loss_sub_bbox_1: 0.50697/0.55132, loss_obj_bbox_1: 0.51398/0.62887, loss_sub_giou_1: 0.93451/0.82808, loss_obj_giou_1: 1.53996/1.22763, obj_cardinality_error_1: 3.00000/3.69783] items per batch[1] items per second[0.81] total items[230] mini batches[   230] memory[1297] epoch remaining[0:05:13]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[240/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 25.04235/29.08765, loss_obj_ce: 0.70120/1.05966, obj_class_error: 100.00000/97.57093, loss_verb_ce: 1.01697/1.80939, loss_sub_bbox: 0.72553/0.54995, loss_obj_bbox: 0.60560/0.63101, loss_sub_giou: 0.87700/0.82898, loss_obj_giou: 1.60362/1.22699, obj_cardinality_error: 2.50000/3.73125, loss_obj_ce_0: 0.84212/1.07975, loss_verb_ce_0: 1.03986/1.84310, loss_sub_bbox_0: 0.49922/0.54461, loss_obj_bbox_0: 0.62331/0.62201, loss_sub_giou_0: 0.72183/0.82271, loss_obj_giou_0: 1.55551/1.22687, obj_cardinality_error_0: 2.50000/3.68333, loss_obj_ce_1: 0.75188/1.06598, loss_verb_ce_1: 0.99414/1.80561, loss_sub_bbox_1: 0.70170/0.54707, loss_obj_bbox_1: 0.60453/0.62615, loss_sub_giou_1: 0.86008/0.82673, loss_obj_giou_1: 1.62745/1.23178, obj_cardinality_error_1: 2.50000/3.61875] items per batch[1] items per second[0.82] total items[240] mini batches[   240] memory[1297] epoch remaining[0:05:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[250/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.97798/28.84132, loss_obj_ce: 0.47537/1.04474, obj_class_error: 66.66667/96.54143, loss_verb_ce: 0.94504/1.77725, loss_sub_bbox: 0.32915/0.55051, loss_obj_bbox: 0.27632/0.62751, loss_sub_giou: 0.58489/0.83515, loss_obj_giou: 0.89899/1.22449, obj_cardinality_error: 3.00000/3.63600, loss_obj_ce_0: 0.49244/1.06597, loss_verb_ce_0: 0.96006/1.81022, loss_sub_bbox_0: 0.31714/0.54496, loss_obj_bbox_0: 0.29454/0.61910, loss_sub_giou_0: 0.59274/0.82747, loss_obj_giou_0: 0.83833/1.22599, obj_cardinality_error_0: 0.50000/3.62000, loss_obj_ce_1: 0.45009/1.05077, loss_verb_ce_1: 0.98551/1.77410, loss_sub_bbox_1: 0.31522/0.54724, loss_obj_bbox_1: 0.27736/0.62272, loss_sub_giou_1: 0.50902/0.83284, loss_obj_giou_1: 0.83058/1.23067, obj_cardinality_error_1: 2.50000/3.52800] items per batch[1] items per second[0.95] total items[250] mini batches[   250] memory[1297] epoch remaining[0:05:08]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[260/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 29.13571/28.61097, loss_obj_ce: 1.43220/1.04087, obj_class_error: 75.00000/95.69368, loss_verb_ce: 1.01038/1.74943, loss_sub_bbox: 0.71264/0.54875, loss_obj_bbox: 0.71670/0.62252, loss_sub_giou: 1.24865/0.83575, loss_obj_giou: 1.44574/1.22061, obj_cardinality_error: 1.50000/3.63077, loss_obj_ce_0: 1.39227/1.06144, loss_verb_ce_0: 1.05027/1.78279, loss_sub_bbox_0: 0.72726/0.54297, loss_obj_bbox_0: 0.71613/0.61570, loss_sub_giou_0: 1.22527/0.82821, loss_obj_giou_0: 1.42696/1.22231, obj_cardinality_error_0: 4.00000/3.59038, loss_obj_ce_1: 1.32434/1.04545, loss_verb_ce_1: 1.05185/1.74690, loss_sub_bbox_1: 0.71723/0.54548, loss_obj_bbox_1: 0.69717/0.61930, loss_sub_giou_1: 1.30073/0.83417, loss_obj_giou_1: 1.39670/1.22712, obj_cardinality_error_1: 2.00000/3.56346] items per batch[1] items per second[0.76] total items[260] mini batches[   260] memory[1297] epoch remaining[0:05:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[270/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.21768/28.35695, loss_obj_ce: 1.49080/1.03627, obj_class_error: 80.00000/94.63007, loss_verb_ce: 0.89890/1.72278, loss_sub_bbox: 0.29465/0.54551, loss_obj_bbox: 0.23722/0.61778, loss_sub_giou: 0.58889/0.83109, loss_obj_giou: 0.69060/1.21614, obj_cardinality_error: 4.00000/3.58333, loss_obj_ce_0: 1.43980/1.05784, loss_verb_ce_0: 0.97286/1.75634, loss_sub_bbox_0: 0.29526/0.54004, loss_obj_bbox_0: 0.28586/0.61184, loss_sub_giou_0: 0.55626/0.82376, loss_obj_giou_0: 0.78977/1.21808, obj_cardinality_error_0: 2.00000/3.52593, loss_obj_ce_1: 1.52429/1.04064, loss_verb_ce_1: 0.93419/1.72072, loss_sub_bbox_1: 0.28676/0.54222, loss_obj_bbox_1: 0.28236/0.61486, loss_sub_giou_1: 0.58374/0.82973, loss_obj_giou_1: 0.73634/1.22308, obj_cardinality_error_1: 2.50000/3.50370] items per batch[1] items per second[0.81] total items[270] mini batches[   270] memory[1297] epoch remaining[0:05:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[280/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.11782/28.10944, loss_obj_ce: 1.04516/1.02872, obj_class_error: 100.00000/94.07696, loss_verb_ce: 0.91997/1.69571, loss_sub_bbox: 0.40793/0.54385, loss_obj_bbox: 0.41079/0.61230, loss_sub_giou: 0.47360/0.82837, loss_obj_giou: 0.83568/1.21090, obj_cardinality_error: 1.50000/3.54286, loss_obj_ce_0: 1.09673/1.05189, loss_verb_ce_0: 1.03030/1.72924, loss_sub_bbox_0: 0.44011/0.53882, loss_obj_bbox_0: 0.36533/0.60763, loss_sub_giou_0: 0.54201/0.82199, loss_obj_giou_0: 0.78454/1.21531, obj_cardinality_error_0: 2.00000/3.47143, loss_obj_ce_1: 1.03434/1.03349, loss_verb_ce_1: 0.96776/1.69356, loss_sub_bbox_1: 0.42575/0.54069, loss_obj_bbox_1: 0.40244/0.61066, loss_sub_giou_1: 0.47573/0.82684, loss_obj_giou_1: 0.86306/1.22003, obj_cardinality_error_1: 1.50000/3.44286] items per batch[1] items per second[0.82] total items[280] mini batches[   280] memory[1297] epoch remaining[0:05:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[290/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.15581/27.93787, loss_obj_ce: 1.77635/1.02975, obj_class_error: 76.47059/93.41558, loss_verb_ce: 0.73877/1.66946, loss_sub_bbox: 0.41126/0.54219, loss_obj_bbox: 0.49625/0.60970, loss_sub_giou: 1.00466/0.82936, loss_obj_giou: 1.48434/1.21455, obj_cardinality_error: 2.00000/3.51379, loss_obj_ce_0: 1.81973/1.05351, loss_verb_ce_0: 0.79247/1.70398, loss_sub_bbox_0: 0.45781/0.53680, loss_obj_bbox_0: 0.47698/0.60513, loss_sub_giou_0: 1.03201/0.82366, loss_obj_giou_0: 1.39724/1.21700, obj_cardinality_error_0: 3.50000/3.43448, loss_obj_ce_1: 1.75361/1.03379, loss_verb_ce_1: 0.74435/1.66747, loss_sub_bbox_1: 0.43022/0.53924, loss_obj_bbox_1: 0.47165/0.60782, loss_sub_giou_1: 1.04443/0.82924, loss_obj_giou_1: 1.43182/1.22298, obj_cardinality_error_1: 2.00000/3.40172] items per batch[1] items per second[0.76] total items[290] mini batches[   290] memory[1297] epoch remaining[0:05:03]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[300/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 24.67908/27.72184, loss_obj_ce: 1.15811/1.02099, obj_class_error: 100.00000/92.62210, loss_verb_ce: 1.21387/1.64411, loss_sub_bbox: 0.39652/0.53890, loss_obj_bbox: 0.50154/0.60474, loss_sub_giou: 0.83153/0.83026, loss_obj_giou: 1.43989/1.21719, obj_cardinality_error: 4.50000/3.57667, loss_obj_ce_0: 1.08597/1.04570, loss_verb_ce_0: 1.15246/1.67958, loss_sub_bbox_0: 0.41585/0.53314, loss_obj_bbox_0: 0.65752/0.60322, loss_sub_giou_0: 0.92626/0.82440, loss_obj_giou_0: 1.21838/1.21812, obj_cardinality_error_0: 5.00000/3.45667, loss_obj_ce_1: 1.03211/1.02466, loss_verb_ce_1: 1.23867/1.64231, loss_sub_bbox_1: 0.43133/0.53609, loss_obj_bbox_1: 0.60054/0.60486, loss_sub_giou_1: 0.93864/0.83122, loss_obj_giou_1: 1.32991/1.22490, obj_cardinality_error_1: 6.00000/3.49833] items per batch[1] items per second[0.75] total items[300] mini batches[   300] memory[1297] epoch remaining[0:05:03]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[310/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.32589/27.46817, loss_obj_ce: 0.63280/1.01257, obj_class_error: 50.00000/91.68446, loss_verb_ce: 0.95252/1.61861, loss_sub_bbox: 0.64043/0.53653, loss_obj_bbox: 0.27487/0.60005, loss_sub_giou: 0.68706/0.82597, loss_obj_giou: 1.03145/1.21124, obj_cardinality_error: 0.50000/3.50645, loss_obj_ce_0: 0.77986/1.03792, loss_verb_ce_0: 1.01906/1.65585, loss_sub_bbox_0: 0.56788/0.53031, loss_obj_bbox_0: 0.21822/0.59939, loss_sub_giou_0: 0.57734/0.82037, loss_obj_giou_0: 0.92267/1.21111, obj_cardinality_error_0: 2.00000/3.42742, loss_obj_ce_1: 0.74827/1.01663, loss_verb_ce_1: 1.07456/1.61828, loss_sub_bbox_1: 0.52631/0.53329, loss_obj_bbox_1: 0.29239/0.60060, loss_sub_giou_1: 0.58394/0.82648, loss_obj_giou_1: 0.96997/1.21997, obj_cardinality_error_1: 1.00000/3.45484] items per batch[1] items per second[0.85] total items[310] mini batches[   310] memory[1297] epoch remaining[0:05:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[320/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.58907/27.23125, loss_obj_ce: 1.18578/1.00698, obj_class_error: 70.00000/91.32973, loss_verb_ce: 0.68583/1.59372, loss_sub_bbox: 0.25663/0.53231, loss_obj_bbox: 0.33047/0.59689, loss_sub_giou: 0.68159/0.81724, loss_obj_giou: 1.17319/1.21292, obj_cardinality_error: 3.00000/3.44844, loss_obj_ce_0: 1.32456/1.03546, loss_verb_ce_0: 0.74551/1.63373, loss_sub_bbox_0: 0.24557/0.52558, loss_obj_bbox_0: 0.36813/0.59553, loss_sub_giou_0: 0.74313/0.81168, loss_obj_giou_0: 1.22181/1.20937, obj_cardinality_error_0: 9.50000/3.41562, loss_obj_ce_1: 1.38856/1.01391, loss_verb_ce_1: 0.85276/1.59640, loss_sub_bbox_1: 0.24200/0.52862, loss_obj_bbox_1: 0.30126/0.59668, loss_sub_giou_1: 0.71103/0.81708, loss_obj_giou_1: 1.23107/1.21990, obj_cardinality_error_1: 11.50000/3.45312] items per batch[1] items per second[0.76] total items[320] mini batches[   320] memory[1297] epoch remaining[0:05:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[330/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.54250/27.04591, loss_obj_ce: 1.00774/0.99795, obj_class_error: 100.00000/91.16823, loss_verb_ce: 1.14578/1.57651, loss_sub_bbox: 0.21528/0.52899, loss_obj_bbox: 0.56554/0.59233, loss_sub_giou: 0.40729/0.81351, loss_obj_giou: 1.26899/1.21130, obj_cardinality_error: 0.00000/3.38939, loss_obj_ce_0: 1.15216/1.02943, loss_verb_ce_0: 1.16797/1.61738, loss_sub_bbox_0: 0.21942/0.52246, loss_obj_bbox_0: 0.53849/0.59171, loss_sub_giou_0: 0.34550/0.80832, loss_obj_giou_0: 1.49440/1.20904, obj_cardinality_error_0: 2.00000/3.38636, loss_obj_ce_1: 1.17174/1.00902, loss_verb_ce_1: 1.15898/1.58228, loss_sub_bbox_1: 0.18083/0.52510, loss_obj_bbox_1: 0.69469/0.59265, loss_sub_giou_1: 0.29078/0.81289, loss_obj_giou_1: 1.42277/1.21899, obj_cardinality_error_1: 2.00000/3.44394] items per batch[1] items per second[0.81] total items[330] mini batches[   330] memory[1297] epoch remaining[0:04:58]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[340/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.72963/26.86171, loss_obj_ce: 0.79344/0.99128, obj_class_error: 100.00000/90.84675, loss_verb_ce: 1.50435/1.56065, loss_sub_bbox: 0.47367/0.52624, loss_obj_bbox: 0.43875/0.58761, loss_sub_giou: 0.53901/0.80913, loss_obj_giou: 1.61279/1.21026, obj_cardinality_error: 2.50000/3.33824, loss_obj_ce_0: 0.76701/1.02361, loss_verb_ce_0: 1.46903/1.60175, loss_sub_bbox_0: 0.30593/0.51980, loss_obj_bbox_0: 0.38051/0.58675, loss_sub_giou_0: 0.57367/0.80398, loss_obj_giou_0: 1.66738/1.20823, obj_cardinality_error_0: 1.50000/3.34559, loss_obj_ce_1: 0.76434/1.00416, loss_verb_ce_1: 1.48943/1.56753, loss_sub_bbox_1: 0.46268/0.52286, loss_obj_bbox_1: 0.33551/0.58705, loss_sub_giou_1: 0.55425/0.80848, loss_obj_giou_1: 1.53950/1.21696, obj_cardinality_error_1: 1.50000/3.43088] items per batch[1] items per second[0.80] total items[340] mini batches[   340] memory[1297] epoch remaining[0:04:57]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[350/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.69997/26.70766, loss_obj_ce: 0.42832/0.98403, obj_class_error: 50.00000/90.27654, loss_verb_ce: 0.78872/1.54016, loss_sub_bbox: 0.35145/0.52595, loss_obj_bbox: 0.39701/0.58726, loss_sub_giou: 0.37213/0.80759, loss_obj_giou: 1.13841/1.20728, obj_cardinality_error: 1.50000/3.30000, loss_obj_ce_0: 0.52097/1.01909, loss_verb_ce_0: 0.90742/1.58297, loss_sub_bbox_0: 0.32348/0.51877, loss_obj_bbox_0: 0.46737/0.58586, loss_sub_giou_0: 0.36968/0.80205, loss_obj_giou_0: 1.06827/1.20655, obj_cardinality_error_0: 1.50000/3.30429, loss_obj_ce_1: 0.47285/0.99881, loss_verb_ce_1: 0.86571/1.54965, loss_sub_bbox_1: 0.34323/0.52207, loss_obj_bbox_1: 0.43563/0.58676, loss_sub_giou_1: 0.35705/0.80583, loss_obj_giou_1: 1.05322/1.21422, obj_cardinality_error_1: 1.50000/3.40000] items per batch[1] items per second[0.84] total items[350] mini batches[   350] memory[1297] epoch remaining[0:04:55]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[360/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.61037/26.50764, loss_obj_ce: 0.37281/0.98009, obj_class_error: 50.00000/89.83409, loss_verb_ce: 1.08530/1.52310, loss_sub_bbox: 0.35347/0.52358, loss_obj_bbox: 0.00000/0.58496, loss_sub_giou: 0.52427/0.79951, loss_obj_giou: 0.00000/1.20027, obj_cardinality_error: 3.50000/3.28611, loss_obj_ce_0: 0.37270/1.01669, loss_verb_ce_0: 1.07082/1.56606, loss_sub_bbox_0: 0.29816/0.51564, loss_obj_bbox_0: 0.00000/0.58205, loss_sub_giou_0: 0.60187/0.79438, loss_obj_giou_0: 0.00000/1.19850, obj_cardinality_error_0: 4.00000/3.30972, loss_obj_ce_1: 0.36492/0.99510, loss_verb_ce_1: 1.04501/1.53276, loss_sub_bbox_1: 0.31106/0.51971, loss_obj_bbox_1: 0.00000/0.58422, loss_sub_giou_1: 0.56480/0.79787, loss_obj_giou_1: 0.00000/1.20596, obj_cardinality_error_1: 3.50000/3.37639] items per batch[1] items per second[0.89] total items[360] mini batches[   360] memory[1297] epoch remaining[0:04:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[370/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.18420/26.36957, loss_obj_ce: 0.63852/0.97676, obj_class_error: 40.00000/89.30318, loss_verb_ce: 0.64835/1.50420, loss_sub_bbox: 0.67504/0.52229, loss_obj_bbox: 0.49877/0.58424, loss_sub_giou: 0.94643/0.79909, loss_obj_giou: 1.35218/1.20017, obj_cardinality_error: 4.50000/3.28514, loss_obj_ce_0: 0.64174/1.01479, loss_verb_ce_0: 0.73992/1.54808, loss_sub_bbox_0: 0.63454/0.51355, loss_obj_bbox_0: 0.46974/0.58090, loss_sub_giou_0: 0.85238/0.79403, loss_obj_giou_0: 1.27169/1.19818, obj_cardinality_error_0: 4.00000/3.33919, loss_obj_ce_1: 0.61829/0.99319, loss_verb_ce_1: 0.68380/1.51574, loss_sub_bbox_1: 0.67052/0.51780, loss_obj_bbox_1: 0.47616/0.58350, loss_sub_giou_1: 0.87385/0.79707, loss_obj_giou_1: 1.28305/1.20455, obj_cardinality_error_1: 2.00000/3.36486] items per batch[1] items per second[0.87] total items[370] mini batches[   370] memory[1297] epoch remaining[0:04:51]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[380/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.44873/26.19561, loss_obj_ce: 0.69542/0.96809, obj_class_error: 100.00000/89.17616, loss_verb_ce: 0.80982/1.48776, loss_sub_bbox: 0.38781/0.51961, loss_obj_bbox: 0.44658/0.58067, loss_sub_giou: 0.81358/0.79905, loss_obj_giou: 1.00453/1.19591, obj_cardinality_error: 0.50000/3.26711, loss_obj_ce_0: 0.85993/1.00769, loss_verb_ce_0: 0.98942/1.53306, loss_sub_bbox_0: 0.43557/0.51158, loss_obj_bbox_0: 0.40566/0.57749, loss_sub_giou_0: 0.86326/0.79331, loss_obj_giou_0: 0.93776/1.19232, obj_cardinality_error_0: 3.00000/3.30000, loss_obj_ce_1: 0.80769/0.98546, loss_verb_ce_1: 0.98645/1.50207, loss_sub_bbox_1: 0.37769/0.51555, loss_obj_bbox_1: 0.42689/0.57983, loss_sub_giou_1: 0.84398/0.79701, loss_obj_giou_1: 0.85069/1.19916, obj_cardinality_error_1: 3.00000/3.32500] items per batch[1] items per second[0.76] total items[380] mini batches[   380] memory[1297] epoch remaining[0:04:51]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[390/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.64575/26.01209, loss_obj_ce: 0.80360/0.96458, obj_class_error: 100.00000/88.76385, loss_verb_ce: 1.19517/1.47057, loss_sub_bbox: 0.30616/0.51527, loss_obj_bbox: 0.55065/0.57740, loss_sub_giou: 0.53889/0.79585, loss_obj_giou: 1.32304/1.19117, obj_cardinality_error: 10.00000/3.33846, loss_obj_ce_0: 0.87488/1.00611, loss_verb_ce_0: 1.29678/1.51698, loss_sub_bbox_0: 0.27252/0.50724, loss_obj_bbox_0: 0.54246/0.57429, loss_sub_giou_0: 0.48638/0.78966, loss_obj_giou_0: 1.31605/1.18860, obj_cardinality_error_0: 5.00000/3.33205, loss_obj_ce_1: 0.90259/0.98377, loss_verb_ce_1: 1.28959/1.48683, loss_sub_bbox_1: 0.22288/0.51091, loss_obj_bbox_1: 0.55594/0.57723, loss_sub_giou_1: 0.38702/0.79232, loss_obj_giou_1: 1.32368/1.19544, obj_cardinality_error_1: 8.00000/3.40000] items per batch[1] items per second[0.83] total items[390] mini batches[   390] memory[1297] epoch remaining[0:04:49]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[400/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.95150/25.82457, loss_obj_ce: 0.85776/0.95833, obj_class_error: 80.00000/88.29878, loss_verb_ce: 0.83527/1.45278, loss_sub_bbox: 0.20266/0.51092, loss_obj_bbox: 0.32754/0.57437, loss_sub_giou: 0.43736/0.79283, loss_obj_giou: 1.25390/1.19088, obj_cardinality_error: 14.50000/3.41000, loss_obj_ce_0: 0.93525/1.00095, loss_verb_ce_0: 0.87527/1.49972, loss_sub_bbox_0: 0.24790/0.50372, loss_obj_bbox_0: 0.28193/0.57109, loss_sub_giou_0: 0.52799/0.78765, loss_obj_giou_0: 1.19074/1.18743, obj_cardinality_error_0: 11.50000/3.34125, loss_obj_ce_1: 0.81255/0.97757, loss_verb_ce_1: 0.82823/1.46964, loss_sub_bbox_1: 0.25350/0.50655, loss_obj_bbox_1: 0.28234/0.57349, loss_sub_giou_1: 0.63484/0.78962, loss_obj_giou_1: 1.23387/1.19467, obj_cardinality_error_1: 9.50000/3.42625] items per batch[1] items per second[0.75] total items[400] mini batches[   400] memory[1297] epoch remaining[0:04:48]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[410/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.92017/25.66478, loss_obj_ce: 0.32182/0.95324, obj_class_error: 100.00000/88.19568, loss_verb_ce: 0.88892/1.43983, loss_sub_bbox: 0.35278/0.50997, loss_obj_bbox: 0.30915/0.57028, loss_sub_giou: 0.74037/0.79061, loss_obj_giou: 0.98521/1.19007, obj_cardinality_error: 0.00000/3.40976, loss_obj_ce_0: 0.36032/0.99524, loss_verb_ce_0: 0.89132/1.48410, loss_sub_bbox_0: 0.30543/0.50119, loss_obj_bbox_0: 0.29585/0.56700, loss_sub_giou_0: 0.74794/0.78519, loss_obj_giou_0: 0.83566/1.18581, obj_cardinality_error_0: 2.50000/3.34024, loss_obj_ce_1: 0.35005/0.97162, loss_verb_ce_1: 0.93077/1.45554, loss_sub_bbox_1: 0.26035/0.50447, loss_obj_bbox_1: 0.35254/0.56884, loss_sub_giou_1: 0.55315/0.78693, loss_obj_giou_1: 0.91338/1.19278, obj_cardinality_error_1: 0.50000/3.37805] items per batch[1] items per second[0.84] total items[410] mini batches[   410] memory[1297] epoch remaining[0:04:47]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[420/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.51417/25.49589, loss_obj_ce: 0.77548/0.94779, obj_class_error: 83.33334/88.23864, loss_verb_ce: 0.78339/1.42677, loss_sub_bbox: 0.54218/0.50768, loss_obj_bbox: 0.36254/0.56613, loss_sub_giou: 0.94905/0.78688, loss_obj_giou: 1.21265/1.18529, obj_cardinality_error: 2.50000/3.37143, loss_obj_ce_0: 0.73620/0.98984, loss_verb_ce_0: 0.83278/1.47109, loss_sub_bbox_0: 0.61367/0.49889, loss_obj_bbox_0: 0.40281/0.56297, loss_sub_giou_0: 0.93974/0.78179, loss_obj_giou_0: 1.09545/1.18031, obj_cardinality_error_0: 2.50000/3.33929, loss_obj_ce_1: 0.75004/0.96630, loss_verb_ce_1: 0.86468/1.44302, loss_sub_bbox_1: 0.54586/0.50188, loss_obj_bbox_1: 0.34685/0.56443, loss_sub_giou_1: 0.99809/0.78383, loss_obj_giou_1: 1.06101/1.18712, obj_cardinality_error_1: 2.50000/3.34048] items per batch[1] items per second[0.85] total items[420] mini batches[   420] memory[1297] epoch remaining[0:04:45]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[430/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.68579/25.35696, loss_obj_ce: 0.41147/0.94779, obj_class_error: 66.66667/88.25582, loss_verb_ce: 0.80968/1.41409, loss_sub_bbox: 0.58032/0.50480, loss_obj_bbox: 0.50897/0.56285, loss_sub_giou: 0.94113/0.78701, loss_obj_giou: 1.42157/1.18268, obj_cardinality_error: 2.50000/3.38256, loss_obj_ce_0: 0.37434/0.98825, loss_verb_ce_0: 0.90613/1.45758, loss_sub_bbox_0: 0.46854/0.49559, loss_obj_bbox_0: 0.48829/0.55936, loss_sub_giou_0: 0.82226/0.78153, loss_obj_giou_0: 1.29606/1.17683, obj_cardinality_error_0: 2.00000/3.37674, loss_obj_ce_1: 0.39281/0.96529, loss_verb_ce_1: 0.84464/1.43057, loss_sub_bbox_1: 0.54858/0.49865, loss_obj_bbox_1: 0.47416/0.56112, loss_sub_giou_1: 0.94151/0.78331, loss_obj_giou_1: 1.29156/1.18383, obj_cardinality_error_1: 3.50000/3.34070] items per batch[1] items per second[0.72] total items[430] mini batches[   430] memory[1297] epoch remaining[0:04:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[440/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.91308/25.23545, loss_obj_ce: 1.02224/0.94670, obj_class_error: 71.42857/87.85188, loss_verb_ce: 0.90507/1.40170, loss_sub_bbox: 0.48029/0.50226, loss_obj_bbox: 0.50004/0.56158, loss_sub_giou: 0.95480/0.78518, loss_obj_giou: 0.82773/1.18026, obj_cardinality_error: 16.50000/3.48977, loss_obj_ce_0: 1.03222/0.98868, loss_verb_ce_0: 0.88626/1.44453, loss_sub_bbox_0: 0.46383/0.49293, loss_obj_bbox_0: 0.48822/0.55804, loss_sub_giou_0: 0.97910/0.77897, loss_obj_giou_0: 0.85893/1.17369, obj_cardinality_error_0: 15.00000/3.43182, loss_obj_ce_1: 1.02311/0.96450, loss_verb_ce_1: 0.80214/1.41788, loss_sub_bbox_1: 0.45242/0.49619, loss_obj_bbox_1: 0.51737/0.55979, loss_sub_giou_1: 0.95819/0.78113, loss_obj_giou_1: 0.81442/1.18117, obj_cardinality_error_1: 12.50000/3.38523] items per batch[1] items per second[0.86] total items[440] mini batches[   440] memory[1297] epoch remaining[0:04:43]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[450/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.67299/25.10860, loss_obj_ce: 1.29253/0.94425, obj_class_error: 100.00000/87.51364, loss_verb_ce: 0.92195/1.38816, loss_sub_bbox: 0.30822/0.49965, loss_obj_bbox: 0.61399/0.56034, loss_sub_giou: 0.47515/0.78201, loss_obj_giou: 1.04466/1.17890, obj_cardinality_error: 1.00000/3.45111, loss_obj_ce_0: 1.26895/0.98871, loss_verb_ce_0: 1.02550/1.43256, loss_sub_bbox_0: 0.29252/0.49032, loss_obj_bbox_0: 0.54342/0.55643, loss_sub_giou_0: 0.44363/0.77521, loss_obj_giou_0: 0.83829/1.17077, obj_cardinality_error_0: 4.50000/3.44556, loss_obj_ce_1: 1.19109/0.96257, loss_verb_ce_1: 0.89854/1.40447, loss_sub_bbox_1: 0.40358/0.49399, loss_obj_bbox_1: 0.54481/0.55853, loss_sub_giou_1: 0.66062/0.77808, loss_obj_giou_1: 0.99975/1.17954, obj_cardinality_error_1: 2.00000/3.35556] items per batch[1] items per second[0.88] total items[450] mini batches[   450] memory[1297] epoch remaining[0:04:41]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[460/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.38475/24.97117, loss_obj_ce: 0.87956/0.94531, obj_class_error: 62.50000/87.12074, loss_verb_ce: 0.82737/1.37451, loss_sub_bbox: 0.31978/0.49614, loss_obj_bbox: 0.33427/0.55806, loss_sub_giou: 0.75923/0.77879, loss_obj_giou: 1.38179/1.17880, obj_cardinality_error: 4.00000/3.45000, loss_obj_ce_0: 0.80647/0.98985, loss_verb_ce_0: 0.81412/1.41857, loss_sub_bbox_0: 0.25356/0.48689, loss_obj_bbox_0: 0.30742/0.55323, loss_sub_giou_0: 0.71414/0.77149, loss_obj_giou_0: 1.32625/1.16934, obj_cardinality_error_0: 2.00000/3.46957, loss_obj_ce_1: 0.90509/0.96416, loss_verb_ce_1: 0.85249/1.39099, loss_sub_bbox_1: 0.30573/0.49057, loss_obj_bbox_1: 0.28542/0.55583, loss_sub_giou_1: 0.86885/0.77507, loss_obj_giou_1: 1.23995/1.17843, obj_cardinality_error_1: 1.50000/3.35326] items per batch[1] items per second[0.78] total items[460] mini batches[   460] memory[1297] epoch remaining[0:04:40]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[470/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.68108/24.85425, loss_obj_ce: 1.31956/0.94421, obj_class_error: 87.50000/86.83601, loss_verb_ce: 0.90780/1.36193, loss_sub_bbox: 0.27466/0.49335, loss_obj_bbox: 0.38469/0.55611, loss_sub_giou: 0.54557/0.77656, loss_obj_giou: 1.19601/1.17854, obj_cardinality_error: 1.00000/3.42553, loss_obj_ce_0: 1.18979/0.98786, loss_verb_ce_0: 0.89517/1.40594, loss_sub_bbox_0: 0.25435/0.48450, loss_obj_bbox_0: 0.43078/0.55155, loss_sub_giou_0: 0.58791/0.76937, loss_obj_giou_0: 1.29421/1.17049, obj_cardinality_error_0: 4.00000/3.43936, loss_obj_ce_1: 1.24503/0.96233, loss_verb_ce_1: 0.96543/1.37920, loss_sub_bbox_1: 0.28580/0.48856, loss_obj_bbox_1: 0.39635/0.55367, loss_sub_giou_1: 0.57050/0.77396, loss_obj_giou_1: 1.12912/1.17745, obj_cardinality_error_1: 3.00000/3.32766] items per batch[1] items per second[0.87] total items[470] mini batches[   470] memory[1297] epoch remaining[0:04:38]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[480/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 25.23274/24.71757, loss_obj_ce: 0.49758/0.93472, obj_class_error: 66.66667/86.33049, loss_verb_ce: 0.90878/1.35080, loss_sub_bbox: 0.96801/0.49273, loss_obj_bbox: 0.72279/0.55461, loss_sub_giou: 1.00426/0.77380, loss_obj_giou: 0.72015/1.17399, obj_cardinality_error: 0.50000/3.37708, loss_obj_ce_0: 0.65201/0.97988, loss_verb_ce_0: 1.03713/1.39452, loss_sub_bbox_0: 0.98533/0.48350, loss_obj_bbox_0: 0.64842/0.54988, loss_sub_giou_0: 0.92815/0.76548, loss_obj_giou_0: 0.66777/1.16597, obj_cardinality_error_0: 6.50000/3.46250, loss_obj_ce_1: 0.50021/0.95264, loss_verb_ce_1: 0.95402/1.36772, loss_sub_bbox_1: 0.99826/0.48856, loss_obj_bbox_1: 0.78210/0.55155, loss_sub_giou_1: 0.98855/0.77046, loss_obj_giou_1: 0.71193/1.17247, obj_cardinality_error_1: 0.50000/3.29479] items per batch[1] items per second[0.86] total items[480] mini batches[   480] memory[1297] epoch remaining[0:04:36]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[490/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.28325/24.58957, loss_obj_ce: 0.62925/0.93069, obj_class_error: 80.00000/85.98256, loss_verb_ce: 0.61859/1.33789, loss_sub_bbox: 0.32614/0.49151, loss_obj_bbox: 0.31732/0.55177, loss_sub_giou: 0.68989/0.77293, loss_obj_giou: 0.82122/1.17036, obj_cardinality_error: 4.50000/3.33776, loss_obj_ce_0: 0.61551/0.97765, loss_verb_ce_0: 0.65521/1.38260, loss_sub_bbox_0: 0.27665/0.48224, loss_obj_bbox_0: 0.22343/0.54719, loss_sub_giou_0: 0.60499/0.76459, loss_obj_giou_0: 0.76624/1.16243, obj_cardinality_error_0: 5.50000/3.49796, loss_obj_ce_1: 0.60444/0.94811, loss_verb_ce_1: 0.57985/1.35428, loss_sub_bbox_1: 0.30214/0.48774, loss_obj_bbox_1: 0.29003/0.54913, loss_sub_giou_1: 0.73853/0.76947, loss_obj_giou_1: 0.76661/1.16984, obj_cardinality_error_1: 0.50000/3.25816] items per batch[1] items per second[0.84] total items[490] mini batches[   490] memory[1297] epoch remaining[0:04:35]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[500/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.38081/24.45793, loss_obj_ce: 0.33958/0.92722, obj_class_error: 66.66667/85.73291, loss_verb_ce: 0.89717/1.33007, loss_sub_bbox: 0.41768/0.48905, loss_obj_bbox: 0.37503/0.54809, loss_sub_giou: 0.59516/0.77019, loss_obj_giou: 1.17665/1.16712, obj_cardinality_error: 1.00000/3.34400, loss_obj_ce_0: 0.36293/0.97455, loss_verb_ce_0: 0.79022/1.37490, loss_sub_bbox_0: 0.31637/0.47903, loss_obj_bbox_0: 0.28900/0.54318, loss_sub_giou_0: 0.41468/0.76119, loss_obj_giou_0: 0.97535/1.15881, obj_cardinality_error_0: 1.50000/3.47600, loss_obj_ce_1: 0.29005/0.94310, loss_verb_ce_1: 0.78518/1.34514, loss_sub_bbox_1: 0.37354/0.48533, loss_obj_bbox_1: 0.22758/0.54469, loss_sub_giou_1: 0.44624/0.76687, loss_obj_giou_1: 0.83699/1.16524, obj_cardinality_error_1: 0.00000/3.21900] items per batch[1] items per second[0.92] total items[500] mini batches[   500] memory[1297] epoch remaining[0:04:33]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[510/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.00446/24.34489, loss_obj_ce: 0.69791/0.92361, obj_class_error: 80.00000/85.59926, loss_verb_ce: 0.95476/1.32226, loss_sub_bbox: 0.55825/0.48698, loss_obj_bbox: 0.66922/0.54466, loss_sub_giou: 0.77445/0.76820, loss_obj_giou: 0.98158/1.16559, obj_cardinality_error: 1.50000/3.32843, loss_obj_ce_0: 0.93759/0.97126, loss_verb_ce_0: 1.10914/1.36638, loss_sub_bbox_0: 0.52749/0.47752, loss_obj_bbox_0: 0.58883/0.53890, loss_sub_giou_0: 0.77541/0.76000, loss_obj_giou_0: 0.99313/1.15511, obj_cardinality_error_0: 1.00000/3.44804, loss_obj_ce_1: 0.75229/0.93876, loss_verb_ce_1: 1.05037/1.33645, loss_sub_bbox_1: 0.58875/0.48385, loss_obj_bbox_1: 0.65561/0.54092, loss_sub_giou_1: 0.82259/0.76607, loss_obj_giou_1: 1.07059/1.16405, obj_cardinality_error_1: 1.50000/3.18235] items per batch[1] items per second[0.82] total items[510] mini batches[   510] memory[1297] epoch remaining[0:04:32]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[520/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.94301/24.23602, loss_obj_ce: 0.78168/0.92186, obj_class_error: 66.66667/85.51562, loss_verb_ce: 0.76991/1.31745, loss_sub_bbox: 0.56620/0.48428, loss_obj_bbox: 0.72389/0.54108, loss_sub_giou: 0.76047/0.76573, loss_obj_giou: 1.09439/1.16131, obj_cardinality_error: 1.50000/3.29808, loss_obj_ce_0: 0.93541/0.97072, loss_verb_ce_0: 0.82267/1.36079, loss_sub_bbox_0: 0.50398/0.47432, loss_obj_bbox_0: 0.58365/0.53458, loss_sub_giou_0: 0.68680/0.75645, loss_obj_giou_0: 1.19584/1.15019, obj_cardinality_error_0: 5.00000/3.48942, loss_obj_ce_1: 0.87952/0.93758, loss_verb_ce_1: 0.80174/1.33110, loss_sub_bbox_1: 0.53996/0.48101, loss_obj_bbox_1: 0.66527/0.53709, loss_sub_giou_1: 0.73638/0.76334, loss_obj_giou_1: 1.12649/1.15926, obj_cardinality_error_1: 5.00000/3.16346] items per batch[1] items per second[0.81] total items[520] mini batches[   520] memory[1297] epoch remaining[0:04:30]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[530/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.44060/24.16267, loss_obj_ce: 0.96475/0.92159, obj_class_error: 100.00000/85.57314, loss_verb_ce: 0.88337/1.30969, loss_sub_bbox: 0.45056/0.48363, loss_obj_bbox: 0.37710/0.53883, loss_sub_giou: 0.49855/0.76594, loss_obj_giou: 0.84364/1.15879, obj_cardinality_error: 1.00000/3.28208, loss_obj_ce_0: 0.94537/0.97095, loss_verb_ce_0: 0.81481/1.35328, loss_sub_bbox_0: 0.32709/0.47352, loss_obj_bbox_0: 0.54483/0.53309, loss_sub_giou_0: 0.36412/0.75561, loss_obj_giou_0: 1.24586/1.14812, obj_cardinality_error_0: 3.00000/3.47453, loss_obj_ce_1: 0.92651/0.93663, loss_verb_ce_1: 0.81685/1.32293, loss_sub_bbox_1: 0.38786/0.48039, loss_obj_bbox_1: 0.41019/0.53570, loss_sub_giou_1: 0.42278/0.76291, loss_obj_giou_1: 0.95484/1.15746, obj_cardinality_error_1: 0.50000/3.12830] items per batch[1] items per second[0.77] total items[530] mini batches[   530] memory[1297] epoch remaining[0:04:29]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[540/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.39416/24.08310, loss_obj_ce: 0.90079/0.91741, obj_class_error: 62.50000/85.39696, loss_verb_ce: 0.61606/1.30156, loss_sub_bbox: 0.38108/0.48258, loss_obj_bbox: 0.65983/0.53824, loss_sub_giou: 0.49950/0.76471, loss_obj_giou: 0.74562/1.15539, obj_cardinality_error: 5.00000/3.31019, loss_obj_ce_0: 1.06724/0.96655, loss_verb_ce_0: 0.77893/1.34529, loss_sub_bbox_0: 0.51834/0.47283, loss_obj_bbox_0: 0.68909/0.53317, loss_sub_giou_0: 0.61704/0.75420, loss_obj_giou_0: 0.79877/1.14566, obj_cardinality_error_0: 1.50000/3.45000, loss_obj_ce_1: 1.01704/0.93266, loss_verb_ce_1: 0.64282/1.31601, loss_sub_bbox_1: 0.45159/0.47961, loss_obj_bbox_1: 0.67279/0.53532, loss_sub_giou_1: 0.52188/0.76136, loss_obj_giou_1: 0.71884/1.15508, obj_cardinality_error_1: 1.00000/3.11667] items per batch[1] items per second[0.88] total items[540] mini batches[   540] memory[1297] epoch remaining[0:04:28]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[550/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.24948/23.97560, loss_obj_ce: 0.68715/0.91248, obj_class_error: 80.00000/85.19407, loss_verb_ce: 0.75814/1.29082, loss_sub_bbox: 0.37743/0.48133, loss_obj_bbox: 0.42451/0.53762, loss_sub_giou: 0.74758/0.76186, loss_obj_giou: 1.03968/1.15516, obj_cardinality_error: 2.00000/3.27636, loss_obj_ce_0: 0.78071/0.96209, loss_verb_ce_0: 0.91751/1.33431, loss_sub_bbox_0: 0.24622/0.47195, loss_obj_bbox_0: 0.46751/0.53171, loss_sub_giou_0: 0.65506/0.75182, loss_obj_giou_0: 1.19743/1.14444, obj_cardinality_error_0: 3.50000/3.41636, loss_obj_ce_1: 0.74741/0.92745, loss_verb_ce_1: 0.92360/1.30533, loss_sub_bbox_1: 0.23151/0.47870, loss_obj_bbox_1: 0.40287/0.53329, loss_sub_giou_1: 0.61112/0.75901, loss_obj_giou_1: 1.20971/1.15385, obj_cardinality_error_1: 2.00000/3.08000] items per batch[1] items per second[0.80] total items[550] mini batches[   550] memory[1297] epoch remaining[0:04:26]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[560/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.97340/23.88023, loss_obj_ce: 0.90656/0.91133, obj_class_error: 80.00000/84.98440, loss_verb_ce: 0.58516/1.28210, loss_sub_bbox: 0.66649/0.47970, loss_obj_bbox: 0.57591/0.53585, loss_sub_giou: 0.95783/0.75962, loss_obj_giou: 1.33532/1.15490, obj_cardinality_error: 5.50000/3.29911, loss_obj_ce_0: 0.91087/0.96069, loss_verb_ce_0: 0.65717/1.32507, loss_sub_bbox_0: 0.53649/0.47040, loss_obj_bbox_0: 0.39510/0.52944, loss_sub_giou_0: 0.98898/0.75033, loss_obj_giou_0: 1.06805/1.14238, obj_cardinality_error_0: 4.50000/3.42679, loss_obj_ce_1: 0.84125/0.92589, loss_verb_ce_1: 0.62742/1.29604, loss_sub_bbox_1: 0.66149/0.47718, loss_obj_bbox_1: 0.44144/0.53105, loss_sub_giou_1: 0.93280/0.75728, loss_obj_giou_1: 1.09994/1.15233, obj_cardinality_error_1: 2.00000/3.07679] items per batch[1] items per second[0.84] total items[560] mini batches[   560] memory[1297] epoch remaining[0:04:25]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[570/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.33676/23.78106, loss_obj_ce: 0.46860/0.90857, obj_class_error: 80.00000/84.75551, loss_verb_ce: 0.79782/1.27320, loss_sub_bbox: 0.31304/0.47830, loss_obj_bbox: 0.32501/0.53373, loss_sub_giou: 0.51177/0.75744, loss_obj_giou: 0.79110/1.15182, obj_cardinality_error: 3.00000/3.29649, loss_obj_ce_0: 0.64822/0.95869, loss_verb_ce_0: 0.89701/1.31733, loss_sub_bbox_0: 0.39084/0.46830, loss_obj_bbox_0: 0.37505/0.52749, loss_sub_giou_0: 0.56634/0.74769, loss_obj_giou_0: 0.94682/1.14009, obj_cardinality_error_0: 1.00000/3.43772, loss_obj_ce_1: 0.45736/0.92353, loss_verb_ce_1: 0.89425/1.28886, loss_sub_bbox_1: 0.37807/0.47556, loss_obj_bbox_1: 0.35024/0.52895, loss_sub_giou_1: 0.54522/0.75472, loss_obj_giou_1: 0.89254/1.14889, obj_cardinality_error_1: 4.00000/3.09912] items per batch[1] items per second[0.87] total items[570] mini batches[   570] memory[1297] epoch remaining[0:04:23]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[580/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.69938/23.67205, loss_obj_ce: 0.77137/0.90667, obj_class_error: 57.14286/84.52861, loss_verb_ce: 0.64344/1.26426, loss_sub_bbox: 0.31015/0.47652, loss_obj_bbox: 0.67608/0.53266, loss_sub_giou: 0.59858/0.75412, loss_obj_giou: 1.00409/1.14686, obj_cardinality_error: 2.50000/3.26724, loss_obj_ce_0: 0.95151/0.95833, loss_verb_ce_0: 0.63898/1.31004, loss_sub_bbox_0: 0.23758/0.46593, loss_obj_bbox_0: 0.40212/0.52582, loss_sub_giou_0: 0.46177/0.74394, loss_obj_giou_0: 0.89840/1.13313, obj_cardinality_error_0: 2.50000/3.41121, loss_obj_ce_1: 0.86156/0.92203, loss_verb_ce_1: 0.62765/1.28113, loss_sub_bbox_1: 0.27162/0.47353, loss_obj_bbox_1: 0.40369/0.52646, loss_sub_giou_1: 0.53265/0.75146, loss_obj_giou_1: 1.04622/1.14236, obj_cardinality_error_1: 3.00000/3.07672] items per batch[1] items per second[0.89] total items[580] mini batches[   580] memory[1297] epoch remaining[0:04:22]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[590/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.04718/23.55532, loss_obj_ce: 0.92049/0.90302, obj_class_error: 70.00000/84.25747, loss_verb_ce: 0.78360/1.25534, loss_sub_bbox: 0.40680/0.47491, loss_obj_bbox: 0.44517/0.52954, loss_sub_giou: 0.79087/0.75156, loss_obj_giou: 1.29073/1.14446, obj_cardinality_error: 5.00000/3.28136, loss_obj_ce_0: 1.04756/0.95551, loss_verb_ce_0: 0.86953/1.30152, loss_sub_bbox_0: 0.36086/0.46357, loss_obj_bbox_0: 0.41351/0.52282, loss_sub_giou_0: 0.78789/0.74131, loss_obj_giou_0: 1.42281/1.13139, obj_cardinality_error_0: 11.00000/3.42881, loss_obj_ce_1: 0.85958/0.91773, loss_verb_ce_1: 0.78665/1.27201, loss_sub_bbox_1: 0.34976/0.47142, loss_obj_bbox_1: 0.41577/0.52355, loss_sub_giou_1: 0.72668/0.74882, loss_obj_giou_1: 1.34135/1.13924, obj_cardinality_error_1: 0.00000/3.06864] items per batch[1] items per second[0.82] total items[590] mini batches[   590] memory[1297] epoch remaining[0:04:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[600/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.07732/23.44535, loss_obj_ce: 0.42277/0.89709, obj_class_error: 50.00000/83.94485, loss_verb_ce: 0.53635/1.24752, loss_sub_bbox: 0.26429/0.47371, loss_obj_bbox: 0.41442/0.52699, loss_sub_giou: 0.24115/0.74885, loss_obj_giou: 1.13536/1.14031, obj_cardinality_error: 1.00000/3.26417, loss_obj_ce_0: 0.65185/0.95094, loss_verb_ce_0: 0.79652/1.29450, loss_sub_bbox_0: 0.29694/0.46223, loss_obj_bbox_0: 0.46069/0.52029, loss_sub_giou_0: 0.26524/0.73813, loss_obj_giou_0: 1.10629/1.12784, obj_cardinality_error_0: 2.00000/3.41583, loss_obj_ce_1: 0.44631/0.91111, loss_verb_ce_1: 0.64645/1.26379, loss_sub_bbox_1: 0.25330/0.47025, loss_obj_bbox_1: 0.49042/0.52149, loss_sub_giou_1: 0.25739/0.74623, loss_obj_giou_1: 1.14214/1.13585, obj_cardinality_error_1: 1.00000/3.04167] items per batch[1] items per second[0.92] total items[600] mini batches[   600] memory[1297] epoch remaining[0:04:19]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[610/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.74502/23.35942, loss_obj_ce: 1.22364/0.89449, obj_class_error: 100.00000/83.85637, loss_verb_ce: 0.98853/1.23930, loss_sub_bbox: 0.47602/0.47217, loss_obj_bbox: 0.60102/0.52515, loss_sub_giou: 0.64649/0.74664, loss_obj_giou: 1.07064/1.14030, obj_cardinality_error: 1.50000/3.23443, loss_obj_ce_0: 1.21019/0.94965, loss_verb_ce_0: 0.98642/1.28699, loss_sub_bbox_0: 0.62131/0.46092, loss_obj_bbox_0: 0.47305/0.51833, loss_sub_giou_0: 0.72358/0.73645, loss_obj_giou_0: 0.96179/1.12698, obj_cardinality_error_0: 2.50000/3.39918, loss_obj_ce_1: 1.11544/0.90821, loss_verb_ce_1: 0.99257/1.25547, loss_sub_bbox_1: 0.50253/0.46897, loss_obj_bbox_1: 0.55877/0.51955, loss_sub_giou_1: 0.65008/0.74449, loss_obj_giou_1: 1.12635/1.13598, obj_cardinality_error_1: 1.00000/3.01311] items per batch[1] items per second[0.76] total items[610] mini batches[   610] memory[1297] epoch remaining[0:04:18]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[620/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.65291/23.29833, loss_obj_ce: 0.82707/0.89112, obj_class_error: 66.66667/83.70277, loss_verb_ce: 0.80116/1.23298, loss_sub_bbox: 0.48013/0.47186, loss_obj_bbox: 0.37378/0.52445, loss_sub_giou: 1.02371/0.74588, loss_obj_giou: 1.31671/1.13819, obj_cardinality_error: 9.50000/3.23387, loss_obj_ce_0: 0.82176/0.94640, loss_verb_ce_0: 0.73712/1.28116, loss_sub_bbox_0: 0.48748/0.46020, loss_obj_bbox_0: 0.43351/0.51795, loss_sub_giou_0: 0.99437/0.73524, loss_obj_giou_0: 1.40622/1.12538, obj_cardinality_error_0: 2.50000/3.39194, loss_obj_ce_1: 0.78693/0.90439, loss_verb_ce_1: 0.71936/1.24882, loss_sub_bbox_1: 0.45703/0.46860, loss_obj_bbox_1: 0.43434/0.51953, loss_sub_giou_1: 0.93648/0.74349, loss_obj_giou_1: 1.35871/1.13583, obj_cardinality_error_1: 3.00000/3.00242] items per batch[1] items per second[0.88] total items[620] mini batches[   620] memory[1297] epoch remaining[0:04:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[630/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.11691/23.20386, loss_obj_ce: 0.60704/0.88641, obj_class_error: 75.00000/83.43614, loss_verb_ce: 1.16248/1.22664, loss_sub_bbox: 0.33528/0.47046, loss_obj_bbox: 0.39591/0.52203, loss_sub_giou: 0.70539/0.74436, loss_obj_giou: 1.01003/1.13427, obj_cardinality_error: 0.50000/3.27937, loss_obj_ce_0: 0.58693/0.94086, loss_verb_ce_0: 1.10081/1.27548, loss_sub_bbox_0: 0.27068/0.45856, loss_obj_bbox_0: 0.43201/0.51603, loss_sub_giou_0: 0.73007/0.73406, loss_obj_giou_0: 1.08945/1.12181, obj_cardinality_error_0: 1.00000/3.39603, loss_obj_ce_1: 0.55089/0.89897, loss_verb_ce_1: 1.11143/1.24220, loss_sub_bbox_1: 0.29803/0.46719, loss_obj_bbox_1: 0.42321/0.51781, loss_sub_giou_1: 0.69776/0.74227, loss_obj_giou_1: 1.00204/1.13199, obj_cardinality_error_1: 0.50000/3.02381] items per batch[1] items per second[0.78] total items[630] mini batches[   630] memory[1297] epoch remaining[0:04:15]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[640/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.91002/23.12238, loss_obj_ce: 0.89993/0.88480, obj_class_error: 83.33334/83.33688, loss_verb_ce: 0.98317/1.22208, loss_sub_bbox: 0.34060/0.46973, loss_obj_bbox: 0.24758/0.52004, loss_sub_giou: 0.43775/0.73996, loss_obj_giou: 1.07440/1.12880, obj_cardinality_error: 2.00000/3.25078, loss_obj_ce_0: 1.02587/0.93978, loss_verb_ce_0: 1.07714/1.27185, loss_sub_bbox_0: 0.20679/0.45745, loss_obj_bbox_0: 0.29337/0.51327, loss_sub_giou_0: 0.36066/0.73046, loss_obj_giou_0: 1.14211/1.11615, obj_cardinality_error_0: 3.00000/3.39844, loss_obj_ce_1: 0.87810/0.89784, loss_verb_ce_1: 1.02861/1.23818, loss_sub_bbox_1: 0.31823/0.46638, loss_obj_bbox_1: 0.31077/0.51537, loss_sub_giou_1: 0.45322/0.73851, loss_obj_giou_1: 1.16680/1.12624, obj_cardinality_error_1: 2.00000/3.01641] items per batch[1] items per second[0.84] total items[640] mini batches[   640] memory[1297] epoch remaining[0:04:14]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[650/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.76874/23.04343, loss_obj_ce: 0.42240/0.88349, obj_class_error: 100.00000/83.37192, loss_verb_ce: 1.01965/1.21813, loss_sub_bbox: 0.14313/0.46738, loss_obj_bbox: 0.19902/0.51763, loss_sub_giou: 0.51337/0.73656, loss_obj_giou: 0.68641/1.12599, obj_cardinality_error: 0.00000/3.22308, loss_obj_ce_0: 0.35350/0.93882, loss_verb_ce_0: 1.01475/1.26794, loss_sub_bbox_0: 0.09635/0.45481, loss_obj_bbox_0: 0.25057/0.51111, loss_sub_giou_0: 0.42607/0.72712, loss_obj_giou_0: 0.67344/1.11455, obj_cardinality_error_0: 1.00000/3.38077, loss_obj_ce_1: 0.42317/0.89698, loss_verb_ce_1: 1.07501/1.23445, loss_sub_bbox_1: 0.16959/0.46398, loss_obj_bbox_1: 0.22680/0.51302, loss_sub_giou_1: 0.63500/0.73537, loss_obj_giou_1: 0.70293/1.12370, obj_cardinality_error_1: 0.50000/2.99769] items per batch[1] items per second[0.83] total items[650] mini batches[   650] memory[1297] epoch remaining[0:04:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[660/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.81906/22.96617, loss_obj_ce: 0.69857/0.88107, obj_class_error: 75.00000/83.24327, loss_verb_ce: 0.91781/1.21370, loss_sub_bbox: 0.42693/0.46633, loss_obj_bbox: 0.34647/0.51607, loss_sub_giou: 0.71515/0.73489, loss_obj_giou: 1.17872/1.12191, obj_cardinality_error: 1.50000/3.19318, loss_obj_ce_0: 0.80711/0.93713, loss_verb_ce_0: 1.01515/1.26299, loss_sub_bbox_0: 0.38473/0.45375, loss_obj_bbox_0: 0.33284/0.50942, loss_sub_giou_0: 0.68260/0.72444, loss_obj_giou_0: 0.96696/1.10965, obj_cardinality_error_0: 2.00000/3.35455, loss_obj_ce_1: 0.73746/0.89430, loss_verb_ce_1: 0.99412/1.22952, loss_sub_bbox_1: 0.45375/0.46304, loss_obj_bbox_1: 0.27374/0.51091, loss_sub_giou_1: 0.64501/0.73301, loss_obj_giou_1: 0.98718/1.11853, obj_cardinality_error_1: 1.00000/2.96818] items per batch[1] items per second[0.80] total items[660] mini batches[   660] memory[1297] epoch remaining[0:04:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[670/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.62792/22.89924, loss_obj_ce: 0.92212/0.88025, obj_class_error: 100.00000/83.27887, loss_verb_ce: 1.16998/1.20881, loss_sub_bbox: 0.17861/0.46470, loss_obj_bbox: 0.21826/0.51438, loss_sub_giou: 0.38648/0.73219, loss_obj_giou: 0.74920/1.12258, obj_cardinality_error: 1.00000/3.16940, loss_obj_ce_0: 0.86887/0.93659, loss_verb_ce_0: 1.08102/1.25848, loss_sub_bbox_0: 0.23205/0.45291, loss_obj_bbox_0: 0.29741/0.50696, loss_sub_giou_0: 0.60242/0.72208, loss_obj_giou_0: 0.91475/1.10948, obj_cardinality_error_0: 3.00000/3.36045, loss_obj_ce_1: 0.94971/0.89362, loss_verb_ce_1: 1.12501/1.22482, loss_sub_bbox_1: 0.16271/0.46142, loss_obj_bbox_1: 0.23882/0.50813, loss_sub_giou_1: 0.34076/0.73026, loss_obj_giou_1: 0.82194/1.11669, obj_cardinality_error_1: 1.00000/2.95746] items per batch[1] items per second[0.85] total items[670] mini batches[   670] memory[1297] epoch remaining[0:04:10]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[680/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.81437/22.82618, loss_obj_ce: 1.22583/0.88039, obj_class_error: 100.00000/83.32157, loss_verb_ce: 1.04125/1.20401, loss_sub_bbox: 0.29840/0.46312, loss_obj_bbox: 0.48933/0.51242, loss_sub_giou: 0.84373/0.73194, loss_obj_giou: 1.05793/1.11824, obj_cardinality_error: 1.50000/3.14779, loss_obj_ce_0: 1.32565/0.93648, loss_verb_ce_0: 1.09633/1.25359, loss_sub_bbox_0: 0.27813/0.45119, loss_obj_bbox_0: 0.41755/0.50486, loss_sub_giou_0: 0.72749/0.72166, loss_obj_giou_0: 0.79241/1.10514, obj_cardinality_error_0: 5.50000/3.35368, loss_obj_ce_1: 1.28746/0.89319, loss_verb_ce_1: 1.02044/1.21969, loss_sub_bbox_1: 0.25481/0.45948, loss_obj_bbox_1: 0.46248/0.50613, loss_sub_giou_1: 0.71240/0.72942, loss_obj_giou_1: 1.02364/1.11216, obj_cardinality_error_1: 2.00000/2.93897] items per batch[1] items per second[0.83] total items[680] mini batches[   680] memory[1297] epoch remaining[0:04:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[690/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.33946/22.74852, loss_obj_ce: 0.36445/0.87872, obj_class_error: 100.00000/83.17371, loss_verb_ce: 0.91291/1.20053, loss_sub_bbox: 0.43705/0.46201, loss_obj_bbox: 0.36233/0.50974, loss_sub_giou: 0.71931/0.73038, loss_obj_giou: 0.78225/1.11220, obj_cardinality_error: 0.00000/3.15290, loss_obj_ce_0: 0.36834/0.93513, loss_verb_ce_0: 0.91317/1.25036, loss_sub_bbox_0: 0.41170/0.44974, loss_obj_bbox_0: 0.41951/0.50217, loss_sub_giou_0: 0.67170/0.71988, loss_obj_giou_0: 0.91158/1.09938, obj_cardinality_error_0: 0.50000/3.35652, loss_obj_ce_1: 0.39185/0.89095, loss_verb_ce_1: 0.97722/1.21564, loss_sub_bbox_1: 0.39269/0.45843, loss_obj_bbox_1: 0.39531/0.50379, loss_sub_giou_1: 0.66032/0.72798, loss_obj_giou_1: 0.81659/1.10614, obj_cardinality_error_1: 0.00000/2.92754] items per batch[1] items per second[0.79] total items[690] mini batches[   690] memory[1297] epoch remaining[0:04:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[700/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.63505/22.67363, loss_obj_ce: 0.97704/0.87897, obj_class_error: 66.66667/83.17519, loss_verb_ce: 0.87865/1.19634, loss_sub_bbox: 0.48839/0.45971, loss_obj_bbox: 0.21182/0.50722, loss_sub_giou: 0.51949/0.72745, loss_obj_giou: 0.63995/1.10736, obj_cardinality_error: 1.50000/3.13786, loss_obj_ce_0: 1.01646/0.93738, loss_verb_ce_0: 0.97731/1.24735, loss_sub_bbox_0: 0.50517/0.44749, loss_obj_bbox_0: 0.31891/0.49967, loss_sub_giou_0: 0.57215/0.71672, loss_obj_giou_0: 0.70698/1.09611, obj_cardinality_error_0: 1.50000/3.36000, loss_obj_ce_1: 0.99961/0.89211, loss_verb_ce_1: 0.86339/1.21157, loss_sub_bbox_1: 0.45906/0.45629, loss_obj_bbox_1: 0.28728/0.50140, loss_sub_giou_1: 0.51013/0.72536, loss_obj_giou_1: 0.57798/1.10222, obj_cardinality_error_1: 2.00000/2.91429] items per batch[1] items per second[0.77] total items[700] mini batches[   700] memory[1297] epoch remaining[0:04:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[710/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.62393/22.60834, loss_obj_ce: 0.52865/0.87780, obj_class_error: 75.00000/83.10935, loss_verb_ce: 0.73784/1.19217, loss_sub_bbox: 0.24716/0.45823, loss_obj_bbox: 0.26701/0.50508, loss_sub_giou: 0.42398/0.72615, loss_obj_giou: 0.76775/1.10462, obj_cardinality_error: 1.50000/3.12394, loss_obj_ce_0: 0.62414/0.93680, loss_verb_ce_0: 0.75017/1.24341, loss_sub_bbox_0: 0.23742/0.44610, loss_obj_bbox_0: 0.32193/0.49809, loss_sub_giou_0: 0.43146/0.71555, loss_obj_giou_0: 0.91410/1.09386, obj_cardinality_error_0: 2.00000/3.35282, loss_obj_ce_1: 0.52105/0.89062, loss_verb_ce_1: 0.69925/1.20749, loss_sub_bbox_1: 0.20554/0.45472, loss_obj_bbox_1: 0.31037/0.49929, loss_sub_giou_1: 0.26711/0.72373, loss_obj_giou_1: 0.79761/1.09927, obj_cardinality_error_1: 1.00000/2.89366] items per batch[1] items per second[0.81] total items[710] mini batches[   710] memory[1297] epoch remaining[0:04:05]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[720/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.92087/22.55782, loss_obj_ce: 0.81111/0.87923, obj_class_error: 75.00000/83.10132, loss_verb_ce: 0.90831/1.18815, loss_sub_bbox: 0.38428/0.45652, loss_obj_bbox: 0.66306/0.50375, loss_sub_giou: 0.55103/0.72453, loss_obj_giou: 1.22618/1.10235, obj_cardinality_error: 1.00000/3.10833, loss_obj_ce_0: 0.86301/0.93899, loss_verb_ce_0: 0.93582/1.23945, loss_sub_bbox_0: 0.40591/0.44481, loss_obj_bbox_0: 0.67830/0.49729, loss_sub_giou_0: 0.57484/0.71413, loss_obj_giou_0: 1.12797/1.09203, obj_cardinality_error_0: 2.00000/3.34167, loss_obj_ce_1: 0.74531/0.89141, loss_verb_ce_1: 0.86627/1.20282, loss_sub_bbox_1: 0.42500/0.45336, loss_obj_bbox_1: 0.64451/0.49829, loss_sub_giou_1: 0.64313/0.72249, loss_obj_giou_1: 0.95481/1.09675, obj_cardinality_error_1: 1.00000/2.88264] items per batch[1] items per second[0.88] total items[720] mini batches[   720] memory[1297] epoch remaining[0:04:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[730/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.73778/22.49478, loss_obj_ce: 0.82606/0.87990, obj_class_error: 66.66667/82.98439, loss_verb_ce: 0.86210/1.18337, loss_sub_bbox: 0.45044/0.45496, loss_obj_bbox: 0.37967/0.50189, loss_sub_giou: 0.90318/0.72350, loss_obj_giou: 1.04562/1.09972, obj_cardinality_error: 2.00000/3.10137, loss_obj_ce_0: 0.95049/0.94009, loss_verb_ce_0: 0.94692/1.23515, loss_sub_bbox_0: 0.41126/0.44329, loss_obj_bbox_0: 0.39910/0.49542, loss_sub_giou_0: 0.89235/0.71278, loss_obj_giou_0: 1.04727/1.08929, obj_cardinality_error_0: 3.00000/3.34384, loss_obj_ce_1: 0.87313/0.89138, loss_verb_ce_1: 0.78028/1.19773, loss_sub_bbox_1: 0.43865/0.45183, loss_obj_bbox_1: 0.36610/0.49645, loss_sub_giou_1: 0.93444/0.72156, loss_obj_giou_1: 0.97359/1.09448, obj_cardinality_error_1: 1.50000/2.87740] items per batch[1] items per second[0.89] total items[730] mini batches[   730] memory[1297] epoch remaining[0:04:02]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[740/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.01875/22.43510, loss_obj_ce: 0.94410/0.87919, obj_class_error: 80.00000/82.85520, loss_verb_ce: 0.86209/1.17934, loss_sub_bbox: 0.48363/0.45384, loss_obj_bbox: 0.32486/0.50004, loss_sub_giou: 0.55541/0.72207, loss_obj_giou: 0.83867/1.09734, obj_cardinality_error: 1.50000/3.08108, loss_obj_ce_0: 1.12138/0.94035, loss_verb_ce_0: 0.97226/1.23236, loss_sub_bbox_0: 0.36866/0.44180, loss_obj_bbox_0: 0.34989/0.49350, loss_sub_giou_0: 0.44439/0.71076, loss_obj_giou_0: 0.79650/1.08642, obj_cardinality_error_0: 2.50000/3.33311, loss_obj_ce_1: 1.05528/0.89136, loss_verb_ce_1: 0.84993/1.19328, loss_sub_bbox_1: 0.37779/0.45072, loss_obj_bbox_1: 0.34176/0.49458, loss_sub_giou_1: 0.45719/0.71988, loss_obj_giou_1: 0.82080/1.09157, obj_cardinality_error_1: 1.50000/2.85946] items per batch[1] items per second[0.83] total items[740] mini batches[   740] memory[1297] epoch remaining[0:04:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[750/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.20527/22.36752, loss_obj_ce: 1.59700/0.87933, obj_class_error: 100.00000/82.90232, loss_verb_ce: 0.72379/1.17543, loss_sub_bbox: 0.17072/0.45199, loss_obj_bbox: 0.23900/0.49795, loss_sub_giou: 0.58170/0.72022, loss_obj_giou: 1.10971/1.09431, obj_cardinality_error: 5.50000/3.07067, loss_obj_ce_0: 1.53560/0.94084, loss_verb_ce_0: 0.71509/1.22828, loss_sub_bbox_0: 0.19217/0.43973, loss_obj_bbox_0: 0.23992/0.49168, loss_sub_giou_0: 0.67081/0.70829, loss_obj_giou_0: 1.17993/1.08335, obj_cardinality_error_0: 4.50000/3.32867, loss_obj_ce_1: 1.57533/0.89134, loss_verb_ce_1: 0.71221/1.18855, loss_sub_bbox_1: 0.14763/0.44919, loss_obj_bbox_1: 0.22576/0.49282, loss_sub_giou_1: 0.55320/0.71835, loss_obj_giou_1: 1.06179/1.08858, obj_cardinality_error_1: 5.50000/2.85133] items per batch[1] items per second[0.82] total items[750] mini batches[   750] memory[1297] epoch remaining[0:04:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[760/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.83722/22.30105, loss_obj_ce: 0.51561/0.87544, obj_class_error: 100.00000/82.99571, loss_verb_ce: 0.93392/1.17282, loss_sub_bbox: 0.37276/0.45085, loss_obj_bbox: 0.20499/0.49580, loss_sub_giou: 0.58624/0.71759, loss_obj_giou: 0.67746/1.09114, obj_cardinality_error: 0.50000/3.04276, loss_obj_ce_0: 0.58170/0.93710, loss_verb_ce_0: 0.94801/1.22551, loss_sub_bbox_0: 0.39189/0.43892, loss_obj_bbox_0: 0.24755/0.48982, loss_sub_giou_0: 0.68800/0.70687, loss_obj_giou_0: 0.81996/1.08027, obj_cardinality_error_0: 1.50000/3.30724, loss_obj_ce_1: 0.54536/0.88749, loss_verb_ce_1: 0.91358/1.18572, loss_sub_bbox_1: 0.38739/0.44810, loss_obj_bbox_1: 0.22733/0.49072, loss_sub_giou_1: 0.65615/0.71622, loss_obj_giou_1: 0.59593/1.08529, obj_cardinality_error_1: 0.50000/2.82632] items per batch[1] items per second[0.75] total items[760] mini batches[   760] memory[1308] epoch remaining[0:03:59]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[770/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.30788/22.25273, loss_obj_ce: 1.35246/0.87618, obj_class_error: 88.88889/82.92691, loss_verb_ce: 0.91889/1.16975, loss_sub_bbox: 0.43688/0.44941, loss_obj_bbox: 0.45984/0.49452, loss_sub_giou: 0.54114/0.71505, loss_obj_giou: 0.81936/1.08963, obj_cardinality_error: 3.50000/3.02662, loss_obj_ce_0: 1.55157/0.93893, loss_verb_ce_0: 0.95955/1.22321, loss_sub_bbox_0: 0.31708/0.43736, loss_obj_bbox_0: 0.51721/0.48801, loss_sub_giou_0: 0.44155/0.70422, loss_obj_giou_0: 0.91808/1.07779, obj_cardinality_error_0: 2.50000/3.29481, loss_obj_ce_1: 1.40125/0.88842, loss_verb_ce_1: 0.93258/1.18239, loss_sub_bbox_1: 0.37365/0.44661, loss_obj_bbox_1: 0.45842/0.48972, loss_sub_giou_1: 0.49486/0.71348, loss_obj_giou_1: 0.75783/1.08423, obj_cardinality_error_1: 3.50000/2.81169] items per batch[1] items per second[0.79] total items[770] mini batches[   770] memory[1308] epoch remaining[0:03:57]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[780/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.86719/22.20646, loss_obj_ce: 0.52062/0.87560, obj_class_error: 75.00000/82.92022, loss_verb_ce: 0.92004/1.16719, loss_sub_bbox: 0.40987/0.44855, loss_obj_bbox: 0.33592/0.49357, loss_sub_giou: 0.56530/0.71380, loss_obj_giou: 0.70652/1.08580, obj_cardinality_error: 1.00000/3.00513, loss_obj_ce_0: 0.70208/0.93811, loss_verb_ce_0: 0.92710/1.22036, loss_sub_bbox_0: 0.37571/0.43669, loss_obj_bbox_0: 0.31446/0.48708, loss_sub_giou_0: 0.56914/0.70305, loss_obj_giou_0: 0.82146/1.07470, obj_cardinality_error_0: 2.00000/3.27949, loss_obj_ce_1: 0.56189/0.88754, loss_verb_ce_1: 0.89375/1.17944, loss_sub_bbox_1: 0.40426/0.44597, loss_obj_bbox_1: 0.31337/0.48853, loss_sub_giou_1: 0.65270/0.71270, loss_obj_giou_1: 0.90174/1.08020, obj_cardinality_error_1: 1.00000/2.79167] items per batch[1] items per second[0.82] total items[780] mini batches[   780] memory[1308] epoch remaining[0:03:56]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[790/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.63125/22.14674, loss_obj_ce: 0.89049/0.87601, obj_class_error: 75.00000/82.90691, loss_verb_ce: 0.76698/1.16330, loss_sub_bbox: 0.29418/0.44690, loss_obj_bbox: 0.45119/0.49176, loss_sub_giou: 0.46065/0.71269, loss_obj_giou: 0.91567/1.08359, obj_cardinality_error: 3.00000/2.99873, loss_obj_ce_0: 1.03418/0.93834, loss_verb_ce_0: 0.89346/1.21644, loss_sub_bbox_0: 0.26141/0.43475, loss_obj_bbox_0: 0.40844/0.48567, loss_sub_giou_0: 0.36430/0.70140, loss_obj_giou_0: 0.79659/1.07327, obj_cardinality_error_0: 3.50000/3.27848, loss_obj_ce_1: 0.84298/0.88741, loss_verb_ce_1: 0.77374/1.17538, loss_sub_bbox_1: 0.27236/0.44397, loss_obj_bbox_1: 0.40596/0.48688, loss_sub_giou_1: 0.42010/0.71085, loss_obj_giou_1: 0.80408/1.07811, obj_cardinality_error_1: 3.00000/2.78608] items per batch[1] items per second[0.79] total items[790] mini batches[   790] memory[1308] epoch remaining[0:03:55]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[800/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.52462/22.08286, loss_obj_ce: 0.38868/0.87261, obj_class_error: 66.66667/82.82563, loss_verb_ce: 0.92900/1.15921, loss_sub_bbox: 0.35021/0.44593, loss_obj_bbox: 0.26446/0.49025, loss_sub_giou: 0.44490/0.71012, loss_obj_giou: 0.73247/1.08148, obj_cardinality_error: 1.50000/2.97688, loss_obj_ce_0: 0.53316/0.93581, loss_verb_ce_0: 1.04584/1.21280, loss_sub_bbox_0: 0.27686/0.43337, loss_obj_bbox_0: 0.20759/0.48543, loss_sub_giou_0: 0.34038/0.69845, loss_obj_giou_0: 0.58803/1.07197, obj_cardinality_error_0: 1.50000/3.26125, loss_obj_ce_1: 0.38709/0.88345, loss_verb_ce_1: 0.91868/1.17085, loss_sub_bbox_1: 0.34891/0.44280, loss_obj_bbox_1: 0.25590/0.48585, loss_sub_giou_1: 0.37635/0.70788, loss_obj_giou_1: 0.68668/1.07627, obj_cardinality_error_1: 0.50000/2.76562] items per batch[1] items per second[0.79] total items[800] mini batches[   800] memory[1308] epoch remaining[0:03:54]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[810/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.02376/22.03412, loss_obj_ce: 1.05103/0.87091, obj_class_error: 80.00000/82.66626, loss_verb_ce: 0.65881/1.15435, loss_sub_bbox: 0.39741/0.44560, loss_obj_bbox: 0.66944/0.48986, loss_sub_giou: 0.52122/0.70843, loss_obj_giou: 1.33323/1.08029, obj_cardinality_error: 3.50000/2.96481, loss_obj_ce_0: 1.30628/0.93520, loss_verb_ce_0: 0.78255/1.20856, loss_sub_bbox_0: 0.32398/0.43277, loss_obj_bbox_0: 0.56590/0.48449, loss_sub_giou_0: 0.48075/0.69662, loss_obj_giou_0: 1.09059/1.07064, obj_cardinality_error_0: 5.50000/3.25247, loss_obj_ce_1: 1.17885/0.88235, loss_verb_ce_1: 0.68260/1.16601, loss_sub_bbox_1: 0.31170/0.44253, loss_obj_bbox_1: 0.58261/0.48516, loss_sub_giou_1: 0.48751/0.70606, loss_obj_giou_1: 1.19879/1.07470, obj_cardinality_error_1: 3.00000/2.75185] items per batch[1] items per second[0.77] total items[810] mini batches[   810] memory[1308] epoch remaining[0:03:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[820/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.30692/21.96891, loss_obj_ce: 0.63587/0.86892, obj_class_error: 71.42857/82.50134, loss_verb_ce: 0.64336/1.15018, loss_sub_bbox: 0.28814/0.44392, loss_obj_bbox: 0.20662/0.48780, loss_sub_giou: 0.88864/0.70829, loss_obj_giou: 0.84926/1.07766, obj_cardinality_error: 3.00000/2.97805, loss_obj_ce_0: 0.72650/0.93413, loss_verb_ce_0: 0.70120/1.20502, loss_sub_bbox_0: 0.31753/0.43077, loss_obj_bbox_0: 0.26549/0.48281, loss_sub_giou_0: 0.97378/0.69626, loss_obj_giou_0: 0.91170/1.06790, obj_cardinality_error_0: 3.00000/3.25976, loss_obj_ce_1: 0.57434/0.88059, loss_verb_ce_1: 0.60038/1.16137, loss_sub_bbox_1: 0.29326/0.44085, loss_obj_bbox_1: 0.28435/0.48342, loss_sub_giou_1: 0.80398/0.70587, loss_obj_giou_1: 0.91454/1.07224, obj_cardinality_error_1: 2.50000/2.75915] items per batch[1] items per second[0.78] total items[820] mini batches[   820] memory[1308] epoch remaining[0:03:52]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[830/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.58436/21.93187, loss_obj_ce: 0.64229/0.86928, obj_class_error: 75.00000/82.40657, loss_verb_ce: 0.71627/1.14625, loss_sub_bbox: 0.32527/0.44472, loss_obj_bbox: 0.31063/0.48669, loss_sub_giou: 0.40853/0.70707, loss_obj_giou: 0.65639/1.07502, obj_cardinality_error: 1.00000/2.96506, loss_obj_ce_0: 0.68345/0.93478, loss_verb_ce_0: 0.72837/1.20189, loss_sub_bbox_0: 0.42567/0.43141, loss_obj_bbox_0: 0.30815/0.48140, loss_sub_giou_0: 0.59556/0.69507, loss_obj_giou_0: 0.53806/1.06464, obj_cardinality_error_0: 1.50000/3.24458, loss_obj_ce_1: 0.54581/0.88028, loss_verb_ce_1: 0.63374/1.15666, loss_sub_bbox_1: 0.39624/0.44182, loss_obj_bbox_1: 0.28620/0.48254, loss_sub_giou_1: 0.58530/0.70496, loss_obj_giou_1: 0.64182/1.06970, obj_cardinality_error_1: 1.00000/2.74337] items per batch[1] items per second[0.80] total items[830] mini batches[   830] memory[1308] epoch remaining[0:03:50]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[840/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.71734/21.87406, loss_obj_ce: 0.92579/0.86663, obj_class_error: 75.00000/82.26238, loss_verb_ce: 0.74153/1.14215, loss_sub_bbox: 0.23423/0.44353, loss_obj_bbox: 0.27867/0.48497, loss_sub_giou: 0.89313/0.70602, loss_obj_giou: 1.27149/1.07392, obj_cardinality_error: 3.50000/2.95238, loss_obj_ce_0: 1.11290/0.93259, loss_verb_ce_0: 0.69964/1.19817, loss_sub_bbox_0: 0.21668/0.43017, loss_obj_bbox_0: 0.35309/0.47994, loss_sub_giou_0: 0.91138/0.69392, loss_obj_giou_0: 1.28684/1.06312, obj_cardinality_error_0: 5.50000/3.23155, loss_obj_ce_1: 0.89361/0.87778, loss_verb_ce_1: 0.61551/1.15280, loss_sub_bbox_1: 0.23517/0.44075, loss_obj_bbox_1: 0.30446/0.48118, loss_sub_giou_1: 0.93222/0.70382, loss_obj_giou_1: 1.32083/1.06867, obj_cardinality_error_1: 5.00000/2.73274] items per batch[1] items per second[0.81] total items[840] mini batches[   840] memory[1308] epoch remaining[0:03:49]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[850/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.21957/21.82017, loss_obj_ce: 1.37592/0.86510, obj_class_error: 71.42857/82.09984, loss_verb_ce: 1.14292/1.13816, loss_sub_bbox: 0.49837/0.44268, loss_obj_bbox: 0.39048/0.48377, loss_sub_giou: 0.57939/0.70496, loss_obj_giou: 0.59862/1.07079, obj_cardinality_error: 1.50000/2.94824, loss_obj_ce_0: 1.33278/0.93115, loss_verb_ce_0: 1.19559/1.19432, loss_sub_bbox_0: 0.46321/0.42962, loss_obj_bbox_0: 0.45039/0.47903, loss_sub_giou_0: 0.51669/0.69353, loss_obj_giou_0: 0.66826/1.06049, obj_cardinality_error_0: 5.00000/3.22412, loss_obj_ce_1: 1.35393/0.87603, loss_verb_ce_1: 1.14716/1.14855, loss_sub_bbox_1: 0.46028/0.43991, loss_obj_bbox_1: 0.38506/0.47991, loss_sub_giou_1: 0.53600/0.70311, loss_obj_giou_1: 0.66718/1.06565, obj_cardinality_error_1: 1.00000/2.72824] items per batch[1] items per second[0.89] total items[850] mini batches[   850] memory[1308] epoch remaining[0:03:48]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[860/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.80630/21.77786, loss_obj_ce: 1.07341/0.86524, obj_class_error: 77.77778/82.01290, loss_verb_ce: 0.88359/1.13457, loss_sub_bbox: 0.25736/0.44220, loss_obj_bbox: 0.21614/0.48272, loss_sub_giou: 0.58838/0.70405, loss_obj_giou: 0.80699/1.06846, obj_cardinality_error: 1.00000/2.93140, loss_obj_ce_0: 1.17294/0.93196, loss_verb_ce_0: 0.93949/1.19107, loss_sub_bbox_0: 0.28042/0.42887, loss_obj_bbox_0: 0.24123/0.47798, loss_sub_giou_0: 0.52526/0.69209, loss_obj_giou_0: 0.95178/1.05772, obj_cardinality_error_0: 1.50000/3.23895, loss_obj_ce_1: 1.08744/0.87664, loss_verb_ce_1: 0.86687/1.14509, loss_sub_bbox_1: 0.27078/0.43954, loss_obj_bbox_1: 0.23608/0.47883, loss_sub_giou_1: 0.60754/0.70220, loss_obj_giou_1: 0.85762/1.06268, obj_cardinality_error_1: 3.00000/2.72733] items per batch[1] items per second[0.86] total items[860] mini batches[   860] memory[1308] epoch remaining[0:03:46]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[870/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.56414/21.72271, loss_obj_ce: 0.51183/0.86447, obj_class_error: 66.66667/81.93229, loss_verb_ce: 0.80750/1.13187, loss_sub_bbox: 0.27443/0.44139, loss_obj_bbox: 0.25297/0.48042, loss_sub_giou: 0.31342/0.70239, loss_obj_giou: 0.66825/1.06533, obj_cardinality_error: 0.50000/2.92471, loss_obj_ce_0: 0.67599/0.93181, loss_verb_ce_0: 0.83910/1.18835, loss_sub_bbox_0: 0.45034/0.42787, loss_obj_bbox_0: 0.31422/0.47583, loss_sub_giou_0: 0.57885/0.69069, loss_obj_giou_0: 0.83985/1.05532, obj_cardinality_error_0: 1.50000/3.23218, loss_obj_ce_1: 0.50226/0.87602, loss_verb_ce_1: 0.79372/1.14224, loss_sub_bbox_1: 0.28519/0.43865, loss_obj_bbox_1: 0.24010/0.47650, loss_sub_giou_1: 0.36938/0.70055, loss_obj_giou_1: 0.68060/1.05954, obj_cardinality_error_1: 1.00000/2.72241] items per batch[1] items per second[0.84] total items[870] mini batches[   870] memory[1308] epoch remaining[0:03:45]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[880/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.11139/21.67453, loss_obj_ce: 0.50194/0.86314, obj_class_error: 66.66667/81.89776, loss_verb_ce: 0.87200/1.12881, loss_sub_bbox: 0.28224/0.44045, loss_obj_bbox: 0.21694/0.47881, loss_sub_giou: 0.59899/0.70185, loss_obj_giou: 0.79317/1.06453, obj_cardinality_error: 0.50000/2.90909, loss_obj_ce_0: 0.63746/0.93139, loss_verb_ce_0: 1.10010/1.18578, loss_sub_bbox_0: 0.22395/0.42668, loss_obj_bbox_0: 0.38321/0.47422, loss_sub_giou_0: 0.36547/0.68932, loss_obj_giou_0: 1.02494/1.05369, obj_cardinality_error_0: 1.50000/3.22216, loss_obj_ce_1: 0.48715/0.87474, loss_verb_ce_1: 0.90839/1.13878, loss_sub_bbox_1: 0.18782/0.43748, loss_obj_bbox_1: 0.39634/0.47500, loss_sub_giou_1: 0.41420/0.69932, loss_obj_giou_1: 1.30084/1.05820, obj_cardinality_error_1: 0.50000/2.70909] items per batch[1] items per second[0.85] total items[880] mini batches[   880] memory[1308] epoch remaining[0:03:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[890/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.13676/21.62518, loss_obj_ce: 0.61315/0.86243, obj_class_error: 83.33334/81.81744, loss_verb_ce: 0.72207/1.12501, loss_sub_bbox: 0.22803/0.43999, loss_obj_bbox: 0.21197/0.47755, loss_sub_giou: 0.72072/0.70144, loss_obj_giou: 0.69900/1.06260, obj_cardinality_error: 2.00000/2.89270, loss_obj_ce_0: 0.59883/0.93070, loss_verb_ce_0: 0.74334/1.18246, loss_sub_bbox_0: 0.24023/0.42605, loss_obj_bbox_0: 0.25787/0.47292, loss_sub_giou_0: 0.84883/0.68806, loss_obj_giou_0: 0.77522/1.05124, obj_cardinality_error_0: 2.50000/3.21236, loss_obj_ce_1: 0.56407/0.87333, loss_verb_ce_1: 0.73285/1.13439, loss_sub_bbox_1: 0.21701/0.43703, loss_obj_bbox_1: 0.24559/0.47351, loss_sub_giou_1: 0.70311/0.69870, loss_obj_giou_1: 0.71560/1.05531, obj_cardinality_error_1: 0.50000/2.69326] items per batch[1] items per second[0.81] total items[890] mini batches[   890] memory[1308] epoch remaining[0:03:42]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[900/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.47392/21.57161, loss_obj_ce: 0.94630/0.86227, obj_class_error: 57.14286/81.73420, loss_verb_ce: 0.54344/1.12179, loss_sub_bbox: 0.36388/0.43891, loss_obj_bbox: 0.30622/0.47581, loss_sub_giou: 0.72191/0.70008, loss_obj_giou: 0.71008/1.05898, obj_cardinality_error: 3.00000/2.88000, loss_obj_ce_0: 1.08990/0.93135, loss_verb_ce_0: 0.51993/1.17877, loss_sub_bbox_0: 0.34807/0.42503, loss_obj_bbox_0: 0.49750/0.47177, loss_sub_giou_0: 0.74748/0.68646, loss_obj_giou_0: 1.06971/1.04843, obj_cardinality_error_0: 1.00000/3.19722, loss_obj_ce_1: 1.00722/0.87352, loss_verb_ce_1: 0.48510/1.13141, loss_sub_bbox_1: 0.31683/0.43569, loss_obj_bbox_1: 0.37793/0.47174, loss_sub_giou_1: 0.71630/0.69715, loss_obj_giou_1: 0.84196/1.05203, obj_cardinality_error_1: 3.50000/2.68389] items per batch[1] items per second[0.83] total items[900] mini batches[   900] memory[1308] epoch remaining[0:03:41]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[910/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.87838/21.53204, loss_obj_ce: 1.08865/0.86290, obj_class_error: 87.50000/81.72988, loss_verb_ce: 0.96007/1.11857, loss_sub_bbox: 0.42522/0.43829, loss_obj_bbox: 0.48526/0.47510, loss_sub_giou: 0.50296/0.69894, loss_obj_giou: 0.98052/1.05693, obj_cardinality_error: 1.50000/2.87418, loss_obj_ce_0: 0.99585/0.93039, loss_verb_ce_0: 0.90156/1.17434, loss_sub_bbox_0: 0.36361/0.42467, loss_obj_bbox_0: 0.52610/0.47111, loss_sub_giou_0: 0.46052/0.68575, loss_obj_giou_0: 1.24717/1.04784, obj_cardinality_error_0: 0.00000/3.18132, loss_obj_ce_1: 1.01842/0.87348, loss_verb_ce_1: 0.81055/1.12748, loss_sub_bbox_1: 0.43328/0.43512, loss_obj_bbox_1: 0.40538/0.47094, loss_sub_giou_1: 0.53528/0.69590, loss_obj_giou_1: 1.10751/1.05100, obj_cardinality_error_1: 5.00000/2.68132] items per batch[1] items per second[0.88] total items[910] mini batches[   910] memory[1308] epoch remaining[0:03:40]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[920/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.09944/21.49782, loss_obj_ce: 1.32489/0.86301, obj_class_error: 83.33334/81.64965, loss_verb_ce: 0.91739/1.11629, loss_sub_bbox: 0.39212/0.43821, loss_obj_bbox: 0.34997/0.47367, loss_sub_giou: 0.69449/0.69861, loss_obj_giou: 0.94439/1.05515, obj_cardinality_error: 1.50000/2.87663, loss_obj_ce_0: 1.23258/0.92947, loss_verb_ce_0: 0.92548/1.17118, loss_sub_bbox_0: 0.44324/0.42454, loss_obj_bbox_0: 0.33091/0.46979, loss_sub_giou_0: 0.70798/0.68534, loss_obj_giou_0: 1.05680/1.04642, obj_cardinality_error_0: 3.50000/3.16576, loss_obj_ce_1: 1.16710/0.87355, loss_verb_ce_1: 0.86763/1.12494, loss_sub_bbox_1: 0.42894/0.43489, loss_obj_bbox_1: 0.36448/0.46956, loss_sub_giou_1: 0.71234/0.69532, loss_obj_giou_1: 1.06374/1.04950, obj_cardinality_error_1: 8.50000/2.69402] items per batch[1] items per second[0.80] total items[920] mini batches[   920] memory[1308] epoch remaining[0:03:39]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[930/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.61007/21.46518, loss_obj_ce: 0.67549/0.86369, obj_class_error: 75.00000/81.65440, loss_verb_ce: 1.03712/1.11441, loss_sub_bbox: 0.41165/0.43723, loss_obj_bbox: 0.38939/0.47241, loss_sub_giou: 0.51055/0.69821, loss_obj_giou: 0.55455/1.05355, obj_cardinality_error: 1.00000/2.86667, loss_obj_ce_0: 0.77752/0.92835, loss_verb_ce_0: 0.95226/1.16791, loss_sub_bbox_0: 0.30758/0.42413, loss_obj_bbox_0: 0.28838/0.46863, loss_sub_giou_0: 0.47308/0.68586, loss_obj_giou_0: 0.48956/1.04564, obj_cardinality_error_0: 6.50000/3.15806, loss_obj_ce_1: 0.67574/0.87444, loss_verb_ce_1: 0.98482/1.12315, loss_sub_bbox_1: 0.32133/0.43404, loss_obj_bbox_1: 0.42483/0.46841, loss_sub_giou_1: 0.51433/0.69469, loss_obj_giou_1: 0.63297/1.04771, obj_cardinality_error_1: 0.50000/2.68817] items per batch[1] items per second[0.77] total items[930] mini batches[   930] memory[1308] epoch remaining[0:03:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[940/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.65483/21.41696, loss_obj_ce: 0.28036/0.86123, obj_class_error: 66.66667/81.50651, loss_verb_ce: 0.85867/1.11247, loss_sub_bbox: 0.35082/0.43611, loss_obj_bbox: 0.31877/0.47079, loss_sub_giou: 0.56923/0.69675, loss_obj_giou: 1.04491/1.05206, obj_cardinality_error: 1.00000/2.85266, loss_obj_ce_0: 0.28653/0.92542, loss_verb_ce_0: 0.97907/1.16537, loss_sub_bbox_0: 0.36731/0.42314, loss_obj_bbox_0: 0.39115/0.46730, loss_sub_giou_0: 0.62983/0.68479, loss_obj_giou_0: 1.14917/1.04512, obj_cardinality_error_0: 0.50000/3.14415, loss_obj_ce_1: 0.24258/0.87170, loss_verb_ce_1: 0.82785/1.12104, loss_sub_bbox_1: 0.39919/0.43296, loss_obj_bbox_1: 0.30609/0.46663, loss_sub_giou_1: 0.73396/0.69350, loss_obj_giou_1: 1.05372/1.04629, obj_cardinality_error_1: 0.00000/2.67128] items per batch[1] items per second[0.69] total items[940] mini batches[   940] memory[1308] epoch remaining[0:03:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[950/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.51746/21.37292, loss_obj_ce: 0.81222/0.86138, obj_class_error: 75.00000/81.42954, loss_verb_ce: 0.91446/1.11033, loss_sub_bbox: 0.34136/0.43544, loss_obj_bbox: 0.29707/0.46912, loss_sub_giou: 0.29312/0.69534, loss_obj_giou: 0.73370/1.04925, obj_cardinality_error: 1.00000/2.84263, loss_obj_ce_0: 1.09050/0.92571, loss_verb_ce_0: 1.10918/1.16316, loss_sub_bbox_0: 0.33429/0.42239, loss_obj_bbox_0: 0.23936/0.46543, loss_sub_giou_0: 0.28460/0.68342, loss_obj_giou_0: 0.65036/1.04167, obj_cardinality_error_0: 1.50000/3.12842, loss_obj_ce_1: 0.88895/0.87206, loss_verb_ce_1: 0.99966/1.11903, loss_sub_bbox_1: 0.33005/0.43237, loss_obj_bbox_1: 0.35047/0.46492, loss_sub_giou_1: 0.28097/0.69221, loss_obj_giou_1: 0.70495/1.04267, obj_cardinality_error_1: 0.50000/2.66316] items per batch[1] items per second[0.91] total items[950] mini batches[   950] memory[1308] epoch remaining[0:03:35]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[960/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.44248/21.31650, loss_obj_ce: 0.66520/0.85800, obj_class_error: 66.66667/81.29052, loss_verb_ce: 0.89280/1.10805, loss_sub_bbox: 0.35917/0.43394, loss_obj_bbox: 0.42726/0.46729, loss_sub_giou: 0.41718/0.69417, loss_obj_giou: 0.77682/1.04690, obj_cardinality_error: 0.50000/2.82240, loss_obj_ce_0: 0.77630/0.92252, loss_verb_ce_0: 1.17352/1.16166, loss_sub_bbox_0: 0.30569/0.42100, loss_obj_bbox_0: 0.37460/0.46360, loss_sub_giou_0: 0.30077/0.68240, loss_obj_giou_0: 0.86982/1.03920, obj_cardinality_error_0: 2.00000/3.11510, loss_obj_ce_1: 0.58878/0.86852, loss_verb_ce_1: 0.95438/1.11697, loss_sub_bbox_1: 0.43195/0.43128, loss_obj_bbox_1: 0.40988/0.46303, loss_sub_giou_1: 0.45713/0.69117, loss_obj_giou_1: 0.77769/1.03991, obj_cardinality_error_1: 0.50000/2.64583] items per batch[1] items per second[0.87] total items[960] mini batches[   960] memory[1308] epoch remaining[0:03:34]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[970/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.74033/21.28198, loss_obj_ce: 1.13703/0.85678, obj_class_error: 87.50000/81.18418, loss_verb_ce: 0.90222/1.10590, loss_sub_bbox: 0.32782/0.43416, loss_obj_bbox: 0.30802/0.46553, loss_sub_giou: 0.76369/0.69443, loss_obj_giou: 1.07707/1.04521, obj_cardinality_error: 3.00000/2.81186, loss_obj_ce_0: 1.11054/0.92172, loss_verb_ce_0: 0.86562/1.16092, loss_sub_bbox_0: 0.32160/0.42070, loss_obj_bbox_0: 0.20621/0.46162, loss_sub_giou_0: 0.83084/0.68248, loss_obj_giou_0: 1.06061/1.03716, obj_cardinality_error_0: 1.50000/3.10103, loss_obj_ce_1: 1.11717/0.86707, loss_verb_ce_1: 0.87585/1.11476, loss_sub_bbox_1: 0.32923/0.43132, loss_obj_bbox_1: 0.27778/0.46080, loss_sub_giou_1: 0.82904/0.69142, loss_obj_giou_1: 1.10028/1.03722, obj_cardinality_error_1: 3.00000/2.63763] items per batch[1] items per second[0.76] total items[970] mini batches[   970] memory[1308] epoch remaining[0:03:33]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[980/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.69673/21.25878, loss_obj_ce: 0.73813/0.85647, obj_class_error: 75.00000/81.21267, loss_verb_ce: 0.98038/1.10534, loss_sub_bbox: 0.27618/0.43362, loss_obj_bbox: 0.46682/0.46474, loss_sub_giou: 0.51943/0.69350, loss_obj_giou: 0.73527/1.04376, obj_cardinality_error: 0.50000/2.79796, loss_obj_ce_0: 0.87038/0.92200, loss_verb_ce_0: 1.19794/1.16060, loss_sub_bbox_0: 0.29461/0.41981, loss_obj_bbox_0: 0.37937/0.46088, loss_sub_giou_0: 0.45501/0.68072, loss_obj_giou_0: 0.79562/1.03611, obj_cardinality_error_0: 3.50000/3.09082, loss_obj_ce_1: 0.71209/0.86632, loss_verb_ce_1: 0.97253/1.11389, loss_sub_bbox_1: 0.34059/0.43074, loss_obj_bbox_1: 0.30263/0.45988, loss_sub_giou_1: 0.61007/0.69038, loss_obj_giou_1: 0.80854/1.03573, obj_cardinality_error_1: 2.00000/2.62755] items per batch[1] items per second[0.85] total items[980] mini batches[   980] memory[1308] epoch remaining[0:03:31]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[990/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.31713/21.21278, loss_obj_ce: 0.55999/0.85308, obj_class_error: 50.00000/81.01163, loss_verb_ce: 0.89608/1.10290, loss_sub_bbox: 0.30212/0.43306, loss_obj_bbox: 0.46901/0.46440, loss_sub_giou: 0.36589/0.69185, loss_obj_giou: 0.74351/1.04205, obj_cardinality_error: 1.00000/2.77980, loss_obj_ce_0: 0.70693/0.91905, loss_verb_ce_0: 1.04866/1.15891, loss_sub_bbox_0: 0.16985/0.41879, loss_obj_bbox_0: 0.50988/0.45958, loss_sub_giou_0: 0.33943/0.67871, loss_obj_giou_0: 0.89027/1.03337, obj_cardinality_error_0: 2.00000/3.07626, loss_obj_ce_1: 0.57112/0.86326, loss_verb_ce_1: 0.93103/1.11164, loss_sub_bbox_1: 0.31252/0.43000, loss_obj_bbox_1: 0.37940/0.45909, loss_sub_giou_1: 0.42024/0.68866, loss_obj_giou_1: 0.61130/1.03357, obj_cardinality_error_1: 1.00000/2.60960] items per batch[1] items per second[0.85] total items[990] mini batches[   990] memory[1308] epoch remaining[0:03:30]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1000/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.04336/21.20287, loss_obj_ce: 1.41445/0.85244, obj_class_error: 88.88889/80.93794, loss_verb_ce: 0.90994/1.10088, loss_sub_bbox: 0.33428/0.43327, loss_obj_bbox: 0.42102/0.46468, loss_sub_giou: 0.43674/0.69172, loss_obj_giou: 0.77059/1.04221, obj_cardinality_error: 3.00000/2.76850, loss_obj_ce_0: 1.38313/0.91784, loss_verb_ce_0: 0.85273/1.15703, loss_sub_bbox_0: 0.39272/0.41901, loss_obj_bbox_0: 0.43788/0.46000, loss_sub_giou_0: 0.51323/0.67863, loss_obj_giou_0: 0.75664/1.03436, obj_cardinality_error_0: 1.50000/3.06400, loss_obj_ce_1: 1.38396/0.86217, loss_verb_ce_1: 0.93255/1.10940, loss_sub_bbox_1: 0.36404/0.43022, loss_obj_bbox_1: 0.36212/0.45936, loss_sub_giou_1: 0.50441/0.68881, loss_obj_giou_1: 0.70962/1.03371, obj_cardinality_error_1: 3.00000/2.60000] items per batch[1] items per second[0.82] total items[1000] mini batches[  1000] memory[1308] epoch remaining[0:03:29]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1010/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.62883/21.15937, loss_obj_ce: 0.61908/0.85230, obj_class_error: 60.00000/80.87011, loss_verb_ce: 0.91093/1.09853, loss_sub_bbox: 0.26089/0.43208, loss_obj_bbox: 0.21550/0.46302, loss_sub_giou: 0.62252/0.69095, loss_obj_giou: 0.91964/1.04144, obj_cardinality_error: 9.00000/2.77574, loss_obj_ce_0: 0.64758/0.91742, loss_verb_ce_0: 0.93350/1.15431, loss_sub_bbox_0: 0.35137/0.41800, loss_obj_bbox_0: 0.17873/0.45833, loss_sub_giou_0: 0.68354/0.67761, loss_obj_giou_0: 0.85436/1.03301, obj_cardinality_error_0: 1.00000/3.05198, loss_obj_ce_1: 0.57689/0.86171, loss_verb_ce_1: 0.90944/1.10694, loss_sub_bbox_1: 0.30341/0.42910, loss_obj_bbox_1: 0.16884/0.45755, loss_sub_giou_1: 0.68209/0.68791, loss_obj_giou_1: 0.81857/1.03227, obj_cardinality_error_1: 5.00000/2.59455] items per batch[1] items per second[0.84] total items[1010] mini batches[  1010] memory[1308] epoch remaining[0:03:27]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1020/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.00573/21.12989, loss_obj_ce: 0.94383/0.85117, obj_class_error: 66.66667/80.80637, loss_verb_ce: 0.88187/1.09659, loss_sub_bbox: 0.32740/0.43185, loss_obj_bbox: 0.27916/0.46242, loss_sub_giou: 0.96182/0.68959, loss_obj_giou: 1.02579/1.04070, obj_cardinality_error: 3.50000/2.76863, loss_obj_ce_0: 1.12020/0.91670, loss_verb_ce_0: 0.91315/1.15273, loss_sub_bbox_0: 0.26830/0.41742, loss_obj_bbox_0: 0.26958/0.45742, loss_sub_giou_0: 1.05063/0.67666, loss_obj_giou_0: 1.11926/1.03168, obj_cardinality_error_0: 2.00000/3.04020, loss_obj_ce_1: 1.06053/0.86050, loss_verb_ce_1: 0.91501/1.10501, loss_sub_bbox_1: 0.26654/0.42870, loss_obj_bbox_1: 0.27540/0.45663, loss_sub_giou_1: 0.95271/0.68699, loss_obj_giou_1: 1.13496/1.03116, obj_cardinality_error_1: 1.50000/2.58922] items per batch[1] items per second[0.81] total items[1020] mini batches[  1020] memory[1308] epoch remaining[0:03:26]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1030/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.61405/21.09040, loss_obj_ce: 0.83150/0.85039, obj_class_error: 85.71429/80.65484, loss_verb_ce: 0.85508/1.09422, loss_sub_bbox: 0.39734/0.43127, loss_obj_bbox: 0.44160/0.46110, loss_sub_giou: 0.53396/0.68852, loss_obj_giou: 0.75964/1.03931, obj_cardinality_error: 2.00000/2.76505, loss_obj_ce_0: 1.05342/0.91677, loss_verb_ce_0: 0.79596/1.15045, loss_sub_bbox_0: 0.34366/0.41651, loss_obj_bbox_0: 0.27616/0.45608, loss_sub_giou_0: 0.51743/0.67535, loss_obj_giou_0: 0.56703/1.02977, obj_cardinality_error_0: 1.00000/3.02718, loss_obj_ce_1: 0.76533/0.85997, loss_verb_ce_1: 0.71858/1.10285, loss_sub_bbox_1: 0.38388/0.42811, loss_obj_bbox_1: 0.39072/0.45508, loss_sub_giou_1: 0.58524/0.68592, loss_obj_giou_1: 0.67785/1.02893, obj_cardinality_error_1: 1.00000/2.57816] items per batch[1] items per second[0.87] total items[1030] mini batches[  1030] memory[1308] epoch remaining[0:03:25]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1040/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.89915/21.05323, loss_obj_ce: 0.76870/0.84776, obj_class_error: 75.00000/80.57803, loss_verb_ce: 1.00971/1.09255, loss_sub_bbox: 0.40727/0.43076, loss_obj_bbox: 0.21331/0.46018, loss_sub_giou: 0.45262/0.68814, loss_obj_giou: 1.10017/1.03809, obj_cardinality_error: 1.00000/2.75000, loss_obj_ce_0: 0.83550/0.91386, loss_verb_ce_0: 1.01823/1.14824, loss_sub_bbox_0: 0.40903/0.41579, loss_obj_bbox_0: 0.21231/0.45549, loss_sub_giou_0: 0.47324/0.67445, loss_obj_giou_0: 0.58312/1.02752, obj_cardinality_error_0: 1.50000/3.01394, loss_obj_ce_1: 0.81695/0.85742, loss_verb_ce_1: 1.06799/1.10107, loss_sub_bbox_1: 0.37045/0.42755, loss_obj_bbox_1: 0.21760/0.45444, loss_sub_giou_1: 0.42515/0.68522, loss_obj_giou_1: 0.67689/1.02651, obj_cardinality_error_1: 1.00000/2.56010] items per batch[1] items per second[0.86] total items[1040] mini batches[  1040] memory[1308] epoch remaining[0:03:24]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1050/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.64036/21.01274, loss_obj_ce: 0.84855/0.84827, obj_class_error: 66.66667/80.49626, loss_verb_ce: 0.78093/1.08949, loss_sub_bbox: 0.28838/0.42940, loss_obj_bbox: 0.22139/0.45871, loss_sub_giou: 0.96129/0.68710, loss_obj_giou: 1.10350/1.03723, obj_cardinality_error: 2.00000/2.75810, loss_obj_ce_0: 0.75828/0.91352, loss_verb_ce_0: 0.76737/1.14453, loss_sub_bbox_0: 0.35305/0.41507, loss_obj_bbox_0: 0.22667/0.45434, loss_sub_giou_0: 0.81296/0.67368, loss_obj_giou_0: 1.14252/1.02728, obj_cardinality_error_0: 2.00000/3.00000, loss_obj_ce_1: 0.80650/0.85789, loss_verb_ce_1: 0.67325/1.09759, loss_sub_bbox_1: 0.32667/0.42638, loss_obj_bbox_1: 0.32136/0.45353, loss_sub_giou_1: 0.95394/0.68434, loss_obj_giou_1: 1.46593/1.02663, obj_cardinality_error_1: 1.50000/2.54810] items per batch[1] items per second[0.82] total items[1050] mini batches[  1050] memory[1414] epoch remaining[0:03:22]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1060/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.61883/20.98760, loss_obj_ce: 0.51884/0.84742, obj_class_error: 66.66667/80.41625, loss_verb_ce: 0.82276/1.08710, loss_sub_bbox: 0.63183/0.42910, loss_obj_bbox: 0.53113/0.45753, loss_sub_giou: 1.15081/0.68722, loss_obj_giou: 1.09020/1.03620, obj_cardinality_error: 0.50000/2.75566, loss_obj_ce_0: 0.81505/0.91316, loss_verb_ce_0: 1.08564/1.14250, loss_sub_bbox_0: 0.46231/0.41461, loss_obj_bbox_0: 0.45330/0.45375, loss_sub_giou_0: 0.87921/0.67312, loss_obj_giou_0: 1.10837/1.02760, obj_cardinality_error_0: 1.50000/2.99104, loss_obj_ce_1: 0.51889/0.85710, loss_verb_ce_1: 0.87586/1.09525, loss_sub_bbox_1: 0.59567/0.42611, loss_obj_bbox_1: 0.48579/0.45274, loss_sub_giou_1: 1.02920/0.68448, loss_obj_giou_1: 1.03966/1.02700, obj_cardinality_error_1: 0.50000/2.54198] items per batch[1] items per second[0.87] total items[1060] mini batches[  1060] memory[1414] epoch remaining[0:03:21]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1070/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.80016/20.94320, loss_obj_ce: 0.84866/0.84523, obj_class_error: 71.42857/80.39968, loss_verb_ce: 0.85962/1.08539, loss_sub_bbox: 0.25676/0.42837, loss_obj_bbox: 0.24044/0.45616, loss_sub_giou: 0.44961/0.68661, loss_obj_giou: 0.76407/1.03371, obj_cardinality_error: 2.50000/2.74019, loss_obj_ce_0: 1.04799/0.91138, loss_verb_ce_0: 0.96383/1.14042, loss_sub_bbox_0: 0.19293/0.41386, loss_obj_bbox_0: 0.21339/0.45211, loss_sub_giou_0: 0.34753/0.67273, loss_obj_giou_0: 0.76116/1.02456, obj_cardinality_error_0: 1.50000/2.99439, loss_obj_ce_1: 0.82825/0.85469, loss_verb_ce_1: 0.74895/1.09312, loss_sub_bbox_1: 0.21811/0.42550, loss_obj_bbox_1: 0.23837/0.45115, loss_sub_giou_1: 0.37543/0.68392, loss_obj_giou_1: 0.83267/1.02463, obj_cardinality_error_1: 4.50000/2.52991] items per batch[1] items per second[0.77] total items[1070] mini batches[  1070] memory[1414] epoch remaining[0:03:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1080/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.76550/20.91498, loss_obj_ce: 1.27953/0.84416, obj_class_error: 70.00000/80.26536, loss_verb_ce: 0.89543/1.08335, loss_sub_bbox: 0.49584/0.42785, loss_obj_bbox: 0.42312/0.45540, loss_sub_giou: 0.73515/0.68562, loss_obj_giou: 0.82616/1.03268, obj_cardinality_error: 2.50000/2.72870, loss_obj_ce_0: 1.40030/0.91091, loss_verb_ce_0: 0.98027/1.13925, loss_sub_bbox_0: 0.43364/0.41331, loss_obj_bbox_0: 0.46868/0.45140, loss_sub_giou_0: 0.72921/0.67153, loss_obj_giou_0: 0.91863/1.02323, obj_cardinality_error_0: 6.00000/2.99352, loss_obj_ce_1: 1.30918/0.85354, loss_verb_ce_1: 0.93890/1.09117, loss_sub_bbox_1: 0.55655/0.42500, loss_obj_bbox_1: 0.48322/0.45064, loss_sub_giou_1: 0.80585/0.68280, loss_obj_giou_1: 0.97965/1.02398, obj_cardinality_error_1: 1.00000/2.51806] items per batch[1] items per second[0.85] total items[1080] mini batches[  1080] memory[1414] epoch remaining[0:03:19]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1090/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.90990/20.88121, loss_obj_ce: 0.21648/0.84318, obj_class_error: 33.33334/80.19641, loss_verb_ce: 0.58950/1.08099, loss_sub_bbox: 0.23369/0.42709, loss_obj_bbox: 0.32596/0.45474, loss_sub_giou: 1.05906/0.68533, loss_obj_giou: 0.97968/1.03187, obj_cardinality_error: 0.50000/2.71560, loss_obj_ce_0: 0.45065/0.90983, loss_verb_ce_0: 0.86168/1.13661, loss_sub_bbox_0: 0.26759/0.41286, loss_obj_bbox_0: 0.27136/0.45019, loss_sub_giou_0: 0.88774/0.67126, loss_obj_giou_0: 0.88460/1.02124, obj_cardinality_error_0: 0.50000/2.98211, loss_obj_ce_1: 0.20626/0.85223, loss_verb_ce_1: 0.59194/1.08873, loss_sub_bbox_1: 0.30767/0.42476, loss_obj_bbox_1: 0.26706/0.44966, loss_sub_giou_1: 1.08493/0.68296, loss_obj_giou_1: 0.87093/1.02240, obj_cardinality_error_1: 0.50000/2.50413] items per batch[1] items per second[0.84] total items[1090] mini batches[  1090] memory[1414] epoch remaining[0:03:17]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1100/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.66592/20.84293, loss_obj_ce: 0.52229/0.84186, obj_class_error: 50.00000/80.14235, loss_verb_ce: 0.77504/1.07837, loss_sub_bbox: 0.27245/0.42641, loss_obj_bbox: 0.15858/0.45442, loss_sub_giou: 0.64900/0.68462, loss_obj_giou: 0.49590/1.02869, obj_cardinality_error: 2.50000/2.69909, loss_obj_ce_0: 0.60817/0.90911, loss_verb_ce_0: 0.85865/1.13451, loss_sub_bbox_0: 0.17999/0.41197, loss_obj_bbox_0: 0.29829/0.44968, loss_sub_giou_0: 0.56012/0.67040, loss_obj_giou_0: 0.79983/1.01796, obj_cardinality_error_0: 2.50000/2.97318, loss_obj_ce_1: 0.45079/0.85073, loss_verb_ce_1: 0.77477/1.08600, loss_sub_bbox_1: 0.23950/0.42405, loss_obj_bbox_1: 0.24551/0.44941, loss_sub_giou_1: 0.67238/0.68237, loss_obj_giou_1: 0.60471/1.01960, obj_cardinality_error_1: 1.00000/2.49318] items per batch[1] items per second[0.85] total items[1100] mini batches[  1100] memory[1414] epoch remaining[0:03:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1110/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.09987/20.81006, loss_obj_ce: 0.60130/0.84005, obj_class_error: 66.66667/80.05799, loss_verb_ce: 0.97313/1.07552, loss_sub_bbox: 0.39143/0.42589, loss_obj_bbox: 0.54796/0.45407, loss_sub_giou: 0.60270/0.68403, loss_obj_giou: 0.86358/1.02716, obj_cardinality_error: 0.50000/2.69189, loss_obj_ce_0: 0.78423/0.90788, loss_verb_ce_0: 1.11479/1.13205, loss_sub_bbox_0: 0.38917/0.41158, loss_obj_bbox_0: 0.40478/0.44923, loss_sub_giou_0: 0.66311/0.67024, loss_obj_giou_0: 0.74250/1.01723, obj_cardinality_error_0: 1.50000/2.95946, loss_obj_ce_1: 0.63700/0.84916, loss_verb_ce_1: 1.01035/1.08303, loss_sub_bbox_1: 0.31490/0.42342, loss_obj_bbox_1: 0.58008/0.44888, loss_sub_giou_1: 0.58604/0.68195, loss_obj_giou_1: 0.85206/1.01845, obj_cardinality_error_1: 0.50000/2.47928] items per batch[1] items per second[0.81] total items[1110] mini batches[  1110] memory[1414] epoch remaining[0:03:15]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1120/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.88501/20.76776, loss_obj_ce: 0.54665/0.83907, obj_class_error: 60.00000/79.89626, loss_verb_ce: 0.72109/1.07256, loss_sub_bbox: 0.35495/0.42505, loss_obj_bbox: 0.28131/0.45247, loss_sub_giou: 0.61477/0.68328, loss_obj_giou: 0.77910/1.02541, obj_cardinality_error: 1.50000/2.67946, loss_obj_ce_0: 0.64290/0.90722, loss_verb_ce_0: 0.76781/1.12913, loss_sub_bbox_0: 0.23463/0.41062, loss_obj_bbox_0: 0.31966/0.44841, loss_sub_giou_0: 0.47508/0.66962, loss_obj_giou_0: 0.64062/1.01676, obj_cardinality_error_0: 1.00000/2.94777, loss_obj_ce_1: 0.53813/0.84837, loss_verb_ce_1: 0.71990/1.07988, loss_sub_bbox_1: 0.42741/0.42266, loss_obj_bbox_1: 0.28331/0.44743, loss_sub_giou_1: 0.73836/0.68184, loss_obj_giou_1: 0.73861/1.01650, obj_cardinality_error_1: 0.50000/2.46830] items per batch[1] items per second[0.80] total items[1120] mini batches[  1120] memory[1414] epoch remaining[0:03:14]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1130/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.63583/20.74070, loss_obj_ce: 0.54654/0.83764, obj_class_error: 66.66667/79.84260, loss_verb_ce: 0.80743/1.07057, loss_sub_bbox: 0.29384/0.42465, loss_obj_bbox: 0.14698/0.45171, loss_sub_giou: 0.44076/0.68358, loss_obj_giou: 0.59208/1.02431, obj_cardinality_error: 4.50000/2.66947, loss_obj_ce_0: 0.85638/0.90673, loss_verb_ce_0: 0.90003/1.12773, loss_sub_bbox_0: 0.23414/0.41002, loss_obj_bbox_0: 0.11558/0.44742, loss_sub_giou_0: 0.41509/0.66932, loss_obj_giou_0: 0.56426/1.01535, obj_cardinality_error_0: 1.50000/2.93584, loss_obj_ce_1: 0.60715/0.84736, loss_verb_ce_1: 0.86057/1.07792, loss_sub_bbox_1: 0.27395/0.42207, loss_obj_bbox_1: 0.18142/0.44651, loss_sub_giou_1: 0.48505/0.68207, loss_obj_giou_1: 0.87773/1.01590, obj_cardinality_error_1: 4.00000/2.46018] items per batch[1] items per second[0.77] total items[1130] mini batches[  1130] memory[1414] epoch remaining[0:03:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1140/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.55226/20.71163, loss_obj_ce: 1.06196/0.83650, obj_class_error: 75.00000/79.76761, loss_verb_ce: 0.69711/1.06912, loss_sub_bbox: 0.36595/0.42406, loss_obj_bbox: 0.41239/0.45119, loss_sub_giou: 0.70548/0.68264, loss_obj_giou: 0.76823/1.02228, obj_cardinality_error: 2.50000/2.65658, loss_obj_ce_0: 1.47659/0.90708, loss_verb_ce_0: 0.98558/1.12642, loss_sub_bbox_0: 0.31765/0.40922, loss_obj_bbox_0: 0.43374/0.44656, loss_sub_giou_0: 0.63779/0.66806, loss_obj_giou_0: 0.87794/1.01299, obj_cardinality_error_0: 1.50000/2.93158, loss_obj_ce_1: 1.45127/0.84677, loss_verb_ce_1: 0.89188/1.07651, loss_sub_bbox_1: 0.34739/0.42151, loss_obj_bbox_1: 0.48043/0.44592, loss_sub_giou_1: 0.65425/0.68103, loss_obj_giou_1: 0.87571/1.01403, obj_cardinality_error_1: 2.50000/2.44956] items per batch[1] items per second[0.87] total items[1140] mini batches[  1140] memory[1414] epoch remaining[0:03:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1150/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.67528/20.67331, loss_obj_ce: 0.60345/0.83322, obj_class_error: 62.50000/79.60473, loss_verb_ce: 0.71464/1.06632, loss_sub_bbox: 0.34700/0.42368, loss_obj_bbox: 0.40764/0.45037, loss_sub_giou: 0.91776/0.68186, loss_obj_giou: 1.01831/1.02069, obj_cardinality_error: 2.00000/2.64348, loss_obj_ce_0: 0.89650/0.90502, loss_verb_ce_0: 0.70929/1.12467, loss_sub_bbox_0: 0.33149/0.40858, loss_obj_bbox_0: 0.33237/0.44558, loss_sub_giou_0: 0.80232/0.66693, loss_obj_giou_0: 1.19149/1.01144, obj_cardinality_error_0: 2.00000/2.91696, loss_obj_ce_1: 0.62544/0.84404, loss_verb_ce_1: 0.73005/1.07412, loss_sub_bbox_1: 0.40039/0.42121, loss_obj_bbox_1: 0.41761/0.44544, loss_sub_giou_1: 0.83922/0.67992, loss_obj_giou_1: 0.88156/1.01280, obj_cardinality_error_1: 3.00000/2.43913] items per batch[1] items per second[0.86] total items[1150] mini batches[  1150] memory[1414] epoch remaining[0:03:10]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1160/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.17803/20.65024, loss_obj_ce: 0.71587/0.83241, obj_class_error: 57.14286/79.54286, loss_verb_ce: 0.71348/1.06424, loss_sub_bbox: 0.40008/0.42318, loss_obj_bbox: 0.63848/0.44974, loss_sub_giou: 0.90181/0.68188, loss_obj_giou: 0.90942/1.02023, obj_cardinality_error: 1.50000/2.63233, loss_obj_ce_0: 0.75460/0.90455, loss_verb_ce_0: 0.79486/1.12309, loss_sub_bbox_0: 0.40939/0.40825, loss_obj_bbox_0: 0.48785/0.44481, loss_sub_giou_0: 0.90447/0.66708, loss_obj_giou_0: 0.79200/1.01126, obj_cardinality_error_0: 2.00000/2.90647, loss_obj_ce_1: 0.78170/0.84344, loss_verb_ce_1: 0.82823/1.07229, loss_sub_bbox_1: 0.37801/0.42079, loss_obj_bbox_1: 0.52945/0.44454, loss_sub_giou_1: 0.83855/0.67985, loss_obj_giou_1: 0.79828/1.01204, obj_cardinality_error_1: 1.50000/2.42974] items per batch[1] items per second[0.80] total items[1160] mini batches[  1160] memory[1414] epoch remaining[0:03:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1170/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.14502/20.62497, loss_obj_ce: 0.78076/0.83169, obj_class_error: 75.00000/79.47697, loss_verb_ce: 0.88730/1.06281, loss_sub_bbox: 0.50244/0.42253, loss_obj_bbox: 0.48597/0.44875, loss_sub_giou: 0.53080/0.68122, loss_obj_giou: 0.83036/1.01911, obj_cardinality_error: 1.00000/2.63590, loss_obj_ce_0: 0.74694/0.90349, loss_verb_ce_0: 0.97700/1.12156, loss_sub_bbox_0: 0.41452/0.40788, loss_obj_bbox_0: 0.52723/0.44409, loss_sub_giou_0: 0.48298/0.66696, loss_obj_giou_0: 1.16865/1.01095, obj_cardinality_error_0: 0.50000/2.90171, loss_obj_ce_1: 0.61072/0.84242, loss_verb_ce_1: 0.78961/1.07067, loss_sub_bbox_1: 0.52179/0.42013, loss_obj_bbox_1: 0.43830/0.44387, loss_sub_giou_1: 0.70721/0.67958, loss_obj_giou_1: 0.75313/1.01130, obj_cardinality_error_1: 1.00000/2.42051] items per batch[1] items per second[0.88] total items[1170] mini batches[  1170] memory[1414] epoch remaining[0:03:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1180/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.66976/20.59234, loss_obj_ce: 0.52149/0.82956, obj_class_error: 60.00000/79.36276, loss_verb_ce: 0.77921/1.06044, loss_sub_bbox: 0.45056/0.42256, loss_obj_bbox: 0.43885/0.44788, loss_sub_giou: 0.77742/0.68080, loss_obj_giou: 0.61845/1.01739, obj_cardinality_error: 2.00000/2.62542, loss_obj_ce_0: 0.67166/0.90192, loss_verb_ce_0: 0.84962/1.11925, loss_sub_bbox_0: 0.38218/0.40793, loss_obj_bbox_0: 0.49936/0.44331, loss_sub_giou_0: 0.65720/0.66663, loss_obj_giou_0: 0.40909/1.00936, obj_cardinality_error_0: 1.00000/2.89237, loss_obj_ce_1: 0.52228/0.84046, loss_verb_ce_1: 0.79531/1.06807, loss_sub_bbox_1: 0.31589/0.41993, loss_obj_bbox_1: 0.53267/0.44318, loss_sub_giou_1: 0.69400/0.67912, loss_obj_giou_1: 0.40112/1.00960, obj_cardinality_error_1: 2.00000/2.41229] items per batch[1] items per second[0.87] total items[1180] mini batches[  1180] memory[1414] epoch remaining[0:03:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1190/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.19373/20.55659, loss_obj_ce: 0.26067/0.82737, obj_class_error: 33.33334/79.23826, loss_verb_ce: 0.94760/1.05813, loss_sub_bbox: 0.41280/0.42176, loss_obj_bbox: 0.22039/0.44652, loss_sub_giou: 0.91047/0.68116, loss_obj_giou: 0.98616/1.01736, obj_cardinality_error: 0.50000/2.61975, loss_obj_ce_0: 0.60254/0.90045, loss_verb_ce_0: 1.23531/1.11716, loss_sub_bbox_0: 0.21647/0.40683, loss_obj_bbox_0: 0.24921/0.44186, loss_sub_giou_0: 0.45260/0.66633, loss_obj_giou_0: 0.95772/1.00904, obj_cardinality_error_0: 1.00000/2.89118, loss_obj_ce_1: 0.28321/0.83846, loss_verb_ce_1: 0.93803/1.06585, loss_sub_bbox_1: 0.40414/0.41896, loss_obj_bbox_1: 0.32232/0.44211, loss_sub_giou_1: 0.80879/0.67912, loss_obj_giou_1: 1.12636/1.00994, obj_cardinality_error_1: 0.50000/2.39916] items per batch[1] items per second[0.83] total items[1190] mini batches[  1190] memory[1414] epoch remaining[0:03:05]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1200/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.33428/20.52544, loss_obj_ce: 0.74161/0.82647, obj_class_error: 71.42857/79.17972, loss_verb_ce: 0.81824/1.05627, loss_sub_bbox: 0.59238/0.42140, loss_obj_bbox: 0.36278/0.44557, loss_sub_giou: 0.75726/0.68026, loss_obj_giou: 1.10349/1.01579, obj_cardinality_error: 2.50000/2.61000, loss_obj_ce_0: 0.89853/0.89998, loss_verb_ce_0: 0.88542/1.11558, loss_sub_bbox_0: 0.51711/0.40629, loss_obj_bbox_0: 0.41059/0.44081, loss_sub_giou_0: 0.71757/0.66523, loss_obj_giou_0: 1.38626/1.00773, obj_cardinality_error_0: 3.00000/2.89417, loss_obj_ce_1: 0.79751/0.83740, loss_verb_ce_1: 0.79371/1.06358, loss_sub_bbox_1: 0.54202/0.41860, loss_obj_bbox_1: 0.40246/0.44134, loss_sub_giou_1: 0.71044/0.67821, loss_obj_giou_1: 1.15852/1.00848, obj_cardinality_error_1: 2.50000/2.39167] items per batch[1] items per second[0.76] total items[1200] mini batches[  1200] memory[1414] epoch remaining[0:03:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1210/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.71306/20.50380, loss_obj_ce: 0.43267/0.82695, obj_class_error: 100.00000/79.23921, loss_verb_ce: 1.10404/1.05581, loss_sub_bbox: 0.38585/0.42088, loss_obj_bbox: 0.32098/0.44489, loss_sub_giou: 0.89052/0.67989, loss_obj_giou: 1.14365/1.01535, obj_cardinality_error: 0.50000/2.60165, loss_obj_ce_0: 0.44616/0.89961, loss_verb_ce_0: 1.10034/1.11457, loss_sub_bbox_0: 0.31534/0.40562, loss_obj_bbox_0: 0.30328/0.44000, loss_sub_giou_0: 0.81117/0.66404, loss_obj_giou_0: 0.87821/1.00626, obj_cardinality_error_0: 1.00000/2.88719, loss_obj_ce_1: 0.39918/0.83725, loss_verb_ce_1: 1.05419/1.06298, loss_sub_bbox_1: 0.33055/0.41781, loss_obj_bbox_1: 0.18968/0.44025, loss_sub_giou_1: 0.81628/0.67722, loss_obj_giou_1: 0.76390/1.00687, obj_cardinality_error_1: 0.00000/2.38347] items per batch[1] items per second[0.81] total items[1210] mini batches[  1210] memory[1414] epoch remaining[0:03:02]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1220/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.27259/20.48631, loss_obj_ce: 0.80785/0.82623, obj_class_error: 70.00000/79.16075, loss_verb_ce: 0.85582/1.05445, loss_sub_bbox: 0.36160/0.42090, loss_obj_bbox: 0.35376/0.44465, loss_sub_giou: 0.57678/0.67978, loss_obj_giou: 1.43051/1.01607, obj_cardinality_error: 2.00000/2.59098, loss_obj_ce_0: 0.84048/0.89891, loss_verb_ce_0: 0.72106/1.11299, loss_sub_bbox_0: 0.36445/0.40522, loss_obj_bbox_0: 0.31516/0.43939, loss_sub_giou_0: 0.68219/0.66324, loss_obj_giou_0: 1.28836/1.00629, obj_cardinality_error_0: 0.50000/2.87705, loss_obj_ce_1: 0.84336/0.83704, loss_verb_ce_1: 0.91559/1.06188, loss_sub_bbox_1: 0.31846/0.41717, loss_obj_bbox_1: 0.29354/0.43971, loss_sub_giou_1: 0.55652/0.67604, loss_obj_giou_1: 1.24417/1.00647, obj_cardinality_error_1: 1.50000/2.37746] items per batch[1] items per second[0.85] total items[1220] mini batches[  1220] memory[1414] epoch remaining[0:03:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1230/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.18092/20.45628, loss_obj_ce: 0.41737/0.82521, obj_class_error: 66.66667/79.08008, loss_verb_ce: 0.88696/1.05266, loss_sub_bbox: 0.86798/0.42064, loss_obj_bbox: 0.54825/0.44370, loss_sub_giou: 0.70362/0.67862, loss_obj_giou: 0.84739/1.01516, obj_cardinality_error: 0.50000/2.58821, loss_obj_ce_0: 0.45281/0.89788, loss_verb_ce_0: 0.88663/1.11096, loss_sub_bbox_0: 0.76176/0.40481, loss_obj_bbox_0: 0.56233/0.43848, loss_sub_giou_0: 0.67817/0.66183, loss_obj_giou_0: 0.95500/1.00585, obj_cardinality_error_0: 1.00000/2.86789, loss_obj_ce_1: 0.38814/0.83609, loss_verb_ce_1: 0.82890/1.06016, loss_sub_bbox_1: 0.85297/0.41680, loss_obj_bbox_1: 0.42662/0.43865, loss_sub_giou_1: 0.68315/0.67475, loss_obj_giou_1: 0.80047/1.00563, obj_cardinality_error_1: 0.50000/2.37724] items per batch[1] items per second[0.79] total items[1230] mini batches[  1230] memory[1414] epoch remaining[0:03:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1240/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.58417/20.42437, loss_obj_ce: 0.51961/0.82323, obj_class_error: 77.77778/78.95667, loss_verb_ce: 0.53941/1.04964, loss_sub_bbox: 0.33886/0.42012, loss_obj_bbox: 0.30584/0.44310, loss_sub_giou: 0.71224/0.67798, loss_obj_giou: 1.40959/1.01535, obj_cardinality_error: 3.00000/2.58306, loss_obj_ce_0: 0.63268/0.89666, loss_verb_ce_0: 0.60425/1.10917, loss_sub_bbox_0: 0.30686/0.40410, loss_obj_bbox_0: 0.25804/0.43775, loss_sub_giou_0: 0.60059/0.66101, loss_obj_giou_0: 1.14550/1.00541, obj_cardinality_error_0: 3.50000/2.85645, loss_obj_ce_1: 0.53374/0.83462, loss_verb_ce_1: 0.55986/1.05803, loss_sub_bbox_1: 0.31720/0.41620, loss_obj_bbox_1: 0.30038/0.43759, loss_sub_giou_1: 0.65977/0.67398, loss_obj_giou_1: 1.39545/1.00528, obj_cardinality_error_1: 4.00000/2.37500] items per batch[1] items per second[0.93] total items[1240] mini batches[  1240] memory[1414] epoch remaining[0:02:58]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1250/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.97244/20.39439, loss_obj_ce: 0.51336/0.82368, obj_class_error: 75.00000/78.87490, loss_verb_ce: 0.84885/1.04667, loss_sub_bbox: 0.31055/0.41949, loss_obj_bbox: 0.52931/0.44257, loss_sub_giou: 0.31861/0.67711, loss_obj_giou: 1.09967/1.01547, obj_cardinality_error: 1.50000/2.58000, loss_obj_ce_0: 0.66770/0.89804, loss_verb_ce_0: 0.93325/1.10669, loss_sub_bbox_0: 0.26134/0.40324, loss_obj_bbox_0: 0.37858/0.43662, loss_sub_giou_0: 0.28169/0.65990, loss_obj_giou_0: 0.96646/1.00449, obj_cardinality_error_0: 1.50000/2.85680, loss_obj_ce_1: 0.56306/0.83535, loss_verb_ce_1: 0.83687/1.05541, loss_sub_bbox_1: 0.29723/0.41548, loss_obj_bbox_1: 0.31361/0.43664, loss_sub_giou_1: 0.29084/0.67300, loss_obj_giou_1: 0.80653/1.00471, obj_cardinality_error_1: 1.00000/2.37280] items per batch[1] items per second[0.82] total items[1250] mini batches[  1250] memory[1414] epoch remaining[0:02:57]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1260/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.68784/20.36750, loss_obj_ce: 0.67497/0.82193, obj_class_error: 100.00000/78.71856, loss_verb_ce: 1.31730/1.04421, loss_sub_bbox: 0.26025/0.41899, loss_obj_bbox: 1.00102/0.44235, loss_sub_giou: 0.26031/0.67648, loss_obj_giou: 0.92053/1.01572, obj_cardinality_error: 1.50000/2.58214, loss_obj_ce_0: 0.77596/0.89670, loss_verb_ce_0: 1.50076/1.10497, loss_sub_bbox_0: 0.24161/0.40241, loss_obj_bbox_0: 1.11998/0.43635, loss_sub_giou_0: 0.22908/0.65902, loss_obj_giou_0: 0.90866/1.00436, obj_cardinality_error_0: 3.00000/2.84841, loss_obj_ce_1: 0.67978/0.83365, loss_verb_ce_1: 1.39411/1.05335, loss_sub_bbox_1: 0.22671/0.41469, loss_obj_bbox_1: 1.05333/0.43637, loss_sub_giou_1: 0.24513/0.67218, loss_obj_giou_1: 0.81184/1.00454, obj_cardinality_error_1: 1.50000/2.36627] items per batch[1] items per second[0.84] total items[1260] mini batches[  1260] memory[1414] epoch remaining[0:02:56]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1270/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.36430/20.34016, loss_obj_ce: 0.28329/0.82140, obj_class_error: 50.00000/78.58192, loss_verb_ce: 0.79539/1.04273, loss_sub_bbox: 0.30740/0.41827, loss_obj_bbox: 0.29244/0.44175, loss_sub_giou: 0.73882/0.67560, loss_obj_giou: 0.77018/1.01493, obj_cardinality_error: 8.50000/2.59685, loss_obj_ce_0: 0.30115/0.89613, loss_verb_ce_0: 0.77790/1.10356, loss_sub_bbox_0: 0.32201/0.40181, loss_obj_bbox_0: 0.28844/0.43569, loss_sub_giou_0: 0.68567/0.65827, loss_obj_giou_0: 0.76759/1.00327, obj_cardinality_error_0: 0.50000/2.84331, loss_obj_ce_1: 0.25678/0.83258, loss_verb_ce_1: 0.61031/1.05118, loss_sub_bbox_1: 0.33609/0.41414, loss_obj_bbox_1: 0.33337/0.43567, loss_sub_giou_1: 0.64535/0.67137, loss_obj_giou_1: 0.84887/1.00334, obj_cardinality_error_1: 6.50000/2.36496] items per batch[1] items per second[0.82] total items[1270] mini batches[  1270] memory[1414] epoch remaining[0:02:55]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1280/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.92637/20.32175, loss_obj_ce: 0.73322/0.82121, obj_class_error: 75.00000/78.59702, loss_verb_ce: 0.97222/1.04137, loss_sub_bbox: 0.28528/0.41791, loss_obj_bbox: 0.35064/0.44138, loss_sub_giou: 0.33364/0.67472, loss_obj_giou: 0.67787/1.01351, obj_cardinality_error: 0.50000/2.58867, loss_obj_ce_0: 0.61386/0.89498, loss_verb_ce_0: 0.91537/1.10140, loss_sub_bbox_0: 0.35106/0.40193, loss_obj_bbox_0: 0.28744/0.43549, loss_sub_giou_0: 0.35496/0.65777, loss_obj_giou_0: 1.02289/1.00321, obj_cardinality_error_0: 0.50000/2.83828, loss_obj_ce_1: 0.75079/0.83202, loss_verb_ce_1: 1.00650/1.04960, loss_sub_bbox_1: 0.35007/0.41423, loss_obj_bbox_1: 0.29063/0.43558, loss_sub_giou_1: 0.33664/0.67060, loss_obj_giou_1: 0.52654/1.00270, obj_cardinality_error_1: 1.00000/2.35898] items per batch[1] items per second[0.83] total items[1280] mini batches[  1280] memory[1414] epoch remaining[0:02:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1290/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.85111/20.29040, loss_obj_ce: 0.97617/0.82042, obj_class_error: 77.77778/78.58421, loss_verb_ce: 0.82576/1.03989, loss_sub_bbox: 0.25341/0.41705, loss_obj_bbox: 0.28740/0.44035, loss_sub_giou: 0.65646/0.67458, loss_obj_giou: 1.15646/1.01247, obj_cardinality_error: 8.00000/2.58217, loss_obj_ce_0: 1.11034/0.89414, loss_verb_ce_0: 0.84422/1.10007, loss_sub_bbox_0: 0.23895/0.40104, loss_obj_bbox_0: 0.39346/0.43436, loss_sub_giou_0: 0.55264/0.65748, loss_obj_giou_0: 1.28071/1.00236, obj_cardinality_error_0: 2.00000/2.82713, loss_obj_ce_1: 0.90696/0.83110, loss_verb_ce_1: 0.69950/1.04799, loss_sub_bbox_1: 0.29916/0.41322, loss_obj_bbox_1: 0.33378/0.43427, loss_sub_giou_1: 0.65199/0.67013, loss_obj_giou_1: 1.30505/1.00109, obj_cardinality_error_1: 3.50000/2.35233] items per batch[1] items per second[0.74] total items[1290] mini batches[  1290] memory[1414] epoch remaining[0:02:52]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1300/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.96463/20.26906, loss_obj_ce: 0.67085/0.82026, obj_class_error: 75.00000/78.55257, loss_verb_ce: 0.89020/1.03848, loss_sub_bbox: 0.27524/0.41646, loss_obj_bbox: 0.31521/0.43951, loss_sub_giou: 0.53653/0.67385, loss_obj_giou: 0.79805/1.01118, obj_cardinality_error: 0.50000/2.57000, loss_obj_ce_0: 0.64483/0.89401, loss_verb_ce_0: 0.97963/1.09869, loss_sub_bbox_0: 0.29769/0.40052, loss_obj_bbox_0: 0.75629/0.43421, loss_sub_giou_0: 0.46108/0.65675, loss_obj_giou_0: 1.21169/1.00225, obj_cardinality_error_0: 1.00000/2.81654, loss_obj_ce_1: 0.61717/0.83096, loss_verb_ce_1: 0.97154/1.04680, loss_sub_bbox_1: 0.27618/0.41255, loss_obj_bbox_1: 0.45437/0.43372, loss_sub_giou_1: 0.34951/0.66919, loss_obj_giou_1: 1.05472/1.00024, obj_cardinality_error_1: 2.00000/2.34615] items per batch[1] items per second[0.91] total items[1300] mini batches[  1300] memory[1414] epoch remaining[0:02:51]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1310/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.81415/20.23767, loss_obj_ce: 1.08469/0.81923, obj_class_error: 75.00000/78.51764, loss_verb_ce: 0.81684/1.03663, loss_sub_bbox: 0.47914/0.41565, loss_obj_bbox: 0.37891/0.43876, loss_sub_giou: 0.83740/0.67294, loss_obj_giou: 0.97872/1.01044, obj_cardinality_error: 7.00000/2.56527, loss_obj_ce_0: 1.20406/0.89280, loss_verb_ce_0: 0.92138/1.09684, loss_sub_bbox_0: 0.36135/0.39975, loss_obj_bbox_0: 0.29801/0.43322, loss_sub_giou_0: 0.77721/0.65593, loss_obj_giou_0: 0.90709/1.00042, obj_cardinality_error_0: 4.50000/2.80954, loss_obj_ce_1: 1.14504/0.82970, loss_verb_ce_1: 0.82012/1.04498, loss_sub_bbox_1: 0.49035/0.41188, loss_obj_bbox_1: 0.36877/0.43319, loss_sub_giou_1: 0.79152/0.66867, loss_obj_giou_1: 1.03042/0.99951, obj_cardinality_error_1: 7.50000/2.35305] items per batch[1] items per second[0.80] total items[1310] mini batches[  1310] memory[1414] epoch remaining[0:02:50]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1320/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.37094/20.20308, loss_obj_ce: 1.15412/0.81822, obj_class_error: 62.50000/78.40516, loss_verb_ce: 0.75501/1.03505, loss_sub_bbox: 0.30056/0.41479, loss_obj_bbox: 0.31504/0.43784, loss_sub_giou: 0.46090/0.67129, loss_obj_giou: 1.01807/1.00848, obj_cardinality_error: 2.50000/2.55644, loss_obj_ce_0: 1.21987/0.89238, loss_verb_ce_0: 0.79822/1.09592, loss_sub_bbox_0: 0.28141/0.39862, loss_obj_bbox_0: 0.33977/0.43231, loss_sub_giou_0: 0.41919/0.65415, loss_obj_giou_0: 0.92938/0.99873, obj_cardinality_error_0: 2.50000/2.80038, loss_obj_ce_1: 1.36785/0.82911, loss_verb_ce_1: 0.89849/1.04399, loss_sub_bbox_1: 0.26254/0.41083, loss_obj_bbox_1: 0.33198/0.43225, loss_sub_giou_1: 0.38766/0.66691, loss_obj_giou_1: 0.93220/0.99728, obj_cardinality_error_1: 2.50000/2.34470] items per batch[1] items per second[0.77] total items[1320] mini batches[  1320] memory[1414] epoch remaining[0:02:49]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1330/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.27898/20.16811, loss_obj_ce: 1.04920/0.81733, obj_class_error: 85.71429/78.34814, loss_verb_ce: 0.73871/1.03335, loss_sub_bbox: 0.25070/0.41382, loss_obj_bbox: 0.32789/0.43657, loss_sub_giou: 0.60348/0.67081, loss_obj_giou: 0.78904/1.00713, obj_cardinality_error: 0.50000/2.54737, loss_obj_ce_0: 1.15894/0.89145, loss_verb_ce_0: 0.74812/1.09381, loss_sub_bbox_0: 0.28377/0.39769, loss_obj_bbox_0: 0.33421/0.43125, loss_sub_giou_0: 0.57916/0.65367, loss_obj_giou_0: 0.75680/0.99721, obj_cardinality_error_0: 2.00000/2.79211, loss_obj_ce_1: 1.27347/0.82860, loss_verb_ce_1: 0.76979/1.04237, loss_sub_bbox_1: 0.22743/0.40983, loss_obj_bbox_1: 0.30254/0.43116, loss_sub_giou_1: 0.52488/0.66638, loss_obj_giou_1: 0.71444/0.99566, obj_cardinality_error_1: 0.50000/2.33759] items per batch[1] items per second[0.75] total items[1330] mini batches[  1330] memory[1414] epoch remaining[0:02:48]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1340/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.45803/20.14120, loss_obj_ce: 0.85109/0.81684, obj_class_error: 71.42857/78.24358, loss_verb_ce: 0.72523/1.03158, loss_sub_bbox: 0.21129/0.41337, loss_obj_bbox: 0.30232/0.43604, loss_sub_giou: 0.58221/0.67001, loss_obj_giou: 1.02383/1.00573, obj_cardinality_error: 2.50000/2.55672, loss_obj_ce_0: 0.85109/0.89101, loss_verb_ce_0: 0.74695/1.09213, loss_sub_bbox_0: 0.27032/0.39718, loss_obj_bbox_0: 0.38030/0.43058, loss_sub_giou_0: 0.72573/0.65321, loss_obj_giou_0: 1.08688/0.99560, obj_cardinality_error_0: 0.50000/2.78470, loss_obj_ce_1: 0.88635/0.82813, loss_verb_ce_1: 0.74074/1.04077, loss_sub_bbox_1: 0.23547/0.40937, loss_obj_bbox_1: 0.28795/0.43035, loss_sub_giou_1: 0.71171/0.66541, loss_obj_giou_1: 1.09416/0.99408, obj_cardinality_error_1: 1.50000/2.34254] items per batch[1] items per second[0.81] total items[1340] mini batches[  1340] memory[1414] epoch remaining[0:02:46]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1350/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.91957/20.11259, loss_obj_ce: 0.50822/0.81614, obj_class_error: 75.00000/78.13852, loss_verb_ce: 0.75860/1.03020, loss_sub_bbox: 0.29333/0.41309, loss_obj_bbox: 0.38674/0.43534, loss_sub_giou: 0.44596/0.66879, loss_obj_giou: 0.65025/1.00417, obj_cardinality_error: 0.00000/2.54519, loss_obj_ce_0: 0.57970/0.89027, loss_verb_ce_0: 0.81346/1.09050, loss_sub_bbox_0: 0.34211/0.39677, loss_obj_bbox_0: 0.35157/0.42976, loss_sub_giou_0: 0.47514/0.65186, loss_obj_giou_0: 0.61036/0.99383, obj_cardinality_error_0: 1.00000/2.78074, loss_obj_ce_1: 0.52151/0.82750, loss_verb_ce_1: 0.82566/1.03940, loss_sub_bbox_1: 0.33093/0.40896, loss_obj_bbox_1: 0.35920/0.42951, loss_sub_giou_1: 0.47050/0.66405, loss_obj_giou_1: 0.70280/0.99219, obj_cardinality_error_1: 0.00000/2.33222] items per batch[1] items per second[0.87] total items[1350] mini batches[  1350] memory[1414] epoch remaining[0:02:45]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1360/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.62413/20.07817, loss_obj_ce: 0.61955/0.81461, obj_class_error: 75.00000/78.04471, loss_verb_ce: 0.82086/1.02868, loss_sub_bbox: 0.17697/0.41286, loss_obj_bbox: 0.19313/0.43424, loss_sub_giou: 0.40669/0.66827, loss_obj_giou: 1.19188/1.00192, obj_cardinality_error: 1.00000/2.53382, loss_obj_ce_0: 0.71016/0.88908, loss_verb_ce_0: 1.02954/1.08944, loss_sub_bbox_0: 0.13972/0.39614, loss_obj_bbox_0: 0.09739/0.42842, loss_sub_giou_0: 0.38213/0.65061, loss_obj_giou_0: 0.61114/0.99138, obj_cardinality_error_0: 2.00000/2.76875, loss_obj_ce_1: 0.67220/0.82555, loss_verb_ce_1: 0.98464/1.03775, loss_sub_bbox_1: 0.17908/0.40860, loss_obj_bbox_1: 0.10648/0.42847, loss_sub_giou_1: 0.46217/0.66315, loss_obj_giou_1: 0.66620/0.99005, obj_cardinality_error_1: 1.00000/2.32390] items per batch[1] items per second[0.76] total items[1360] mini batches[  1360] memory[1414] epoch remaining[0:02:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1370/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.12745/20.05402, loss_obj_ce: 0.85435/0.81495, obj_class_error: 100.00000/78.08575, loss_verb_ce: 1.14112/1.02794, loss_sub_bbox: 0.36727/0.41232, loss_obj_bbox: 0.35130/0.43342, loss_sub_giou: 0.42904/0.66692, loss_obj_giou: 0.51862/1.00056, obj_cardinality_error: 0.50000/2.52701, loss_obj_ce_0: 0.83356/0.88912, loss_verb_ce_0: 1.13028/1.08842, loss_sub_bbox_0: 0.38661/0.39563, loss_obj_bbox_0: 0.38748/0.42765, loss_sub_giou_0: 0.47354/0.64928, loss_obj_giou_0: 0.72209/0.99002, obj_cardinality_error_0: 3.50000/2.76460, loss_obj_ce_1: 0.81866/0.82564, loss_verb_ce_1: 1.08413/1.03689, loss_sub_bbox_1: 0.39639/0.40797, loss_obj_bbox_1: 0.37064/0.42747, loss_sub_giou_1: 0.46745/0.66182, loss_obj_giou_1: 0.64986/0.98808, obj_cardinality_error_1: 1.00000/2.31752] items per batch[1] items per second[0.85] total items[1370] mini batches[  1370] memory[1414] epoch remaining[0:02:43]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1380/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.05493/20.03767, loss_obj_ce: 0.95969/0.81514, obj_class_error: 80.00000/78.01591, loss_verb_ce: 0.91653/1.02671, loss_sub_bbox: 0.37877/0.41180, loss_obj_bbox: 0.47137/0.43268, loss_sub_giou: 0.58935/0.66681, loss_obj_giou: 1.07719/0.99954, obj_cardinality_error: 0.50000/2.52283, loss_obj_ce_0: 0.99114/0.88914, loss_verb_ce_0: 0.93135/1.08702, loss_sub_bbox_0: 0.42966/0.39550, loss_obj_bbox_0: 0.38296/0.42738, loss_sub_giou_0: 0.58596/0.64929, loss_obj_giou_0: 0.86318/0.98947, obj_cardinality_error_0: 4.00000/2.76739, loss_obj_ce_1: 0.96672/0.82578, loss_verb_ce_1: 0.89672/1.03551, loss_sub_bbox_1: 0.38239/0.40757, loss_obj_bbox_1: 0.40821/0.42693, loss_sub_giou_1: 0.59613/0.66179, loss_obj_giou_1: 0.80293/0.98756, obj_cardinality_error_1: 0.50000/2.31014] items per batch[1] items per second[0.85] total items[1380] mini batches[  1380] memory[1414] epoch remaining[0:02:41]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1390/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.34273/20.01014, loss_obj_ce: 0.67809/0.81411, obj_class_error: 50.00000/77.92827, loss_verb_ce: 0.71076/1.02548, loss_sub_bbox: 0.39091/0.41110, loss_obj_bbox: 0.34151/0.43187, loss_sub_giou: 0.47972/0.66634, loss_obj_giou: 0.49544/0.99850, obj_cardinality_error: 1.00000/2.51187, loss_obj_ce_0: 0.79316/0.88848, loss_verb_ce_0: 0.73400/1.08588, loss_sub_bbox_0: 0.35172/0.39494, loss_obj_bbox_0: 0.23912/0.42614, loss_sub_giou_0: 0.49148/0.64883, loss_obj_giou_0: 0.49295/0.98782, obj_cardinality_error_0: 9.00000/2.77050, loss_obj_ce_1: 0.71115/0.82448, loss_verb_ce_1: 0.75197/1.03409, loss_sub_bbox_1: 0.31670/0.40662, loss_obj_bbox_1: 0.30743/0.42647, loss_sub_giou_1: 0.50801/0.66092, loss_obj_giou_1: 0.43078/0.98692, obj_cardinality_error_1: 1.00000/2.30036] items per batch[1] items per second[0.76] total items[1390] mini batches[  1390] memory[1414] epoch remaining[0:02:40]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1400/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.95771/19.98042, loss_obj_ce: 0.72786/0.81252, obj_class_error: 66.66667/77.81807, loss_verb_ce: 0.73129/1.02378, loss_sub_bbox: 0.36136/0.41097, loss_obj_bbox: 0.27870/0.43080, loss_sub_giou: 0.43018/0.66516, loss_obj_giou: 0.93797/0.99776, obj_cardinality_error: 1.00000/2.50000, loss_obj_ce_0: 1.02728/0.88752, loss_verb_ce_0: 0.84608/1.08459, loss_sub_bbox_0: 0.30690/0.39450, loss_obj_bbox_0: 0.13904/0.42508, loss_sub_giou_0: 0.38103/0.64784, loss_obj_giou_0: 0.53655/0.98715, obj_cardinality_error_0: 3.00000/2.76321, loss_obj_ce_1: 1.01905/0.82280, loss_verb_ce_1: 0.81111/1.03204, loss_sub_bbox_1: 0.33422/0.40645, loss_obj_bbox_1: 0.21041/0.42547, loss_sub_giou_1: 0.40133/0.65961, loss_obj_giou_1: 0.64290/0.98605, obj_cardinality_error_1: 2.00000/2.29036] items per batch[1] items per second[0.76] total items[1400] mini batches[  1400] memory[1414] epoch remaining[0:02:39]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1410/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.75067/19.95302, loss_obj_ce: 0.65075/0.81106, obj_class_error: 100.00000/77.79985, loss_verb_ce: 0.88528/1.02235, loss_sub_bbox: 0.24264/0.41029, loss_obj_bbox: 0.23603/0.42968, loss_sub_giou: 0.69425/0.66453, loss_obj_giou: 0.83082/0.99763, obj_cardinality_error: 0.50000/2.48688, loss_obj_ce_0: 0.57283/0.88620, loss_verb_ce_0: 0.97926/1.08347, loss_sub_bbox_0: 0.31720/0.39390, loss_obj_bbox_0: 0.23640/0.42372, loss_sub_giou_0: 0.60361/0.64708, loss_obj_giou_0: 0.89870/0.98685, obj_cardinality_error_0: 1.50000/2.75709, loss_obj_ce_1: 0.57257/0.82149, loss_verb_ce_1: 0.93747/1.03111, loss_sub_bbox_1: 0.26813/0.40566, loss_obj_bbox_1: 0.21659/0.42446, loss_sub_giou_1: 0.62778/0.65867, loss_obj_giou_1: 0.90288/0.98634, obj_cardinality_error_1: 0.50000/2.27943] items per batch[1] items per second[0.82] total items[1410] mini batches[  1410] memory[1414] epoch remaining[0:02:38]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1420/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.49354/19.93197, loss_obj_ce: 0.50567/0.81069, obj_class_error: 50.00000/77.71426, loss_verb_ce: 0.67476/1.02068, loss_sub_bbox: 0.31020/0.41015, loss_obj_bbox: 0.26989/0.42883, loss_sub_giou: 0.56462/0.66438, loss_obj_giou: 1.21188/0.99695, obj_cardinality_error: 0.50000/2.48662, loss_obj_ce_0: 0.69871/0.88569, loss_verb_ce_0: 1.01745/1.08196, loss_sub_bbox_0: 0.26393/0.39368, loss_obj_bbox_0: 0.33037/0.42287, loss_sub_giou_0: 0.51556/0.64678, loss_obj_giou_0: 0.89721/0.98623, obj_cardinality_error_0: 2.50000/2.75246, loss_obj_ce_1: 0.47972/0.82130, loss_verb_ce_1: 0.78326/1.02965, loss_sub_bbox_1: 0.24923/0.40536, loss_obj_bbox_1: 0.19861/0.42343, loss_sub_giou_1: 0.38567/0.65825, loss_obj_giou_1: 1.22801/0.98632, obj_cardinality_error_1: 0.50000/2.27606] items per batch[1] items per second[0.78] total items[1420] mini batches[  1420] memory[1414] epoch remaining[0:02:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1430/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.64724/19.90739, loss_obj_ce: 1.15777/0.80958, obj_class_error: 83.33334/77.64516, loss_verb_ce: 0.97653/1.01941, loss_sub_bbox: 0.35120/0.41003, loss_obj_bbox: 0.24685/0.42805, loss_sub_giou: 0.45940/0.66348, loss_obj_giou: 0.66978/0.99511, obj_cardinality_error: 1.50000/2.47308, loss_obj_ce_0: 1.11720/0.88457, loss_verb_ce_0: 0.88055/1.08059, loss_sub_bbox_0: 0.49134/0.39376, loss_obj_bbox_0: 0.27543/0.42217, loss_sub_giou_0: 0.51777/0.64592, loss_obj_giou_0: 0.79456/0.98476, obj_cardinality_error_0: 2.00000/2.74406, loss_obj_ce_1: 1.05531/0.81995, loss_verb_ce_1: 0.95193/1.02849, loss_sub_bbox_1: 0.34119/0.40529, loss_obj_bbox_1: 0.26682/0.42267, loss_sub_giou_1: 0.43160/0.65740, loss_obj_giou_1: 0.89377/0.98477, obj_cardinality_error_1: 1.00000/2.26678] items per batch[1] items per second[0.83] total items[1430] mini batches[  1430] memory[1414] epoch remaining[0:02:35]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1440/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.72624/19.87878, loss_obj_ce: 0.79528/0.80855, obj_class_error: 85.71429/77.57884, loss_verb_ce: 0.85466/1.01794, loss_sub_bbox: 0.22653/0.40944, loss_obj_bbox: 0.21895/0.42681, loss_sub_giou: 0.51435/0.66320, loss_obj_giou: 0.85739/0.99412, obj_cardinality_error: 2.50000/2.46563, loss_obj_ce_0: 0.64008/0.88309, loss_verb_ce_0: 0.72969/1.07907, loss_sub_bbox_0: 0.27361/0.39340, loss_obj_bbox_0: 0.29196/0.42130, loss_sub_giou_0: 0.49642/0.64559, loss_obj_giou_0: 1.01273/0.98461, obj_cardinality_error_0: 2.00000/2.73542, loss_obj_ce_1: 0.63077/0.81873, loss_verb_ce_1: 0.74014/1.02682, loss_sub_bbox_1: 0.23849/0.40469, loss_obj_bbox_1: 0.26001/0.42142, loss_sub_giou_1: 0.50301/0.65696, loss_obj_giou_1: 0.85332/0.98367, obj_cardinality_error_1: 4.50000/2.26319] items per batch[1] items per second[0.77] total items[1440] mini batches[  1440] memory[1414] epoch remaining[0:02:34]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1450/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.23719/19.84869, loss_obj_ce: 0.45706/0.80695, obj_class_error: 66.66667/77.47156, loss_verb_ce: 0.78650/1.01616, loss_sub_bbox: 0.34460/0.40927, loss_obj_bbox: 0.33154/0.42612, loss_sub_giou: 0.36734/0.66231, loss_obj_giou: 0.59472/0.99248, obj_cardinality_error: 0.50000/2.45690, loss_obj_ce_0: 0.61203/0.88127, loss_verb_ce_0: 1.16029/1.07747, loss_sub_bbox_0: 0.17440/0.39292, loss_obj_bbox_0: 0.32416/0.42059, loss_sub_giou_0: 0.19672/0.64453, loss_obj_giou_0: 0.67890/0.98307, obj_cardinality_error_0: 1.50000/2.73690, loss_obj_ce_1: 0.38264/0.81690, loss_verb_ce_1: 0.73603/1.02507, loss_sub_bbox_1: 0.39442/0.40451, loss_obj_bbox_1: 0.32520/0.42076, loss_sub_giou_1: 0.37130/0.65630, loss_obj_giou_1: 0.47504/0.98204, obj_cardinality_error_1: 0.50000/2.26379] items per batch[1] items per second[0.82] total items[1450] mini batches[  1450] memory[1414] epoch remaining[0:02:33]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1460/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.50620/19.82356, loss_obj_ce: 0.39364/0.80533, obj_class_error: 40.00000/77.40702, loss_verb_ce: 0.68551/1.01455, loss_sub_bbox: 0.30812/0.40902, loss_obj_bbox: 0.20107/0.42514, loss_sub_giou: 0.88728/0.66200, loss_obj_giou: 1.05984/0.99119, obj_cardinality_error: 1.50000/2.44760, loss_obj_ce_0: 0.47128/0.88000, loss_verb_ce_0: 0.73876/1.07605, loss_sub_bbox_0: 0.24329/0.39255, loss_obj_bbox_0: 0.21359/0.41977, loss_sub_giou_0: 0.89441/0.64438, loss_obj_giou_0: 0.99532/0.98226, obj_cardinality_error_0: 0.50000/2.73801, loss_obj_ce_1: 0.40669/0.81515, loss_verb_ce_1: 0.69314/1.02342, loss_sub_bbox_1: 0.30499/0.40435, loss_obj_bbox_1: 0.26044/0.42015, loss_sub_giou_1: 0.97660/0.65616, loss_obj_giou_1: 1.35759/0.98158, obj_cardinality_error_1: 2.50000/2.25856] items per batch[1] items per second[0.83] total items[1460] mini batches[  1460] memory[1414] epoch remaining[0:02:32]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1470/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.19585/19.80214, loss_obj_ce: 0.66766/0.80458, obj_class_error: 66.66667/77.30566, loss_verb_ce: 0.80125/1.01290, loss_sub_bbox: 0.62461/0.40869, loss_obj_bbox: 0.48019/0.42488, loss_sub_giou: 0.95410/0.66120, loss_obj_giou: 1.12854/0.99068, obj_cardinality_error: 0.50000/2.45748, loss_obj_ce_0: 0.93102/0.87899, loss_verb_ce_0: 0.99637/1.07473, loss_sub_bbox_0: 0.54702/0.39210, loss_obj_bbox_0: 0.35379/0.41918, loss_sub_giou_0: 0.90685/0.64379, loss_obj_giou_0: 1.21176/0.98134, obj_cardinality_error_0: 2.50000/2.75850, loss_obj_ce_1: 1.01111/0.81446, loss_verb_ce_1: 1.14404/1.02218, loss_sub_bbox_1: 0.54025/0.40385, loss_obj_bbox_1: 0.46231/0.41977, loss_sub_giou_1: 0.80988/0.65532, loss_obj_giou_1: 1.17118/0.98100, obj_cardinality_error_1: 1.50000/2.26088] items per batch[1] items per second[0.79] total items[1470] mini batches[  1470] memory[1414] epoch remaining[0:02:31]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1480/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.58054/19.77302, loss_obj_ce: 0.36511/0.80367, obj_class_error: 33.33334/77.22670, loss_verb_ce: 0.78302/1.01210, loss_sub_bbox: 0.37185/0.40804, loss_obj_bbox: 0.25667/0.42388, loss_sub_giou: 0.52341/0.66009, loss_obj_giou: 0.30602/0.98854, obj_cardinality_error: 0.50000/2.45405, loss_obj_ce_0: 0.44386/0.87789, loss_verb_ce_0: 0.88265/1.07427, loss_sub_bbox_0: 0.30729/0.39154, loss_obj_bbox_0: 0.17335/0.41824, loss_sub_giou_0: 0.54678/0.64278, loss_obj_giou_0: 0.24398/0.97923, obj_cardinality_error_0: 1.50000/2.75000, loss_obj_ce_1: 0.37273/0.81310, loss_verb_ce_1: 0.80619/1.02065, loss_sub_bbox_1: 0.35642/0.40341, loss_obj_bbox_1: 0.17123/0.41892, loss_sub_giou_1: 0.49087/0.65445, loss_obj_giou_1: 0.25206/0.97920, obj_cardinality_error_1: 0.50000/2.25507] items per batch[1] items per second[0.81] total items[1480] mini batches[  1480] memory[1414] epoch remaining[0:02:29]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1490/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 10.20399/19.74666, loss_obj_ce: 0.24284/0.80210, obj_class_error: 33.33334/77.18251, loss_verb_ce: 0.76359/1.01139, loss_sub_bbox: 0.28751/0.40735, loss_obj_bbox: 0.13843/0.42326, loss_sub_giou: 0.38013/0.65930, loss_obj_giou: 0.21579/0.98747, obj_cardinality_error: 0.50000/2.44631, loss_obj_ce_0: 0.36724/0.87633, loss_verb_ce_0: 0.86729/1.07345, loss_sub_bbox_0: 0.27000/0.39078, loss_obj_bbox_0: 0.12199/0.41754, loss_sub_giou_0: 0.45128/0.64174, loss_obj_giou_0: 0.20096/0.97770, obj_cardinality_error_0: 1.50000/2.74262, loss_obj_ce_1: 0.37023/0.81152, loss_verb_ce_1: 0.80208/1.01967, loss_sub_bbox_1: 0.15603/0.40266, loss_obj_bbox_1: 0.09021/0.41817, loss_sub_giou_1: 0.32170/0.65385, loss_obj_giou_1: 0.12746/0.97823, obj_cardinality_error_1: 1.00000/2.24765] items per batch[1] items per second[0.93] total items[1490] mini batches[  1490] memory[1414] epoch remaining[0:02:28]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1500/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.94522/19.72042, loss_obj_ce: 0.19796/0.80069, obj_class_error: 50.00000/77.08586, loss_verb_ce: 0.65281/1.00981, loss_sub_bbox: 0.36905/0.40672, loss_obj_bbox: 0.24973/0.42269, loss_sub_giou: 0.73774/0.65865, loss_obj_giou: 0.56015/0.98768, obj_cardinality_error: 1.00000/2.43633, loss_obj_ce_0: 0.34253/0.87487, loss_verb_ce_0: 0.85679/1.07185, loss_sub_bbox_0: 0.24908/0.39011, loss_obj_bbox_0: 0.19209/0.41659, loss_sub_giou_0: 0.68719/0.64127, loss_obj_giou_0: 0.57010/0.97767, obj_cardinality_error_0: 1.00000/2.73333, loss_obj_ce_1: 0.18638/0.81010, loss_verb_ce_1: 0.71734/1.01831, loss_sub_bbox_1: 0.32980/0.40189, loss_obj_bbox_1: 0.17424/0.41729, loss_sub_giou_1: 0.68926/0.65320, loss_obj_giou_1: 0.61009/0.97812, obj_cardinality_error_1: 0.50000/2.23800] items per batch[1] items per second[0.88] total items[1500] mini batches[  1500] memory[1414] epoch remaining[0:02:27]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1510/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.19220/19.68827, loss_obj_ce: 0.77094/0.79994, obj_class_error: 75.00000/77.00684, loss_verb_ce: 0.91226/1.00838, loss_sub_bbox: 0.25401/0.40584, loss_obj_bbox: 0.33599/0.42170, loss_sub_giou: 0.45236/0.65793, loss_obj_giou: 0.78643/0.98595, obj_cardinality_error: 1.00000/2.43377, loss_obj_ce_0: 0.90152/0.87445, loss_verb_ce_0: 0.97528/1.07098, loss_sub_bbox_0: 0.15398/0.38917, loss_obj_bbox_0: 0.27035/0.41539, loss_sub_giou_0: 0.38116/0.64025, loss_obj_giou_0: 0.53469/0.97586, obj_cardinality_error_0: 3.50000/2.73377, loss_obj_ce_1: 0.78993/0.80956, loss_verb_ce_1: 0.91684/1.01748, loss_sub_bbox_1: 0.24359/0.40096, loss_obj_bbox_1: 0.29043/0.41594, loss_sub_giou_1: 0.43557/0.65212, loss_obj_giou_1: 0.65996/0.97602, obj_cardinality_error_1: 1.00000/2.23477] items per batch[1] items per second[0.81] total items[1510] mini batches[  1510] memory[1414] epoch remaining[0:02:25]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1520/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.33771/19.67430, loss_obj_ce: 0.54066/0.79964, obj_class_error: 66.66667/76.94187, loss_verb_ce: 0.68779/1.00713, loss_sub_bbox: 0.34767/0.40568, loss_obj_bbox: 0.22447/0.42115, loss_sub_giou: 0.74572/0.65749, loss_obj_giou: 0.55466/0.98526, obj_cardinality_error: 1.00000/2.42632, loss_obj_ce_0: 0.60420/0.87453, loss_verb_ce_0: 0.85852/1.07016, loss_sub_bbox_0: 0.32825/0.38890, loss_obj_bbox_0: 0.22110/0.41498, loss_sub_giou_0: 0.64859/0.63979, loss_obj_giou_0: 0.54845/0.97617, obj_cardinality_error_0: 1.50000/2.73289, loss_obj_ce_1: 0.57329/0.80952, loss_verb_ce_1: 0.89044/1.01664, loss_sub_bbox_1: 0.23695/0.40058, loss_obj_bbox_1: 0.26109/0.41544, loss_sub_giou_1: 0.58372/0.65139, loss_obj_giou_1: 0.61609/0.97584, obj_cardinality_error_1: 0.50000/2.23191] items per batch[1] items per second[0.77] total items[1520] mini batches[  1520] memory[1414] epoch remaining[0:02:24]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1530/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.49594/19.65943, loss_obj_ce: 0.78449/0.79982, obj_class_error: 75.00000/76.91188, loss_verb_ce: 0.87044/1.00556, loss_sub_bbox: 0.36596/0.40529, loss_obj_bbox: 0.24722/0.42087, loss_sub_giou: 0.92316/0.65760, loss_obj_giou: 0.94988/0.98462, obj_cardinality_error: 0.50000/2.42320, loss_obj_ce_0: 0.80772/0.87514, loss_verb_ce_0: 1.02259/1.06926, loss_sub_bbox_0: 0.28905/0.38843, loss_obj_bbox_0: 0.24291/0.41449, loss_sub_giou_0: 0.68037/0.63965, loss_obj_giou_0: 0.94281/0.97531, obj_cardinality_error_0: 1.00000/2.73105, loss_obj_ce_1: 0.69060/0.80994, loss_verb_ce_1: 0.90333/1.01533, loss_sub_bbox_1: 0.34203/0.40013, loss_obj_bbox_1: 0.24528/0.41510, loss_sub_giou_1: 0.78130/0.65113, loss_obj_giou_1: 1.01178/0.97515, obj_cardinality_error_1: 1.00000/2.23039] items per batch[1] items per second[0.71] total items[1530] mini batches[  1530] memory[1414] epoch remaining[0:02:23]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1540/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.68203/19.63969, loss_obj_ce: 0.62071/0.79926, obj_class_error: 60.00000/76.88323, loss_verb_ce: 0.65908/1.00434, loss_sub_bbox: 0.25792/0.40490, loss_obj_bbox: 0.26938/0.42008, loss_sub_giou: 0.45762/0.65683, loss_obj_giou: 0.80549/0.98403, obj_cardinality_error: 1.50000/2.41916, loss_obj_ce_0: 0.66149/0.87493, loss_verb_ce_0: 0.80425/1.06843, loss_sub_bbox_0: 0.25680/0.38791, loss_obj_bbox_0: 0.26718/0.41353, loss_sub_giou_0: 0.48094/0.63896, loss_obj_giou_0: 0.79183/0.97468, obj_cardinality_error_0: 1.50000/2.72760, loss_obj_ce_1: 0.84602/0.80970, loss_verb_ce_1: 0.96610/1.01433, loss_sub_bbox_1: 0.27258/0.39983, loss_obj_bbox_1: 0.25088/0.41442, loss_sub_giou_1: 0.45540/0.65042, loss_obj_giou_1: 0.76680/0.97502, obj_cardinality_error_1: 0.50000/2.22532] items per batch[1] items per second[0.73] total items[1540] mini batches[  1540] memory[1414] epoch remaining[0:02:22]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1550/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.50243/19.61054, loss_obj_ce: 0.21919/0.79762, obj_class_error: 33.33334/76.85925, loss_verb_ce: 0.60681/1.00337, loss_sub_bbox: 0.27827/0.40456, loss_obj_bbox: 0.18731/0.41918, loss_sub_giou: 0.43611/0.65584, loss_obj_giou: 0.65603/0.98199, obj_cardinality_error: 0.50000/2.40839, loss_obj_ce_0: 0.36797/0.87340, loss_verb_ce_0: 0.73664/1.06727, loss_sub_bbox_0: 0.31314/0.38748, loss_obj_bbox_0: 0.32331/0.41269, loss_sub_giou_0: 0.40856/0.63804, loss_obj_giou_0: 1.12084/0.97325, obj_cardinality_error_0: 1.50000/2.71903, loss_obj_ce_1: 0.40571/0.80821, loss_verb_ce_1: 0.71389/1.01323, loss_sub_bbox_1: 0.23849/0.39939, loss_obj_bbox_1: 0.17599/0.41354, loss_sub_giou_1: 0.34767/0.64935, loss_obj_giou_1: 0.63439/0.97300, obj_cardinality_error_1: 1.50000/2.21677] items per batch[1] items per second[0.77] total items[1550] mini batches[  1550] memory[1414] epoch remaining[0:02:21]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1560/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.75099/19.58985, loss_obj_ce: 0.59316/0.79722, obj_class_error: 60.00000/76.77949, loss_verb_ce: 0.66513/1.00183, loss_sub_bbox: 0.13897/0.40400, loss_obj_bbox: 0.17722/0.41861, loss_sub_giou: 0.33378/0.65525, loss_obj_giou: 0.73688/0.98173, obj_cardinality_error: 1.50000/2.40032, loss_obj_ce_0: 0.74449/0.87327, loss_verb_ce_0: 0.83512/1.06577, loss_sub_bbox_0: 0.13906/0.38704, loss_obj_bbox_0: 0.26966/0.41222, loss_sub_giou_0: 0.39110/0.63769, loss_obj_giou_0: 0.77958/0.97299, obj_cardinality_error_0: 2.50000/2.71571, loss_obj_ce_1: 0.71557/0.80773, loss_verb_ce_1: 0.69409/1.01149, loss_sub_bbox_1: 0.15101/0.39900, loss_obj_bbox_1: 0.24690/0.41296, loss_sub_giou_1: 0.35325/0.64888, loss_obj_giou_1: 0.90746/0.97234, obj_cardinality_error_1: 1.00000/2.21314] items per batch[1] items per second[0.76] total items[1560] mini batches[  1560] memory[1414] epoch remaining[0:02:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1570/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.50100/19.57476, loss_obj_ce: 0.85281/0.79739, obj_class_error: 71.42857/76.70098, loss_verb_ce: 0.74119/1.00040, loss_sub_bbox: 0.34778/0.40380, loss_obj_bbox: 0.47059/0.41854, loss_sub_giou: 0.89706/0.65484, loss_obj_giou: 0.98718/0.98034, obj_cardinality_error: 3.50000/2.40000, loss_obj_ce_0: 0.95520/0.87347, loss_verb_ce_0: 0.84548/1.06443, loss_sub_bbox_0: 0.21171/0.38682, loss_obj_bbox_0: 0.40530/0.41222, loss_sub_giou_0: 0.67338/0.63720, loss_obj_giou_0: 0.92104/0.97225, obj_cardinality_error_0: 1.00000/2.70924, loss_obj_ce_1: 1.02948/0.80785, loss_verb_ce_1: 0.88353/1.01010, loss_sub_bbox_1: 0.28543/0.39872, loss_obj_bbox_1: 0.45623/0.41280, loss_sub_giou_1: 0.81076/0.64843, loss_obj_giou_1: 0.99106/0.97086, obj_cardinality_error_1: 6.00000/2.21561] items per batch[1] items per second[0.84] total items[1570] mini batches[  1570] memory[1414] epoch remaining[0:02:18]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1580/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.95020/19.55941, loss_obj_ce: 0.57333/0.79740, obj_class_error: 60.00000/76.72130, loss_verb_ce: 0.87946/0.99981, loss_sub_bbox: 0.40380/0.40348, loss_obj_bbox: 0.42603/0.41803, loss_sub_giou: 0.69819/0.65471, loss_obj_giou: 0.86444/0.97901, obj_cardinality_error: 1.00000/2.40348, loss_obj_ce_0: 0.64709/0.87343, loss_verb_ce_0: 0.96171/1.06342, loss_sub_bbox_0: 0.47035/0.38659, loss_obj_bbox_0: 0.43026/0.41161, loss_sub_giou_0: 0.79428/0.63718, loss_obj_giou_0: 0.78372/0.97077, obj_cardinality_error_0: 1.00000/2.70316, loss_obj_ce_1: 0.54182/0.80786, loss_verb_ce_1: 0.85032/1.00934, loss_sub_bbox_1: 0.40324/0.39847, loss_obj_bbox_1: 0.35052/0.41229, loss_sub_giou_1: 0.73489/0.64837, loss_obj_giou_1: 0.71895/0.96933, obj_cardinality_error_1: 3.50000/2.22880] items per batch[1] items per second[0.82] total items[1580] mini batches[  1580] memory[1414] epoch remaining[0:02:17]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1590/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.96077/19.54287, loss_obj_ce: 0.74472/0.79777, obj_class_error: 80.00000/76.67686, loss_verb_ce: 0.83668/0.99897, loss_sub_bbox: 0.27182/0.40291, loss_obj_bbox: 0.26459/0.41721, loss_sub_giou: 0.33707/0.65409, loss_obj_giou: 0.66832/0.97889, obj_cardinality_error: 1.00000/2.39686, loss_obj_ce_0: 0.80369/0.87378, loss_verb_ce_0: 0.80634/1.06242, loss_sub_bbox_0: 0.34870/0.38612, loss_obj_bbox_0: 0.24824/0.41099, loss_sub_giou_0: 0.43557/0.63674, loss_obj_giou_0: 0.70984/0.97066, obj_cardinality_error_0: 0.50000/2.69811, loss_obj_ce_1: 0.70752/0.80803, loss_verb_ce_1: 0.78518/1.00830, loss_sub_bbox_1: 0.32718/0.39792, loss_obj_bbox_1: 0.31558/0.41154, loss_sub_giou_1: 0.44738/0.64780, loss_obj_giou_1: 0.80999/0.96901, obj_cardinality_error_1: 1.50000/2.22453] items per batch[1] items per second[0.80] total items[1590] mini batches[  1590] memory[1414] epoch remaining[0:02:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1600/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.16646/19.52192, loss_obj_ce: 0.70406/0.79662, obj_class_error: 75.00000/76.55641, loss_verb_ce: 0.77893/0.99736, loss_sub_bbox: 0.36991/0.40254, loss_obj_bbox: 0.45227/0.41662, loss_sub_giou: 0.67195/0.65385, loss_obj_giou: 0.79475/0.97864, obj_cardinality_error: 0.50000/2.39125, loss_obj_ce_0: 0.87850/0.87281, loss_verb_ce_0: 0.75712/1.06112, loss_sub_bbox_0: 0.26063/0.38570, loss_obj_bbox_0: 0.19284/0.41072, loss_sub_giou_0: 0.49522/0.63627, loss_obj_giou_0: 0.41701/0.97030, obj_cardinality_error_0: 1.50000/2.69156, loss_obj_ce_1: 0.70303/0.80684, loss_verb_ce_1: 0.85434/1.00655, loss_sub_bbox_1: 0.32807/0.39762, loss_obj_bbox_1: 0.25124/0.41095, loss_sub_giou_1: 0.55185/0.64751, loss_obj_giou_1: 0.53193/0.96865, obj_cardinality_error_1: 1.00000/2.22531] items per batch[1] items per second[0.87] total items[1600] mini batches[  1600] memory[1414] epoch remaining[0:02:15]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1610/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.16490/19.50847, loss_obj_ce: 0.48802/0.79657, obj_class_error: 100.00000/76.54630, loss_verb_ce: 0.70514/0.99609, loss_sub_bbox: 0.26322/0.40209, loss_obj_bbox: 0.41510/0.41634, loss_sub_giou: 0.49044/0.65314, loss_obj_giou: 1.16167/0.97988, obj_cardinality_error: 1.00000/2.38478, loss_obj_ce_0: 0.46172/0.87266, loss_verb_ce_0: 0.87974/1.06003, loss_sub_bbox_0: 0.23959/0.38528, loss_obj_bbox_0: 0.32698/0.41013, loss_sub_giou_0: 0.41795/0.63558, loss_obj_giou_0: 1.03378/0.97100, obj_cardinality_error_0: 1.00000/2.68354, loss_obj_ce_1: 0.41932/0.80687, loss_verb_ce_1: 0.70363/1.00531, loss_sub_bbox_1: 0.25592/0.39708, loss_obj_bbox_1: 0.34756/0.41043, loss_sub_giou_1: 0.54919/0.64673, loss_obj_giou_1: 0.94487/0.96979, obj_cardinality_error_1: 4.00000/2.22267] items per batch[1] items per second[0.78] total items[1610] mini batches[  1610] memory[1414] epoch remaining[0:02:14]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1620/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.42501/19.48910, loss_obj_ce: 0.62789/0.79619, obj_class_error: 60.00000/76.53778, loss_verb_ce: 0.77408/0.99510, loss_sub_bbox: 0.19292/0.40139, loss_obj_bbox: 0.12456/0.41547, loss_sub_giou: 0.25437/0.65269, loss_obj_giou: 0.43157/0.97929, obj_cardinality_error: 1.00000/2.37840, loss_obj_ce_0: 0.77350/0.87263, loss_verb_ce_0: 0.90574/1.05946, loss_sub_bbox_0: 0.32831/0.38486, loss_obj_bbox_0: 0.15804/0.40915, loss_sub_giou_0: 0.31326/0.63543, loss_obj_giou_0: 0.49742/0.97003, obj_cardinality_error_0: 0.50000/2.67901, loss_obj_ce_1: 0.72224/0.80659, loss_verb_ce_1: 0.85319/1.00449, loss_sub_bbox_1: 0.24762/0.39645, loss_obj_bbox_1: 0.14168/0.40965, loss_sub_giou_1: 0.27604/0.64617, loss_obj_giou_1: 0.47991/0.96953, obj_cardinality_error_1: 0.00000/2.21728] items per batch[1] items per second[0.78] total items[1620] mini batches[  1620] memory[1414] epoch remaining[0:02:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1630/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.62288/19.47545, loss_obj_ce: 0.24006/0.79507, obj_class_error: 33.33334/76.52733, loss_verb_ce: 0.70592/0.99424, loss_sub_bbox: 0.52198/0.40099, loss_obj_bbox: 0.58859/0.41513, loss_sub_giou: 0.36928/0.65222, loss_obj_giou: 1.03424/0.97905, obj_cardinality_error: 0.50000/2.37086, loss_obj_ce_0: 0.52915/0.87206, loss_verb_ce_0: 1.03044/1.05923, loss_sub_bbox_0: 0.30147/0.38443, loss_obj_bbox_0: 0.60474/0.40900, loss_sub_giou_0: 0.24392/0.63488, loss_obj_giou_0: 1.29498/0.97009, obj_cardinality_error_0: 1.00000/2.67761, loss_obj_ce_1: 0.35792/0.80610, loss_verb_ce_1: 0.80667/1.00437, loss_sub_bbox_1: 0.42210/0.39582, loss_obj_bbox_1: 0.46638/0.40913, loss_sub_giou_1: 0.31403/0.64522, loss_obj_giou_1: 0.89011/0.96885, obj_cardinality_error_1: 0.50000/2.21043] items per batch[1] items per second[0.84] total items[1630] mini batches[  1630] memory[1414] epoch remaining[0:02:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1640/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.98779/19.45939, loss_obj_ce: 0.91388/0.79506, obj_class_error: 83.33334/76.58383, loss_verb_ce: 0.81099/0.99379, loss_sub_bbox: 0.30258/0.40029, loss_obj_bbox: 0.15967/0.41416, loss_sub_giou: 0.46284/0.65143, loss_obj_giou: 0.58220/0.97821, obj_cardinality_error: 0.50000/2.36616, loss_obj_ce_0: 1.01646/0.87252, loss_verb_ce_0: 1.01330/1.05901, loss_sub_bbox_0: 0.27633/0.38385, loss_obj_bbox_0: 0.13689/0.40824, loss_sub_giou_0: 0.43693/0.63448, loss_obj_giou_0: 0.59932/0.96987, obj_cardinality_error_0: 2.50000/2.67470, loss_obj_ce_1: 0.84261/0.80662, loss_verb_ce_1: 0.89572/1.00407, loss_sub_bbox_1: 0.30970/0.39508, loss_obj_bbox_1: 0.16188/0.40824, loss_sub_giou_1: 0.44440/0.64456, loss_obj_giou_1: 0.88151/0.96823, obj_cardinality_error_1: 0.50000/2.21707] items per batch[1] items per second[0.73] total items[1640] mini batches[  1640] memory[1414] epoch remaining[0:02:10]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1650/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.14955/19.44508, loss_obj_ce: 0.71984/0.79483, obj_class_error: 80.00000/76.63998, loss_verb_ce: 0.84937/0.99297, loss_sub_bbox: 0.35216/0.39994, loss_obj_bbox: 0.52450/0.41385, loss_sub_giou: 0.54785/0.65123, loss_obj_giou: 0.47240/0.97748, obj_cardinality_error: 1.00000/2.37242, loss_obj_ce_0: 0.90331/0.87253, loss_verb_ce_0: 0.94631/1.05828, loss_sub_bbox_0: 0.43969/0.38334, loss_obj_bbox_0: 0.30030/0.40762, loss_sub_giou_0: 0.56356/0.63417, loss_obj_giou_0: 0.45718/0.96898, obj_cardinality_error_0: 2.50000/2.67485, loss_obj_ce_1: 0.75414/0.80667, loss_verb_ce_1: 0.91003/1.00358, loss_sub_bbox_1: 0.38542/0.39449, loss_obj_bbox_1: 0.52603/0.40791, loss_sub_giou_1: 0.51260/0.64397, loss_obj_giou_1: 0.48701/0.96770, obj_cardinality_error_1: 3.00000/2.22758] items per batch[1] items per second[0.81] total items[1650] mini batches[  1650] memory[1414] epoch remaining[0:02:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1660/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.47545/19.43313, loss_obj_ce: 0.77440/0.79401, obj_class_error: 100.00000/76.63340, loss_verb_ce: 1.03532/0.99214, loss_sub_bbox: 0.39549/0.39975, loss_obj_bbox: 0.17813/0.41348, loss_sub_giou: 0.56994/0.65034, loss_obj_giou: 0.89115/0.97756, obj_cardinality_error: 0.00000/2.36566, loss_obj_ce_0: 0.81941/0.87168, loss_verb_ce_0: 1.13509/1.05799, loss_sub_bbox_0: 0.33194/0.38331, loss_obj_bbox_0: 0.20210/0.40725, loss_sub_giou_0: 0.53420/0.63354, loss_obj_giou_0: 0.93942/0.96829, obj_cardinality_error_0: 2.00000/2.66777, loss_obj_ce_1: 0.90471/0.80619, loss_verb_ce_1: 1.12407/1.00331, loss_sub_bbox_1: 0.34517/0.39437, loss_obj_bbox_1: 0.17300/0.40758, loss_sub_giou_1: 0.52908/0.64319, loss_obj_giou_1: 0.85962/0.96707, obj_cardinality_error_1: 0.50000/2.22711] items per batch[1] items per second[0.78] total items[1660] mini batches[  1660] memory[1414] epoch remaining[0:02:08]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1670/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.34940/19.40876, loss_obj_ce: 0.48917/0.79355, obj_class_error: 66.66667/76.61614, loss_verb_ce: 0.79600/0.99105, loss_sub_bbox: 0.30590/0.39893, loss_obj_bbox: 0.18571/0.41249, loss_sub_giou: 0.75464/0.64960, loss_obj_giou: 0.92264/0.97681, obj_cardinality_error: 1.00000/2.35808, loss_obj_ce_0: 0.67339/0.87161, loss_verb_ce_0: 0.95595/1.05682, loss_sub_bbox_0: 0.31053/0.38245, loss_obj_bbox_0: 0.21185/0.40634, loss_sub_giou_0: 0.74021/0.63295, loss_obj_giou_0: 0.96600/0.96776, obj_cardinality_error_0: 3.00000/2.66647, loss_obj_ce_1: 0.67898/0.80611, loss_verb_ce_1: 0.95043/1.00240, loss_sub_bbox_1: 0.26902/0.39342, loss_obj_bbox_1: 0.25637/0.40666, loss_sub_giou_1: 0.75156/0.64262, loss_obj_giou_1: 1.11957/0.96647, obj_cardinality_error_1: 1.50000/2.22216] items per batch[1] items per second[0.83] total items[1670] mini batches[  1670] memory[1414] epoch remaining[0:02:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1680/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.75352/19.39319, loss_obj_ce: 0.64624/0.79385, obj_class_error: 50.00000/76.66250, loss_verb_ce: 0.69836/0.99046, loss_sub_bbox: 0.30221/0.39839, loss_obj_bbox: 0.23651/0.41219, loss_sub_giou: 0.40357/0.64878, loss_obj_giou: 0.75414/0.97607, obj_cardinality_error: 1.00000/2.35208, loss_obj_ce_0: 0.74103/0.87169, loss_verb_ce_0: 0.82374/1.05599, loss_sub_bbox_0: 0.23225/0.38185, loss_obj_bbox_0: 0.22468/0.40595, loss_sub_giou_0: 0.40334/0.63225, loss_obj_giou_0: 0.75901/0.96665, obj_cardinality_error_0: 2.50000/2.66429, loss_obj_ce_1: 0.70576/0.80640, loss_verb_ce_1: 0.70819/1.00165, loss_sub_bbox_1: 0.24825/0.39287, loss_obj_bbox_1: 0.28246/0.40623, loss_sub_giou_1: 0.32889/0.64182, loss_obj_giou_1: 0.73509/0.96575, obj_cardinality_error_1: 1.00000/2.21875] items per batch[1] items per second[0.82] total items[1680] mini batches[  1680] memory[1414] epoch remaining[0:02:05]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1690/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.03346/19.37303, loss_obj_ce: 0.64170/0.79361, obj_class_error: 100.00000/76.61387, loss_verb_ce: 1.17536/0.98973, loss_sub_bbox: 0.43333/0.39757, loss_obj_bbox: 0.32960/0.41139, loss_sub_giou: 0.56223/0.64789, loss_obj_giou: 1.23886/0.97608, obj_cardinality_error: 1.50000/2.35325, loss_obj_ce_0: 0.71851/0.87170, loss_verb_ce_0: 1.21886/1.05537, loss_sub_bbox_0: 0.32719/0.38103, loss_obj_bbox_0: 0.27678/0.40513, loss_sub_giou_0: 0.46401/0.63119, loss_obj_giou_0: 1.11959/0.96626, obj_cardinality_error_0: 2.00000/2.65828, loss_obj_ce_1: 0.64192/0.80662, loss_verb_ce_1: 1.17939/1.00116, loss_sub_bbox_1: 0.39313/0.39192, loss_obj_bbox_1: 0.22103/0.40539, loss_sub_giou_1: 0.52436/0.64072, loss_obj_giou_1: 1.02238/0.96534, obj_cardinality_error_1: 1.00000/2.21598] items per batch[1] items per second[0.77] total items[1690] mini batches[  1690] memory[1414] epoch remaining[0:02:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1700/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.65184/19.36315, loss_obj_ce: 1.10112/0.79351, obj_class_error: 100.00000/76.61250, loss_verb_ce: 0.95625/0.98904, loss_sub_bbox: 0.57982/0.39737, loss_obj_bbox: 0.55223/0.41105, loss_sub_giou: 0.70455/0.64781, loss_obj_giou: 0.63686/0.97578, obj_cardinality_error: 2.50000/2.35324, loss_obj_ce_0: 1.01454/0.87174, loss_verb_ce_0: 0.99704/1.05472, loss_sub_bbox_0: 0.78583/0.38091, loss_obj_bbox_0: 0.59162/0.40479, loss_sub_giou_0: 0.93252/0.63095, loss_obj_giou_0: 0.74988/0.96576, obj_cardinality_error_0: 2.50000/2.65618, loss_obj_ce_1: 0.94948/0.80662, loss_verb_ce_1: 0.97319/1.00065, loss_sub_bbox_1: 0.67976/0.39177, loss_obj_bbox_1: 0.49433/0.40497, loss_sub_giou_1: 0.83513/0.64034, loss_obj_giou_1: 0.66582/0.96464, obj_cardinality_error_1: 2.50000/2.21529] items per batch[1] items per second[0.75] total items[1700] mini batches[  1700] memory[1414] epoch remaining[0:02:03]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1710/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.50839/19.35070, loss_obj_ce: 0.90366/0.79364, obj_class_error: 54.54546/76.59480, loss_verb_ce: 0.75687/0.98866, loss_sub_bbox: 0.31204/0.39699, loss_obj_bbox: 0.38357/0.41060, loss_sub_giou: 0.50254/0.64749, loss_obj_giou: 1.08997/0.97526, obj_cardinality_error: 3.50000/2.34854, loss_obj_ce_0: 1.09266/0.87194, loss_verb_ce_0: 0.83849/1.05415, loss_sub_bbox_0: 0.35547/0.38060, loss_obj_bbox_0: 0.30290/0.40406, loss_sub_giou_0: 0.55051/0.63057, loss_obj_giou_0: 0.97817/0.96496, obj_cardinality_error_0: 1.00000/2.64854, loss_obj_ce_1: 1.10980/0.80704, loss_verb_ce_1: 0.81956/1.00034, loss_sub_bbox_1: 0.33259/0.39131, loss_obj_bbox_1: 0.30767/0.40433, loss_sub_giou_1: 0.55014/0.63982, loss_obj_giou_1: 0.91553/0.96397, obj_cardinality_error_1: 4.00000/2.21433] items per batch[1] items per second[0.86] total items[1710] mini batches[  1710] memory[1414] epoch remaining[0:02:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1720/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.48773/19.32711, loss_obj_ce: 0.64284/0.79323, obj_class_error: 66.66667/76.53283, loss_verb_ce: 0.82232/0.98789, loss_sub_bbox: 0.30116/0.39641, loss_obj_bbox: 0.43735/0.40983, loss_sub_giou: 0.53701/0.64657, loss_obj_giou: 1.06100/0.97349, obj_cardinality_error: 1.00000/2.35407, loss_obj_ce_0: 0.80103/0.87150, loss_verb_ce_0: 0.89196/1.05332, loss_sub_bbox_0: 0.27500/0.38007, loss_obj_bbox_0: 0.29476/0.40329, loss_sub_giou_0: 0.63370/0.62975, loss_obj_giou_0: 0.73827/0.96331, obj_cardinality_error_0: 1.50000/2.65087, loss_obj_ce_1: 0.72603/0.80670, loss_verb_ce_1: 0.79303/0.99941, loss_sub_bbox_1: 0.32217/0.39073, loss_obj_bbox_1: 0.33241/0.40362, loss_sub_giou_1: 0.53639/0.63899, loss_obj_giou_1: 0.88975/0.96246, obj_cardinality_error_1: 0.00000/2.22267] items per batch[1] items per second[0.74] total items[1720] mini batches[  1720] memory[1414] epoch remaining[0:02:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1730/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.26942/19.31135, loss_obj_ce: 0.89667/0.79225, obj_class_error: 80.00000/76.53023, loss_verb_ce: 1.18451/0.98747, loss_sub_bbox: 0.35528/0.39603, loss_obj_bbox: 0.26147/0.40923, loss_sub_giou: 0.60798/0.64607, loss_obj_giou: 0.93926/0.97293, obj_cardinality_error: 1.00000/2.35000, loss_obj_ce_0: 0.96402/0.87061, loss_verb_ce_0: 1.04686/1.05269, loss_sub_bbox_0: 0.34504/0.37957, loss_obj_bbox_0: 0.23008/0.40269, loss_sub_giou_0: 0.68518/0.62934, loss_obj_giou_0: 1.05661/0.96311, obj_cardinality_error_0: 1.50000/2.64451, loss_obj_ce_1: 0.76170/0.80558, loss_verb_ce_1: 0.98607/0.99878, loss_sub_bbox_1: 0.49707/0.39040, loss_obj_bbox_1: 0.29235/0.40321, loss_sub_giou_1: 0.81638/0.63862, loss_obj_giou_1: 1.15352/0.96213, obj_cardinality_error_1: 0.50000/2.21676] items per batch[1] items per second[0.75] total items[1730] mini batches[  1730] memory[1414] epoch remaining[0:01:59]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1740/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.45192/19.30195, loss_obj_ce: 0.55972/0.79267, obj_class_error: 100.00000/76.54857, loss_verb_ce: 0.75602/0.98669, loss_sub_bbox: 0.18194/0.39554, loss_obj_bbox: 0.22739/0.40902, loss_sub_giou: 0.19679/0.64608, loss_obj_giou: 0.41389/0.97211, obj_cardinality_error: 1.50000/2.35316, loss_obj_ce_0: 0.65545/0.87140, loss_verb_ce_0: 0.82372/1.05159, loss_sub_bbox_0: 0.21049/0.37920, loss_obj_bbox_0: 0.21603/0.40259, loss_sub_giou_0: 0.27142/0.62960, loss_obj_giou_0: 0.51177/0.96264, obj_cardinality_error_0: 2.00000/2.64569, loss_obj_ce_1: 0.63811/0.80616, loss_verb_ce_1: 0.74532/0.99793, loss_sub_bbox_1: 0.16380/0.38997, loss_obj_bbox_1: 0.18621/0.40314, loss_sub_giou_1: 0.22577/0.63885, loss_obj_giou_1: 0.36423/0.96136, obj_cardinality_error_1: 2.00000/2.21983] items per batch[1] items per second[0.79] total items[1740] mini batches[  1740] memory[1414] epoch remaining[0:01:58]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1750/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.94962/19.29546, loss_obj_ce: 0.70927/0.79213, obj_class_error: 80.00000/76.48503, loss_verb_ce: 0.91249/0.98579, loss_sub_bbox: 0.27711/0.39571, loss_obj_bbox: 0.25410/0.40900, loss_sub_giou: 0.37056/0.64593, loss_obj_giou: 1.18470/0.97147, obj_cardinality_error: 2.00000/2.35257, loss_obj_ce_0: 0.64543/0.87092, loss_verb_ce_0: 0.75898/1.05061, loss_sub_bbox_0: 0.35987/0.37949, loss_obj_bbox_0: 0.19403/0.40279, loss_sub_giou_0: 0.43111/0.62974, loss_obj_giou_0: 0.81357/0.96220, obj_cardinality_error_0: 1.50000/2.64229, loss_obj_ce_1: 0.56492/0.80589, loss_verb_ce_1: 0.78992/0.99720, loss_sub_bbox_1: 0.36150/0.39017, loss_obj_bbox_1: 0.18760/0.40323, loss_sub_giou_1: 0.40550/0.63855, loss_obj_giou_1: 0.81624/0.96047, obj_cardinality_error_1: 1.50000/2.21657] items per batch[1] items per second[0.77] total items[1750] mini batches[  1750] memory[1414] epoch remaining[0:01:57]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1760/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.28860/19.28348, loss_obj_ce: 0.55515/0.79206, obj_class_error: 57.14286/76.47357, loss_verb_ce: 0.78978/0.98529, loss_sub_bbox: 0.32699/0.39528, loss_obj_bbox: 0.32049/0.40862, loss_sub_giou: 0.63585/0.64555, loss_obj_giou: 1.21265/0.97070, obj_cardinality_error: 3.00000/2.34801, loss_obj_ce_0: 0.66147/0.87092, loss_verb_ce_0: 0.74446/1.04986, loss_sub_bbox_0: 0.38557/0.37916, loss_obj_bbox_0: 0.23722/0.40242, loss_sub_giou_0: 0.66821/0.62957, loss_obj_giou_0: 1.15871/0.96157, obj_cardinality_error_0: 4.00000/2.64091, loss_obj_ce_1: 0.50969/0.80585, loss_verb_ce_1: 0.57104/0.99643, loss_sub_bbox_1: 0.34442/0.38979, loss_obj_bbox_1: 0.30186/0.40295, loss_sub_giou_1: 0.63280/0.63843, loss_obj_giou_1: 1.25217/0.96012, obj_cardinality_error_1: 3.50000/2.21477] items per batch[1] items per second[0.75] total items[1760] mini batches[  1760] memory[1414] epoch remaining[0:01:55]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1770/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.97370/19.27042, loss_obj_ce: 0.48963/0.79214, obj_class_error: 50.00000/76.40552, loss_verb_ce: 0.64928/0.98489, loss_sub_bbox: 0.25806/0.39482, loss_obj_bbox: 0.21068/0.40810, loss_sub_giou: 0.43205/0.64522, loss_obj_giou: 1.10047/0.97035, obj_cardinality_error: 0.50000/2.35311, loss_obj_ce_0: 0.54563/0.87092, loss_verb_ce_0: 0.73563/1.04941, loss_sub_bbox_0: 0.25064/0.37870, loss_obj_bbox_0: 0.32899/0.40182, loss_sub_giou_0: 0.40940/0.62920, loss_obj_giou_0: 1.33356/0.96103, obj_cardinality_error_0: 1.50000/2.65593, loss_obj_ce_1: 0.47440/0.80591, loss_verb_ce_1: 0.60806/0.99607, loss_sub_bbox_1: 0.18539/0.38923, loss_obj_bbox_1: 0.24695/0.40224, loss_sub_giou_1: 0.40949/0.63812, loss_obj_giou_1: 1.09138/0.95956, obj_cardinality_error_1: 1.00000/2.21780] items per batch[1] items per second[0.86] total items[1770] mini batches[  1770] memory[1414] epoch remaining[0:01:54]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1780/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.52709/19.24765, loss_obj_ce: 1.08003/0.79133, obj_class_error: 71.42857/76.36826, loss_verb_ce: 0.66539/0.98385, loss_sub_bbox: 0.30900/0.39430, loss_obj_bbox: 0.24636/0.40731, loss_sub_giou: 0.59507/0.64441, loss_obj_giou: 0.58374/0.96942, obj_cardinality_error: 1.50000/2.34663, loss_obj_ce_0: 1.21900/0.87045, loss_verb_ce_0: 0.81658/1.04844, loss_sub_bbox_0: 0.25319/0.37835, loss_obj_bbox_0: 0.23898/0.40086, loss_sub_giou_0: 0.48999/0.62867, loss_obj_giou_0: 0.67572/0.95973, obj_cardinality_error_0: 3.50000/2.65112, loss_obj_ce_1: 1.08417/0.80536, loss_verb_ce_1: 0.84889/0.99525, loss_sub_bbox_1: 0.27971/0.38869, loss_obj_bbox_1: 0.27484/0.40142, loss_sub_giou_1: 0.50148/0.63748, loss_obj_giou_1: 0.63101/0.95839, obj_cardinality_error_1: 1.50000/2.21320] items per batch[1] items per second[0.76] total items[1780] mini batches[  1780] memory[1414] epoch remaining[0:01:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1790/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.53955/19.23577, loss_obj_ce: 0.37509/0.79047, obj_class_error: 66.66667/76.31526, loss_verb_ce: 0.84452/0.98281, loss_sub_bbox: 0.53049/0.39433, loss_obj_bbox: 0.41848/0.40712, loss_sub_giou: 0.54670/0.64421, loss_obj_giou: 0.71304/0.96879, obj_cardinality_error: 2.00000/2.33911, loss_obj_ce_0: 0.57084/0.86984, loss_verb_ce_0: 1.01574/1.04754, loss_sub_bbox_0: 0.56601/0.37834, loss_obj_bbox_0: 0.35899/0.40065, loss_sub_giou_0: 0.54751/0.62841, loss_obj_giou_0: 0.69537/0.95936, obj_cardinality_error_0: 0.50000/2.64497, loss_obj_ce_1: 0.50689/0.80453, loss_verb_ce_1: 1.03298/0.99436, loss_sub_bbox_1: 0.54976/0.38866, loss_obj_bbox_1: 0.24008/0.40121, loss_sub_giou_1: 0.61308/0.63716, loss_obj_giou_1: 0.52501/0.95783, obj_cardinality_error_1: 1.50000/2.20698] items per batch[1] items per second[0.83] total items[1790] mini batches[  1790] memory[1414] epoch remaining[0:01:52]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1800/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.83335/19.22572, loss_obj_ce: 0.94256/0.78998, obj_class_error: 60.00000/76.25411, loss_verb_ce: 0.68070/0.98166, loss_sub_bbox: 0.42101/0.39454, loss_obj_bbox: 0.44476/0.40693, loss_sub_giou: 0.51466/0.64407, loss_obj_giou: 0.80018/0.96837, obj_cardinality_error: 1.00000/2.33000, loss_obj_ce_0: 1.01397/0.86963, loss_verb_ce_0: 0.75152/1.04661, loss_sub_bbox_0: 0.29691/0.37845, loss_obj_bbox_0: 0.29489/0.40043, loss_sub_giou_0: 0.43258/0.62824, loss_obj_giou_0: 0.53212/0.95847, obj_cardinality_error_0: 4.00000/2.64028, loss_obj_ce_1: 1.18556/0.80439, loss_verb_ce_1: 0.72010/0.99324, loss_sub_bbox_1: 0.33021/0.38867, loss_obj_bbox_1: 0.26515/0.40113, loss_sub_giou_1: 0.42437/0.63687, loss_obj_giou_1: 0.55036/0.95734, obj_cardinality_error_1: 5.00000/2.20639] items per batch[1] items per second[0.84] total items[1800] mini batches[  1800] memory[1414] epoch remaining[0:01:50]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1810/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.48395/19.20822, loss_obj_ce: 0.45212/0.78950, obj_class_error: 66.66667/76.25120, loss_verb_ce: 0.74413/0.98105, loss_sub_bbox: 0.33324/0.39396, loss_obj_bbox: 0.46811/0.40618, loss_sub_giou: 0.81292/0.64382, loss_obj_giou: 0.99002/0.96776, obj_cardinality_error: 1.00000/2.32376, loss_obj_ce_0: 0.49276/0.86911, loss_verb_ce_0: 0.86210/1.04565, loss_sub_bbox_0: 0.37783/0.37806, loss_obj_bbox_0: 0.32589/0.39975, loss_sub_giou_0: 0.95045/0.62818, loss_obj_giou_0: 0.70312/0.95764, obj_cardinality_error_0: 1.00000/2.63729, loss_obj_ce_1: 0.42961/0.80380, loss_verb_ce_1: 0.86023/0.99224, loss_sub_bbox_1: 0.40382/0.38824, loss_obj_bbox_1: 0.36067/0.40051, loss_sub_giou_1: 1.04175/0.63701, loss_obj_giou_1: 1.00434/0.95678, obj_cardinality_error_1: 1.00000/2.20249] items per batch[1] items per second[0.79] total items[1810] mini batches[  1810] memory[1414] epoch remaining[0:01:49]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1820/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.91570/19.19470, loss_obj_ce: 0.42226/0.78871, obj_class_error: 25.00000/76.20998, loss_verb_ce: 0.66652/0.98067, loss_sub_bbox: 0.36577/0.39354, loss_obj_bbox: 0.47815/0.40577, loss_sub_giou: 0.62853/0.64331, loss_obj_giou: 1.06379/0.96780, obj_cardinality_error: 1.00000/2.31896, loss_obj_ce_0: 0.54327/0.86828, loss_verb_ce_0: 0.77072/1.04475, loss_sub_bbox_0: 0.37184/0.37793, loss_obj_bbox_0: 0.37857/0.39930, loss_sub_giou_0: 0.64167/0.62797, loss_obj_giou_0: 0.91099/0.95736, obj_cardinality_error_0: 2.00000/2.63214, loss_obj_ce_1: 0.48713/0.80276, loss_verb_ce_1: 0.80029/0.99141, loss_sub_bbox_1: 0.38588/0.38796, loss_obj_bbox_1: 0.36976/0.40007, loss_sub_giou_1: 0.60694/0.63649, loss_obj_giou_1: 1.26114/0.95690, obj_cardinality_error_1: 2.00000/2.19670] items per batch[1] items per second[0.82] total items[1820] mini batches[  1820] memory[1414] epoch remaining[0:01:48]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1830/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.18624/19.17884, loss_obj_ce: 0.55017/0.78885, obj_class_error: 50.00000/76.17423, loss_verb_ce: 0.88551/0.97969, loss_sub_bbox: 0.14666/0.39307, loss_obj_bbox: 0.38719/0.40535, loss_sub_giou: 0.42501/0.64262, loss_obj_giou: 0.95249/0.96636, obj_cardinality_error: 1.50000/2.31448, loss_obj_ce_0: 0.61958/0.86827, loss_verb_ce_0: 0.98727/1.04377, loss_sub_bbox_0: 0.19934/0.37755, loss_obj_bbox_0: 0.44361/0.39914, loss_sub_giou_0: 0.52241/0.62735, loss_obj_giou_0: 1.06980/0.95685, obj_cardinality_error_0: 1.00000/2.62760, loss_obj_ce_1: 0.57159/0.80306, loss_verb_ce_1: 0.88576/0.99058, loss_sub_bbox_1: 0.20638/0.38748, loss_obj_bbox_1: 0.42519/0.39974, loss_sub_giou_1: 0.57678/0.63593, loss_obj_giou_1: 0.86042/0.95564, obj_cardinality_error_1: 1.50000/2.19399] items per batch[1] items per second[0.81] total items[1830] mini batches[  1830] memory[1414] epoch remaining[0:01:47]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1840/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.20156/19.15766, loss_obj_ce: 0.80263/0.78809, obj_class_error: 80.00000/76.08813, loss_verb_ce: 0.94379/0.97819, loss_sub_bbox: 0.22713/0.39272, loss_obj_bbox: 0.25403/0.40486, loss_sub_giou: 0.46337/0.64205, loss_obj_giou: 1.00750/0.96607, obj_cardinality_error: 1.50000/2.31141, loss_obj_ce_0: 0.72896/0.86736, loss_verb_ce_0: 0.95770/1.04217, loss_sub_bbox_0: 0.28619/0.37715, loss_obj_bbox_0: 0.22112/0.39861, loss_sub_giou_0: 0.52760/0.62684, loss_obj_giou_0: 0.95855/0.95650, obj_cardinality_error_0: 2.00000/2.62255, loss_obj_ce_1: 0.73600/0.80238, loss_verb_ce_1: 0.97580/0.98901, loss_sub_bbox_1: 0.29453/0.38708, loss_obj_bbox_1: 0.21067/0.39910, loss_sub_giou_1: 0.46958/0.63548, loss_obj_giou_1: 1.01860/0.95534, obj_cardinality_error_1: 1.00000/2.19049] items per batch[1] items per second[0.81] total items[1840] mini batches[  1840] memory[1414] epoch remaining[0:01:46]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1850/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.18739/19.13829, loss_obj_ce: 0.50810/0.78693, obj_class_error: 75.00000/76.08257, loss_verb_ce: 0.78783/0.97683, loss_sub_bbox: 0.25251/0.39234, loss_obj_bbox: 0.27552/0.40473, loss_sub_giou: 0.44236/0.64140, loss_obj_giou: 1.16649/0.96598, obj_cardinality_error: 2.50000/2.30568, loss_obj_ce_0: 0.44371/0.86573, loss_verb_ce_0: 0.97370/1.04064, loss_sub_bbox_0: 0.25248/0.37698, loss_obj_bbox_0: 0.32072/0.39829, loss_sub_giou_0: 0.43878/0.62626, loss_obj_giou_0: 1.44287/0.95656, obj_cardinality_error_0: 2.00000/2.61595, loss_obj_ce_1: 0.41817/0.80112, loss_verb_ce_1: 0.81656/0.98763, loss_sub_bbox_1: 0.30371/0.38672, loss_obj_bbox_1: 0.31625/0.39862, loss_sub_giou_1: 0.58571/0.63492, loss_obj_giou_1: 1.28201/0.95499, obj_cardinality_error_1: 1.00000/2.18378] items per batch[1] items per second[0.76] total items[1850] mini batches[  1850] memory[1414] epoch remaining[0:01:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1860/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.76147/19.12112, loss_obj_ce: 0.40534/0.78560, obj_class_error: 100.00000/76.04450, loss_verb_ce: 0.79111/0.97578, loss_sub_bbox: 0.25063/0.39172, loss_obj_bbox: 0.15863/0.40436, loss_sub_giou: 0.42727/0.64129, loss_obj_giou: 0.76201/0.96620, obj_cardinality_error: 1.50000/2.30215, loss_obj_ce_0: 0.51191/0.86410, loss_verb_ce_0: 0.79468/1.03950, loss_sub_bbox_0: 0.17218/0.37659, loss_obj_bbox_0: 0.22900/0.39786, loss_sub_giou_0: 0.37336/0.62625, loss_obj_giou_0: 0.79389/0.95628, obj_cardinality_error_0: 0.50000/2.61129, loss_obj_ce_1: 0.58725/0.79981, loss_verb_ce_1: 1.22771/0.98679, loss_sub_bbox_1: 0.20038/0.38623, loss_obj_bbox_1: 0.15927/0.39826, loss_sub_giou_1: 0.43301/0.63491, loss_obj_giou_1: 0.91520/0.95497, obj_cardinality_error_1: 2.00000/2.18145] items per batch[1] items per second[0.91] total items[1860] mini batches[  1860] memory[1414] epoch remaining[0:01:43]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1870/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.28686/19.11176, loss_obj_ce: 0.35957/0.78422, obj_class_error: 66.66667/76.07233, loss_verb_ce: 0.64376/0.97447, loss_sub_bbox: 0.38033/0.39145, loss_obj_bbox: 0.58133/0.40446, loss_sub_giou: 0.52782/0.64129, loss_obj_giou: 1.36163/0.96786, obj_cardinality_error: 0.50000/2.29679, loss_obj_ce_0: 0.41641/0.86258, loss_verb_ce_0: 0.67594/1.03806, loss_sub_bbox_0: 0.31034/0.37628, loss_obj_bbox_0: 0.28111/0.39778, loss_sub_giou_0: 0.49521/0.62648, loss_obj_giou_0: 0.97526/0.95791, obj_cardinality_error_0: 2.00000/2.60588, loss_obj_ce_1: 0.37618/0.79837, loss_verb_ce_1: 0.63610/0.98547, loss_sub_bbox_1: 0.30483/0.38593, loss_obj_bbox_1: 0.26501/0.39809, loss_sub_giou_1: 0.49071/0.63502, loss_obj_giou_1: 1.06505/0.95704, obj_cardinality_error_1: 1.50000/2.17701] items per batch[1] items per second[0.85] total items[1870] mini batches[  1870] memory[1414] epoch remaining[0:01:42]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1880/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.80582/19.09898, loss_obj_ce: 0.80888/0.78458, obj_class_error: 100.00000/76.11243, loss_verb_ce: 1.00145/0.97379, loss_sub_bbox: 0.14425/0.39083, loss_obj_bbox: 0.23399/0.40403, loss_sub_giou: 0.52475/0.64061, loss_obj_giou: 0.83116/0.96756, obj_cardinality_error: 0.50000/2.29096, loss_obj_ce_0: 0.75300/0.86265, loss_verb_ce_0: 0.83105/1.03681, loss_sub_bbox_0: 0.33817/0.37599, loss_obj_bbox_0: 0.35187/0.39760, loss_sub_giou_0: 0.85464/0.62621, loss_obj_giou_0: 1.10055/0.95803, obj_cardinality_error_0: 1.00000/2.59973, loss_obj_ce_1: 0.75328/0.79847, loss_verb_ce_1: 0.86656/0.98458, loss_sub_bbox_1: 0.23903/0.38545, loss_obj_bbox_1: 0.30990/0.39776, loss_sub_giou_1: 0.71616/0.63453, loss_obj_giou_1: 1.02229/0.95684, obj_cardinality_error_1: 0.50000/2.17101] items per batch[1] items per second[0.77] total items[1880] mini batches[  1880] memory[1414] epoch remaining[0:01:41]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1890/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.64668/19.08604, loss_obj_ce: 1.39365/0.78438, obj_class_error: 72.72727/76.09023, loss_verb_ce: 0.75880/0.97304, loss_sub_bbox: 0.28850/0.39031, loss_obj_bbox: 0.32128/0.40384, loss_sub_giou: 0.53384/0.64004, loss_obj_giou: 0.88097/0.96673, obj_cardinality_error: 2.50000/2.29471, loss_obj_ce_0: 1.77452/0.86260, loss_verb_ce_0: 0.80598/1.03603, loss_sub_bbox_0: 0.28135/0.37563, loss_obj_bbox_0: 0.33602/0.39737, loss_sub_giou_0: 0.50935/0.62601, loss_obj_giou_0: 0.88964/0.95752, obj_cardinality_error_0: 3.00000/2.59735, loss_obj_ce_1: 1.78542/0.79855, loss_verb_ce_1: 0.91011/0.98419, loss_sub_bbox_1: 0.27616/0.38485, loss_obj_bbox_1: 0.33218/0.39749, loss_sub_giou_1: 0.49178/0.63386, loss_obj_giou_1: 0.84899/0.95611, obj_cardinality_error_1: 3.00000/2.17513] items per batch[1] items per second[0.85] total items[1890] mini batches[  1890] memory[1414] epoch remaining[0:01:39]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1900/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.47027/19.07116, loss_obj_ce: 0.57353/0.78419, obj_class_error: 100.00000/76.06684, loss_verb_ce: 1.08085/0.97264, loss_sub_bbox: 0.41091/0.38985, loss_obj_bbox: 0.37441/0.40345, loss_sub_giou: 0.45382/0.63913, loss_obj_giou: 0.67176/0.96572, obj_cardinality_error: 0.00000/2.28789, loss_obj_ce_0: 0.79173/0.86236, loss_verb_ce_0: 1.19817/1.03514, loss_sub_bbox_0: 0.38372/0.37528, loss_obj_bbox_0: 0.43468/0.39700, loss_sub_giou_0: 0.49866/0.62520, loss_obj_giou_0: 0.73920/0.95651, obj_cardinality_error_0: 1.50000/2.59395, loss_obj_ce_1: 0.63293/0.79832, loss_verb_ce_1: 1.14011/0.98358, loss_sub_bbox_1: 0.44012/0.38459, loss_obj_bbox_1: 0.38599/0.39734, loss_sub_giou_1: 0.55797/0.63306, loss_obj_giou_1: 0.63781/0.95517, obj_cardinality_error_1: 0.00000/2.17395] items per batch[1] items per second[0.87] total items[1900] mini batches[  1900] memory[1414] epoch remaining[0:01:38]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1910/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.30986/19.06024, loss_obj_ce: 0.74851/0.78407, obj_class_error: 66.66667/76.04464, loss_verb_ce: 0.76613/0.97207, loss_sub_bbox: 0.28178/0.38956, loss_obj_bbox: 0.54537/0.40298, loss_sub_giou: 0.49110/0.63833, loss_obj_giou: 1.20558/0.96541, obj_cardinality_error: 0.50000/2.28298, loss_obj_ce_0: 0.77002/0.86201, loss_verb_ce_0: 0.74965/1.03446, loss_sub_bbox_0: 0.35085/0.37513, loss_obj_bbox_0: 0.63409/0.39659, loss_sub_giou_0: 0.55765/0.62474, loss_obj_giou_0: 1.47808/0.95636, obj_cardinality_error_0: 2.50000/2.59555, loss_obj_ce_1: 0.73383/0.79819, loss_verb_ce_1: 0.67698/0.98309, loss_sub_bbox_1: 0.40655/0.38437, loss_obj_bbox_1: 0.65551/0.39705, loss_sub_giou_1: 0.51982/0.63242, loss_obj_giou_1: 1.23440/0.95523, obj_cardinality_error_1: 1.00000/2.17094] items per batch[1] items per second[0.78] total items[1910] mini batches[  1910] memory[1414] epoch remaining[0:01:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1920/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.92255/19.05427, loss_obj_ce: 0.53093/0.78382, obj_class_error: 66.66667/76.00939, loss_verb_ce: 0.85070/0.97182, loss_sub_bbox: 0.30889/0.38966, loss_obj_bbox: 0.21770/0.40280, loss_sub_giou: 0.46190/0.63802, loss_obj_giou: 0.66965/0.96432, obj_cardinality_error: 1.00000/2.27708, loss_obj_ce_0: 0.62996/0.86177, loss_verb_ce_0: 0.89715/1.03405, loss_sub_bbox_0: 0.30198/0.37523, loss_obj_bbox_0: 0.27192/0.39655, loss_sub_giou_0: 0.54250/0.62451, loss_obj_giou_0: 0.53697/0.95535, obj_cardinality_error_0: 3.50000/2.60703, loss_obj_ce_1: 0.54201/0.79810, loss_verb_ce_1: 0.92563/0.98275, loss_sub_bbox_1: 0.27320/0.38449, loss_obj_bbox_1: 0.31084/0.39710, loss_sub_giou_1: 0.51374/0.63213, loss_obj_giou_1: 0.93656/0.95445, obj_cardinality_error_1: 1.00000/2.16693] items per batch[1] items per second[0.86] total items[1920] mini batches[  1920] memory[1414] epoch remaining[0:01:36]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1930/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.02054/19.03910, loss_obj_ce: 0.49401/0.78282, obj_class_error: 40.00000/75.96743, loss_verb_ce: 0.62004/0.97097, loss_sub_bbox: 0.21107/0.38950, loss_obj_bbox: 0.12499/0.40239, loss_sub_giou: 0.29238/0.63790, loss_obj_giou: 0.28012/0.96398, obj_cardinality_error: 1.50000/2.27720, loss_obj_ce_0: 0.63138/0.86066, loss_verb_ce_0: 0.82015/1.03327, loss_sub_bbox_0: 0.26502/0.37498, loss_obj_bbox_0: 0.28583/0.39620, loss_sub_giou_0: 0.29424/0.62420, loss_obj_giou_0: 0.59630/0.95490, obj_cardinality_error_0: 0.50000/2.59974, loss_obj_ce_1: 0.53914/0.79722, loss_verb_ce_1: 0.64340/0.98205, loss_sub_bbox_1: 0.19144/0.38420, loss_obj_bbox_1: 0.17321/0.39649, loss_sub_giou_1: 0.22700/0.63169, loss_obj_giou_1: 0.36989/0.95374, obj_cardinality_error_1: 2.00000/2.16295] items per batch[1] items per second[0.76] total items[1930] mini batches[  1930] memory[1414] epoch remaining[0:01:34]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1940/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.11122/19.02431, loss_obj_ce: 0.97802/0.78246, obj_class_error: 100.00000/75.94603, loss_verb_ce: 0.98883/0.97052, loss_sub_bbox: 0.44141/0.38906, loss_obj_bbox: 0.40052/0.40177, loss_sub_giou: 0.62060/0.63762, loss_obj_giou: 0.85354/0.96327, obj_cardinality_error: 5.00000/2.27680, loss_obj_ce_0: 1.01264/0.86033, loss_verb_ce_0: 0.98176/1.03248, loss_sub_bbox_0: 0.53945/0.37481, loss_obj_bbox_0: 0.36178/0.39573, loss_sub_giou_0: 0.68430/0.62402, loss_obj_giou_0: 0.75525/0.95428, obj_cardinality_error_0: 1.00000/2.59639, loss_obj_ce_1: 0.82120/0.79683, loss_verb_ce_1: 0.81428/0.98128, loss_sub_bbox_1: 0.46894/0.38380, loss_obj_bbox_1: 0.34658/0.39592, loss_sub_giou_1: 0.65378/0.63127, loss_obj_giou_1: 0.76543/0.95299, obj_cardinality_error_1: 1.50000/2.15979] items per batch[1] items per second[0.76] total items[1940] mini batches[  1940] memory[1414] epoch remaining[0:01:33]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1950/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.54998/19.00031, loss_obj_ce: 0.97662/0.78177, obj_class_error: 57.14286/75.89295, loss_verb_ce: 0.91312/0.96966, loss_sub_bbox: 0.17947/0.38832, loss_obj_bbox: 0.22520/0.40100, loss_sub_giou: 0.43118/0.63649, loss_obj_giou: 0.64040/0.96246, obj_cardinality_error: 3.50000/2.27692, loss_obj_ce_0: 1.05011/0.85943, loss_verb_ce_0: 0.93948/1.03153, loss_sub_bbox_0: 0.14358/0.37433, loss_obj_bbox_0: 0.19153/0.39500, loss_sub_giou_0: 0.41316/0.62331, loss_obj_giou_0: 0.62522/0.95331, obj_cardinality_error_0: 1.00000/2.59026, loss_obj_ce_1: 1.01098/0.79623, loss_verb_ce_1: 0.92914/0.98054, loss_sub_bbox_1: 0.18275/0.38315, loss_obj_bbox_1: 0.17771/0.39497, loss_sub_giou_1: 0.44248/0.63017, loss_obj_giou_1: 0.64576/0.95173, obj_cardinality_error_1: 1.00000/2.15949] items per batch[1] items per second[0.80] total items[1950] mini batches[  1950] memory[1414] epoch remaining[0:01:32]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1960/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.81573/18.98474, loss_obj_ce: 0.40632/0.78080, obj_class_error: 50.00000/75.80986, loss_verb_ce: 1.21050/0.96894, loss_sub_bbox: 0.27402/0.38788, loss_obj_bbox: 0.24359/0.40050, loss_sub_giou: 0.23325/0.63613, loss_obj_giou: 0.51778/0.96236, obj_cardinality_error: 5.00000/2.28036, loss_obj_ce_0: 0.46708/0.85845, loss_verb_ce_0: 1.15412/1.03074, loss_sub_bbox_0: 0.25216/0.37402, loss_obj_bbox_0: 0.35719/0.39467, loss_sub_giou_0: 0.26175/0.62310, loss_obj_giou_0: 0.76602/0.95325, obj_cardinality_error_0: 2.00000/2.58699, loss_obj_ce_1: 0.42598/0.79530, loss_verb_ce_1: 1.06260/0.97979, loss_sub_bbox_1: 0.18028/0.38267, loss_obj_bbox_1: 0.27890/0.39435, loss_sub_giou_1: 0.22488/0.62983, loss_obj_giou_1: 0.69291/0.95137, obj_cardinality_error_1: 4.50000/2.16250] items per batch[1] items per second[0.86] total items[1960] mini batches[  1960] memory[1414] epoch remaining[0:01:31]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1970/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.00490/18.97469, loss_obj_ce: 0.52337/0.78061, obj_class_error: 60.00000/75.71650, loss_verb_ce: 0.66513/0.96755, loss_sub_bbox: 0.23267/0.38767, loss_obj_bbox: 0.18078/0.40034, loss_sub_giou: 0.63696/0.63602, loss_obj_giou: 0.64003/0.96262, obj_cardinality_error: 1.00000/2.28325, loss_obj_ce_0: 0.75486/0.85841, loss_verb_ce_0: 0.85357/1.02960, loss_sub_bbox_0: 0.22421/0.37380, loss_obj_bbox_0: 0.23430/0.39451, loss_sub_giou_0: 0.60197/0.62284, loss_obj_giou_0: 0.65394/0.95356, obj_cardinality_error_0: 2.50000/2.58858, loss_obj_ce_1: 0.68574/0.79525, loss_verb_ce_1: 0.79428/0.97861, loss_sub_bbox_1: 0.26193/0.38245, loss_obj_bbox_1: 0.26872/0.39424, loss_sub_giou_1: 0.67696/0.62959, loss_obj_giou_1: 0.69859/0.95173, obj_cardinality_error_1: 4.00000/2.17056] items per batch[1] items per second[0.71] total items[1970] mini batches[  1970] memory[1414] epoch remaining[0:01:30]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1980/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.83417/18.95912, loss_obj_ce: 0.50819/0.77934, obj_class_error: 100.00000/75.65792, loss_verb_ce: 0.88699/0.96631, loss_sub_bbox: 0.53310/0.38745, loss_obj_bbox: 0.33393/0.40004, loss_sub_giou: 0.76212/0.63604, loss_obj_giou: 0.90903/0.96221, obj_cardinality_error: 1.00000/2.28207, loss_obj_ce_0: 0.53989/0.85726, loss_verb_ce_0: 0.90409/1.02832, loss_sub_bbox_0: 0.48789/0.37358, loss_obj_bbox_0: 0.32839/0.39415, loss_sub_giou_0: 0.75663/0.62271, loss_obj_giou_0: 0.85568/0.95320, obj_cardinality_error_0: 3.00000/2.58561, loss_obj_ce_1: 0.52167/0.79394, loss_verb_ce_1: 0.85650/0.97728, loss_sub_bbox_1: 0.56109/0.38240, loss_obj_bbox_1: 0.45550/0.39411, loss_sub_giou_1: 0.79930/0.62981, loss_obj_giou_1: 1.13674/0.95146, obj_cardinality_error_1: 1.50000/2.17247] items per batch[1] items per second[0.79] total items[1980] mini batches[  1980] memory[1414] epoch remaining[0:01:28]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[1990/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.55075/18.94364, loss_obj_ce: 0.64067/0.77825, obj_class_error: 100.00000/75.63787, loss_verb_ce: 1.10836/0.96569, loss_sub_bbox: 0.40808/0.38735, loss_obj_bbox: 0.37926/0.39970, loss_sub_giou: 0.78031/0.63574, loss_obj_giou: 0.85497/0.96123, obj_cardinality_error: 1.50000/2.27764, loss_obj_ce_0: 0.64469/0.85599, loss_verb_ce_0: 1.17136/1.02774, loss_sub_bbox_0: 0.29586/0.37335, loss_obj_bbox_0: 0.42980/0.39380, loss_sub_giou_0: 0.53808/0.62220, loss_obj_giou_0: 0.90869/0.95206, obj_cardinality_error_0: 2.50000/2.58191, loss_obj_ce_1: 0.62054/0.79267, loss_verb_ce_1: 1.22050/0.97701, loss_sub_bbox_1: 0.36675/0.38214, loss_obj_bbox_1: 0.24493/0.39370, loss_sub_giou_1: 0.66131/0.62938, loss_obj_giou_1: 0.58940/0.95015, obj_cardinality_error_1: 3.50000/2.17010] items per batch[1] items per second[0.90] total items[1990] mini batches[  1990] memory[1414] epoch remaining[0:01:27]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2000/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.20634/18.93071, loss_obj_ce: 0.50663/0.77836, obj_class_error: 60.00000/75.59369, loss_verb_ce: 0.72353/0.96474, loss_sub_bbox: 0.25665/0.38693, loss_obj_bbox: 0.24465/0.39945, loss_sub_giou: 0.52671/0.63522, loss_obj_giou: 0.92590/0.96094, obj_cardinality_error: 5.50000/2.29000, loss_obj_ce_0: 0.58122/0.85595, loss_verb_ce_0: 0.70436/1.02678, loss_sub_bbox_0: 0.19591/0.37299, loss_obj_bbox_0: 0.23439/0.39363, loss_sub_giou_0: 0.36190/0.62179, loss_obj_giou_0: 0.86118/0.95190, obj_cardinality_error_0: 1.50000/2.58150, loss_obj_ce_1: 0.42132/0.79252, loss_verb_ce_1: 0.70909/0.97590, loss_sub_bbox_1: 0.20686/0.38165, loss_obj_bbox_1: 0.24258/0.39354, loss_sub_giou_1: 0.36019/0.62869, loss_obj_giou_1: 0.93477/0.95001, obj_cardinality_error_1: 5.00000/2.18075] items per batch[1] items per second[0.82] total items[2000] mini batches[  2000] memory[1414] epoch remaining[0:01:26]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2010/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.51060/18.92105, loss_obj_ce: 0.99262/0.77852, obj_class_error: 66.66667/75.55180, loss_verb_ce: 0.68196/0.96368, loss_sub_bbox: 0.33141/0.38654, loss_obj_bbox: 0.49396/0.39940, loss_sub_giou: 0.55668/0.63505, loss_obj_giou: 0.84308/0.96067, obj_cardinality_error: 2.50000/2.29900, loss_obj_ce_0: 1.21599/0.85625, loss_verb_ce_0: 0.92321/1.02580, loss_sub_bbox_0: 0.25732/0.37262, loss_obj_bbox_0: 0.46533/0.39365, loss_sub_giou_0: 0.44483/0.62168, loss_obj_giou_0: 0.84814/0.95154, obj_cardinality_error_0: 2.00000/2.57687, loss_obj_ce_1: 1.07450/0.79264, loss_verb_ce_1: 0.72398/0.97490, loss_sub_bbox_1: 0.26743/0.38128, loss_obj_bbox_1: 0.42611/0.39356, loss_sub_giou_1: 0.49254/0.62847, loss_obj_giou_1: 0.78003/0.94983, obj_cardinality_error_1: 1.50000/2.18458] items per batch[1] items per second[0.75] total items[2010] mini batches[  2010] memory[1414] epoch remaining[0:01:25]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2020/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.21771/18.89939, loss_obj_ce: 0.49455/0.77730, obj_class_error: 50.00000/75.41570, loss_verb_ce: 0.77376/0.96236, loss_sub_bbox: 0.30890/0.38622, loss_obj_bbox: 0.31649/0.39914, loss_sub_giou: 0.42821/0.63445, loss_obj_giou: 0.70428/0.96020, obj_cardinality_error: 0.50000/2.31733, loss_obj_ce_0: 0.63450/0.85507, loss_verb_ce_0: 0.86729/1.02466, loss_sub_bbox_0: 0.28286/0.37218, loss_obj_bbox_0: 0.13702/0.39318, loss_sub_giou_0: 0.42416/0.62099, loss_obj_giou_0: 0.54484/0.95109, obj_cardinality_error_0: 1.50000/2.57228, loss_obj_ce_1: 0.54860/0.79128, loss_verb_ce_1: 0.72921/0.97350, loss_sub_bbox_1: 0.30864/0.38092, loss_obj_bbox_1: 0.17267/0.39296, loss_sub_giou_1: 0.45998/0.62782, loss_obj_giou_1: 0.42166/0.94866, obj_cardinality_error_1: 1.00000/2.19851] items per batch[1] items per second[0.78] total items[2020] mini batches[  2020] memory[1414] epoch remaining[0:01:23]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2030/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.95291/18.88711, loss_obj_ce: 0.66919/0.77671, obj_class_error: 100.00000/75.38145, loss_verb_ce: 1.30471/0.96226, loss_sub_bbox: 0.11868/0.38584, loss_obj_bbox: 0.27964/0.39882, loss_sub_giou: 0.25644/0.63416, loss_obj_giou: 1.23392/0.96005, obj_cardinality_error: 1.00000/2.31897, loss_obj_ce_0: 0.68447/0.85390, loss_verb_ce_0: 1.10767/1.02367, loss_sub_bbox_0: 0.17044/0.37183, loss_obj_bbox_0: 0.20118/0.39249, loss_sub_giou_0: 0.29261/0.62083, loss_obj_giou_0: 0.91694/0.95079, obj_cardinality_error_0: 1.00000/2.56823, loss_obj_ce_1: 0.65167/0.79065, loss_verb_ce_1: 1.16358/0.97311, loss_sub_bbox_1: 0.19700/0.38062, loss_obj_bbox_1: 0.38594/0.39265, loss_sub_giou_1: 0.34576/0.62760, loss_obj_giou_1: 1.36780/0.94875, obj_cardinality_error_1: 3.00000/2.20296] items per batch[1] items per second[0.74] total items[2030] mini batches[  2030] memory[1414] epoch remaining[0:01:22]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2040/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.08621/18.87812, loss_obj_ce: 1.03953/0.77697, obj_class_error: 100.00000/75.43922, loss_verb_ce: 1.06693/0.96221, loss_sub_bbox: 0.43824/0.38539, loss_obj_bbox: 0.47820/0.39847, loss_sub_giou: 0.76870/0.63410, loss_obj_giou: 1.18872/0.95960, obj_cardinality_error: 5.00000/2.31765, loss_obj_ce_0: 1.04949/0.85348, loss_verb_ce_0: 1.10833/1.02286, loss_sub_bbox_0: 0.56604/0.37154, loss_obj_bbox_0: 0.40140/0.39224, loss_sub_giou_0: 0.84154/0.62097, loss_obj_giou_0: 1.06690/0.95088, obj_cardinality_error_0: 3.00000/2.56422, loss_obj_ce_1: 0.90189/0.79053, loss_verb_ce_1: 1.04079/0.97269, loss_sub_bbox_1: 0.40994/0.38015, loss_obj_bbox_1: 0.48234/0.39230, loss_sub_giou_1: 0.70360/0.62751, loss_obj_giou_1: 1.15337/0.94836, obj_cardinality_error_1: 2.00000/2.19926] items per batch[1] items per second[0.76] total items[2040] mini batches[  2040] memory[1414] epoch remaining[0:01:21]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2050/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.16632/18.86603, loss_obj_ce: 0.65001/0.77725, obj_class_error: 80.00000/75.44247, loss_verb_ce: 0.83035/0.96145, loss_sub_bbox: 0.33182/0.38509, loss_obj_bbox: 0.37350/0.39813, loss_sub_giou: 0.42175/0.63366, loss_obj_giou: 0.87286/0.95924, obj_cardinality_error: 1.50000/2.32561, loss_obj_ce_0: 0.71364/0.85346, loss_verb_ce_0: 0.86523/1.02179, loss_sub_bbox_0: 0.37092/0.37137, loss_obj_bbox_0: 0.33391/0.39184, loss_sub_giou_0: 0.51162/0.62059, loss_obj_giou_0: 0.85128/0.95048, obj_cardinality_error_0: 1.50000/2.56293, loss_obj_ce_1: 0.72871/0.79110, loss_verb_ce_1: 0.85000/0.97190, loss_sub_bbox_1: 0.37610/0.37989, loss_obj_bbox_1: 0.30484/0.39183, loss_sub_giou_1: 0.45944/0.62700, loss_obj_giou_1: 0.63813/0.94761, obj_cardinality_error_1: 1.00000/2.20049] items per batch[1] items per second[0.90] total items[2050] mini batches[  2050] memory[1414] epoch remaining[0:01:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2060/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.90680/18.84787, loss_obj_ce: 0.80117/0.77657, obj_class_error: 50.00000/75.41836, loss_verb_ce: 0.80138/0.96056, loss_sub_bbox: 0.47630/0.38481, loss_obj_bbox: 0.45651/0.39757, loss_sub_giou: 0.82723/0.63338, loss_obj_giou: 0.95791/0.95838, obj_cardinality_error: 2.00000/2.32112, loss_obj_ce_0: 0.68149/0.85237, loss_verb_ce_0: 0.76943/1.02048, loss_sub_bbox_0: 0.49991/0.37116, loss_obj_bbox_0: 0.45259/0.39136, loss_sub_giou_0: 0.69652/0.62030, loss_obj_giou_0: 1.02722/0.94996, obj_cardinality_error_0: 1.50000/2.55558, loss_obj_ce_1: 0.79638/0.79031, loss_verb_ce_1: 0.75378/0.97079, loss_sub_bbox_1: 0.45501/0.37953, loss_obj_bbox_1: 0.42196/0.39132, loss_sub_giou_1: 0.77294/0.62674, loss_obj_giou_1: 0.79105/0.94683, obj_cardinality_error_1: 2.00000/2.19733] items per batch[1] items per second[0.79] total items[2060] mini batches[  2060] memory[1414] epoch remaining[0:01:19]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2070/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.08348/18.83432, loss_obj_ce: 0.99921/0.77633, obj_class_error: 87.50000/75.41525, loss_verb_ce: 0.90575/0.95968, loss_sub_bbox: 0.40221/0.38463, loss_obj_bbox: 0.43252/0.39723, loss_sub_giou: 0.56193/0.63315, loss_obj_giou: 1.26622/0.95823, obj_cardinality_error: 0.50000/2.31401, loss_obj_ce_0: 0.82397/0.85171, loss_verb_ce_0: 0.68025/1.01926, loss_sub_bbox_0: 0.52021/0.37107, loss_obj_bbox_0: 0.40862/0.39105, loss_sub_giou_0: 0.71167/0.62006, loss_obj_giou_0: 1.23013/0.94957, obj_cardinality_error_0: 1.00000/2.55048, loss_obj_ce_1: 0.57842/0.78976, loss_verb_ce_1: 0.65719/0.96967, loss_sub_bbox_1: 0.54906/0.37930, loss_obj_bbox_1: 0.34998/0.39092, loss_sub_giou_1: 0.66261/0.62648, loss_obj_giou_1: 1.10644/0.94632, obj_cardinality_error_1: 0.50000/2.19155] items per batch[1] items per second[0.81] total items[2070] mini batches[  2070] memory[1414] epoch remaining[0:01:17]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2080/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.80026/18.82740, loss_obj_ce: 0.57181/0.77612, obj_class_error: 75.00000/75.39293, loss_verb_ce: 0.67483/0.95870, loss_sub_bbox: 0.20576/0.38469, loss_obj_bbox: 0.46786/0.39695, loss_sub_giou: 0.42198/0.63322, loss_obj_giou: 0.72676/0.95804, obj_cardinality_error: 0.00000/2.31250, loss_obj_ce_0: 0.57060/0.85121, loss_verb_ce_0: 0.75322/1.01821, loss_sub_bbox_0: 0.21769/0.37133, loss_obj_bbox_0: 0.34810/0.39097, loss_sub_giou_0: 0.46491/0.62036, loss_obj_giou_0: 0.70280/0.94964, obj_cardinality_error_0: 0.50000/2.54591, loss_obj_ce_1: 0.60846/0.78945, loss_verb_ce_1: 0.65578/0.96863, loss_sub_bbox_1: 0.20398/0.37955, loss_obj_bbox_1: 0.32704/0.39059, loss_sub_giou_1: 0.38889/0.62663, loss_obj_giou_1: 0.75028/0.94643, obj_cardinality_error_1: 0.50000/2.18822] items per batch[1] items per second[0.88] total items[2080] mini batches[  2080] memory[1414] epoch remaining[0:01:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2090/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.39447/18.81479, loss_obj_ce: 0.89316/0.77538, obj_class_error: 62.50000/75.30430, loss_verb_ce: 0.61795/0.95769, loss_sub_bbox: 0.24719/0.38446, loss_obj_bbox: 0.20819/0.39664, loss_sub_giou: 0.52589/0.63295, loss_obj_giou: 0.65451/0.95804, obj_cardinality_error: 6.50000/2.32440, loss_obj_ce_0: 0.82874/0.85025, loss_verb_ce_0: 0.68248/1.01717, loss_sub_bbox_0: 0.28906/0.37122, loss_obj_bbox_0: 0.21336/0.39074, loss_sub_giou_0: 0.60573/0.62019, loss_obj_giou_0: 0.83298/0.94973, obj_cardinality_error_0: 3.00000/2.54426, loss_obj_ce_1: 0.95708/0.78861, loss_verb_ce_1: 0.69358/0.96768, loss_sub_bbox_1: 0.25621/0.37940, loss_obj_bbox_1: 0.22865/0.39029, loss_sub_giou_1: 0.61215/0.62636, loss_obj_giou_1: 0.88952/0.94634, obj_cardinality_error_1: 4.00000/2.19115] items per batch[1] items per second[0.82] total items[2090] mini batches[  2090] memory[1414] epoch remaining[0:01:15]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2100/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.79142/18.79597, loss_obj_ce: 0.57063/0.77485, obj_class_error: 100.00000/75.29613, loss_verb_ce: 0.99227/0.95726, loss_sub_bbox: 0.35586/0.38384, loss_obj_bbox: 0.44598/0.39584, loss_sub_giou: 0.50847/0.63239, loss_obj_giou: 0.91624/0.95714, obj_cardinality_error: 1.50000/2.33548, loss_obj_ce_0: 0.53179/0.84923, loss_verb_ce_0: 0.93973/1.01631, loss_sub_bbox_0: 0.41037/0.37092, loss_obj_bbox_0: 0.46601/0.39016, loss_sub_giou_0: 0.51143/0.61988, loss_obj_giou_0: 0.77073/0.94890, obj_cardinality_error_0: 0.50000/2.54238, loss_obj_ce_1: 0.39143/0.78774, loss_verb_ce_1: 0.79976/0.96698, loss_sub_bbox_1: 0.51499/0.37900, loss_obj_bbox_1: 0.46638/0.38961, loss_sub_giou_1: 0.65800/0.62596, loss_obj_giou_1: 0.82024/0.94532, obj_cardinality_error_1: 0.50000/2.20024] items per batch[1] items per second[0.82] total items[2100] mini batches[  2100] memory[1414] epoch remaining[0:01:14]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2110/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.97921/18.78669, loss_obj_ce: 0.69154/0.77480, obj_class_error: 57.14286/75.27125, loss_verb_ce: 0.79693/0.95664, loss_sub_bbox: 0.33206/0.38352, loss_obj_bbox: 0.32975/0.39559, loss_sub_giou: 0.76558/0.63189, loss_obj_giou: 0.92513/0.95674, obj_cardinality_error: 2.00000/2.33720, loss_obj_ce_0: 0.54272/0.84912, loss_verb_ce_0: 0.84247/1.01564, loss_sub_bbox_0: 0.37947/0.37093, loss_obj_bbox_0: 0.28242/0.38994, loss_sub_giou_0: 1.08108/0.61984, loss_obj_giou_0: 0.99096/0.94870, obj_cardinality_error_0: 0.00000/2.53934, loss_obj_ce_1: 0.53434/0.78757, loss_verb_ce_1: 0.73745/0.96630, loss_sub_bbox_1: 0.29701/0.37880, loss_obj_bbox_1: 0.33533/0.38931, loss_sub_giou_1: 0.79817/0.62569, loss_obj_giou_1: 1.00590/0.94496, obj_cardinality_error_1: 1.00000/2.19929] items per batch[1] items per second[0.77] total items[2110] mini batches[  2110] memory[1414] epoch remaining[0:01:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2120/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.40866/18.77393, loss_obj_ce: 0.51247/0.77483, obj_class_error: 50.00000/75.21943, loss_verb_ce: 0.71891/0.95601, loss_sub_bbox: 0.24878/0.38306, loss_obj_bbox: 0.25186/0.39528, loss_sub_giou: 0.58547/0.63175, loss_obj_giou: 0.60785/0.95603, obj_cardinality_error: 1.00000/2.33538, loss_obj_ce_0: 0.51312/0.84866, loss_verb_ce_0: 0.76521/1.01461, loss_sub_bbox_0: 0.31500/0.37075, loss_obj_bbox_0: 0.26158/0.38960, loss_sub_giou_0: 0.58029/0.61988, loss_obj_giou_0: 0.66234/0.94810, obj_cardinality_error_0: 1.00000/2.53302, loss_obj_ce_1: 0.54312/0.78721, loss_verb_ce_1: 0.79530/0.96527, loss_sub_bbox_1: 0.34515/0.37858, loss_obj_bbox_1: 0.36206/0.38899, loss_sub_giou_1: 0.56642/0.62569, loss_obj_giou_1: 0.81764/0.94435, obj_cardinality_error_1: 0.50000/2.19670] items per batch[1] items per second[0.79] total items[2120] mini batches[  2120] memory[1414] epoch remaining[0:01:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2130/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.35532/18.76038, loss_obj_ce: 0.42062/0.77425, obj_class_error: 80.00000/75.19415, loss_verb_ce: 0.91848/0.95520, loss_sub_bbox: 0.29984/0.38276, loss_obj_bbox: 0.37696/0.39506, loss_sub_giou: 0.58447/0.63122, loss_obj_giou: 0.98016/0.95593, obj_cardinality_error: 1.50000/2.33146, loss_obj_ce_0: 0.36406/0.84777, loss_verb_ce_0: 0.95266/1.01344, loss_sub_bbox_0: 0.35547/0.37061, loss_obj_bbox_0: 0.39505/0.38922, loss_sub_giou_0: 0.73282/0.61967, loss_obj_giou_0: 1.06063/0.94804, obj_cardinality_error_0: 0.50000/2.52817, loss_obj_ce_1: 0.37281/0.78640, loss_verb_ce_1: 0.92572/0.96438, loss_sub_bbox_1: 0.35642/0.37830, loss_obj_bbox_1: 0.38617/0.38872, loss_sub_giou_1: 0.64320/0.62507, loss_obj_giou_1: 1.17808/0.94435, obj_cardinality_error_1: 1.00000/2.19413] items per batch[1] items per second[0.76] total items[2130] mini batches[  2130] memory[1414] epoch remaining[0:01:10]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2140/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.72660/18.75560, loss_obj_ce: 0.91187/0.77400, obj_class_error: 66.66667/75.19713, loss_verb_ce: 0.77698/0.95458, loss_sub_bbox: 0.40155/0.38261, loss_obj_bbox: 0.41499/0.39495, loss_sub_giou: 0.94022/0.63129, loss_obj_giou: 1.39957/0.95619, obj_cardinality_error: 6.50000/2.33551, loss_obj_ce_0: 0.65013/0.84724, loss_verb_ce_0: 0.66423/1.01266, loss_sub_bbox_0: 0.40559/0.37056, loss_obj_bbox_0: 0.45544/0.38925, loss_sub_giou_0: 1.02023/0.61992, loss_obj_giou_0: 1.50217/0.94847, obj_cardinality_error_0: 7.50000/2.53341, loss_obj_ce_1: 0.55716/0.78617, loss_verb_ce_1: 0.67097/0.96387, loss_sub_bbox_1: 0.38007/0.37809, loss_obj_bbox_1: 0.40661/0.38875, loss_sub_giou_1: 0.91656/0.62493, loss_obj_giou_1: 1.44370/0.94460, obj_cardinality_error_1: 8.00000/2.20093] items per batch[1] items per second[0.83] total items[2140] mini batches[  2140] memory[1414] epoch remaining[0:01:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2150/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.19771/18.74387, loss_obj_ce: 0.44773/0.77365, obj_class_error: 66.66667/75.21518, loss_verb_ce: 0.91637/0.95403, loss_sub_bbox: 0.25956/0.38220, loss_obj_bbox: 0.12418/0.39460, loss_sub_giou: 0.56848/0.63129, loss_obj_giou: 0.55136/0.95582, obj_cardinality_error: 0.50000/2.33186, loss_obj_ce_0: 0.66757/0.84669, loss_verb_ce_0: 1.19042/1.01193, loss_sub_bbox_0: 0.19711/0.37020, loss_obj_bbox_0: 0.04124/0.38886, loss_sub_giou_0: 0.48586/0.62011, loss_obj_giou_0: 0.36879/0.94801, obj_cardinality_error_0: 0.50000/2.53070, loss_obj_ce_1: 0.31620/0.78554, loss_verb_ce_1: 0.64511/0.96303, loss_sub_bbox_1: 0.31678/0.37779, loss_obj_bbox_1: 0.17140/0.38849, loss_sub_giou_1: 0.62528/0.62498, loss_obj_giou_1: 0.88695/0.94444, obj_cardinality_error_1: 1.50000/2.19837] items per batch[1] items per second[0.82] total items[2150] mini batches[  2150] memory[1414] epoch remaining[0:01:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2160/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.57614/18.73134, loss_obj_ce: 0.40391/0.77305, obj_class_error: 40.00000/75.13658, loss_verb_ce: 0.70403/0.95301, loss_sub_bbox: 0.28134/0.38204, loss_obj_bbox: 0.17247/0.39439, loss_sub_giou: 0.52139/0.63057, loss_obj_giou: 0.83907/0.95557, obj_cardinality_error: 0.50000/2.32454, loss_obj_ce_0: 0.48427/0.84610, loss_verb_ce_0: 0.75633/1.01082, loss_sub_bbox_0: 0.27854/0.37003, loss_obj_bbox_0: 0.18496/0.38872, loss_sub_giou_0: 0.46023/0.61945, loss_obj_giou_0: 0.94718/0.94778, obj_cardinality_error_0: 0.50000/2.52431, loss_obj_ce_1: 0.64802/0.78515, loss_verb_ce_1: 0.93895/0.96219, loss_sub_bbox_1: 0.21802/0.37754, loss_obj_bbox_1: 0.17574/0.38854, loss_sub_giou_1: 0.36706/0.62423, loss_obj_giou_1: 0.82872/0.94424, obj_cardinality_error_1: 1.50000/2.19375] items per batch[1] items per second[0.85] total items[2160] mini batches[  2160] memory[1414] epoch remaining[0:01:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2170/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.41650/18.71926, loss_obj_ce: 0.26386/0.77239, obj_class_error: 66.66667/75.06455, loss_verb_ce: 0.56090/0.95190, loss_sub_bbox: 0.23875/0.38195, loss_obj_bbox: 0.20885/0.39415, loss_sub_giou: 0.70186/0.63054, loss_obj_giou: 1.11593/0.95626, obj_cardinality_error: 2.00000/2.32442, loss_obj_ce_0: 0.37575/0.84511, loss_verb_ce_0: 0.63176/1.00938, loss_sub_bbox_0: 0.33433/0.36998, loss_obj_bbox_0: 0.20700/0.38832, loss_sub_giou_0: 0.78631/0.61956, loss_obj_giou_0: 1.08755/0.94796, obj_cardinality_error_0: 1.50000/2.51797, loss_obj_ce_1: 0.30464/0.78437, loss_verb_ce_1: 0.62057/0.96118, loss_sub_bbox_1: 0.28265/0.37742, loss_obj_bbox_1: 0.13179/0.38797, loss_sub_giou_1: 0.82233/0.62428, loss_obj_giou_1: 0.82338/0.94438, obj_cardinality_error_1: 3.00000/2.19355] items per batch[1] items per second[0.86] total items[2170] mini batches[  2170] memory[1414] epoch remaining[0:01:05]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2180/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.01779/18.70392, loss_obj_ce: 1.22409/0.77170, obj_class_error: 66.66667/75.03018, loss_verb_ce: 0.68182/0.95119, loss_sub_bbox: 0.32809/0.38182, loss_obj_bbox: 0.29843/0.39350, loss_sub_giou: 0.50469/0.63024, loss_obj_giou: 0.44695/0.95583, obj_cardinality_error: 6.50000/2.32385, loss_obj_ce_0: 1.03793/0.84437, loss_verb_ce_0: 0.60783/1.00854, loss_sub_bbox_0: 0.34499/0.36988, loss_obj_bbox_0: 0.26195/0.38761, loss_sub_giou_0: 0.54395/0.61947, loss_obj_giou_0: 0.51399/0.94728, obj_cardinality_error_0: 2.50000/2.51560, loss_obj_ce_1: 1.19040/0.78349, loss_verb_ce_1: 0.70038/0.96028, loss_sub_bbox_1: 0.31832/0.37742, loss_obj_bbox_1: 0.28430/0.38721, loss_sub_giou_1: 0.50729/0.62429, loss_obj_giou_1: 0.47823/0.94365, obj_cardinality_error_1: 7.50000/2.19610] items per batch[1] items per second[0.85] total items[2180] mini batches[  2180] memory[1414] epoch remaining[0:01:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2190/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.34346/18.68808, loss_obj_ce: 0.42302/0.77045, obj_class_error: 100.00000/74.95851, loss_verb_ce: 0.81941/0.95013, loss_sub_bbox: 0.19414/0.38147, loss_obj_bbox: 0.37685/0.39329, loss_sub_giou: 0.42025/0.62973, loss_obj_giou: 0.62313/0.95573, obj_cardinality_error: 2.00000/2.32306, loss_obj_ce_0: 0.33470/0.84286, loss_verb_ce_0: 0.76442/1.00729, loss_sub_bbox_0: 0.33202/0.36975, loss_obj_bbox_0: 0.37446/0.38724, loss_sub_giou_0: 0.63118/0.61924, loss_obj_giou_0: 0.71130/0.94677, obj_cardinality_error_0: 1.00000/2.51393, loss_obj_ce_1: 0.56944/0.78262, loss_verb_ce_1: 0.90132/0.95956, loss_sub_bbox_1: 0.27915/0.37714, loss_obj_bbox_1: 0.30645/0.38701, loss_sub_giou_1: 0.42673/0.62367, loss_obj_giou_1: 0.57577/0.94327, obj_cardinality_error_1: 0.50000/2.19772] items per batch[1] items per second[0.88] total items[2190] mini batches[  2190] memory[1414] epoch remaining[0:01:02]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2200/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.27986/18.67106, loss_obj_ce: 0.62738/0.76994, obj_class_error: 100.00000/74.98824, loss_verb_ce: 0.81950/0.94977, loss_sub_bbox: 0.26932/0.38087, loss_obj_bbox: 0.28545/0.39277, loss_sub_giou: 0.39713/0.62912, loss_obj_giou: 1.19417/0.95520, obj_cardinality_error: 1.00000/2.31932, loss_obj_ce_0: 0.59736/0.84186, loss_verb_ce_0: 0.76579/1.00624, loss_sub_bbox_0: 0.25141/0.36931, loss_obj_bbox_0: 0.21744/0.38666, loss_sub_giou_0: 0.38087/0.61866, loss_obj_giou_0: 1.02676/0.94605, obj_cardinality_error_0: 2.00000/2.50841, loss_obj_ce_1: 0.64911/0.78212, loss_verb_ce_1: 0.85084/0.95926, loss_sub_bbox_1: 0.33578/0.37653, loss_obj_bbox_1: 0.27649/0.38662, loss_sub_giou_1: 0.47694/0.62291, loss_obj_giou_1: 0.96812/0.94277, obj_cardinality_error_1: 1.50000/2.19386] items per batch[1] items per second[0.80] total items[2200] mini batches[  2200] memory[1414] epoch remaining[0:01:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2210/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.65156/18.65404, loss_obj_ce: 0.54699/0.76930, obj_class_error: 80.00000/74.99605, loss_verb_ce: 0.72439/0.94883, loss_sub_bbox: 0.26196/0.38062, loss_obj_bbox: 0.22685/0.39234, loss_sub_giou: 0.68369/0.62855, loss_obj_giou: 1.04927/0.95425, obj_cardinality_error: 2.00000/2.31425, loss_obj_ce_0: 0.68763/0.84081, loss_verb_ce_0: 0.78880/1.00507, loss_sub_bbox_0: 0.21618/0.36924, loss_obj_bbox_0: 0.17312/0.38635, loss_sub_giou_0: 0.75192/0.61830, loss_obj_giou_0: 0.99348/0.94538, obj_cardinality_error_0: 1.50000/2.50362, loss_obj_ce_1: 0.59002/0.78135, loss_verb_ce_1: 0.66616/0.95831, loss_sub_bbox_1: 0.20229/0.37618, loss_obj_bbox_1: 0.25407/0.38624, loss_sub_giou_1: 0.69128/0.62227, loss_obj_giou_1: 0.96243/0.94198, obj_cardinality_error_1: 1.00000/2.18891] items per batch[1] items per second[0.76] total items[2210] mini batches[  2210] memory[1414] epoch remaining[0:01:00]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2220/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.27154/18.63963, loss_obj_ce: 0.53208/0.76858, obj_class_error: 75.00000/74.99757, loss_verb_ce: 1.01077/0.94843, loss_sub_bbox: 0.23871/0.38015, loss_obj_bbox: 0.25917/0.39177, loss_sub_giou: 0.32467/0.62815, loss_obj_giou: 0.41584/0.95344, obj_cardinality_error: 1.00000/2.31622, loss_obj_ce_0: 0.58477/0.84009, loss_verb_ce_0: 1.04778/1.00480, loss_sub_bbox_0: 0.35028/0.36894, loss_obj_bbox_0: 0.27420/0.38579, loss_sub_giou_0: 0.44110/0.61804, loss_obj_giou_0: 0.39452/0.94446, obj_cardinality_error_0: 4.50000/2.50541, loss_obj_ce_1: 0.53491/0.78077, loss_verb_ce_1: 0.99342/0.95816, loss_sub_bbox_1: 0.28730/0.37576, loss_obj_bbox_1: 0.23340/0.38564, loss_sub_giou_1: 0.39356/0.62195, loss_obj_giou_1: 0.43850/0.94124, obj_cardinality_error_1: 3.00000/2.19505] items per batch[1] items per second[0.82] total items[2220] mini batches[  2220] memory[1414] epoch remaining[0:00:59]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2230/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.01617/18.62480, loss_obj_ce: 0.51817/0.76731, obj_class_error: 75.00000/74.98487, loss_verb_ce: 0.90370/0.94767, loss_sub_bbox: 0.33313/0.37993, loss_obj_bbox: 0.28067/0.39134, loss_sub_giou: 0.42391/0.62812, loss_obj_giou: 0.62886/0.95267, obj_cardinality_error: 0.50000/2.31143, loss_obj_ce_0: 0.68308/0.83893, loss_verb_ce_0: 1.08838/1.00418, loss_sub_bbox_0: 0.20315/0.36872, loss_obj_bbox_0: 0.28044/0.38534, loss_sub_giou_0: 0.31325/0.61803, loss_obj_giou_0: 0.58347/0.94391, obj_cardinality_error_0: 1.00000/2.50067, loss_obj_ce_1: 0.52996/0.77950, loss_verb_ce_1: 0.87715/0.95772, loss_sub_bbox_1: 0.34799/0.37539, loss_obj_bbox_1: 0.28450/0.38521, loss_sub_giou_1: 0.52395/0.62160, loss_obj_giou_1: 0.74836/0.94079, obj_cardinality_error_1: 1.50000/2.19013] items per batch[1] items per second[0.83] total items[2230] mini batches[  2230] memory[1414] epoch remaining[0:00:57]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2240/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.13715/18.61626, loss_obj_ce: 0.53725/0.76704, obj_class_error: 60.00000/74.93293, loss_verb_ce: 0.70193/0.94689, loss_sub_bbox: 0.45280/0.37971, loss_obj_bbox: 0.28893/0.39128, loss_sub_giou: 0.75729/0.62810, loss_obj_giou: 1.06271/0.95261, obj_cardinality_error: 3.50000/2.31295, loss_obj_ce_0: 0.76781/0.83890, loss_verb_ce_0: 0.81741/1.00334, loss_sub_bbox_0: 0.40758/0.36855, loss_obj_bbox_0: 0.18433/0.38506, loss_sub_giou_0: 0.67435/0.61815, loss_obj_giou_0: 0.90363/0.94341, obj_cardinality_error_0: 2.50000/2.49799, loss_obj_ce_1: 0.66207/0.77955, loss_verb_ce_1: 0.90159/0.95731, loss_sub_bbox_1: 0.49539/0.37510, loss_obj_bbox_1: 0.25389/0.38491, loss_sub_giou_1: 0.64370/0.62146, loss_obj_giou_1: 1.07920/0.94041, obj_cardinality_error_1: 1.50000/2.18795] items per batch[1] items per second[0.79] total items[2240] mini batches[  2240] memory[1414] epoch remaining[0:00:56]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2250/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.07155/18.59610, loss_obj_ce: 0.51571/0.76575, obj_class_error: 100.00000/74.94063, loss_verb_ce: 0.91570/0.94652, loss_sub_bbox: 0.21111/0.37904, loss_obj_bbox: 0.21572/0.39072, loss_sub_giou: 0.50725/0.62731, loss_obj_giou: 1.13880/0.95190, obj_cardinality_error: 1.00000/2.30733, loss_obj_ce_0: 0.50055/0.83770, loss_verb_ce_0: 0.80745/1.00291, loss_sub_bbox_0: 0.27673/0.36805, loss_obj_bbox_0: 0.21441/0.38433, loss_sub_giou_0: 0.54649/0.61757, loss_obj_giou_0: 1.03704/0.94214, obj_cardinality_error_0: 1.50000/2.49311, loss_obj_ce_1: 0.46370/0.77841, loss_verb_ce_1: 0.86588/0.95693, loss_sub_bbox_1: 0.25137/0.37457, loss_obj_bbox_1: 0.22976/0.38422, loss_sub_giou_1: 0.63849/0.62088, loss_obj_giou_1: 1.04769/0.93941, obj_cardinality_error_1: 1.00000/2.18200] items per batch[1] items per second[0.78] total items[2250] mini batches[  2250] memory[1414] epoch remaining[0:00:55]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2260/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.54999/18.58497, loss_obj_ce: 0.26601/0.76505, obj_class_error: 25.00000/74.91730, loss_verb_ce: 0.54684/0.94581, loss_sub_bbox: 0.19470/0.37868, loss_obj_bbox: 0.28000/0.39033, loss_sub_giou: 0.26939/0.62695, loss_obj_giou: 1.43584/0.95177, obj_cardinality_error: 1.50000/2.30487, loss_obj_ce_0: 0.34166/0.83722, loss_verb_ce_0: 0.58352/1.00217, loss_sub_bbox_0: 0.30370/0.36778, loss_obj_bbox_0: 0.24424/0.38403, loss_sub_giou_0: 0.48562/0.61734, loss_obj_giou_0: 0.93424/0.94228, obj_cardinality_error_0: 0.50000/2.49049, loss_obj_ce_1: 0.33630/0.77806, loss_verb_ce_1: 0.60749/0.95650, loss_sub_bbox_1: 0.25862/0.37426, loss_obj_bbox_1: 0.17309/0.38383, loss_sub_giou_1: 0.38479/0.62064, loss_obj_giou_1: 0.98458/0.93937, obj_cardinality_error_1: 1.50000/2.18031] items per batch[1] items per second[0.80] total items[2260] mini batches[  2260] memory[1414] epoch remaining[0:00:54]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2270/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.52208/18.57255, loss_obj_ce: 0.77217/0.76494, obj_class_error: 60.00000/74.89993, loss_verb_ce: 0.55675/0.94494, loss_sub_bbox: 0.23741/0.37836, loss_obj_bbox: 0.43818/0.39012, loss_sub_giou: 0.32742/0.62681, loss_obj_giou: 0.86611/0.95131, obj_cardinality_error: 0.50000/2.30661, loss_obj_ce_0: 0.86269/0.83716, loss_verb_ce_0: 0.74848/1.00117, loss_sub_bbox_0: 0.25326/0.36750, loss_obj_bbox_0: 0.30805/0.38374, loss_sub_giou_0: 0.37592/0.61710, loss_obj_giou_0: 0.61679/0.94183, obj_cardinality_error_0: 0.50000/2.48722, loss_obj_ce_1: 0.82207/0.77796, loss_verb_ce_1: 0.62780/0.95568, loss_sub_bbox_1: 0.32197/0.37390, loss_obj_bbox_1: 0.36034/0.38344, loss_sub_giou_1: 0.51515/0.62053, loss_obj_giou_1: 0.69968/0.93865, obj_cardinality_error_1: 1.00000/2.17996] items per batch[1] items per second[0.84] total items[2270] mini batches[  2270] memory[1414] epoch remaining[0:00:53]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2280/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.65778/18.55737, loss_obj_ce: 0.47907/0.76384, obj_class_error: 66.66667/74.77683, loss_verb_ce: 0.80589/0.94400, loss_sub_bbox: 0.18228/0.37798, loss_obj_bbox: 0.23889/0.38985, loss_sub_giou: 0.41894/0.62698, loss_obj_giou: 0.97552/0.95106, obj_cardinality_error: 4.50000/2.30789, loss_obj_ce_0: 0.56136/0.83587, loss_verb_ce_0: 1.07257/1.00033, loss_sub_bbox_0: 0.29335/0.36709, loss_obj_bbox_0: 0.16858/0.38330, loss_sub_giou_0: 0.68176/0.61701, loss_obj_giou_0: 0.69474/0.94139, obj_cardinality_error_0: 5.50000/2.48377, loss_obj_ce_1: 0.52842/0.77690, loss_verb_ce_1: 0.94034/0.95488, loss_sub_bbox_1: 0.21563/0.37341, loss_obj_bbox_1: 0.24562/0.38316, loss_sub_giou_1: 0.53842/0.62047, loss_obj_giou_1: 0.78108/0.93842, obj_cardinality_error_1: 4.50000/2.18180] items per batch[1] items per second[0.77] total items[2280] mini batches[  2280] memory[1414] epoch remaining[0:00:51]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2290/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 10.32953/18.53978, loss_obj_ce: 0.28143/0.76256, obj_class_error: 66.66667/74.70700, loss_verb_ce: 0.54043/0.94262, loss_sub_bbox: 0.23609/0.37776, loss_obj_bbox: 0.29309/0.38976, loss_sub_giou: 0.27146/0.62601, loss_obj_giou: 0.47467/0.94994, obj_cardinality_error: 1.50000/2.30480, loss_obj_ce_0: 0.50402/0.83513, loss_verb_ce_0: 0.77749/0.99953, loss_sub_bbox_0: 0.23629/0.36696, loss_obj_bbox_0: 0.21785/0.38307, loss_sub_giou_0: 0.27789/0.61616, loss_obj_giou_0: 0.44150/0.94005, obj_cardinality_error_0: 1.00000/2.47729, loss_obj_ce_1: 0.34204/0.77609, loss_verb_ce_1: 0.58256/0.95401, loss_sub_bbox_1: 0.19820/0.37316, loss_obj_bbox_1: 0.15313/0.38317, loss_sub_giou_1: 0.25004/0.61946, loss_obj_giou_1: 0.34890/0.93732, obj_cardinality_error_1: 1.00000/2.17795] items per batch[1] items per second[0.79] total items[2290] mini batches[  2290] memory[1414] epoch remaining[0:00:50]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2300/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.44303/18.52678, loss_obj_ce: 0.91297/0.76204, obj_class_error: 50.00000/74.66501, loss_verb_ce: 0.63863/0.94161, loss_sub_bbox: 0.50470/0.37766, loss_obj_bbox: 0.30309/0.38924, loss_sub_giou: 0.51000/0.62580, loss_obj_giou: 0.47510/0.94884, obj_cardinality_error: 1.00000/2.29978, loss_obj_ce_0: 1.08956/0.83509, loss_verb_ce_0: 0.70612/0.99929, loss_sub_bbox_0: 0.47094/0.36692, loss_obj_bbox_0: 0.36438/0.38262, loss_sub_giou_0: 0.57866/0.61599, loss_obj_giou_0: 0.66712/0.93901, obj_cardinality_error_0: 1.00000/2.47761, loss_obj_ce_1: 0.94977/0.77568, loss_verb_ce_1: 0.72850/0.95328, loss_sub_bbox_1: 0.45255/0.37310, loss_obj_bbox_1: 0.30520/0.38263, loss_sub_giou_1: 0.50510/0.61928, loss_obj_giou_1: 0.60606/0.93626, obj_cardinality_error_1: 0.50000/2.17348] items per batch[1] items per second[0.82] total items[2300] mini batches[  2300] memory[1414] epoch remaining[0:00:49]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2310/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.77688/18.51640, loss_obj_ce: 0.75836/0.76181, obj_class_error: 88.88889/74.66154, loss_verb_ce: 0.74587/0.94118, loss_sub_bbox: 0.31431/0.37738, loss_obj_bbox: 0.18115/0.38896, loss_sub_giou: 0.76961/0.62544, loss_obj_giou: 1.03559/0.94820, obj_cardinality_error: 2.50000/2.29762, loss_obj_ce_0: 0.72937/0.83460, loss_verb_ce_0: 0.61068/0.99855, loss_sub_bbox_0: 0.41300/0.36687, loss_obj_bbox_0: 0.36454/0.38244, loss_sub_giou_0: 0.97775/0.61601, loss_obj_giou_0: 1.11792/0.93854, obj_cardinality_error_0: 1.50000/2.47143, loss_obj_ce_1: 0.53504/0.77505, loss_verb_ce_1: 0.56407/0.95247, loss_sub_bbox_1: 0.33465/0.37293, loss_obj_bbox_1: 0.30774/0.38232, loss_sub_giou_1: 0.91883/0.61915, loss_obj_giou_1: 1.30467/0.93597, obj_cardinality_error_1: 1.50000/2.16905] items per batch[1] items per second[0.83] total items[2310] mini batches[  2310] memory[1414] epoch remaining[0:00:48]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2320/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.66209/18.50555, loss_obj_ce: 0.48899/0.76178, obj_class_error: 25.00000/74.60262, loss_verb_ce: 0.51324/0.94029, loss_sub_bbox: 0.29618/0.37718, loss_obj_bbox: 0.34902/0.38862, loss_sub_giou: 0.53998/0.62537, loss_obj_giou: 1.07169/0.94784, obj_cardinality_error: 4.00000/2.29634, loss_obj_ce_0: 0.55362/0.83444, loss_verb_ce_0: 0.53959/0.99742, loss_sub_bbox_0: 0.43035/0.36681, loss_obj_bbox_0: 0.44391/0.38221, loss_sub_giou_0: 0.62414/0.61596, loss_obj_giou_0: 1.26527/0.93826, obj_cardinality_error_0: 0.50000/2.46659, loss_obj_ce_1: 0.53064/0.77493, loss_verb_ce_1: 0.47277/0.95150, loss_sub_bbox_1: 0.37149/0.37279, loss_obj_bbox_1: 0.38036/0.38198, loss_sub_giou_1: 0.56476/0.61910, loss_obj_giou_1: 1.29349/0.93547, obj_cardinality_error_1: 2.50000/2.16530] items per batch[1] items per second[0.81] total items[2320] mini batches[  2320] memory[1414] epoch remaining[0:00:46]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2330/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.08555/18.49136, loss_obj_ce: 0.68502/0.76086, obj_class_error: 57.14286/74.56893, loss_verb_ce: 0.50812/0.93936, loss_sub_bbox: 0.31787/0.37694, loss_obj_bbox: 0.45745/0.38835, loss_sub_giou: 0.72265/0.62534, loss_obj_giou: 1.01242/0.94722, obj_cardinality_error: 1.50000/2.30107, loss_obj_ce_0: 0.65044/0.83352, loss_verb_ce_0: 0.51182/0.99646, loss_sub_bbox_0: 0.39134/0.36655, loss_obj_bbox_0: 0.34130/0.38192, loss_sub_giou_0: 0.79632/0.61580, loss_obj_giou_0: 0.94524/0.93795, obj_cardinality_error_0: 1.00000/2.46567, loss_obj_ce_1: 0.69674/0.77407, loss_verb_ce_1: 0.44223/0.95059, loss_sub_bbox_1: 0.37349/0.37246, loss_obj_bbox_1: 0.50654/0.38175, loss_sub_giou_1: 0.78939/0.61893, loss_obj_giou_1: 0.89299/0.93494, obj_cardinality_error_1: 1.00000/2.16609] items per batch[1] items per second[0.82] total items[2330] mini batches[  2330] memory[1414] epoch remaining[0:00:45]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2340/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.34069/18.47961, loss_obj_ce: 0.68823/0.76036, obj_class_error: 60.00000/74.55225, loss_verb_ce: 0.68617/0.93843, loss_sub_bbox: 0.33433/0.37680, loss_obj_bbox: 0.32179/0.38820, loss_sub_giou: 0.45425/0.62491, loss_obj_giou: 0.78487/0.94681, obj_cardinality_error: 3.00000/2.30107, loss_obj_ce_0: 0.82257/0.83288, loss_verb_ce_0: 0.69303/0.99524, loss_sub_bbox_0: 0.34784/0.36647, loss_obj_bbox_0: 0.34092/0.38173, loss_sub_giou_0: 0.47644/0.61545, loss_obj_giou_0: 0.71206/0.93754, obj_cardinality_error_0: 1.50000/2.46325, loss_obj_ce_1: 0.74621/0.77360, loss_verb_ce_1: 0.73976/0.94970, loss_sub_bbox_1: 0.34937/0.37232, loss_obj_bbox_1: 0.35430/0.38163, loss_sub_giou_1: 0.44853/0.61862, loss_obj_giou_1: 0.84824/0.93480, obj_cardinality_error_1: 2.50000/2.16688] items per batch[1] items per second[0.89] total items[2340] mini batches[  2340] memory[1414] epoch remaining[0:00:44]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2350/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.93929/18.46528, loss_obj_ce: 0.45595/0.75937, obj_class_error: 50.00000/74.47462, loss_verb_ce: 0.58726/0.93731, loss_sub_bbox: 0.29699/0.37649, loss_obj_bbox: 0.29118/0.38798, loss_sub_giou: 0.67724/0.62459, loss_obj_giou: 1.11096/0.94670, obj_cardinality_error: 3.50000/2.30426, loss_obj_ce_0: 0.62164/0.83199, loss_verb_ce_0: 0.69496/0.99397, loss_sub_bbox_0: 0.31365/0.36630, loss_obj_bbox_0: 0.27651/0.38150, loss_sub_giou_0: 0.63547/0.61526, loss_obj_giou_0: 1.06705/0.93725, obj_cardinality_error_0: 1.50000/2.45809, loss_obj_ce_1: 0.48601/0.77262, loss_verb_ce_1: 0.59577/0.94854, loss_sub_bbox_1: 0.33234/0.37221, loss_obj_bbox_1: 0.25462/0.38141, loss_sub_giou_1: 0.69739/0.61854, loss_obj_giou_1: 1.01840/0.93455, obj_cardinality_error_1: 5.50000/2.16872] items per batch[1] items per second[0.80] total items[2350] mini batches[  2350] memory[1414] epoch remaining[0:00:43]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2360/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.46576/18.45674, loss_obj_ce: 1.07084/0.75915, obj_class_error: 53.33334/74.37317, loss_verb_ce: 0.56356/0.93619, loss_sub_bbox: 0.28170/0.37638, loss_obj_bbox: 0.31866/0.38799, loss_sub_giou: 0.93955/0.62481, loss_obj_giou: 0.91140/0.94657, obj_cardinality_error: 2.50000/2.30720, loss_obj_ce_0: 1.20782/0.83181, loss_verb_ce_0: 0.64480/0.99297, loss_sub_bbox_0: 0.25246/0.36610, loss_obj_bbox_0: 0.31395/0.38145, loss_sub_giou_0: 0.98223/0.61555, loss_obj_giou_0: 0.97861/0.93702, obj_cardinality_error_0: 2.50000/2.45763, loss_obj_ce_1: 1.15831/0.77218, loss_verb_ce_1: 0.49938/0.94716, loss_sub_bbox_1: 0.28274/0.37203, loss_obj_bbox_1: 0.38350/0.38153, loss_sub_giou_1: 1.11607/0.61878, loss_obj_giou_1: 1.10290/0.93455, obj_cardinality_error_1: 3.00000/2.17140] items per batch[1] items per second[0.80] total items[2360] mini batches[  2360] memory[1414] epoch remaining[0:00:41]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2370/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 10.14256/18.43816, loss_obj_ce: 0.27588/0.75819, obj_class_error: 0.00000/74.21914, loss_verb_ce: 0.49528/0.93501, loss_sub_bbox: 0.22845/0.37592, loss_obj_bbox: 0.23397/0.38755, loss_sub_giou: 0.45657/0.62452, loss_obj_giou: 0.75813/0.94623, obj_cardinality_error: 10.50000/2.33080, loss_obj_ce_0: 0.33660/0.83081, loss_verb_ce_0: 0.59022/0.99172, loss_sub_bbox_0: 0.19717/0.36573, loss_obj_bbox_0: 0.17591/0.38089, loss_sub_giou_0: 0.45695/0.61550, loss_obj_giou_0: 0.50061/0.93633, obj_cardinality_error_0: 5.50000/2.46688, loss_obj_ce_1: 0.27984/0.77103, loss_verb_ce_1: 0.47763/0.94592, loss_sub_bbox_1: 0.16523/0.37154, loss_obj_bbox_1: 0.19954/0.38116, loss_sub_giou_1: 0.31144/0.61872, loss_obj_giou_1: 0.63958/0.93454, obj_cardinality_error_1: 9.00000/2.18776] items per batch[1] items per second[0.80] total items[2370] mini batches[  2370] memory[1414] epoch remaining[0:00:40]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2380/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.88943/18.43226, loss_obj_ce: 0.64565/0.75748, obj_class_error: 28.57143/74.12638, loss_verb_ce: 0.55746/0.93406, loss_sub_bbox: 0.35012/0.37592, loss_obj_bbox: 0.35817/0.38755, loss_sub_giou: 1.17101/0.62498, loss_obj_giou: 1.34468/0.94643, obj_cardinality_error: 5.50000/2.34076, loss_obj_ce_0: 0.64566/0.83021, loss_verb_ce_0: 0.60853/0.99089, loss_sub_bbox_0: 0.39066/0.36571, loss_obj_bbox_0: 0.36493/0.38091, loss_sub_giou_0: 1.09812/0.61578, loss_obj_giou_0: 1.58995/0.93618, obj_cardinality_error_0: 4.50000/2.47290, loss_obj_ce_1: 0.74495/0.77020, loss_verb_ce_1: 0.71877/0.94503, loss_sub_bbox_1: 0.35174/0.37163, loss_obj_bbox_1: 0.32267/0.38118, loss_sub_giou_1: 1.09927/0.61922, loss_obj_giou_1: 1.43490/0.93458, obj_cardinality_error_1: 5.00000/2.19790] items per batch[1] items per second[0.81] total items[2380] mini batches[  2380] memory[1414] epoch remaining[0:00:39]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2390/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.14653/18.41658, loss_obj_ce: 0.83436/0.75664, obj_class_error: 71.42857/74.07099, loss_verb_ce: 0.68024/0.93293, loss_sub_bbox: 0.28523/0.37557, loss_obj_bbox: 0.26782/0.38743, loss_sub_giou: 0.39468/0.62436, loss_obj_giou: 0.44169/0.94576, obj_cardinality_error: 1.00000/2.33912, loss_obj_ce_0: 1.15514/0.82960, loss_verb_ce_0: 0.82700/0.98978, loss_sub_bbox_0: 0.31390/0.36568, loss_obj_bbox_0: 0.33766/0.38074, loss_sub_giou_0: 0.45537/0.61543, loss_obj_giou_0: 0.51800/0.93521, obj_cardinality_error_0: 2.00000/2.46946, loss_obj_ce_1: 0.90569/0.76945, loss_verb_ce_1: 0.63200/0.94384, loss_sub_bbox_1: 0.29567/0.37135, loss_obj_bbox_1: 0.22954/0.38106, loss_sub_giou_1: 0.46055/0.61865, loss_obj_giou_1: 0.37799/0.93380, obj_cardinality_error_1: 2.00000/2.19833] items per batch[1] items per second[0.82] total items[2390] mini batches[  2390] memory[1414] epoch remaining[0:00:38]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2400/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.21280/18.40561, loss_obj_ce: 0.19248/0.75561, obj_class_error: 25.00000/74.00863, loss_verb_ce: 0.42817/0.93223, loss_sub_bbox: 0.39753/0.37520, loss_obj_bbox: 0.29003/0.38712, loss_sub_giou: 0.45279/0.62455, loss_obj_giou: 0.71455/0.94587, obj_cardinality_error: 2.00000/2.33562, loss_obj_ce_0: 0.48438/0.82892, loss_verb_ce_0: 0.48531/0.98920, loss_sub_bbox_0: 0.40258/0.36547, loss_obj_bbox_0: 0.22876/0.38033, loss_sub_giou_0: 0.48912/0.61579, loss_obj_giou_0: 0.68320/0.93496, obj_cardinality_error_0: 0.50000/2.46417, loss_obj_ce_1: 0.27237/0.76848, loss_verb_ce_1: 0.48876/0.94306, loss_sub_bbox_1: 0.42008/0.37101, loss_obj_bbox_1: 0.22190/0.38077, loss_sub_giou_1: 0.45768/0.61887, loss_obj_giou_1: 0.75956/0.93385, obj_cardinality_error_1: 1.00000/2.19333] items per batch[1] items per second[0.78] total items[2400] mini batches[  2400] memory[1414] epoch remaining[0:00:37]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2410/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 10.72557/18.38945, loss_obj_ce: 0.25304/0.75432, obj_class_error: 100.00000/73.94600, loss_verb_ce: 0.53204/0.93085, loss_sub_bbox: 0.18897/0.37503, loss_obj_bbox: 0.26779/0.38681, loss_sub_giou: 0.31575/0.62404, loss_obj_giou: 0.83543/0.94559, obj_cardinality_error: 1.00000/2.33091, loss_obj_ce_0: 0.34315/0.82817, loss_verb_ce_0: 0.63546/0.98813, loss_sub_bbox_0: 0.21381/0.36529, loss_obj_bbox_0: 0.22651/0.38001, loss_sub_giou_0: 0.31444/0.61530, loss_obj_giou_0: 0.52157/0.93443, obj_cardinality_error_0: 1.50000/2.45954, loss_obj_ce_1: 0.28647/0.76728, loss_verb_ce_1: 0.58193/0.94187, loss_sub_bbox_1: 0.17920/0.37088, loss_obj_bbox_1: 0.22490/0.38053, loss_sub_giou_1: 0.30888/0.61848, loss_obj_giou_1: 0.79503/0.93381, obj_cardinality_error_1: 1.00000/2.18880] items per batch[1] items per second[0.83] total items[2410] mini batches[  2410] memory[1414] epoch remaining[0:00:35]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2420/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.40477/18.38525, loss_obj_ce: 1.06891/0.75462, obj_class_error: 100.00000/73.92438, loss_verb_ce: 0.86025/0.93023, loss_sub_bbox: 0.26366/0.37477, loss_obj_bbox: 0.23534/0.38679, loss_sub_giou: 0.66133/0.62402, loss_obj_giou: 0.87119/0.94555, obj_cardinality_error: 1.00000/2.32996, loss_obj_ce_0: 1.27842/0.82859, loss_verb_ce_0: 1.05892/0.98733, loss_sub_bbox_0: 0.27405/0.36519, loss_obj_bbox_0: 0.25088/0.38009, loss_sub_giou_0: 0.65679/0.61534, loss_obj_giou_0: 0.87391/0.93448, obj_cardinality_error_0: 1.50000/2.45868, loss_obj_ce_1: 0.95234/0.76762, loss_verb_ce_1: 0.84435/0.94125, loss_sub_bbox_1: 0.30735/0.37074, loss_obj_bbox_1: 0.27481/0.38050, loss_sub_giou_1: 0.69369/0.61863, loss_obj_giou_1: 0.80589/0.93362, obj_cardinality_error_1: 0.50000/2.18760] items per batch[1] items per second[0.77] total items[2420] mini batches[  2420] memory[1414] epoch remaining[0:00:34]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2430/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.90172/18.36853, loss_obj_ce: 0.46029/0.75376, obj_class_error: 50.00000/73.84768, loss_verb_ce: 0.63709/0.92934, loss_sub_bbox: 0.37902/0.37431, loss_obj_bbox: 0.34071/0.38628, loss_sub_giou: 0.64845/0.62391, loss_obj_giou: 1.13665/0.94474, obj_cardinality_error: 16.50000/2.34177, loss_obj_ce_0: 0.50299/0.82755, loss_verb_ce_0: 0.71275/0.98626, loss_sub_bbox_0: 0.49256/0.36498, loss_obj_bbox_0: 0.37661/0.37969, loss_sub_giou_0: 0.81063/0.61563, loss_obj_giou_0: 1.21708/0.93404, obj_cardinality_error_0: 5.50000/2.45617, loss_obj_ce_1: 0.34890/0.76672, loss_verb_ce_1: 0.53923/0.94030, loss_sub_bbox_1: 0.47027/0.37031, loss_obj_bbox_1: 0.33512/0.37996, loss_sub_giou_1: 0.83942/0.61857, loss_obj_giou_1: 1.17346/0.93298, obj_cardinality_error_1: 13.50000/2.19691] items per batch[1] items per second[0.79] total items[2430] mini batches[  2430] memory[1414] epoch remaining[0:00:33]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2440/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.50761/18.35311, loss_obj_ce: 0.77671/0.75292, obj_class_error: 75.00000/73.76008, loss_verb_ce: 0.77620/0.92844, loss_sub_bbox: 0.34177/0.37399, loss_obj_bbox: 0.22650/0.38582, loss_sub_giou: 0.51212/0.62369, loss_obj_giou: 0.82738/0.94423, obj_cardinality_error: 1.50000/2.35635, loss_obj_ce_0: 0.81174/0.82656, loss_verb_ce_0: 0.80796/0.98502, loss_sub_bbox_0: 0.30123/0.36480, loss_obj_bbox_0: 0.22451/0.37923, loss_sub_giou_0: 0.71368/0.61586, loss_obj_giou_0: 1.00742/0.93349, obj_cardinality_error_0: 2.50000/2.46045, loss_obj_ce_1: 0.81862/0.76569, loss_verb_ce_1: 0.88542/0.93945, loss_sub_bbox_1: 0.26219/0.37004, loss_obj_bbox_1: 0.19398/0.37961, loss_sub_giou_1: 0.44257/0.61857, loss_obj_giou_1: 0.78277/0.93256, obj_cardinality_error_1: 2.00000/2.20451] items per batch[1] items per second[0.78] total items[2440] mini batches[  2440] memory[1414] epoch remaining[0:00:32]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2450/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.91821/18.34242, loss_obj_ce: 0.45225/0.75266, obj_class_error: 66.66667/73.72699, loss_verb_ce: 0.96192/0.92773, loss_sub_bbox: 0.22575/0.37375, loss_obj_bbox: 0.23160/0.38548, loss_sub_giou: 0.84981/0.62344, loss_obj_giou: 0.95171/0.94378, obj_cardinality_error: 4.00000/2.36143, loss_obj_ce_0: 0.46471/0.82623, loss_verb_ce_0: 0.90323/0.98422, loss_sub_bbox_0: 0.18851/0.36480, loss_obj_bbox_0: 0.21995/0.37889, loss_sub_giou_0: 0.74417/0.61580, loss_obj_giou_0: 0.74480/0.93277, obj_cardinality_error_0: 4.50000/2.46510, loss_obj_ce_1: 0.43918/0.76543, loss_verb_ce_1: 0.97534/0.93878, loss_sub_bbox_1: 0.28015/0.36987, loss_obj_bbox_1: 0.26402/0.37931, loss_sub_giou_1: 0.96904/0.61843, loss_obj_giou_1: 1.09661/0.93215, obj_cardinality_error_1: 4.00000/2.21347] items per batch[1] items per second[0.76] total items[2450] mini batches[  2450] memory[1414] epoch remaining[0:00:30]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2460/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.50901/18.33045, loss_obj_ce: 0.84232/0.75256, obj_class_error: 88.88889/73.74071, loss_verb_ce: 0.79983/0.92758, loss_sub_bbox: 0.29391/0.37335, loss_obj_bbox: 0.29511/0.38507, loss_sub_giou: 0.69447/0.62281, loss_obj_giou: 0.90454/0.94307, obj_cardinality_error: 2.00000/2.36179, loss_obj_ce_0: 0.93512/0.82575, loss_verb_ce_0: 0.69569/0.98342, loss_sub_bbox_0: 0.37009/0.36482, loss_obj_bbox_0: 0.32350/0.37856, loss_sub_giou_0: 0.84721/0.61588, loss_obj_giou_0: 0.92465/0.93207, obj_cardinality_error_0: 3.00000/2.46524, loss_obj_ce_1: 0.78900/0.76497, loss_verb_ce_1: 0.71687/0.93810, loss_sub_bbox_1: 0.31751/0.36963, loss_obj_bbox_1: 0.24075/0.37887, loss_sub_giou_1: 0.71133/0.61805, loss_obj_giou_1: 0.83341/0.93138, obj_cardinality_error_1: 3.00000/2.21463] items per batch[1] items per second[0.89] total items[2460] mini batches[  2460] memory[1414] epoch remaining[0:00:29]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2470/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.64457/18.31567, loss_obj_ce: 0.26957/0.75148, obj_class_error: 100.00000/73.68435, loss_verb_ce: 0.76561/0.92675, loss_sub_bbox: 0.19867/0.37301, loss_obj_bbox: 0.14728/0.38488, loss_sub_giou: 0.38600/0.62243, loss_obj_giou: 0.56418/0.94253, obj_cardinality_error: 0.00000/2.35769, loss_obj_ce_0: 0.26512/0.82469, loss_verb_ce_0: 0.88411/0.98271, loss_sub_bbox_0: 0.21389/0.36444, loss_obj_bbox_0: 0.16008/0.37847, loss_sub_giou_0: 0.53718/0.61539, loss_obj_giou_0: 0.64961/0.93150, obj_cardinality_error_0: 0.50000/2.45891, loss_obj_ce_1: 0.26695/0.76394, loss_verb_ce_1: 0.77124/0.93722, loss_sub_bbox_1: 0.21169/0.36936, loss_obj_bbox_1: 0.16657/0.37864, loss_sub_giou_1: 0.46141/0.61753, loss_obj_giou_1: 0.65716/0.93083, obj_cardinality_error_1: 0.50000/2.21012] items per batch[1] items per second[0.82] total items[2470] mini batches[  2470] memory[1414] epoch remaining[0:00:28]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2480/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.65285/18.30485, loss_obj_ce: 0.19870/0.75063, obj_class_error: 33.33334/73.66142, loss_verb_ce: 0.58628/0.92610, loss_sub_bbox: 0.38022/0.37278, loss_obj_bbox: 0.13640/0.38460, loss_sub_giou: 0.49317/0.62241, loss_obj_giou: 0.78315/0.94193, obj_cardinality_error: 0.50000/2.35141, loss_obj_ce_0: 0.28880/0.82372, loss_verb_ce_0: 0.63741/0.98195, loss_sub_bbox_0: 0.37644/0.36433, loss_obj_bbox_0: 0.29268/0.37834, loss_sub_giou_0: 0.65616/0.61539, loss_obj_giou_0: 1.57156/0.93154, obj_cardinality_error_0: 1.00000/2.45383, loss_obj_ce_1: 0.22417/0.76307, loss_verb_ce_1: 0.64785/0.93662, loss_sub_bbox_1: 0.34680/0.36915, loss_obj_bbox_1: 0.12208/0.37831, loss_sub_giou_1: 0.55432/0.61749, loss_obj_giou_1: 1.00319/0.93055, obj_cardinality_error_1: 0.50000/2.20444] items per batch[1] items per second[0.85] total items[2480] mini batches[  2480] memory[1414] epoch remaining[0:00:27]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2490/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.36355/18.29019, loss_obj_ce: 0.86867/0.75006, obj_class_error: 100.00000/73.62721, loss_verb_ce: 1.01871/0.92521, loss_sub_bbox: 0.28718/0.37245, loss_obj_bbox: 0.50004/0.38414, loss_sub_giou: 0.50607/0.62220, loss_obj_giou: 0.65016/0.94121, obj_cardinality_error: 2.00000/2.35040, loss_obj_ce_0: 0.82211/0.82326, loss_verb_ce_0: 0.86771/0.98084, loss_sub_bbox_0: 0.37433/0.36405, loss_obj_bbox_0: 0.55805/0.37815, loss_sub_giou_0: 0.67631/0.61508, loss_obj_giou_0: 0.94966/0.93162, obj_cardinality_error_0: 1.00000/2.44900, loss_obj_ce_1: 0.60923/0.76238, loss_verb_ce_1: 0.72829/0.93544, loss_sub_bbox_1: 0.43596/0.36887, loss_obj_bbox_1: 0.44325/0.37790, loss_sub_giou_1: 0.72882/0.61733, loss_obj_giou_1: 0.82610/0.93020, obj_cardinality_error_1: 1.50000/2.20261] items per batch[1] items per second[0.79] total items[2490] mini batches[  2490] memory[1414] epoch remaining[0:00:25]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2500/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.76650/18.27642, loss_obj_ce: 0.74162/0.74920, obj_class_error: 71.42857/73.54028, loss_verb_ce: 0.65821/0.92449, loss_sub_bbox: 0.34113/0.37226, loss_obj_bbox: 0.28879/0.38369, loss_sub_giou: 0.69755/0.62211, loss_obj_giou: 0.77293/0.94077, obj_cardinality_error: 2.50000/2.35400, loss_obj_ce_0: 0.89568/0.82226, loss_verb_ce_0: 0.72812/0.97992, loss_sub_bbox_0: 0.26349/0.36396, loss_obj_bbox_0: 0.22806/0.37770, loss_sub_giou_0: 0.54876/0.61494, loss_obj_giou_0: 0.86089/0.93158, obj_cardinality_error_0: 3.50000/2.44580, loss_obj_ce_1: 0.66114/0.76118, loss_verb_ce_1: 0.73345/0.93451, loss_sub_bbox_1: 0.29140/0.36869, loss_obj_bbox_1: 0.23701/0.37743, loss_sub_giou_1: 0.53998/0.61731, loss_obj_giou_1: 0.68369/0.92988, obj_cardinality_error_1: 2.50000/2.20100] items per batch[1] items per second[0.86] total items[2500] mini batches[  2500] memory[1414] epoch remaining[0:00:24]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2510/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.22019/18.26868, loss_obj_ce: 0.46043/0.74893, obj_class_error: 50.00000/73.52949, loss_verb_ce: 0.81010/0.92461, loss_sub_bbox: 0.25024/0.37208, loss_obj_bbox: 0.19434/0.38343, loss_sub_giou: 0.35334/0.62151, loss_obj_giou: 0.59413/0.94004, obj_cardinality_error: 4.00000/2.35378, loss_obj_ce_0: 0.58236/0.82154, loss_verb_ce_0: 0.81874/0.97958, loss_sub_bbox_0: 0.34623/0.36408, loss_obj_bbox_0: 0.18435/0.37747, loss_sub_giou_0: 0.42503/0.61468, loss_obj_giou_0: 0.66905/0.93104, obj_cardinality_error_0: 7.50000/2.44841, loss_obj_ce_1: 0.55763/0.76057, loss_verb_ce_1: 0.82888/0.93423, loss_sub_bbox_1: 0.26399/0.36863, loss_obj_bbox_1: 0.20193/0.37722, loss_sub_giou_1: 0.30123/0.61680, loss_obj_giou_1: 0.75882/0.92941, obj_cardinality_error_1: 6.00000/2.20418] items per batch[1] items per second[0.82] total items[2510] mini batches[  2510] memory[1414] epoch remaining[0:00:23]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2520/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.19044/18.26363, loss_obj_ce: 1.07608/0.74873, obj_class_error: 80.00000/73.51495, loss_verb_ce: 0.96195/0.92424, loss_sub_bbox: 0.43166/0.37189, loss_obj_bbox: 0.50647/0.38324, loss_sub_giou: 0.59719/0.62131, loss_obj_giou: 0.92005/0.93979, obj_cardinality_error: 0.50000/2.35159, loss_obj_ce_0: 1.03628/0.82151, loss_verb_ce_0: 0.90354/0.97916, loss_sub_bbox_0: 0.46234/0.36402, loss_obj_bbox_0: 0.46129/0.37738, loss_sub_giou_0: 0.62695/0.61456, loss_obj_giou_0: 0.95706/0.93130, obj_cardinality_error_0: 2.00000/2.45000, loss_obj_ce_1: 0.95822/0.76040, loss_verb_ce_1: 0.93731/0.93368, loss_sub_bbox_1: 0.42655/0.36858, loss_obj_bbox_1: 0.45909/0.37706, loss_sub_giou_1: 0.62791/0.61698, loss_obj_giou_1: 0.91660/0.92943, obj_cardinality_error_1: 1.50000/2.20456] items per batch[1] items per second[0.79] total items[2520] mini batches[  2520] memory[1414] epoch remaining[0:00:22]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2530/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.29432/18.25564, loss_obj_ce: 0.51738/0.74792, obj_class_error: 50.00000/73.48412, loss_verb_ce: 0.74615/0.92341, loss_sub_bbox: 0.42377/0.37182, loss_obj_bbox: 0.33326/0.38336, loss_sub_giou: 0.78225/0.62115, loss_obj_giou: 1.40362/0.93974, obj_cardinality_error: 0.50000/2.34585, loss_obj_ce_0: 0.50302/0.82085, loss_verb_ce_0: 0.73981/0.97837, loss_sub_bbox_0: 0.48566/0.36398, loss_obj_bbox_0: 0.29440/0.37736, loss_sub_giou_0: 0.93186/0.61450, loss_obj_giou_0: 1.34250/0.93111, obj_cardinality_error_0: 0.50000/2.44486, loss_obj_ce_1: 0.46487/0.75953, loss_verb_ce_1: 0.73034/0.93281, loss_sub_bbox_1: 0.39716/0.36846, loss_obj_bbox_1: 0.34971/0.37720, loss_sub_giou_1: 0.81878/0.61698, loss_obj_giou_1: 1.38759/0.92924, obj_cardinality_error_1: 1.00000/2.20119] items per batch[1] items per second[0.91] total items[2530] mini batches[  2530] memory[1414] epoch remaining[0:00:20]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2540/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.90220/18.24332, loss_obj_ce: 0.81327/0.74714, obj_class_error: 100.00000/73.47237, loss_verb_ce: 0.88065/0.92287, loss_sub_bbox: 0.30009/0.37190, loss_obj_bbox: 0.24448/0.38289, loss_sub_giou: 0.82068/0.62108, loss_obj_giou: 1.08171/0.93890, obj_cardinality_error: 1.00000/2.34035, loss_obj_ce_0: 0.76370/0.82007, loss_verb_ce_0: 0.90191/0.97779, loss_sub_bbox_0: 0.28405/0.36393, loss_obj_bbox_0: 0.28051/0.37672, loss_sub_giou_0: 0.72924/0.61437, loss_obj_giou_0: 1.07428/0.93004, obj_cardinality_error_0: 0.50000/2.44094, loss_obj_ce_1: 0.53416/0.75873, loss_verb_ce_1: 0.73130/0.93242, loss_sub_bbox_1: 0.30989/0.36844, loss_obj_bbox_1: 0.23113/0.37664, loss_sub_giou_1: 0.86221/0.61708, loss_obj_giou_1: 1.06985/0.92844, obj_cardinality_error_1: 0.50000/2.19606] items per batch[1] items per second[0.89] total items[2540] mini batches[  2540] memory[1414] epoch remaining[0:00:19]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2550/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.78121/18.23649, loss_obj_ce: 0.52397/0.74689, obj_class_error: 75.00000/73.45791, loss_verb_ce: 0.87797/0.92244, loss_sub_bbox: 0.29215/0.37169, loss_obj_bbox: 0.38342/0.38281, loss_sub_giou: 0.54553/0.62073, loss_obj_giou: 0.76191/0.93859, obj_cardinality_error: 1.00000/2.33529, loss_obj_ce_0: 0.57492/0.81981, loss_verb_ce_0: 0.95260/0.97731, loss_sub_bbox_0: 0.27285/0.36398, loss_obj_bbox_0: 0.30156/0.37660, loss_sub_giou_0: 0.40850/0.61430, loss_obj_giou_0: 0.68836/0.92948, obj_cardinality_error_0: 1.50000/2.43647, loss_obj_ce_1: 0.54104/0.75851, loss_verb_ce_1: 0.96006/0.93203, loss_sub_bbox_1: 0.26749/0.36836, loss_obj_bbox_1: 0.47347/0.37652, loss_sub_giou_1: 0.37090/0.61685, loss_obj_giou_1: 0.80746/0.92788, obj_cardinality_error_1: 2.00000/2.19255] items per batch[1] items per second[0.82] total items[2550] mini batches[  2550] memory[1414] epoch remaining[0:00:18]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2560/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.80868/18.22714, loss_obj_ce: 0.82511/0.74620, obj_class_error: 85.71429/73.42287, loss_verb_ce: 0.89328/0.92173, loss_sub_bbox: 0.42530/0.37143, loss_obj_bbox: 0.36031/0.38252, loss_sub_giou: 0.72149/0.62036, loss_obj_giou: 0.78863/0.93886, obj_cardinality_error: 1.50000/2.33379, loss_obj_ce_0: 0.90064/0.81928, loss_verb_ce_0: 0.85082/0.97654, loss_sub_bbox_0: 0.46076/0.36380, loss_obj_bbox_0: 0.45033/0.37629, loss_sub_giou_0: 0.69693/0.61403, loss_obj_giou_0: 0.90770/0.92966, obj_cardinality_error_0: 2.00000/2.43398, loss_obj_ce_1: 0.78924/0.75784, loss_verb_ce_1: 0.83831/0.93119, loss_sub_bbox_1: 0.40653/0.36811, loss_obj_bbox_1: 0.45993/0.37652, loss_sub_giou_1: 0.69339/0.61668, loss_obj_giou_1: 0.91284/0.92865, obj_cardinality_error_1: 1.50000/2.19199] items per batch[1] items per second[0.77] total items[2560] mini batches[  2560] memory[1414] epoch remaining[0:00:17]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2570/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.65574/18.21531, loss_obj_ce: 0.52403/0.74568, obj_class_error: 75.00000/73.40480, loss_verb_ce: 0.82724/0.92112, loss_sub_bbox: 0.24923/0.37112, loss_obj_bbox: 0.27586/0.38227, loss_sub_giou: 0.35917/0.61996, loss_obj_giou: 0.47032/0.93871, obj_cardinality_error: 2.00000/2.33405, loss_obj_ce_0: 0.59673/0.81861, loss_verb_ce_0: 0.94678/0.97582, loss_sub_bbox_0: 0.29275/0.36355, loss_obj_bbox_0: 0.28622/0.37602, loss_sub_giou_0: 0.37339/0.61362, loss_obj_giou_0: 0.48620/0.92920, obj_cardinality_error_0: 1.00000/2.43521, loss_obj_ce_1: 0.51440/0.75714, loss_verb_ce_1: 0.77055/0.93039, loss_sub_bbox_1: 0.34835/0.36790, loss_obj_bbox_1: 0.28484/0.37628, loss_sub_giou_1: 0.41693/0.61638, loss_obj_giou_1: 0.48234/0.92849, obj_cardinality_error_1: 1.50000/2.19591] items per batch[1] items per second[0.79] total items[2570] mini batches[  2570] memory[1414] epoch remaining[0:00:16]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2580/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.07497/18.20181, loss_obj_ce: 0.81397/0.74540, obj_class_error: 100.00000/73.40068, loss_verb_ce: 0.97574/0.92062, loss_sub_bbox: 0.30048/0.37069, loss_obj_bbox: 0.19738/0.38194, loss_sub_giou: 0.47316/0.61956, loss_obj_giou: 0.72264/0.93799, obj_cardinality_error: 0.50000/2.33585, loss_obj_ce_0: 0.83061/0.81843, loss_verb_ce_0: 0.98301/0.97521, loss_sub_bbox_0: 0.29752/0.36322, loss_obj_bbox_0: 0.16087/0.37550, loss_sub_giou_0: 0.44747/0.61333, loss_obj_giou_0: 0.63519/0.92820, obj_cardinality_error_0: 1.50000/2.43140, loss_obj_ce_1: 0.70982/0.75682, loss_verb_ce_1: 1.00120/0.92993, loss_sub_bbox_1: 0.29382/0.36751, loss_obj_bbox_1: 0.15170/0.37587, loss_sub_giou_1: 0.53181/0.61607, loss_obj_giou_1: 0.48595/0.92769, obj_cardinality_error_1: 0.50000/2.19864] items per batch[1] items per second[0.77] total items[2580] mini batches[  2580] memory[1414] epoch remaining[0:00:14]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2590/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.72510/18.19077, loss_obj_ce: 0.65445/0.74513, obj_class_error: 75.00000/73.35285, loss_verb_ce: 1.03895/0.92024, loss_sub_bbox: 0.26403/0.37039, loss_obj_bbox: 0.17826/0.38161, loss_sub_giou: 0.34601/0.61914, loss_obj_giou: 0.54259/0.93728, obj_cardinality_error: 1.00000/2.33340, loss_obj_ce_0: 0.69779/0.81823, loss_verb_ce_0: 1.00100/0.97481, loss_sub_bbox_0: 0.18836/0.36297, loss_obj_bbox_0: 0.15915/0.37518, loss_sub_giou_0: 0.23379/0.61300, loss_obj_giou_0: 0.64936/0.92744, obj_cardinality_error_0: 1.50000/2.42934, loss_obj_ce_1: 0.66557/0.75666, loss_verb_ce_1: 1.04440/0.92969, loss_sub_bbox_1: 0.22174/0.36714, loss_obj_bbox_1: 0.14148/0.37543, loss_sub_giou_1: 0.36711/0.61564, loss_obj_giou_1: 0.51722/0.92692, obj_cardinality_error_1: 1.00000/2.19903] items per batch[1] items per second[0.77] total items[2590] mini batches[  2590] memory[1414] epoch remaining[0:00:13]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2600/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.83899/18.18186, loss_obj_ce: 0.83166/0.74449, obj_class_error: 71.42857/73.32833, loss_verb_ce: 0.75823/0.91999, loss_sub_bbox: 0.27321/0.37041, loss_obj_bbox: 0.32411/0.38119, loss_sub_giou: 0.77738/0.61918, loss_obj_giou: 1.10222/0.93679, obj_cardinality_error: 1.00000/2.33115, loss_obj_ce_0: 0.65356/0.81743, loss_verb_ce_0: 0.55143/0.97458, loss_sub_bbox_0: 0.27463/0.36280, loss_obj_bbox_0: 0.26995/0.37476, loss_sub_giou_0: 0.76212/0.61302, loss_obj_giou_0: 1.25859/0.92720, obj_cardinality_error_0: 1.00000/2.42558, loss_obj_ce_1: 0.59147/0.75594, loss_verb_ce_1: 0.63066/0.92956, loss_sub_bbox_1: 0.20382/0.36693, loss_obj_bbox_1: 0.25570/0.37492, loss_sub_giou_1: 0.68678/0.61547, loss_obj_giou_1: 1.29098/0.92655, obj_cardinality_error_1: 0.50000/2.19577] items per batch[1] items per second[0.80] total items[2600] mini batches[  2600] memory[1414] epoch remaining[0:00:12]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2610/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.29786/18.17147, loss_obj_ce: 0.75746/0.74405, obj_class_error: 66.66667/73.30463, loss_verb_ce: 0.80377/0.91973, loss_sub_bbox: 0.30200/0.37037, loss_obj_bbox: 0.18719/0.38082, loss_sub_giou: 0.50471/0.61868, loss_obj_giou: 0.73899/0.93623, obj_cardinality_error: 1.00000/2.32663, loss_obj_ce_0: 0.69115/0.81658, loss_verb_ce_0: 0.86008/0.97387, loss_sub_bbox_0: 0.27327/0.36276, loss_obj_bbox_0: 0.26754/0.37451, loss_sub_giou_0: 0.53075/0.61259, loss_obj_giou_0: 1.06883/0.92669, obj_cardinality_error_0: 1.50000/2.42031, loss_obj_ce_1: 0.76142/0.75532, loss_verb_ce_1: 0.82631/0.92908, loss_sub_bbox_1: 0.26110/0.36691, loss_obj_bbox_1: 0.27851/0.37457, loss_sub_giou_1: 0.49064/0.61514, loss_obj_giou_1: 0.84957/0.92597, obj_cardinality_error_1: 1.50000/2.19234] items per batch[1] items per second[0.81] total items[2610] mini batches[  2610] memory[1414] epoch remaining[0:00:11]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2620/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.85977/18.16152, loss_obj_ce: 0.82032/0.74380, obj_class_error: 100.00000/73.26829, loss_verb_ce: 0.92297/0.91929, loss_sub_bbox: 0.25880/0.37004, loss_obj_bbox: 0.09226/0.38042, loss_sub_giou: 0.66402/0.61828, loss_obj_giou: 0.69650/0.93621, obj_cardinality_error: 0.50000/2.32595, loss_obj_ce_0: 0.81524/0.81611, loss_verb_ce_0: 0.83330/0.97310, loss_sub_bbox_0: 0.17094/0.36259, loss_obj_bbox_0: 0.13468/0.37419, loss_sub_giou_0: 0.69440/0.61246, loss_obj_giou_0: 0.76673/0.92658, obj_cardinality_error_0: 0.50000/2.41679, loss_obj_ce_1: 0.89227/0.75503, loss_verb_ce_1: 0.93107/0.92858, loss_sub_bbox_1: 0.24549/0.36666, loss_obj_bbox_1: 0.19130/0.37422, loss_sub_giou_1: 0.61576/0.61477, loss_obj_giou_1: 0.78617/0.92604, obj_cardinality_error_1: 0.50000/2.19008] items per batch[1] items per second[0.87] total items[2620] mini batches[  2620] memory[1414] epoch remaining[0:00:09]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2630/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.99599/18.15738, loss_obj_ce: 1.33020/0.74395, obj_class_error: 66.66667/73.20291, loss_verb_ce: 0.88904/0.91902, loss_sub_bbox: 0.65185/0.37006, loss_obj_bbox: 0.37822/0.38037, loss_sub_giou: 0.88234/0.61812, loss_obj_giou: 0.59923/0.93547, obj_cardinality_error: 2.00000/2.32338, loss_obj_ce_0: 1.31922/0.81630, loss_verb_ce_0: 0.89451/0.97279, loss_sub_bbox_0: 0.57770/0.36258, loss_obj_bbox_0: 0.56883/0.37416, loss_sub_giou_0: 0.66669/0.61209, loss_obj_giou_0: 0.72643/0.92580, obj_cardinality_error_0: 1.50000/2.41445, loss_obj_ce_1: 1.26895/0.75526, loss_verb_ce_1: 0.87854/0.92837, loss_sub_bbox_1: 0.50089/0.36673, loss_obj_bbox_1: 0.38959/0.37418, loss_sub_giou_1: 0.60181/0.61455, loss_obj_giou_1: 0.60926/0.92528, obj_cardinality_error_1: 1.50000/2.18840] items per batch[1] items per second[0.83] total items[2630] mini batches[  2630] memory[1414] epoch remaining[0:00:08]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2640/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.96894/18.14719, loss_obj_ce: 0.74624/0.74362, obj_class_error: 80.00000/73.15502, loss_verb_ce: 0.69391/0.91810, loss_sub_bbox: 0.36295/0.36994, loss_obj_bbox: 0.46241/0.38022, loss_sub_giou: 0.60029/0.61802, loss_obj_giou: 0.98401/0.93476, obj_cardinality_error: 2.00000/2.31932, loss_obj_ce_0: 0.85851/0.81592, loss_verb_ce_0: 0.72800/0.97190, loss_sub_bbox_0: 0.37057/0.36258, loss_obj_bbox_0: 0.36328/0.37412, loss_sub_giou_0: 0.74117/0.61213, loss_obj_giou_0: 0.68679/0.92517, obj_cardinality_error_0: 1.50000/2.40871, loss_obj_ce_1: 0.78730/0.75484, loss_verb_ce_1: 0.73432/0.92746, loss_sub_bbox_1: 0.36496/0.36666, loss_obj_bbox_1: 0.40470/0.37398, loss_sub_giou_1: 0.63613/0.61461, loss_obj_giou_1: 0.79387/0.92447, obj_cardinality_error_1: 1.50000/2.18580] items per batch[1] items per second[0.82] total items[2640] mini batches[  2640] memory[1414] epoch remaining[0:00:07]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2650/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.45774/18.13760, loss_obj_ce: 0.48914/0.74354, obj_class_error: 75.00000/73.13171, loss_verb_ce: 0.94635/0.91742, loss_sub_bbox: 0.31048/0.36976, loss_obj_bbox: 0.28233/0.37979, loss_sub_giou: 0.69146/0.61794, loss_obj_giou: 0.91970/0.93451, obj_cardinality_error: 1.00000/2.31566, loss_obj_ce_0: 0.65988/0.81571, loss_verb_ce_0: 1.01732/0.97118, loss_sub_bbox_0: 0.27274/0.36237, loss_obj_bbox_0: 0.26422/0.37380, loss_sub_giou_0: 0.64787/0.61197, loss_obj_giou_0: 0.84820/0.92498, obj_cardinality_error_0: 0.50000/2.40472, loss_obj_ce_1: 0.54230/0.75483, loss_verb_ce_1: 0.94083/0.92689, loss_sub_bbox_1: 0.28527/0.36649, loss_obj_bbox_1: 0.28556/0.37360, loss_sub_giou_1: 0.66268/0.61451, loss_obj_giou_1: 0.93605/0.92410, obj_cardinality_error_1: 1.00000/2.18283] items per batch[1] items per second[0.79] total items[2650] mini batches[  2650] memory[1414] epoch remaining[0:00:06]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2660/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.23728/18.12799, loss_obj_ce: 0.52241/0.74305, obj_class_error: 50.00000/73.06623, loss_verb_ce: 0.50173/0.91624, loss_sub_bbox: 0.35017/0.36966, loss_obj_bbox: 0.42523/0.37948, loss_sub_giou: 0.48546/0.61828, loss_obj_giou: 0.64241/0.93482, obj_cardinality_error: 1.50000/2.31617, loss_obj_ce_0: 0.51796/0.81532, loss_verb_ce_0: 0.57919/0.97006, loss_sub_bbox_0: 0.38107/0.36226, loss_obj_bbox_0: 0.38000/0.37357, loss_sub_giou_0: 0.49566/0.61235, loss_obj_giou_0: 0.59900/0.92505, obj_cardinality_error_0: 1.50000/2.40282, loss_obj_ce_1: 0.52939/0.75424, loss_verb_ce_1: 0.49913/0.92575, loss_sub_bbox_1: 0.32418/0.36639, loss_obj_bbox_1: 0.24545/0.37330, loss_sub_giou_1: 0.46671/0.61486, loss_obj_giou_1: 0.55292/0.92431, obj_cardinality_error_1: 1.50000/2.18515] items per batch[1] items per second[0.87] total items[2660] mini batches[  2660] memory[1414] epoch remaining[0:00:04]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2670/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.93387/18.11249, loss_obj_ce: 0.49356/0.74210, obj_class_error: 75.00000/73.02832, loss_verb_ce: 0.84401/0.91540, loss_sub_bbox: 0.27309/0.36936, loss_obj_bbox: 0.32491/0.37942, loss_sub_giou: 0.54577/0.61787, loss_obj_giou: 0.46086/0.93414, obj_cardinality_error: 1.00000/2.31217, loss_obj_ce_0: 0.51883/0.81412, loss_verb_ce_0: 0.77270/0.96908, loss_sub_bbox_0: 0.37837/0.36197, loss_obj_bbox_0: 0.26176/0.37334, loss_sub_giou_0: 0.59889/0.61189, loss_obj_giou_0: 0.45989/0.92408, obj_cardinality_error_0: 1.50000/2.39888, loss_obj_ce_1: 0.49315/0.75320, loss_verb_ce_1: 0.82414/0.92483, loss_sub_bbox_1: 0.26473/0.36608, loss_obj_bbox_1: 0.31960/0.37315, loss_sub_giou_1: 0.43702/0.61454, loss_obj_giou_1: 0.48805/0.92363, obj_cardinality_error_1: 0.50000/2.18221] items per batch[1] items per second[0.83] total items[2670] mini batches[  2670] memory[1414] epoch remaining[0:00:03]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2680/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.10514/18.10310, loss_obj_ce: 0.35511/0.74136, obj_class_error: 25.00000/72.99952, loss_verb_ce: 0.71751/0.91534, loss_sub_bbox: 0.38508/0.36915, loss_obj_bbox: 0.28209/0.37902, loss_sub_giou: 0.60779/0.61730, loss_obj_giou: 1.31054/0.93421, obj_cardinality_error: 1.50000/2.30690, loss_obj_ce_0: 0.46434/0.81320, loss_verb_ce_0: 0.77806/0.96859, loss_sub_bbox_0: 0.39545/0.36179, loss_obj_bbox_0: 0.31501/0.37310, loss_sub_giou_0: 0.67918/0.61144, loss_obj_giou_0: 1.17527/0.92389, obj_cardinality_error_0: 1.50000/2.39608, loss_obj_ce_1: 0.58232/0.75240, loss_verb_ce_1: 0.90465/0.92477, loss_sub_bbox_1: 0.32801/0.36581, loss_obj_bbox_1: 0.37280/0.37287, loss_sub_giou_1: 0.62026/0.61403, loss_obj_giou_1: 1.31375/0.92353, obj_cardinality_error_1: 1.00000/2.17705] items per batch[1] items per second[0.82] total items[2680] mini batches[  2680] memory[1414] epoch remaining[0:00:02]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2690/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.86534/18.10188, loss_obj_ce: 0.79612/0.74099, obj_class_error: 75.00000/72.96411, loss_verb_ce: 0.75285/0.91485, loss_sub_bbox: 0.19629/0.36941, loss_obj_bbox: 0.36264/0.37912, loss_sub_giou: 0.37972/0.61750, loss_obj_giou: 0.82473/0.93414, obj_cardinality_error: 1.00000/2.30223, loss_obj_ce_0: 0.48126/0.81273, loss_verb_ce_0: 0.72675/0.96835, loss_sub_bbox_0: 0.30437/0.36197, loss_obj_bbox_0: 0.32180/0.37311, loss_sub_giou_0: 0.59045/0.61163, loss_obj_giou_0: 0.78491/0.92383, obj_cardinality_error_0: 0.50000/2.39331, loss_obj_ce_1: 0.62910/0.75224, loss_verb_ce_1: 0.69297/0.92465, loss_sub_bbox_1: 0.30743/0.36587, loss_obj_bbox_1: 0.34475/0.37279, loss_sub_giou_1: 0.61358/0.61410, loss_obj_giou_1: 0.82714/0.92336, obj_cardinality_error_1: 2.50000/2.17435] items per batch[1] items per second[0.90] total items[2690] mini batches[  2690] memory[1414] epoch remaining[0:00:01]\n",
      "INFO:trainer.default_trainer:epochs[     0] optim steps[2700/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.99197/18.09307, loss_obj_ce: 1.01406/0.74082, obj_class_error: 83.33334/72.97377, loss_verb_ce: 1.16604/0.91449, loss_sub_bbox: 0.30296/0.36917, loss_obj_bbox: 0.33510/0.37886, loss_sub_giou: 0.57957/0.61718, loss_obj_giou: 0.86505/0.93364, obj_cardinality_error: 3.00000/2.29889, loss_obj_ce_0: 0.87310/0.81253, loss_verb_ce_0: 1.04081/0.96781, loss_sub_bbox_0: 0.30045/0.36184, loss_obj_bbox_0: 0.32510/0.37297, loss_sub_giou_0: 0.56559/0.61130, loss_obj_giou_0: 0.83563/0.92366, obj_cardinality_error_0: 2.00000/2.39204, loss_obj_ce_1: 0.85836/0.75201, loss_verb_ce_1: 0.97105/0.92416, loss_sub_bbox_1: 0.28837/0.36561, loss_obj_bbox_1: 0.31324/0.37248, loss_sub_giou_1: 0.50734/0.61371, loss_obj_giou_1: 0.87444/0.92299, obj_cardinality_error_1: 2.50000/2.17222] items per batch[1] items per second[0.83] total items[2700] mini batches[  2700] memory[1414] epoch remaining[0:00:00]\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n",
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.27 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/2473. Dataloading: 0.0143 s/iter. Inference: 0.1257 s/iter. Eval: 0.0003 s/iter. Total: 0.1403 s/iter. ETA=0:05:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 47/2473. Dataloading: 0.0171 s/iter. Inference: 0.1219 s/iter. Eval: 0.0003 s/iter. Total: 0.1393 s/iter. ETA=0:05:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 84/2473. Dataloading: 0.0172 s/iter. Inference: 0.1201 s/iter. Eval: 0.0003 s/iter. Total: 0.1376 s/iter. ETA=0:05:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 120/2473. Dataloading: 0.0173 s/iter. Inference: 0.1213 s/iter. Eval: 0.0003 s/iter. Total: 0.1390 s/iter. ETA=0:05:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 158/2473. Dataloading: 0.0174 s/iter. Inference: 0.1206 s/iter. Eval: 0.0003 s/iter. Total: 0.1382 s/iter. ETA=0:05:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 196/2473. Dataloading: 0.0173 s/iter. Inference: 0.1197 s/iter. Eval: 0.0003 s/iter. Total: 0.1374 s/iter. ETA=0:05:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 232/2473. Dataloading: 0.0174 s/iter. Inference: 0.1201 s/iter. Eval: 0.0003 s/iter. Total: 0.1377 s/iter. ETA=0:05:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 267/2473. Dataloading: 0.0174 s/iter. Inference: 0.1210 s/iter. Eval: 0.0003 s/iter. Total: 0.1387 s/iter. ETA=0:05:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 302/2473. Dataloading: 0.0175 s/iter. Inference: 0.1216 s/iter. Eval: 0.0003 s/iter. Total: 0.1394 s/iter. ETA=0:05:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 337/2473. Dataloading: 0.0176 s/iter. Inference: 0.1222 s/iter. Eval: 0.0003 s/iter. Total: 0.1401 s/iter. ETA=0:04:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 374/2473. Dataloading: 0.0177 s/iter. Inference: 0.1218 s/iter. Eval: 0.0003 s/iter. Total: 0.1399 s/iter. ETA=0:04:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 409/2473. Dataloading: 0.0177 s/iter. Inference: 0.1221 s/iter. Eval: 0.0003 s/iter. Total: 0.1402 s/iter. ETA=0:04:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 446/2473. Dataloading: 0.0177 s/iter. Inference: 0.1218 s/iter. Eval: 0.0003 s/iter. Total: 0.1398 s/iter. ETA=0:04:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 483/2473. Dataloading: 0.0177 s/iter. Inference: 0.1215 s/iter. Eval: 0.0003 s/iter. Total: 0.1395 s/iter. ETA=0:04:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 518/2473. Dataloading: 0.0177 s/iter. Inference: 0.1219 s/iter. Eval: 0.0003 s/iter. Total: 0.1399 s/iter. ETA=0:04:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 554/2473. Dataloading: 0.0177 s/iter. Inference: 0.1221 s/iter. Eval: 0.0003 s/iter. Total: 0.1401 s/iter. ETA=0:04:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 591/2473. Dataloading: 0.0177 s/iter. Inference: 0.1219 s/iter. Eval: 0.0003 s/iter. Total: 0.1399 s/iter. ETA=0:04:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 627/2473. Dataloading: 0.0177 s/iter. Inference: 0.1220 s/iter. Eval: 0.0003 s/iter. Total: 0.1400 s/iter. ETA=0:04:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 662/2473. Dataloading: 0.0177 s/iter. Inference: 0.1223 s/iter. Eval: 0.0003 s/iter. Total: 0.1403 s/iter. ETA=0:04:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 700/2473. Dataloading: 0.0177 s/iter. Inference: 0.1219 s/iter. Eval: 0.0003 s/iter. Total: 0.1399 s/iter. ETA=0:04:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 738/2473. Dataloading: 0.0177 s/iter. Inference: 0.1215 s/iter. Eval: 0.0003 s/iter. Total: 0.1395 s/iter. ETA=0:04:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 775/2473. Dataloading: 0.0177 s/iter. Inference: 0.1214 s/iter. Eval: 0.0003 s/iter. Total: 0.1394 s/iter. ETA=0:03:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 813/2473. Dataloading: 0.0176 s/iter. Inference: 0.1212 s/iter. Eval: 0.0003 s/iter. Total: 0.1391 s/iter. ETA=0:03:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 850/2473. Dataloading: 0.0176 s/iter. Inference: 0.1211 s/iter. Eval: 0.0003 s/iter. Total: 0.1390 s/iter. ETA=0:03:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 887/2473. Dataloading: 0.0176 s/iter. Inference: 0.1211 s/iter. Eval: 0.0003 s/iter. Total: 0.1390 s/iter. ETA=0:03:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 924/2473. Dataloading: 0.0176 s/iter. Inference: 0.1210 s/iter. Eval: 0.0003 s/iter. Total: 0.1389 s/iter. ETA=0:03:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 962/2473. Dataloading: 0.0176 s/iter. Inference: 0.1208 s/iter. Eval: 0.0003 s/iter. Total: 0.1387 s/iter. ETA=0:03:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1000/2473. Dataloading: 0.0176 s/iter. Inference: 0.1207 s/iter. Eval: 0.0003 s/iter. Total: 0.1386 s/iter. ETA=0:03:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1037/2473. Dataloading: 0.0176 s/iter. Inference: 0.1207 s/iter. Eval: 0.0003 s/iter. Total: 0.1386 s/iter. ETA=0:03:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1073/2473. Dataloading: 0.0176 s/iter. Inference: 0.1208 s/iter. Eval: 0.0003 s/iter. Total: 0.1386 s/iter. ETA=0:03:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1109/2473. Dataloading: 0.0176 s/iter. Inference: 0.1208 s/iter. Eval: 0.0003 s/iter. Total: 0.1387 s/iter. ETA=0:03:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1144/2473. Dataloading: 0.0176 s/iter. Inference: 0.1210 s/iter. Eval: 0.0003 s/iter. Total: 0.1389 s/iter. ETA=0:03:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1182/2473. Dataloading: 0.0176 s/iter. Inference: 0.1208 s/iter. Eval: 0.0003 s/iter. Total: 0.1387 s/iter. ETA=0:02:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1219/2473. Dataloading: 0.0175 s/iter. Inference: 0.1208 s/iter. Eval: 0.0003 s/iter. Total: 0.1386 s/iter. ETA=0:02:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1257/2473. Dataloading: 0.0175 s/iter. Inference: 0.1206 s/iter. Eval: 0.0003 s/iter. Total: 0.1384 s/iter. ETA=0:02:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1294/2473. Dataloading: 0.0175 s/iter. Inference: 0.1205 s/iter. Eval: 0.0003 s/iter. Total: 0.1384 s/iter. ETA=0:02:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1332/2473. Dataloading: 0.0175 s/iter. Inference: 0.1204 s/iter. Eval: 0.0003 s/iter. Total: 0.1382 s/iter. ETA=0:02:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1370/2473. Dataloading: 0.0175 s/iter. Inference: 0.1203 s/iter. Eval: 0.0003 s/iter. Total: 0.1381 s/iter. ETA=0:02:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1407/2473. Dataloading: 0.0175 s/iter. Inference: 0.1203 s/iter. Eval: 0.0003 s/iter. Total: 0.1381 s/iter. ETA=0:02:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1444/2473. Dataloading: 0.0175 s/iter. Inference: 0.1202 s/iter. Eval: 0.0003 s/iter. Total: 0.1380 s/iter. ETA=0:02:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1481/2473. Dataloading: 0.0175 s/iter. Inference: 0.1202 s/iter. Eval: 0.0003 s/iter. Total: 0.1380 s/iter. ETA=0:02:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1518/2473. Dataloading: 0.0175 s/iter. Inference: 0.1202 s/iter. Eval: 0.0003 s/iter. Total: 0.1380 s/iter. ETA=0:02:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1557/2473. Dataloading: 0.0175 s/iter. Inference: 0.1200 s/iter. Eval: 0.0003 s/iter. Total: 0.1378 s/iter. ETA=0:02:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1596/2473. Dataloading: 0.0175 s/iter. Inference: 0.1198 s/iter. Eval: 0.0003 s/iter. Total: 0.1376 s/iter. ETA=0:02:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1631/2473. Dataloading: 0.0175 s/iter. Inference: 0.1199 s/iter. Eval: 0.0003 s/iter. Total: 0.1377 s/iter. ETA=0:01:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1669/2473. Dataloading: 0.0175 s/iter. Inference: 0.1198 s/iter. Eval: 0.0003 s/iter. Total: 0.1376 s/iter. ETA=0:01:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1707/2473. Dataloading: 0.0175 s/iter. Inference: 0.1198 s/iter. Eval: 0.0003 s/iter. Total: 0.1375 s/iter. ETA=0:01:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1744/2473. Dataloading: 0.0175 s/iter. Inference: 0.1198 s/iter. Eval: 0.0003 s/iter. Total: 0.1376 s/iter. ETA=0:01:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1781/2473. Dataloading: 0.0175 s/iter. Inference: 0.1198 s/iter. Eval: 0.0003 s/iter. Total: 0.1375 s/iter. ETA=0:01:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1819/2473. Dataloading: 0.0175 s/iter. Inference: 0.1196 s/iter. Eval: 0.0003 s/iter. Total: 0.1374 s/iter. ETA=0:01:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1857/2473. Dataloading: 0.0175 s/iter. Inference: 0.1195 s/iter. Eval: 0.0003 s/iter. Total: 0.1373 s/iter. ETA=0:01:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1895/2473. Dataloading: 0.0175 s/iter. Inference: 0.1195 s/iter. Eval: 0.0003 s/iter. Total: 0.1373 s/iter. ETA=0:01:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1933/2473. Dataloading: 0.0175 s/iter. Inference: 0.1194 s/iter. Eval: 0.0003 s/iter. Total: 0.1372 s/iter. ETA=0:01:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1970/2473. Dataloading: 0.0175 s/iter. Inference: 0.1194 s/iter. Eval: 0.0003 s/iter. Total: 0.1372 s/iter. ETA=0:01:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2008/2473. Dataloading: 0.0175 s/iter. Inference: 0.1194 s/iter. Eval: 0.0003 s/iter. Total: 0.1371 s/iter. ETA=0:01:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2046/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1371 s/iter. ETA=0:00:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2084/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2121/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2158/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2195/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2231/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1371 s/iter. ETA=0:00:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2270/2473. Dataloading: 0.0175 s/iter. Inference: 0.1192 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2308/2473. Dataloading: 0.0175 s/iter. Inference: 0.1192 s/iter. Eval: 0.0002 s/iter. Total: 0.1369 s/iter. ETA=0:00:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2344/2473. Dataloading: 0.0175 s/iter. Inference: 0.1192 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2381/2473. Dataloading: 0.0175 s/iter. Inference: 0.1193 s/iter. Eval: 0.0002 s/iter. Total: 0.1370 s/iter. ETA=0:00:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2417/2473. Dataloading: 0.0175 s/iter. Inference: 0.1194 s/iter. Eval: 0.0002 s/iter. Total: 0.1371 s/iter. ETA=0:00:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2454/2473. Dataloading: 0.0175 s/iter. Inference: 0.1194 s/iter. Eval: 0.0002 s/iter. Total: 0.1371 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "               hold_obj: #GTs = 3608, AP = 0.0107\n",
      "                  stand: #GTs = 4118, AP = 0.0222\n",
      "              sit_instr: #GTs = 1916, AP = 0.0059\n",
      "             ride_instr: #GTs = 0556, AP = 0.0001\n",
      "                   walk: #GTs = 0597, AP = 0.0009\n",
      "               look_obj: #GTs = 3347, AP = 0.0004\n",
      "              hit_instr: #GTs = 0349, AP = 0.0006\n",
      "                hit_obj: #GTs = 0349, AP = 0.0009\n",
      "                eat_obj: #GTs = 0521, AP = 0.0010\n",
      "              eat_instr: #GTs = 0521, AP = 0.0909\n",
      "             jump_instr: #GTs = 0635, AP = 0.0004\n",
      "              lay_instr: #GTs = 0387, AP = 0.0001\n",
      "    talk_on_phone_instr: #GTs = 0285, AP = 0.0000\n",
      "              carry_obj: #GTs = 0472, AP = 0.0001\n",
      "              throw_obj: #GTs = 0244, AP = 0.0002\n",
      "              catch_obj: #GTs = 0246, AP = 0.0000\n",
      "              cut_instr: #GTs = 0269, AP = 0.0000\n",
      "                cut_obj: #GTs = 0269, AP = 0.0026\n",
      "                    run: #GTs = 0687, AP = 0.0065\n",
      " work_on_computer_instr: #GTs = 0410, AP = 0.0182\n",
      "              ski_instr: #GTs = 0424, AP = 0.0006\n",
      "             surf_instr: #GTs = 0486, AP = 0.0000\n",
      "       skateboard_instr: #GTs = 0417, AP = 0.0000\n",
      "                  smile: #GTs = 1415, AP = 0.0918\n",
      "            drink_instr: #GTs = 0082, AP = 0.0000\n",
      "               kick_obj: #GTs = 0180, AP = 0.0000\n",
      "            point_instr: #GTs = 0031, AP = 0.0000\n",
      "               read_obj: #GTs = 0111, AP = 0.0004\n",
      "        snowboard_instr: #GTs = 0277, AP = 0.0002\n",
      "------------------------------------------------------------\n",
      "mAP all: 0.0088 mAP thesis: 0.0056\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.default_trainer:{'vcoco_val/vcoco': {'AP_hold_obj': 0.0106951871657754, 'AP_stand': 0.022228189910446797, 'AP_sit_instr': 0.005865102639296188, 'AP_ride_instr': 0.00011420740063956144, 'AP_walk': 0.0009072763563781528, 'AP_look_obj': 0.00042087542087542086, 'AP_hit_instr': 0.0005681818181818183, 'AP_hit_obj': 0.0009182736455463729, 'AP_eat_obj': 0.0010330578512396695, 'AP_eat_instr': 0.09090909090909091, 'AP_jump_instr': 0.0003852080123266564, 'AP_lay_instr': 0.00010215779974801077, 'AP_talk_on_phone_instr': 3.258390355164549e-05, 'AP_carry_obj': 6.343970056461333e-05, 'AP_throw_obj': 0.0001967729240456513, 'AP_catch_obj': 0.0, 'AP_cut_instr': 0.0, 'AP_cut_obj': 0.0025974025974025974, 'AP_run': 0.006493506493506493, 'AP_work_on_computer_instr': 0.018181818181818184, 'AP_ski_instr': 0.0006142506142506142, 'AP_surf_instr': 0.0, 'AP_skateboard_instr': 4.274052228918237e-05, 'AP_smile': 0.09184724491067855, 'AP_drink_instr': 0.0, 'AP_kick_obj': 0.0, 'AP_point_instr': 0.0, 'AP_read_obj': 0.0003710575139146568, 'AP_snowboard_instr': 0.00015513496742165683, 'mAP_all': 0.008784233146861683, 'mAP_thesis': 0.005552772649499116}}\n",
      "INFO:trainer.default_trainer:removed previous save directory..\n",
      "WARNING:trainer.utils_trainer:Saving best checkpoint...\n",
      "WARNING:trainer.utils_trainer:Finished saving checkpoint and model to /home/djjin/Mygit/X-Decoder/notebooks/data/output/test/00002700.\n",
      "INFO:trainer.default_trainer:This epoch takes 0:11:30.757983\n",
      "INFO:trainer.default_trainer:PROGRESS: 1.11%\n",
      "INFO:trainer.default_trainer:Config files are at ['/home/djjin/Mygit/X-Decoder/configs/hdecoder/vcoco.yaml']\n",
      "INFO:trainer.default_trainer:Start epoch: 1 training.\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[10/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.29652/18.08557, loss_obj_ce: 0.75313/0.74057, obj_class_error: 83.33334/72.97347, loss_verb_ce: 0.70941/0.91405, loss_sub_bbox: 0.36780/0.36895, loss_obj_bbox: 0.31471/0.37860, loss_sub_giou: 0.66219/0.61717, loss_obj_giou: 0.93543/0.93363, obj_cardinality_error: 1.50000/2.29373, loss_obj_ce_0: 0.56598/0.81210, loss_verb_ce_0: 0.66667/0.96724, loss_sub_bbox_0: 0.38192/0.36168, loss_obj_bbox_0: 0.26401/0.37276, loss_sub_giou_0: 0.72107/0.61128, loss_obj_giou_0: 1.03774/0.92382, obj_cardinality_error_0: 1.00000/2.38801, loss_obj_ce_1: 0.70099/0.75136, loss_verb_ce_1: 0.80840/0.92346, loss_sub_bbox_1: 0.33473/0.36546, loss_obj_bbox_1: 0.27129/0.37222, loss_sub_giou_1: 0.62661/0.61384, loss_obj_giou_1: 1.08827/0.92316, obj_cardinality_error_1: 1.50000/2.16845] items per batch[1] items per second[0.00] total items[2710] mini batches[  2710] memory[1606] epoch remaining[0:05:52]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[20/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.85678/18.07064, loss_obj_ce: 0.59484/0.73963, obj_class_error: 71.42857/72.89715, loss_verb_ce: 0.65425/0.91292, loss_sub_bbox: 0.29198/0.36873, loss_obj_bbox: 0.27443/0.37832, loss_sub_giou: 0.76431/0.61686, loss_obj_giou: 1.14045/0.93325, obj_cardinality_error: 2.00000/2.29154, loss_obj_ce_0: 0.63733/0.81105, loss_verb_ce_0: 0.63433/0.96625, loss_sub_bbox_0: 0.27322/0.36142, loss_obj_bbox_0: 0.23011/0.37264, loss_sub_giou_0: 0.74759/0.61087, loss_obj_giou_0: 0.96919/0.92367, obj_cardinality_error_0: 1.00000/2.38585, loss_obj_ce_1: 0.60270/0.75038, loss_verb_ce_1: 0.67814/0.92240, loss_sub_bbox_1: 0.21700/0.36515, loss_obj_bbox_1: 0.23925/0.37198, loss_sub_giou_1: 0.66439/0.61335, loss_obj_giou_1: 0.98756/0.92284, obj_cardinality_error_1: 1.50000/2.16673] items per batch[1] items per second[0.81] total items[2720] mini batches[  2720] memory[1606] epoch remaining[0:05:41]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[30/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.78261/18.06427, loss_obj_ce: 0.91281/0.73941, obj_class_error: 66.66667/72.86639, loss_verb_ce: 0.87855/0.91251, loss_sub_bbox: 0.29600/0.36855, loss_obj_bbox: 0.35012/0.37808, loss_sub_giou: 0.56921/0.61666, loss_obj_giou: 1.15783/0.93358, obj_cardinality_error: 1.50000/2.28736, loss_obj_ce_0: 0.76932/0.81063, loss_verb_ce_0: 0.83464/0.96576, loss_sub_bbox_0: 0.29483/0.36129, loss_obj_bbox_0: 0.32435/0.37237, loss_sub_giou_0: 0.55685/0.61073, loss_obj_giou_0: 1.49680/0.92405, obj_cardinality_error_0: 1.00000/2.38114, loss_obj_ce_1: 1.03151/0.75021, loss_verb_ce_1: 0.97964/0.92201, loss_sub_bbox_1: 0.24830/0.36494, loss_obj_bbox_1: 0.23528/0.37166, loss_sub_giou_1: 0.59624/0.61318, loss_obj_giou_1: 0.93420/0.92304, obj_cardinality_error_1: 1.50000/2.16410] items per batch[1] items per second[0.84] total items[2730] mini batches[  2730] memory[1606] epoch remaining[0:05:33]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[40/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.92298/18.05382, loss_obj_ce: 0.92686/0.73901, obj_class_error: 75.00000/72.85137, loss_verb_ce: 0.64545/0.91203, loss_sub_bbox: 0.33359/0.36826, loss_obj_bbox: 0.43424/0.37773, loss_sub_giou: 0.75520/0.61637, loss_obj_giou: 0.70744/0.93266, obj_cardinality_error: 1.50000/2.28339, loss_obj_ce_0: 1.03117/0.81025, loss_verb_ce_0: 0.58829/0.96523, loss_sub_bbox_0: 0.24029/0.36109, loss_obj_bbox_0: 0.53320/0.37233, loss_sub_giou_0: 0.51897/0.61061, loss_obj_giou_0: 0.90513/0.92370, obj_cardinality_error_0: 2.00000/2.37664, loss_obj_ce_1: 0.94315/0.74986, loss_verb_ce_1: 0.69128/0.92157, loss_sub_bbox_1: 0.32207/0.36470, loss_obj_bbox_1: 0.44794/0.37132, loss_sub_giou_1: 0.70363/0.61292, loss_obj_giou_1: 0.80309/0.92219, obj_cardinality_error_1: 1.00000/2.16186] items per batch[1] items per second[0.77] total items[2740] mini batches[  2740] memory[1606] epoch remaining[0:05:35]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[50/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.45937/18.05009, loss_obj_ce: 0.63632/0.73877, obj_class_error: 100.00000/72.86181, loss_verb_ce: 1.18595/0.91177, loss_sub_bbox: 0.54082/0.36839, loss_obj_bbox: 0.42718/0.37759, loss_sub_giou: 0.62407/0.61637, loss_obj_giou: 0.74749/0.93188, obj_cardinality_error: 0.50000/2.27964, loss_obj_ce_0: 0.70674/0.80981, loss_verb_ce_0: 1.20214/0.96487, loss_sub_bbox_0: 0.43240/0.36110, loss_obj_bbox_0: 0.37904/0.37220, loss_sub_giou_0: 0.53083/0.61052, loss_obj_giou_0: 0.77534/0.92319, obj_cardinality_error_0: 0.00000/2.37327, loss_obj_ce_1: 0.54175/0.74938, loss_verb_ce_1: 1.19927/0.92123, loss_sub_bbox_1: 0.43526/0.36496, loss_obj_bbox_1: 0.29234/0.37147, loss_sub_giou_1: 0.66463/0.61310, loss_obj_giou_1: 0.78984/0.92210, obj_cardinality_error_1: 0.50000/2.15855] items per batch[1] items per second[0.80] total items[2750] mini batches[  2750] memory[1606] epoch remaining[0:05:33]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[60/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.38536/18.04169, loss_obj_ce: 0.40994/0.73815, obj_class_error: 75.00000/72.85204, loss_verb_ce: 0.69578/0.91139, loss_sub_bbox: 0.23441/0.36814, loss_obj_bbox: 0.30914/0.37727, loss_sub_giou: 0.60341/0.61622, loss_obj_giou: 0.96586/0.93139, obj_cardinality_error: 1.00000/2.27717, loss_obj_ce_0: 0.53065/0.80896, loss_verb_ce_0: 0.84062/0.96428, loss_sub_bbox_0: 0.22588/0.36103, loss_obj_bbox_0: 0.18368/0.37187, loss_sub_giou_0: 0.51457/0.61057, loss_obj_giou_0: 0.90005/0.92285, obj_cardinality_error_0: 1.50000/2.37011, loss_obj_ce_1: 0.43886/0.74863, loss_verb_ce_1: 0.70458/0.92070, loss_sub_bbox_1: 0.36569/0.36490, loss_obj_bbox_1: 0.48299/0.37143, loss_sub_giou_1: 0.90762/0.61334, loss_obj_giou_1: 1.12795/0.92222, obj_cardinality_error_1: 0.50000/2.15652] items per batch[1] items per second[0.81] total items[2760] mini batches[  2760] memory[1606] epoch remaining[0:05:31]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[70/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.79998/18.02971, loss_obj_ce: 0.68368/0.73757, obj_class_error: 75.00000/72.82871, loss_verb_ce: 0.55927/0.91065, loss_sub_bbox: 0.43347/0.36787, loss_obj_bbox: 0.32846/0.37698, loss_sub_giou: 0.46000/0.61602, loss_obj_giou: 0.65365/0.93115, obj_cardinality_error: 0.50000/2.27274, loss_obj_ce_0: 0.80512/0.80839, loss_verb_ce_0: 0.68910/0.96356, loss_sub_bbox_0: 0.40378/0.36088, loss_obj_bbox_0: 0.36210/0.37150, loss_sub_giou_0: 0.40598/0.61057, loss_obj_giou_0: 0.54931/0.92198, obj_cardinality_error_0: 0.50000/2.36534, loss_obj_ce_1: 0.78279/0.74804, loss_verb_ce_1: 0.62695/0.91994, loss_sub_bbox_1: 0.50327/0.36469, loss_obj_bbox_1: 0.49276/0.37119, loss_sub_giou_1: 0.59651/0.61323, loss_obj_giou_1: 0.80271/0.92169, obj_cardinality_error_1: 0.00000/2.15415] items per batch[1] items per second[0.80] total items[2770] mini batches[  2770] memory[1606] epoch remaining[0:05:29]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[80/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.20504/18.02848, loss_obj_ce: 1.07684/0.73751, obj_class_error: 62.50000/72.77764, loss_verb_ce: 0.66897/0.91031, loss_sub_bbox: 0.38746/0.36791, loss_obj_bbox: 0.71553/0.37708, loss_sub_giou: 0.55908/0.61622, loss_obj_giou: 1.07430/0.93104, obj_cardinality_error: 1.50000/2.27302, loss_obj_ce_0: 0.75611/0.80818, loss_verb_ce_0: 0.59730/0.96333, loss_sub_bbox_0: 0.44455/0.36093, loss_obj_bbox_0: 0.56458/0.37145, loss_sub_giou_0: 0.64100/0.61084, loss_obj_giou_0: 1.30002/0.92183, obj_cardinality_error_0: 1.50000/2.36313, loss_obj_ce_1: 0.74974/0.74788, loss_verb_ce_1: 0.53038/0.91964, loss_sub_bbox_1: 0.41100/0.36473, loss_obj_bbox_1: 0.59411/0.37125, loss_sub_giou_1: 0.56054/0.61339, loss_obj_giou_1: 1.10106/0.92163, obj_cardinality_error_1: 2.50000/2.15162] items per batch[1] items per second[0.86] total items[2780] mini batches[  2780] memory[1606] epoch remaining[0:05:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[90/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.45236/18.01741, loss_obj_ce: 0.28797/0.73707, obj_class_error: 33.33334/72.71115, loss_verb_ce: 0.52821/0.90930, loss_sub_bbox: 0.23273/0.36762, loss_obj_bbox: 0.34952/0.37697, loss_sub_giou: 0.49883/0.61608, loss_obj_giou: 0.86424/0.93136, obj_cardinality_error: 2.00000/2.27509, loss_obj_ce_0: 0.28449/0.80771, loss_verb_ce_0: 0.54717/0.96246, loss_sub_bbox_0: 0.36593/0.36072, loss_obj_bbox_0: 0.24512/0.37109, loss_sub_giou_0: 0.68842/0.61063, loss_obj_giou_0: 0.65517/0.92153, obj_cardinality_error_0: 2.00000/2.36111, loss_obj_ce_1: 0.30350/0.74756, loss_verb_ce_1: 0.54272/0.91874, loss_sub_bbox_1: 0.27113/0.36446, loss_obj_bbox_1: 0.26999/0.37102, loss_sub_giou_1: 0.59568/0.61325, loss_obj_giou_1: 0.70179/0.92152, obj_cardinality_error_1: 3.00000/2.15466] items per batch[1] items per second[0.78] total items[2790] mini batches[  2790] memory[1606] epoch remaining[0:05:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[100/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.69916/18.01150, loss_obj_ce: 0.72289/0.73673, obj_class_error: 62.50000/72.69572, loss_verb_ce: 0.80288/0.90896, loss_sub_bbox: 0.35210/0.36762, loss_obj_bbox: 0.41282/0.37677, loss_sub_giou: 0.72053/0.61627, loss_obj_giou: 1.13344/0.93126, obj_cardinality_error: 2.00000/2.27250, loss_obj_ce_0: 0.77734/0.80730, loss_verb_ce_0: 0.80942/0.96197, loss_sub_bbox_0: 0.34833/0.36063, loss_obj_bbox_0: 0.32905/0.37078, loss_sub_giou_0: 0.67545/0.61078, loss_obj_giou_0: 0.95859/0.92125, obj_cardinality_error_0: 2.00000/2.35821, loss_obj_ce_1: 0.77440/0.74709, loss_verb_ce_1: 0.78391/0.91830, loss_sub_bbox_1: 0.33292/0.36444, loss_obj_bbox_1: 0.37953/0.37081, loss_sub_giou_1: 0.69949/0.61343, loss_obj_giou_1: 1.05771/0.92128, obj_cardinality_error_1: 1.50000/2.15232] items per batch[1] items per second[0.71] total items[2800] mini batches[  2800] memory[1606] epoch remaining[0:05:28]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[110/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.21097/18.00312, loss_obj_ce: 0.72575/0.73599, obj_class_error: 85.71429/72.67334, loss_verb_ce: 0.78307/0.90843, loss_sub_bbox: 0.21621/0.36743, loss_obj_bbox: 0.32024/0.37653, loss_sub_giou: 0.69839/0.61600, loss_obj_giou: 1.37691/0.93128, obj_cardinality_error: 2.00000/2.27633, loss_obj_ce_0: 0.77810/0.80644, loss_verb_ce_0: 0.69974/0.96131, loss_sub_bbox_0: 0.24800/0.36047, loss_obj_bbox_0: 0.13070/0.37062, loss_sub_giou_0: 0.79899/0.61077, loss_obj_giou_0: 1.10661/0.92169, obj_cardinality_error_0: 2.00000/2.35427, loss_obj_ce_1: 0.73099/0.74627, loss_verb_ce_1: 0.68267/0.91761, loss_sub_bbox_1: 0.29939/0.36427, loss_obj_bbox_1: 0.24347/0.37068, loss_sub_giou_1: 0.79687/0.61349, loss_obj_giou_1: 1.22236/0.92152, obj_cardinality_error_1: 0.50000/2.15231] items per batch[1] items per second[0.87] total items[2810] mini batches[  2810] memory[1606] epoch remaining[0:05:24]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[120/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.00089/17.99975, loss_obj_ce: 0.99440/0.73585, obj_class_error: 66.66667/72.65820, loss_verb_ce: 0.65585/0.90786, loss_sub_bbox: 0.32948/0.36735, loss_obj_bbox: 0.50540/0.37643, loss_sub_giou: 0.84314/0.61625, loss_obj_giou: 1.04704/0.93127, obj_cardinality_error: 12.00000/2.27713, loss_obj_ce_0: 1.10630/0.80658, loss_verb_ce_0: 0.59123/0.96093, loss_sub_bbox_0: 0.22219/0.36034, loss_obj_bbox_0: 0.42106/0.37052, loss_sub_giou_0: 0.80549/0.61119, loss_obj_giou_0: 1.03356/0.92199, obj_cardinality_error_0: 4.00000/2.35266, loss_obj_ce_1: 0.91933/0.74601, loss_verb_ce_1: 0.60828/0.91711, loss_sub_bbox_1: 0.29364/0.36416, loss_obj_bbox_1: 0.47168/0.37055, loss_sub_giou_1: 0.85246/0.61381, loss_obj_giou_1: 1.07982/0.92163, obj_cardinality_error_1: 4.50000/2.14982] items per batch[1] items per second[0.72] total items[2820] mini batches[  2820] memory[1606] epoch remaining[0:05:26]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[130/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.69339/17.99237, loss_obj_ce: 0.89510/0.73607, obj_class_error: 80.00000/72.65579, loss_verb_ce: 0.82595/0.90740, loss_sub_bbox: 0.22552/0.36703, loss_obj_bbox: 0.34264/0.37608, loss_sub_giou: 0.56098/0.61598, loss_obj_giou: 1.48715/0.93093, obj_cardinality_error: 1.00000/2.27456, loss_obj_ce_0: 0.61623/0.80695, loss_verb_ce_0: 0.86894/0.96055, loss_sub_bbox_0: 0.34220/0.36015, loss_obj_bbox_0: 0.42279/0.37022, loss_sub_giou_0: 0.69819/0.61105, loss_obj_giou_0: 1.52120/0.92172, obj_cardinality_error_0: 1.00000/2.35018, loss_obj_ce_1: 0.94350/0.74620, loss_verb_ce_1: 0.91486/0.91678, loss_sub_bbox_1: 0.24621/0.36391, loss_obj_bbox_1: 0.30463/0.37027, loss_sub_giou_1: 0.65978/0.61363, loss_obj_giou_1: 1.38178/0.92124, obj_cardinality_error_1: 1.00000/2.14788] items per batch[1] items per second[0.76] total items[2830] mini batches[  2830] memory[1606] epoch remaining[0:05:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[140/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.78601/17.98850, loss_obj_ce: 0.65324/0.73601, obj_class_error: 75.00000/72.65541, loss_verb_ce: 1.19891/0.90717, loss_sub_bbox: 0.51330/0.36695, loss_obj_bbox: 0.55477/0.37599, loss_sub_giou: 0.79857/0.61583, loss_obj_giou: 1.02460/0.93064, obj_cardinality_error: 0.00000/2.27218, loss_obj_ce_0: 0.62591/0.80669, loss_verb_ce_0: 1.09188/0.96009, loss_sub_bbox_0: 0.51747/0.36018, loss_obj_bbox_0: 0.58198/0.37024, loss_sub_giou_0: 0.74063/0.61109, loss_obj_giou_0: 1.16615/0.92166, obj_cardinality_error_0: 0.00000/2.34630, loss_obj_ce_1: 0.69242/0.74615, loss_verb_ce_1: 1.26569/0.91650, loss_sub_bbox_1: 0.53267/0.36391, loss_obj_bbox_1: 0.52275/0.37012, loss_sub_giou_1: 0.77829/0.61364, loss_obj_giou_1: 1.13588/0.92080, obj_cardinality_error_1: 0.00000/2.14401] items per batch[1] items per second[0.77] total items[2840] mini batches[  2840] memory[1606] epoch remaining[0:05:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[150/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.32469/17.97833, loss_obj_ce: 0.98831/0.73545, obj_class_error: 71.42857/72.62262, loss_verb_ce: 0.78603/0.90648, loss_sub_bbox: 0.36368/0.36667, loss_obj_bbox: 0.41039/0.37587, loss_sub_giou: 0.73100/0.61565, loss_obj_giou: 1.10840/0.93014, obj_cardinality_error: 0.50000/2.26684, loss_obj_ce_0: 0.78553/0.80615, loss_verb_ce_0: 0.76706/0.95936, loss_sub_bbox_0: 0.40073/0.35997, loss_obj_bbox_0: 0.42945/0.37021, loss_sub_giou_0: 0.74075/0.61097, loss_obj_giou_0: 1.10203/0.92116, obj_cardinality_error_0: 1.00000/2.34123, loss_obj_ce_1: 1.09346/0.74565, loss_verb_ce_1: 0.81735/0.91575, loss_sub_bbox_1: 0.41204/0.36376, loss_obj_bbox_1: 0.44348/0.36997, loss_sub_giou_1: 0.81116/0.61366, loss_obj_giou_1: 1.07371/0.92018, obj_cardinality_error_1: 1.00000/2.13930] items per batch[1] items per second[0.82] total items[2850] mini batches[  2850] memory[1606] epoch remaining[0:05:23]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[160/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.74751/17.96913, loss_obj_ce: 0.44948/0.73497, obj_class_error: 50.00000/72.61819, loss_verb_ce: 0.83235/0.90612, loss_sub_bbox: 0.38821/0.36652, loss_obj_bbox: 0.30805/0.37563, loss_sub_giou: 0.53384/0.61548, loss_obj_giou: 0.55860/0.92941, obj_cardinality_error: 1.00000/2.26276, loss_obj_ce_0: 0.62023/0.80550, loss_verb_ce_0: 0.98870/0.95903, loss_sub_bbox_0: 0.30347/0.35985, loss_obj_bbox_0: 0.38825/0.37000, loss_sub_giou_0: 0.53491/0.61081, loss_obj_giou_0: 0.68885/0.92042, obj_cardinality_error_0: 1.00000/2.33724, loss_obj_ce_1: 0.70208/0.74515, loss_verb_ce_1: 0.96255/0.91540, loss_sub_bbox_1: 0.31386/0.36363, loss_obj_bbox_1: 0.29960/0.36974, loss_sub_giou_1: 0.50371/0.61352, loss_obj_giou_1: 0.58500/0.91931, obj_cardinality_error_1: 1.00000/2.13584] items per batch[1] items per second[0.75] total items[2860] mini batches[  2860] memory[1606] epoch remaining[0:05:22]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[170/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.73020/17.96317, loss_obj_ce: 0.61296/0.73452, obj_class_error: 66.66667/72.57822, loss_verb_ce: 0.49321/0.90530, loss_sub_bbox: 0.20181/0.36671, loss_obj_bbox: 0.22073/0.37551, loss_sub_giou: 0.67182/0.61571, loss_obj_giou: 1.17213/0.92898, obj_cardinality_error: 1.50000/2.25923, loss_obj_ce_0: 0.57430/0.80516, loss_verb_ce_0: 0.54278/0.95820, loss_sub_bbox_0: 0.20836/0.35998, loss_obj_bbox_0: 0.31079/0.37001, loss_sub_giou_0: 0.61213/0.61103, loss_obj_giou_0: 1.18241/0.92011, obj_cardinality_error_0: 1.50000/2.33449, loss_obj_ce_1: 0.62996/0.74487, loss_verb_ce_1: 0.60542/0.91474, loss_sub_bbox_1: 0.19051/0.36370, loss_obj_bbox_1: 0.17879/0.36962, loss_sub_giou_1: 0.66441/0.61368, loss_obj_giou_1: 1.04977/0.91881, obj_cardinality_error_1: 1.00000/2.13275] items per batch[1] items per second[0.84] total items[2870] mini batches[  2870] memory[1606] epoch remaining[0:05:20]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[180/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.32944/17.94959, loss_obj_ce: 0.52107/0.73360, obj_class_error: 33.33334/72.54033, loss_verb_ce: 0.40246/0.90499, loss_sub_bbox: 0.28527/0.36645, loss_obj_bbox: 0.33574/0.37501, loss_sub_giou: 0.75947/0.61542, loss_obj_giou: 0.84712/0.92796, obj_cardinality_error: 1.00000/2.25590, loss_obj_ce_0: 0.51857/0.80418, loss_verb_ce_0: 0.47354/0.95772, loss_sub_bbox_0: 0.33959/0.35979, loss_obj_bbox_0: 0.44495/0.36963, loss_sub_giou_0: 0.67495/0.61090, loss_obj_giou_0: 0.81803/0.91928, obj_cardinality_error_0: 1.50000/2.33194, loss_obj_ce_1: 0.65550/0.74399, loss_verb_ce_1: 0.53691/0.91442, loss_sub_bbox_1: 0.22946/0.36335, loss_obj_bbox_1: 0.40566/0.36914, loss_sub_giou_1: 0.78407/0.61348, loss_obj_giou_1: 0.82314/0.91807, obj_cardinality_error_1: 1.50000/2.12969] items per batch[1] items per second[0.81] total items[2880] mini batches[  2880] memory[1606] epoch remaining[0:05:18]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[190/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.72295/17.93772, loss_obj_ce: 1.17094/0.73310, obj_class_error: 88.88889/72.54459, loss_verb_ce: 0.86628/0.90465, loss_sub_bbox: 0.38184/0.36609, loss_obj_bbox: 0.33740/0.37480, loss_sub_giou: 0.64272/0.61466, loss_obj_giou: 0.73078/0.92707, obj_cardinality_error: 3.50000/2.25190, loss_obj_ce_0: 1.05328/0.80345, loss_verb_ce_0: 0.82515/0.95744, loss_sub_bbox_0: 0.31806/0.35949, loss_obj_bbox_0: 0.33634/0.36942, loss_sub_giou_0: 0.56340/0.61020, loss_obj_giou_0: 0.92640/0.91846, obj_cardinality_error_0: 3.50000/2.32803, loss_obj_ce_1: 1.09039/0.74354, loss_verb_ce_1: 0.77864/0.91422, loss_sub_bbox_1: 0.39950/0.36308, loss_obj_bbox_1: 0.33665/0.36896, loss_sub_giou_1: 0.59881/0.61273, loss_obj_giou_1: 0.73162/0.91733, obj_cardinality_error_1: 3.50000/2.12595] items per batch[1] items per second[0.90] total items[2890] mini batches[  2890] memory[1606] epoch remaining[0:05:15]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[200/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.10702/17.93148, loss_obj_ce: 0.62822/0.73372, obj_class_error: 80.00000/72.55004, loss_verb_ce: 1.07898/0.90446, loss_sub_bbox: 0.15835/0.36579, loss_obj_bbox: 0.13899/0.37433, loss_sub_giou: 0.55986/0.61427, loss_obj_giou: 0.98283/0.92721, obj_cardinality_error: 3.00000/2.25345, loss_obj_ce_0: 0.79934/0.80390, loss_verb_ce_0: 0.74744/0.95683, loss_sub_bbox_0: 0.11780/0.35927, loss_obj_bbox_0: 0.23084/0.36912, loss_sub_giou_0: 0.51725/0.60987, loss_obj_giou_0: 0.85963/0.91871, obj_cardinality_error_0: 0.50000/2.32690, loss_obj_ce_1: 0.61463/0.74413, loss_verb_ce_1: 0.88122/0.91381, loss_sub_bbox_1: 0.16393/0.36283, loss_obj_bbox_1: 0.16444/0.36855, loss_sub_giou_1: 0.46109/0.61234, loss_obj_giou_1: 0.83308/0.91740, obj_cardinality_error_1: 7.00000/2.12724] items per batch[1] items per second[0.79] total items[2900] mini batches[  2900] memory[1606] epoch remaining[0:05:14]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[210/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.43933/17.92625, loss_obj_ce: 0.69949/0.73383, obj_class_error: 100.00000/72.55800, loss_verb_ce: 0.91743/0.90393, loss_sub_bbox: 0.42047/0.36572, loss_obj_bbox: 0.52018/0.37416, loss_sub_giou: 0.59807/0.61440, loss_obj_giou: 0.66043/0.92689, obj_cardinality_error: 0.00000/2.25619, loss_obj_ce_0: 0.71222/0.80397, loss_verb_ce_0: 0.98405/0.95627, loss_sub_bbox_0: 0.31456/0.35922, loss_obj_bbox_0: 0.51236/0.36890, loss_sub_giou_0: 0.44852/0.61003, loss_obj_giou_0: 0.54804/0.91818, obj_cardinality_error_0: 1.50000/2.32955, loss_obj_ce_1: 0.60378/0.74437, loss_verb_ce_1: 0.91526/0.91339, loss_sub_bbox_1: 0.39504/0.36276, loss_obj_bbox_1: 0.44774/0.36835, loss_sub_giou_1: 0.51917/0.61244, loss_obj_giou_1: 0.49027/0.91719, obj_cardinality_error_1: 0.50000/2.13385] items per batch[1] items per second[0.74] total items[2910] mini batches[  2910] memory[1606] epoch remaining[0:05:14]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[220/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.80987/17.91370, loss_obj_ce: 1.17885/0.73322, obj_class_error: 90.90909/72.56667, loss_verb_ce: 0.62484/0.90337, loss_sub_bbox: 0.21259/0.36546, loss_obj_bbox: 0.18242/0.37377, loss_sub_giou: 0.73785/0.61425, loss_obj_giou: 1.15456/0.92665, obj_cardinality_error: 9.50000/2.25599, loss_obj_ce_0: 1.05618/0.80320, loss_verb_ce_0: 0.61921/0.95561, loss_sub_bbox_0: 0.20690/0.35899, loss_obj_bbox_0: 0.18769/0.36852, loss_sub_giou_0: 0.62252/0.60992, loss_obj_giou_0: 0.93811/0.91751, obj_cardinality_error_0: 9.50000/2.32842, loss_obj_ce_1: 0.80293/0.74359, loss_verb_ce_1: 0.58877/0.91284, loss_sub_bbox_1: 0.21305/0.36247, loss_obj_bbox_1: 0.18256/0.36792, loss_sub_giou_1: 0.66479/0.61226, loss_obj_giou_1: 1.02544/0.91661, obj_cardinality_error_1: 8.00000/2.13459] items per batch[1] items per second[0.79] total items[2920] mini batches[  2920] memory[1606] epoch remaining[0:05:12]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[230/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.53792/17.90116, loss_obj_ce: 0.70913/0.73279, obj_class_error: 57.14286/72.52936, loss_verb_ce: 0.57487/0.90262, loss_sub_bbox: 0.19428/0.36534, loss_obj_bbox: 0.16459/0.37348, loss_sub_giou: 0.41457/0.61382, loss_obj_giou: 0.75367/0.92629, obj_cardinality_error: 6.00000/2.25427, loss_obj_ce_0: 0.68183/0.80278, loss_verb_ce_0: 0.62281/0.95482, loss_sub_bbox_0: 0.15707/0.35879, loss_obj_bbox_0: 0.20068/0.36821, loss_sub_giou_0: 0.25019/0.60939, loss_obj_giou_0: 0.70943/0.91690, obj_cardinality_error_0: 1.50000/2.32560, loss_obj_ce_1: 0.62733/0.74314, loss_verb_ce_1: 0.54972/0.91198, loss_sub_bbox_1: 0.16908/0.36229, loss_obj_bbox_1: 0.21170/0.36766, loss_sub_giou_1: 0.36475/0.61177, loss_obj_giou_1: 0.78870/0.91608, obj_cardinality_error_1: 1.00000/2.13396] items per batch[1] items per second[0.84] total items[2930] mini batches[  2930] memory[1606] epoch remaining[0:05:10]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[240/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.07141/17.89202, loss_obj_ce: 0.45299/0.73285, obj_class_error: 75.00000/72.51382, loss_verb_ce: 0.76376/0.90214, loss_sub_bbox: 0.19794/0.36497, loss_obj_bbox: 0.27985/0.37329, loss_sub_giou: 0.42134/0.61337, loss_obj_giou: 0.68416/0.92624, obj_cardinality_error: 1.00000/2.25680, loss_obj_ce_0: 0.42393/0.80274, loss_verb_ce_0: 0.70266/0.95433, loss_sub_bbox_0: 0.22714/0.35845, loss_obj_bbox_0: 0.19650/0.36792, loss_sub_giou_0: 0.58151/0.60901, loss_obj_giou_0: 0.87178/0.91652, obj_cardinality_error_0: 0.50000/2.32228, loss_obj_ce_1: 0.29358/0.74318, loss_verb_ce_1: 0.72400/0.91153, loss_sub_bbox_1: 0.24452/0.36197, loss_obj_bbox_1: 0.29493/0.36739, loss_sub_giou_1: 0.60084/0.61130, loss_obj_giou_1: 0.75822/0.91579, obj_cardinality_error_1: 1.00000/2.13537] items per batch[1] items per second[0.85] total items[2940] mini batches[  2940] memory[1606] epoch remaining[0:05:08]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[250/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.88962/17.88531, loss_obj_ce: 0.59943/0.73290, obj_class_error: 100.00000/72.52451, loss_verb_ce: 0.90220/0.90175, loss_sub_bbox: 0.15409/0.36484, loss_obj_bbox: 0.20629/0.37305, loss_sub_giou: 0.44037/0.61315, loss_obj_giou: 0.88879/0.92604, obj_cardinality_error: 1.50000/2.25475, loss_obj_ce_0: 0.70841/0.80271, loss_verb_ce_0: 0.85466/0.95396, loss_sub_bbox_0: 0.20687/0.35839, loss_obj_bbox_0: 0.14552/0.36765, loss_sub_giou_0: 0.61625/0.60898, loss_obj_giou_0: 0.80782/0.91608, obj_cardinality_error_0: 2.50000/2.31898, loss_obj_ce_1: 0.53428/0.74324, loss_verb_ce_1: 0.84125/0.91120, loss_sub_bbox_1: 0.21770/0.36182, loss_obj_bbox_1: 0.18267/0.36703, loss_sub_giou_1: 0.55272/0.61123, loss_obj_giou_1: 0.76250/0.91521, obj_cardinality_error_1: 1.00000/2.13492] items per batch[1] items per second[0.80] total items[2950] mini batches[  2950] memory[1606] epoch remaining[0:05:07]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[260/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.82507/17.87633, loss_obj_ce: 0.27021/0.73249, obj_class_error: 100.00000/72.52872, loss_verb_ce: 0.93755/0.90135, loss_sub_bbox: 0.25190/0.36459, loss_obj_bbox: 0.20430/0.37281, loss_sub_giou: 0.69706/0.61287, loss_obj_giou: 0.90642/0.92579, obj_cardinality_error: 0.00000/2.25152, loss_obj_ce_0: 0.37754/0.80233, loss_verb_ce_0: 0.96354/0.95351, loss_sub_bbox_0: 0.25683/0.35815, loss_obj_bbox_0: 0.26331/0.36731, loss_sub_giou_0: 0.49717/0.60869, loss_obj_giou_0: 0.77271/0.91578, obj_cardinality_error_0: 0.00000/2.31486, loss_obj_ce_1: 0.38504/0.74287, loss_verb_ce_1: 0.86962/0.91072, loss_sub_bbox_1: 0.20880/0.36163, loss_obj_bbox_1: 0.26378/0.36682, loss_sub_giou_1: 0.69721/0.61110, loss_obj_giou_1: 1.05802/0.91500, obj_cardinality_error_1: 0.00000/2.13142] items per batch[1] items per second[0.77] total items[2960] mini batches[  2960] memory[1606] epoch remaining[0:05:06]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[270/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.73225/17.86956, loss_obj_ce: 0.82748/0.73194, obj_class_error: 57.14286/72.53905, loss_verb_ce: 0.81771/0.90097, loss_sub_bbox: 0.40066/0.36450, loss_obj_bbox: 0.41961/0.37281, loss_sub_giou: 0.52695/0.61289, loss_obj_giou: 0.80746/0.92550, obj_cardinality_error: 1.50000/2.24562, loss_obj_ce_0: 0.95400/0.80177, loss_verb_ce_0: 0.82642/0.95328, loss_sub_bbox_0: 0.35039/0.35800, loss_obj_bbox_0: 0.46600/0.36727, loss_sub_giou_0: 0.43822/0.60854, loss_obj_giou_0: 0.76180/0.91508, obj_cardinality_error_0: 1.50000/2.30976, loss_obj_ce_1: 0.85657/0.74230, loss_verb_ce_1: 0.85543/0.91041, loss_sub_bbox_1: 0.39415/0.36146, loss_obj_bbox_1: 0.45250/0.36672, loss_sub_giou_1: 0.48349/0.61088, loss_obj_giou_1: 0.86890/0.91439, obj_cardinality_error_1: 1.50000/2.12626] items per batch[1] items per second[0.70] total items[2970] mini batches[  2970] memory[1606] epoch remaining[0:05:07]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[280/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.13858/17.85835, loss_obj_ce: 0.42703/0.73151, obj_class_error: 50.00000/72.50200, loss_verb_ce: 0.73331/0.90031, loss_sub_bbox: 0.31771/0.36435, loss_obj_bbox: 0.18580/0.37237, loss_sub_giou: 0.52918/0.61247, loss_obj_giou: 0.62695/0.92514, obj_cardinality_error: 0.00000/2.24866, loss_obj_ce_0: 0.64778/0.80138, loss_verb_ce_0: 1.09438/0.95271, loss_sub_bbox_0: 0.26909/0.35791, loss_obj_bbox_0: 0.22910/0.36692, loss_sub_giou_0: 0.39177/0.60811, loss_obj_giou_0: 0.84602/0.91482, obj_cardinality_error_0: 1.00000/2.30654, loss_obj_ce_1: 0.41658/0.74194, loss_verb_ce_1: 0.74432/0.90986, loss_sub_bbox_1: 0.29219/0.36139, loss_obj_bbox_1: 0.18547/0.36621, loss_sub_giou_1: 0.60545/0.61048, loss_obj_giou_1: 0.80539/0.91389, obj_cardinality_error_1: 1.00000/2.13356] items per batch[1] items per second[0.87] total items[2980] mini batches[  2980] memory[1606] epoch remaining[0:05:04]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[290/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.22822/17.84797, loss_obj_ce: 1.20496/0.73081, obj_class_error: 77.77778/72.46930, loss_verb_ce: 0.70844/0.89946, loss_sub_bbox: 0.38270/0.36427, loss_obj_bbox: 0.30622/0.37205, loss_sub_giou: 0.55605/0.61228, loss_obj_giou: 1.17647/0.92522, obj_cardinality_error: 2.50000/2.24615, loss_obj_ce_0: 1.23356/0.80076, loss_verb_ce_0: 0.65286/0.95219, loss_sub_bbox_0: 0.39928/0.35778, loss_obj_bbox_0: 0.36941/0.36659, loss_sub_giou_0: 0.60021/0.60793, loss_obj_giou_0: 1.14810/0.91452, obj_cardinality_error_0: 2.00000/2.30234, loss_obj_ce_1: 1.27967/0.74120, loss_verb_ce_1: 0.64849/0.90910, loss_sub_bbox_1: 0.34270/0.36123, loss_obj_bbox_1: 0.35341/0.36590, loss_sub_giou_1: 0.53333/0.61023, loss_obj_giou_1: 1.09202/0.91396, obj_cardinality_error_1: 2.50000/2.12977] items per batch[1] items per second[0.78] total items[2990] mini batches[  2990] memory[1606] epoch remaining[0:05:03]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[300/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.25744/17.84313, loss_obj_ce: 0.54484/0.73046, obj_class_error: 75.00000/72.45940, loss_verb_ce: 0.82932/0.89907, loss_sub_bbox: 0.22491/0.36419, loss_obj_bbox: 0.25371/0.37167, loss_sub_giou: 1.00437/0.61257, loss_obj_giou: 1.23244/0.92531, obj_cardinality_error: 1.00000/2.24450, loss_obj_ce_0: 0.45503/0.80049, loss_verb_ce_0: 0.54181/0.95191, loss_sub_bbox_0: 0.22797/0.35779, loss_obj_bbox_0: 0.18399/0.36645, loss_sub_giou_0: 0.96385/0.60818, loss_obj_giou_0: 0.86539/0.91446, obj_cardinality_error_0: 1.50000/2.29917, loss_obj_ce_1: 0.54471/0.74081, loss_verb_ce_1: 0.75941/0.90869, loss_sub_bbox_1: 0.14070/0.36115, loss_obj_bbox_1: 0.16561/0.36561, loss_sub_giou_1: 0.63111/0.61042, loss_obj_giou_1: 0.76237/0.91397, obj_cardinality_error_1: 1.00000/2.12683] items per batch[1] items per second[0.84] total items[3000] mini batches[  3000] memory[1606] epoch remaining[0:05:01]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[310/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.59614/17.83445, loss_obj_ce: 0.39416/0.73006, obj_class_error: 25.00000/72.46883, loss_verb_ce: 0.43345/0.89851, loss_sub_bbox: 0.21364/0.36404, loss_obj_bbox: 0.22620/0.37146, loss_sub_giou: 0.40295/0.61225, loss_obj_giou: 1.38173/0.92497, obj_cardinality_error: 3.50000/2.24203, loss_obj_ce_0: 0.43363/0.79984, loss_verb_ce_0: 0.52814/0.95127, loss_sub_bbox_0: 0.23618/0.35778, loss_obj_bbox_0: 0.18762/0.36631, loss_sub_giou_0: 0.38981/0.60814, loss_obj_giou_0: 1.22792/0.91411, obj_cardinality_error_0: 1.50000/2.29585, loss_obj_ce_1: 0.42264/0.74043, loss_verb_ce_1: 0.49760/0.90828, loss_sub_bbox_1: 0.23196/0.36091, loss_obj_bbox_1: 0.22937/0.36540, loss_sub_giou_1: 0.37385/0.61006, loss_obj_giou_1: 1.33866/0.91374, obj_cardinality_error_1: 2.50000/2.12442] items per batch[1] items per second[0.77] total items[3010] mini batches[  3010] memory[1606] epoch remaining[0:05:00]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[320/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.99288/17.82247, loss_obj_ce: 0.64575/0.72954, obj_class_error: 66.66667/72.45224, loss_verb_ce: 0.71678/0.89791, loss_sub_bbox: 0.38200/0.36380, loss_obj_bbox: 0.26122/0.37123, loss_sub_giou: 0.50600/0.61191, loss_obj_giou: 0.47469/0.92481, obj_cardinality_error: 6.00000/2.24056, loss_obj_ce_0: 0.80465/0.79903, loss_verb_ce_0: 0.79530/0.95049, loss_sub_bbox_0: 0.31349/0.35756, loss_obj_bbox_0: 0.22755/0.36601, loss_sub_giou_0: 0.49165/0.60783, loss_obj_giou_0: 0.49247/0.91360, obj_cardinality_error_0: 1.00000/2.29205, loss_obj_ce_1: 0.66045/0.73968, loss_verb_ce_1: 0.64151/0.90745, loss_sub_bbox_1: 0.39892/0.36071, loss_obj_bbox_1: 0.25550/0.36515, loss_sub_giou_1: 0.51882/0.60975, loss_obj_giou_1: 0.49453/0.91346, obj_cardinality_error_1: 4.50000/2.12235] items per batch[1] items per second[0.76] total items[3020] mini batches[  3020] memory[1606] epoch remaining[0:05:00]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[330/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.57709/17.81285, loss_obj_ce: 0.65886/0.72902, obj_class_error: 83.33334/72.44293, loss_verb_ce: 0.67539/0.89725, loss_sub_bbox: 0.29884/0.36355, loss_obj_bbox: 0.31084/0.37118, loss_sub_giou: 0.60731/0.61144, loss_obj_giou: 1.09955/0.92490, obj_cardinality_error: 1.50000/2.23746, loss_obj_ce_0: 0.68978/0.79845, loss_verb_ce_0: 0.77005/0.94971, loss_sub_bbox_0: 0.26749/0.35738, loss_obj_bbox_0: 0.23958/0.36585, loss_sub_giou_0: 0.60934/0.60744, loss_obj_giou_0: 0.90989/0.91338, obj_cardinality_error_0: 1.50000/2.28944, loss_obj_ce_1: 0.55429/0.73920, loss_verb_ce_1: 0.69790/0.90668, loss_sub_bbox_1: 0.34081/0.36053, loss_obj_bbox_1: 0.35378/0.36510, loss_sub_giou_1: 0.56098/0.60939, loss_obj_giou_1: 1.07202/0.91340, obj_cardinality_error_1: 2.00000/2.11881] items per batch[1] items per second[0.83] total items[3030] mini batches[  3030] memory[1606] epoch remaining[0:04:58]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[340/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.69768/17.80216, loss_obj_ce: 1.46695/0.72853, obj_class_error: 85.71429/72.42213, loss_verb_ce: 0.71473/0.89636, loss_sub_bbox: 0.42851/0.36345, loss_obj_bbox: 0.27401/0.37099, loss_sub_giou: 0.65573/0.61119, loss_obj_giou: 0.74418/0.92421, obj_cardinality_error: 2.50000/2.23355, loss_obj_ce_0: 1.36673/0.79796, loss_verb_ce_0: 0.77641/0.94900, loss_sub_bbox_0: 0.47778/0.35736, loss_obj_bbox_0: 0.34817/0.36560, loss_sub_giou_0: 0.81659/0.60738, loss_obj_giou_0: 0.86505/0.91271, obj_cardinality_error_0: 2.50000/2.28569, loss_obj_ce_1: 1.38844/0.73868, loss_verb_ce_1: 0.69498/0.90583, loss_sub_bbox_1: 0.43189/0.36046, loss_obj_bbox_1: 0.28867/0.36497, loss_sub_giou_1: 0.61656/0.60921, loss_obj_giou_1: 0.78263/0.91284, obj_cardinality_error_1: 2.50000/2.11579] items per batch[1] items per second[0.82] total items[3040] mini batches[  3040] memory[1606] epoch remaining[0:04:56]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[350/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.96755/17.79071, loss_obj_ce: 0.47995/0.72750, obj_class_error: 100.00000/72.37593, loss_verb_ce: 0.84843/0.89561, loss_sub_bbox: 0.29355/0.36327, loss_obj_bbox: 0.24562/0.37082, loss_sub_giou: 0.35713/0.61108, loss_obj_giou: 0.47728/0.92380, obj_cardinality_error: 0.50000/2.23311, loss_obj_ce_0: 0.40459/0.79696, loss_verb_ce_0: 0.76434/0.94849, loss_sub_bbox_0: 0.33016/0.35715, loss_obj_bbox_0: 0.30593/0.36540, loss_sub_giou_0: 0.41204/0.60745, loss_obj_giou_0: 0.42812/0.91237, obj_cardinality_error_0: 1.00000/2.28197, loss_obj_ce_1: 0.60750/0.73765, loss_verb_ce_1: 0.86228/0.90506, loss_sub_bbox_1: 0.24031/0.36023, loss_obj_bbox_1: 0.22206/0.36471, loss_sub_giou_1: 0.34714/0.60920, loss_obj_giou_1: 0.40958/0.91240, obj_cardinality_error_1: 1.50000/2.11492] items per batch[1] items per second[0.78] total items[3050] mini batches[  3050] memory[1606] epoch remaining[0:04:55]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[360/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.04700/17.78366, loss_obj_ce: 0.50425/0.72647, obj_class_error: 50.00000/72.30079, loss_verb_ce: 0.58689/0.89462, loss_sub_bbox: 0.31164/0.36311, loss_obj_bbox: 0.38252/0.37080, loss_sub_giou: 0.49941/0.61105, loss_obj_giou: 1.00442/0.92406, obj_cardinality_error: 1.00000/2.23350, loss_obj_ce_0: 0.71772/0.79621, loss_verb_ce_0: 0.65186/0.94761, loss_sub_bbox_0: 0.29296/0.35716, loss_obj_bbox_0: 0.62435/0.36564, loss_sub_giou_0: 0.43225/0.60767, loss_obj_giou_0: 1.28299/0.91288, obj_cardinality_error_0: 2.00000/2.28039, loss_obj_ce_1: 0.53059/0.73672, loss_verb_ce_1: 0.62036/0.90404, loss_sub_bbox_1: 0.31654/0.36006, loss_obj_bbox_1: 0.40385/0.36483, loss_sub_giou_1: 0.51545/0.60921, loss_obj_giou_1: 1.01205/0.91286, obj_cardinality_error_1: 1.50000/2.11307] items per batch[1] items per second[0.86] total items[3060] mini batches[  3060] memory[1606] epoch remaining[0:04:53]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[370/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.95613/17.77436, loss_obj_ce: 0.25578/0.72565, obj_class_error: 0.00000/72.20259, loss_verb_ce: 0.51400/0.89339, loss_sub_bbox: 0.48738/0.36304, loss_obj_bbox: 0.36994/0.37069, loss_sub_giou: 0.89086/0.61115, loss_obj_giou: 0.95515/0.92424, obj_cardinality_error: 9.50000/2.23453, loss_obj_ce_0: 0.43889/0.79577, loss_verb_ce_0: 0.66416/0.94678, loss_sub_bbox_0: 0.35858/0.35700, loss_obj_bbox_0: 0.20280/0.36548, loss_sub_giou_0: 0.69333/0.60756, loss_obj_giou_0: 0.66099/0.91291, obj_cardinality_error_0: 0.50000/2.27818, loss_obj_ce_1: 0.33499/0.73601, loss_verb_ce_1: 0.60556/0.90299, loss_sub_bbox_1: 0.46401/0.35998, loss_obj_bbox_1: 0.34250/0.36476, loss_sub_giou_1: 0.73578/0.60921, loss_obj_giou_1: 0.85989/0.91317, obj_cardinality_error_1: 4.00000/2.11254] items per batch[1] items per second[0.77] total items[3070] mini batches[  3070] memory[1606] epoch remaining[0:04:52]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[380/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.34663/17.76581, loss_obj_ce: 0.46143/0.72469, obj_class_error: 66.66667/72.11060, loss_verb_ce: 0.66816/0.89246, loss_sub_bbox: 0.23100/0.36283, loss_obj_bbox: 0.10196/0.37039, loss_sub_giou: 0.48364/0.61105, loss_obj_giou: 0.74637/0.92439, obj_cardinality_error: 4.00000/2.24010, loss_obj_ce_0: 0.88157/0.79529, loss_verb_ce_0: 1.01759/0.94673, loss_sub_bbox_0: 0.17267/0.35672, loss_obj_bbox_0: 0.21557/0.36520, loss_sub_giou_0: 0.33684/0.60733, loss_obj_giou_0: 1.01887/0.91295, obj_cardinality_error_0: 1.50000/2.28295, loss_obj_ce_1: 0.50103/0.73517, loss_verb_ce_1: 0.72080/0.90259, loss_sub_bbox_1: 0.17428/0.35973, loss_obj_bbox_1: 0.18237/0.36454, loss_sub_giou_1: 0.36144/0.60919, loss_obj_giou_1: 1.04772/0.91368, obj_cardinality_error_1: 9.00000/2.12354] items per batch[1] items per second[0.89] total items[3080] mini batches[  3080] memory[1606] epoch remaining[0:04:50]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[390/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.42264/17.75563, loss_obj_ce: 0.55764/0.72393, obj_class_error: 25.00000/72.03142, loss_verb_ce: 0.58193/0.89157, loss_sub_bbox: 0.22948/0.36272, loss_obj_bbox: 0.21879/0.37018, loss_sub_giou: 0.52395/0.61090, loss_obj_giou: 0.78641/0.92409, obj_cardinality_error: 11.00000/2.25049, loss_obj_ce_0: 0.67091/0.79479, loss_verb_ce_0: 0.63498/0.94624, loss_sub_bbox_0: 0.19447/0.35677, loss_obj_bbox_0: 0.13122/0.36490, loss_sub_giou_0: 0.46494/0.60733, loss_obj_giou_0: 0.54650/0.91244, obj_cardinality_error_0: 16.00000/2.28673, loss_obj_ce_1: 0.78140/0.73460, loss_verb_ce_1: 0.67557/0.90187, loss_sub_bbox_1: 0.22241/0.35965, loss_obj_bbox_1: 0.22916/0.36425, loss_sub_giou_1: 0.45294/0.60899, loss_obj_giou_1: 0.78917/0.91305, obj_cardinality_error_1: 16.50000/2.13738] items per batch[1] items per second[0.79] total items[3090] mini batches[  3090] memory[1606] epoch remaining[0:04:49]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[400/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.95402/17.74345, loss_obj_ce: 0.46184/0.72305, obj_class_error: 42.85714/71.98754, loss_verb_ce: 0.57880/0.89079, loss_sub_bbox: 0.27788/0.36264, loss_obj_bbox: 0.27835/0.36968, loss_sub_giou: 0.53510/0.61095, loss_obj_giou: 0.69693/0.92379, obj_cardinality_error: 0.50000/2.24516, loss_obj_ce_0: 0.55712/0.79397, loss_verb_ce_0: 0.70636/0.94571, loss_sub_bbox_0: 0.29008/0.35680, loss_obj_bbox_0: 0.27902/0.36429, loss_sub_giou_0: 0.55307/0.60738, loss_obj_giou_0: 0.97974/0.91177, obj_cardinality_error_0: 1.50000/2.28194, loss_obj_ce_1: 0.43145/0.73374, loss_verb_ce_1: 0.67287/0.90120, loss_sub_bbox_1: 0.26058/0.35953, loss_obj_bbox_1: 0.36878/0.36374, loss_sub_giou_1: 0.52997/0.60889, loss_obj_giou_1: 0.90602/0.91283, obj_cardinality_error_1: 0.50000/2.13274] items per batch[1] items per second[0.78] total items[3100] mini batches[  3100] memory[1606] epoch remaining[0:04:48]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[410/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.94619/17.74127, loss_obj_ce: 0.38092/0.72349, obj_class_error: 50.00000/72.00964, loss_verb_ce: 0.57343/0.89031, loss_sub_bbox: 0.21819/0.36244, loss_obj_bbox: 0.32595/0.36967, loss_sub_giou: 0.23084/0.61089, loss_obj_giou: 0.58539/0.92376, obj_cardinality_error: 1.00000/2.24180, loss_obj_ce_0: 0.57514/0.79438, loss_verb_ce_0: 0.67615/0.94536, loss_sub_bbox_0: 0.25433/0.35674, loss_obj_bbox_0: 0.34895/0.36431, loss_sub_giou_0: 0.28014/0.60740, loss_obj_giou_0: 0.61589/0.91180, obj_cardinality_error_0: 0.50000/2.27894, loss_obj_ce_1: 0.50123/0.73399, loss_verb_ce_1: 0.59531/0.90066, loss_sub_bbox_1: 0.23975/0.35945, loss_obj_bbox_1: 0.32242/0.36377, loss_sub_giou_1: 0.23494/0.60894, loss_obj_giou_1: 0.57797/0.91303, obj_cardinality_error_1: 0.50000/2.13023] items per batch[1] items per second[0.86] total items[3110] mini batches[  3110] memory[1606] epoch remaining[0:04:46]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[420/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 9.88376/17.73588, loss_obj_ce: 0.40740/0.72355, obj_class_error: 50.00000/72.01152, loss_verb_ce: 0.49639/0.89004, loss_sub_bbox: 0.24631/0.36213, loss_obj_bbox: 0.24813/0.36968, loss_sub_giou: 0.33332/0.61060, loss_obj_giou: 0.62607/0.92327, obj_cardinality_error: 1.00000/2.24311, loss_obj_ce_0: 0.44791/0.79459, loss_verb_ce_0: 0.62983/0.94511, loss_sub_bbox_0: 0.15738/0.35652, loss_obj_bbox_0: 0.18829/0.36435, loss_sub_giou_0: 0.28339/0.60718, loss_obj_giou_0: 0.38343/0.91132, obj_cardinality_error_0: 0.00000/2.27772, loss_obj_ce_1: 0.44875/0.73409, loss_verb_ce_1: 0.52562/0.90037, loss_sub_bbox_1: 0.18183/0.35924, loss_obj_bbox_1: 0.17865/0.36370, loss_sub_giou_1: 0.23749/0.60873, loss_obj_giou_1: 0.41085/0.91241, obj_cardinality_error_1: 1.50000/2.13029] items per batch[1] items per second[0.83] total items[3120] mini batches[  3120] memory[1606] epoch remaining[0:04:45]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[430/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.56384/17.72411, loss_obj_ce: 0.57712/0.72313, obj_class_error: 50.00000/71.97218, loss_verb_ce: 0.47456/0.88938, loss_sub_bbox: 0.27253/0.36188, loss_obj_bbox: 0.21499/0.36945, loss_sub_giou: 0.51216/0.61023, loss_obj_giou: 0.82850/0.92281, obj_cardinality_error: 9.50000/2.24856, loss_obj_ce_0: 0.69715/0.79413, loss_verb_ce_0: 0.58347/0.94450, loss_sub_bbox_0: 0.24107/0.35630, loss_obj_bbox_0: 0.19965/0.36408, loss_sub_giou_0: 0.47625/0.60687, loss_obj_giou_0: 0.74221/0.91075, obj_cardinality_error_0: 2.50000/2.27444, loss_obj_ce_1: 0.50954/0.73354, loss_verb_ce_1: 0.51882/0.89971, loss_sub_bbox_1: 0.30225/0.35896, loss_obj_bbox_1: 0.25437/0.36340, loss_sub_giou_1: 0.50619/0.60833, loss_obj_giou_1: 0.84887/0.91195, obj_cardinality_error_1: 15.00000/2.13435] items per batch[1] items per second[0.84] total items[3130] mini batches[  3130] memory[1606] epoch remaining[0:04:43]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[440/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.07855/17.71765, loss_obj_ce: 0.62898/0.72313, obj_class_error: 11.11111/71.94934, loss_verb_ce: 0.72321/0.88889, loss_sub_bbox: 0.15873/0.36175, loss_obj_bbox: 0.05168/0.36924, loss_sub_giou: 0.68441/0.61000, loss_obj_giou: 0.37354/0.92229, obj_cardinality_error: 20.00000/2.25653, loss_obj_ce_0: 0.54061/0.79413, loss_verb_ce_0: 0.59194/0.94400, loss_sub_bbox_0: 0.19642/0.35620, loss_obj_bbox_0: 0.25128/0.36388, loss_sub_giou_0: 0.83162/0.60672, loss_obj_giou_0: 1.46359/0.91052, obj_cardinality_error_0: 1.00000/2.27213, loss_obj_ce_1: 0.61970/0.73354, loss_verb_ce_1: 0.76910/0.89938, loss_sub_bbox_1: 0.20055/0.35881, loss_obj_bbox_1: 0.21348/0.36328, loss_sub_giou_1: 0.75896/0.60811, loss_obj_giou_1: 1.32828/0.91179, obj_cardinality_error_1: 7.00000/2.13599] items per batch[1] items per second[0.83] total items[3140] mini batches[  3140] memory[1606] epoch remaining[0:04:42]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[450/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 8.49666/17.70935, loss_obj_ce: 0.32270/0.72287, obj_class_error: 50.00000/71.94447, loss_verb_ce: 0.78060/0.88868, loss_sub_bbox: 0.32766/0.36154, loss_obj_bbox: 0.00000/0.36887, loss_sub_giou: 0.45177/0.60982, loss_obj_giou: 0.00000/0.92167, obj_cardinality_error: 2.00000/2.25698, loss_obj_ce_0: 0.33805/0.79382, loss_verb_ce_0: 0.55489/0.94363, loss_sub_bbox_0: 0.25756/0.35603, loss_obj_bbox_0: 0.00000/0.36366, loss_sub_giou_0: 0.58930/0.60663, loss_obj_giou_0: 0.00000/0.91014, obj_cardinality_error_0: 1.50000/2.27111, loss_obj_ce_1: 0.19651/0.73324, loss_verb_ce_1: 0.41063/0.89894, loss_sub_bbox_1: 0.44368/0.35870, loss_obj_bbox_1: 0.00000/0.36301, loss_sub_giou_1: 0.53385/0.60802, loss_obj_giou_1: 0.00000/0.91110, obj_cardinality_error_1: 1.50000/2.13571] items per batch[1] items per second[0.88] total items[3150] mini batches[  3150] memory[1606] epoch remaining[0:04:40]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[460/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.91147/17.70296, loss_obj_ce: 0.55700/0.72277, obj_class_error: 57.14286/71.93520, loss_verb_ce: 0.51767/0.88833, loss_sub_bbox: 0.26630/0.36135, loss_obj_bbox: 0.26324/0.36879, loss_sub_giou: 0.75445/0.60976, loss_obj_giou: 0.77960/0.92143, obj_cardinality_error: 0.50000/2.25791, loss_obj_ce_0: 0.57863/0.79346, loss_verb_ce_0: 0.72434/0.94305, loss_sub_bbox_0: 0.34028/0.35588, loss_obj_bbox_0: 0.34848/0.36367, loss_sub_giou_0: 0.77704/0.60662, loss_obj_giou_0: 1.12434/0.91000, obj_cardinality_error_0: 0.50000/2.26709, loss_obj_ce_1: 0.54643/0.73287, loss_verb_ce_1: 0.57711/0.89827, loss_sub_bbox_1: 0.25198/0.35859, loss_obj_bbox_1: 0.27249/0.36287, loss_sub_giou_1: 0.73106/0.60810, loss_obj_giou_1: 1.06779/0.91081, obj_cardinality_error_1: 5.00000/2.13797] items per batch[1] items per second[0.87] total items[3160] mini batches[  3160] memory[1606] epoch remaining[0:04:38]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[470/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.82273/17.69540, loss_obj_ce: 0.83083/0.72252, obj_class_error: 80.00000/71.94419, loss_verb_ce: 1.19237/0.88784, loss_sub_bbox: 0.36553/0.36119, loss_obj_bbox: 0.61212/0.36864, loss_sub_giou: 0.67208/0.60960, loss_obj_giou: 0.88540/0.92115, obj_cardinality_error: 3.00000/2.25599, loss_obj_ce_0: 0.66653/0.79296, loss_verb_ce_0: 0.80911/0.94232, loss_sub_bbox_0: 0.39385/0.35581, loss_obj_bbox_0: 0.43113/0.36355, loss_sub_giou_0: 0.72514/0.60663, loss_obj_giou_0: 0.91482/0.90995, obj_cardinality_error_0: 1.50000/2.26420, loss_obj_ce_1: 0.80632/0.73252, loss_verb_ce_1: 1.12898/0.89776, loss_sub_bbox_1: 0.37564/0.35840, loss_obj_bbox_1: 0.43474/0.36269, loss_sub_giou_1: 0.65126/0.60795, loss_obj_giou_1: 0.87693/0.91058, obj_cardinality_error_1: 1.50000/2.13722] items per batch[1] items per second[0.81] total items[3170] mini batches[  3170] memory[1606] epoch remaining[0:04:37]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[480/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.76645/17.68658, loss_obj_ce: 0.40401/0.72237, obj_class_error: 66.66667/71.92775, loss_verb_ce: 0.91135/0.88714, loss_sub_bbox: 0.28214/0.36101, loss_obj_bbox: 0.18961/0.36853, loss_sub_giou: 0.52451/0.60926, loss_obj_giou: 0.71181/0.92105, obj_cardinality_error: 0.50000/2.25535, loss_obj_ce_0: 0.50004/0.79275, loss_verb_ce_0: 0.93056/0.94141, loss_sub_bbox_0: 0.27772/0.35558, loss_obj_bbox_0: 0.17143/0.36340, loss_sub_giou_0: 0.63315/0.60649, loss_obj_giou_0: 0.83951/0.90990, obj_cardinality_error_0: 2.00000/2.26101, loss_obj_ce_1: 0.42281/0.73231, loss_verb_ce_1: 0.92726/0.89704, loss_sub_bbox_1: 0.33756/0.35816, loss_obj_bbox_1: 0.19436/0.36257, loss_sub_giou_1: 0.67703/0.60769, loss_obj_giou_1: 0.88319/0.91044, obj_cardinality_error_1: 1.50000/2.13836] items per batch[1] items per second[0.80] total items[3180] mini batches[  3180] memory[1606] epoch remaining[0:04:36]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[490/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.19195/17.67897, loss_obj_ce: 0.31623/0.72220, obj_class_error: 33.33334/71.89947, loss_verb_ce: 0.65265/0.88658, loss_sub_bbox: 0.27879/0.36065, loss_obj_bbox: 0.30966/0.36834, loss_sub_giou: 0.74106/0.60916, loss_obj_giou: 0.91294/0.92158, obj_cardinality_error: 4.00000/2.26379, loss_obj_ce_0: 0.41899/0.79245, loss_verb_ce_0: 0.98013/0.94071, loss_sub_bbox_0: 0.15166/0.35527, loss_obj_bbox_0: 0.28215/0.36321, loss_sub_giou_0: 0.49973/0.60636, loss_obj_giou_0: 0.85883/0.91028, obj_cardinality_error_0: 2.00000/2.26082, loss_obj_ce_1: 0.42583/0.73220, loss_verb_ce_1: 0.68489/0.89641, loss_sub_bbox_1: 0.21790/0.35785, loss_obj_bbox_1: 0.34158/0.36238, loss_sub_giou_1: 0.61043/0.60757, loss_obj_giou_1: 0.81817/0.91054, obj_cardinality_error_1: 4.50000/2.14969] items per batch[1] items per second[0.81] total items[3190] mini batches[  3190] memory[1606] epoch remaining[0:04:34]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[500/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 21.77045/17.67188, loss_obj_ce: 0.94885/0.72140, obj_class_error: 100.00000/71.85655, loss_verb_ce: 1.15045/0.88604, loss_sub_bbox: 0.48360/0.36054, loss_obj_bbox: 0.48488/0.36815, loss_sub_giou: 0.65533/0.60913, loss_obj_giou: 1.05155/0.92177, obj_cardinality_error: 1.00000/2.26672, loss_obj_ce_0: 0.69033/0.79136, loss_verb_ce_0: 0.75454/0.93991, loss_sub_bbox_0: 0.50949/0.35542, loss_obj_bbox_0: 0.55081/0.36312, loss_sub_giou_0: 0.69299/0.60668, loss_obj_giou_0: 1.12654/0.91039, obj_cardinality_error_0: 1.00000/2.25687, loss_obj_ce_1: 0.89213/0.73138, loss_verb_ce_1: 0.98676/0.89576, loss_sub_bbox_1: 0.59210/0.35777, loss_obj_bbox_1: 0.63228/0.36226, loss_sub_giou_1: 0.77227/0.60762, loss_obj_giou_1: 1.02407/0.91058, obj_cardinality_error_1: 0.50000/2.15422] items per batch[1] items per second[0.84] total items[3200] mini batches[  3200] memory[1606] epoch remaining[0:04:33]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[510/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 22.20807/17.66529, loss_obj_ce: 0.85327/0.72065, obj_class_error: 100.00000/71.81057, loss_verb_ce: 0.86095/0.88517, loss_sub_bbox: 0.66146/0.36059, loss_obj_bbox: 0.52417/0.36808, loss_sub_giou: 0.97453/0.60899, loss_obj_giou: 0.71905/0.92198, obj_cardinality_error: 1.00000/2.26511, loss_obj_ce_0: 0.83015/0.79067, loss_verb_ce_0: 0.94137/0.93949, loss_sub_bbox_0: 0.73668/0.35550, loss_obj_bbox_0: 0.46238/0.36310, loss_sub_giou_0: 1.03593/0.60645, loss_obj_giou_0: 0.71400/0.91050, obj_cardinality_error_0: 1.00000/2.25498, loss_obj_ce_1: 0.84812/0.73076, loss_verb_ce_1: 0.93782/0.89512, loss_sub_bbox_1: 0.63996/0.35785, loss_obj_bbox_1: 0.58262/0.36202, loss_sub_giou_1: 0.99591/0.60747, loss_obj_giou_1: 0.73866/0.91041, obj_cardinality_error_1: 1.00000/2.15218] items per batch[1] items per second[0.83] total items[3210] mini batches[  3210] memory[1606] epoch remaining[0:04:32]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[520/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.44862/17.65467, loss_obj_ce: 0.53733/0.71979, obj_class_error: 83.33334/71.77322, loss_verb_ce: 0.71589/0.88433, loss_sub_bbox: 0.32139/0.36037, loss_obj_bbox: 0.20971/0.36782, loss_sub_giou: 0.73564/0.60865, loss_obj_giou: 0.95886/0.92212, obj_cardinality_error: 1.50000/2.26506, loss_obj_ce_0: 0.60674/0.78966, loss_verb_ce_0: 0.85252/0.93857, loss_sub_bbox_0: 0.32843/0.35543, loss_obj_bbox_0: 0.19519/0.36296, loss_sub_giou_0: 0.71911/0.60624, loss_obj_giou_0: 0.79777/0.91066, obj_cardinality_error_0: 2.00000/2.25186, loss_obj_ce_1: 0.66840/0.73014, loss_verb_ce_1: 0.93998/0.89449, loss_sub_bbox_1: 0.26914/0.35762, loss_obj_bbox_1: 0.23821/0.36181, loss_sub_giou_1: 0.63078/0.60714, loss_obj_giou_1: 0.87203/0.91047, obj_cardinality_error_1: 0.50000/2.15016] items per batch[1] items per second[0.84] total items[3220] mini batches[  3220] memory[1606] epoch remaining[0:04:30]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[530/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.67090/17.64507, loss_obj_ce: 0.89958/0.71942, obj_class_error: 81.81818/71.74445, loss_verb_ce: 0.92113/0.88386, loss_sub_bbox: 0.21285/0.36023, loss_obj_bbox: 0.22874/0.36759, loss_sub_giou: 0.69600/0.60827, loss_obj_giou: 1.20341/0.92139, obj_cardinality_error: 3.50000/2.26378, loss_obj_ce_0: 1.00059/0.78912, loss_verb_ce_0: 0.86906/0.93789, loss_sub_bbox_0: 0.26644/0.35538, loss_obj_bbox_0: 0.24754/0.36289, loss_sub_giou_0: 0.55821/0.60590, loss_obj_giou_0: 1.23184/0.91007, obj_cardinality_error_0: 2.50000/2.25093, loss_obj_ce_1: 1.08864/0.72986, loss_verb_ce_1: 0.95681/0.89396, loss_sub_bbox_1: 0.25286/0.35756, loss_obj_bbox_1: 0.22302/0.36161, loss_sub_giou_1: 0.66601/0.60681, loss_obj_giou_1: 1.25397/0.90967, obj_cardinality_error_1: 3.50000/2.14892] items per batch[1] items per second[0.83] total items[3230] mini batches[  3230] memory[1606] epoch remaining[0:04:29]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[540/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.34831/17.63697, loss_obj_ce: 1.21916/0.71940, obj_class_error: 66.66667/71.69406, loss_verb_ce: 0.89721/0.88350, loss_sub_bbox: 0.26161/0.35997, loss_obj_bbox: 0.30536/0.36739, loss_sub_giou: 0.48011/0.60802, loss_obj_giou: 0.86551/0.92087, obj_cardinality_error: 1.50000/2.26265, loss_obj_ce_0: 1.29400/0.78899, loss_verb_ce_0: 0.97949/0.93738, loss_sub_bbox_0: 0.26828/0.35525, loss_obj_bbox_0: 0.24862/0.36261, loss_sub_giou_0: 0.47310/0.60577, loss_obj_giou_0: 0.74623/0.90952, obj_cardinality_error_0: 1.00000/2.25000, loss_obj_ce_1: 1.27797/0.72979, loss_verb_ce_1: 0.90620/0.89360, loss_sub_bbox_1: 0.28454/0.35731, loss_obj_bbox_1: 0.28517/0.36146, loss_sub_giou_1: 0.51176/0.60654, loss_obj_giou_1: 0.78070/0.90911, obj_cardinality_error_1: 2.00000/2.14722] items per batch[1] items per second[0.67] total items[3240] mini batches[  3240] memory[1606] epoch remaining[0:04:28]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[550/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.51250/17.63489, loss_obj_ce: 0.80629/0.71976, obj_class_error: 71.42857/71.69961, loss_verb_ce: 0.90571/0.88344, loss_sub_bbox: 0.42852/0.35984, loss_obj_bbox: 0.53086/0.36723, loss_sub_giou: 0.67036/0.60814, loss_obj_giou: 1.04734/0.92057, obj_cardinality_error: 1.50000/2.26446, loss_obj_ce_0: 0.70074/0.78909, loss_verb_ce_0: 0.83748/0.93719, loss_sub_bbox_0: 0.45902/0.35517, loss_obj_bbox_0: 0.54089/0.36241, loss_sub_giou_0: 0.66479/0.60596, loss_obj_giou_0: 0.91431/0.90907, obj_cardinality_error_0: 1.50000/2.25169, loss_obj_ce_1: 0.72205/0.72999, loss_verb_ce_1: 0.79083/0.89362, loss_sub_bbox_1: 0.45815/0.35723, loss_obj_bbox_1: 0.49096/0.36140, loss_sub_giou_1: 0.71793/0.60676, loss_obj_giou_1: 0.92968/0.90886, obj_cardinality_error_1: 1.50000/2.14477] items per batch[1] items per second[0.76] total items[3250] mini batches[  3250] memory[1606] epoch remaining[0:04:27]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[560/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.35331/17.62558, loss_obj_ce: 0.45215/0.71943, obj_class_error: 75.00000/71.72024, loss_verb_ce: 0.93130/0.88310, loss_sub_bbox: 0.36009/0.35954, loss_obj_bbox: 0.37716/0.36712, loss_sub_giou: 0.52927/0.60775, loss_obj_giou: 0.54725/0.92010, obj_cardinality_error: 0.50000/2.26212, loss_obj_ce_0: 0.47368/0.78855, loss_verb_ce_0: 0.80717/0.93662, loss_sub_bbox_0: 0.36847/0.35492, loss_obj_bbox_0: 0.22930/0.36224, loss_sub_giou_0: 0.56443/0.60564, loss_obj_giou_0: 0.68602/0.90871, obj_cardinality_error_0: 1.00000/2.24801, loss_obj_ce_1: 0.50684/0.72952, loss_verb_ce_1: 0.93782/0.89318, loss_sub_bbox_1: 0.31528/0.35690, loss_obj_bbox_1: 0.36667/0.36138, loss_sub_giou_1: 0.54195/0.60630, loss_obj_giou_1: 0.65669/0.90852, obj_cardinality_error_1: 0.50000/2.14156] items per batch[1] items per second[0.82] total items[3260] mini batches[  3260] memory[1606] epoch remaining[0:04:26]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[570/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.88876/17.61618, loss_obj_ce: 1.00875/0.71899, obj_class_error: 62.50000/71.68262, loss_verb_ce: 0.76047/0.88270, loss_sub_bbox: 0.42556/0.35940, loss_obj_bbox: 0.35529/0.36673, loss_sub_giou: 0.66711/0.60759, loss_obj_giou: 0.95638/0.91983, obj_cardinality_error: 10.00000/2.26162, loss_obj_ce_0: 0.69528/0.78784, loss_verb_ce_0: 0.67349/0.93611, loss_sub_bbox_0: 0.38462/0.35475, loss_obj_bbox_0: 0.39699/0.36203, loss_sub_giou_0: 0.69968/0.60550, loss_obj_giou_0: 1.04147/0.90862, obj_cardinality_error_0: 6.00000/2.24709, loss_obj_ce_1: 0.85952/0.72890, loss_verb_ce_1: 0.75454/0.89269, loss_sub_bbox_1: 0.37214/0.35673, loss_obj_bbox_1: 0.42671/0.36105, loss_sub_giou_1: 0.60691/0.60614, loss_obj_giou_1: 1.07342/0.90808, obj_cardinality_error_1: 7.00000/2.14052] items per batch[1] items per second[0.77] total items[3270] mini batches[  3270] memory[1606] epoch remaining[0:04:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[580/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.83393/17.60765, loss_obj_ce: 0.50277/0.71881, obj_class_error: 50.00000/71.65648, loss_verb_ce: 0.74470/0.88213, loss_sub_bbox: 0.49026/0.35926, loss_obj_bbox: 0.54327/0.36657, loss_sub_giou: 0.43423/0.60715, loss_obj_giou: 0.78715/0.91953, obj_cardinality_error: 1.00000/2.25838, loss_obj_ce_0: 0.56744/0.78744, loss_verb_ce_0: 1.00614/0.93549, loss_sub_bbox_0: 0.31976/0.35455, loss_obj_bbox_0: 0.34157/0.36183, loss_sub_giou_0: 0.33944/0.60505, loss_obj_giou_0: 0.55326/0.90832, obj_cardinality_error_0: 1.00000/2.24329, loss_obj_ce_1: 0.63741/0.72871, loss_verb_ce_1: 0.92903/0.89225, loss_sub_bbox_1: 0.45467/0.35657, loss_obj_bbox_1: 0.46490/0.36092, loss_sub_giou_1: 0.43502/0.60572, loss_obj_giou_1: 0.68136/0.90793, obj_cardinality_error_1: 1.00000/2.13796] items per batch[1] items per second[0.83] total items[3280] mini batches[  3280] memory[1606] epoch remaining[0:04:24]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[590/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.10684/17.60367, loss_obj_ce: 0.68096/0.71866, obj_class_error: 57.14286/71.64906, loss_verb_ce: 0.59710/0.88175, loss_sub_bbox: 0.21824/0.35919, loss_obj_bbox: 0.38892/0.36666, loss_sub_giou: 0.59472/0.60736, loss_obj_giou: 0.68129/0.91934, obj_cardinality_error: 1.00000/2.25426, loss_obj_ce_0: 0.73876/0.78709, loss_verb_ce_0: 0.58590/0.93496, loss_sub_bbox_0: 0.28358/0.35447, loss_obj_bbox_0: 0.34536/0.36172, loss_sub_giou_0: 0.67110/0.60526, loss_obj_giou_0: 0.76516/0.90788, obj_cardinality_error_0: 0.00000/2.24088, loss_obj_ce_1: 0.66762/0.72859, loss_verb_ce_1: 0.56959/0.89183, loss_sub_bbox_1: 0.18813/0.35646, loss_obj_bbox_1: 0.35742/0.36095, loss_sub_giou_1: 0.61290/0.60598, loss_obj_giou_1: 0.73505/0.90781, obj_cardinality_error_1: 1.00000/2.13587] items per batch[1] items per second[0.82] total items[3290] mini batches[  3290] memory[1606] epoch remaining[0:04:22]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[600/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.44600/17.59677, loss_obj_ce: 1.11546/0.71870, obj_class_error: 88.88889/71.64354, loss_verb_ce: 0.81087/0.88153, loss_sub_bbox: 0.12836/0.35893, loss_obj_bbox: 0.23259/0.36641, loss_sub_giou: 0.50635/0.60717, loss_obj_giou: 0.77946/0.91879, obj_cardinality_error: 2.50000/2.25197, loss_obj_ce_0: 1.09504/0.78689, loss_verb_ce_0: 0.77198/0.93473, loss_sub_bbox_0: 0.13601/0.35431, loss_obj_bbox_0: 0.17769/0.36149, loss_sub_giou_0: 0.51262/0.60515, loss_obj_giou_0: 0.63771/0.90740, obj_cardinality_error_0: 2.50000/2.24182, loss_obj_ce_1: 1.04782/0.72853, loss_verb_ce_1: 0.78289/0.89153, loss_sub_bbox_1: 0.11355/0.35628, loss_obj_bbox_1: 0.23296/0.36072, loss_sub_giou_1: 0.55773/0.60590, loss_obj_giou_1: 0.90944/0.90731, obj_cardinality_error_1: 2.50000/2.13591] items per batch[1] items per second[0.86] total items[3300] mini batches[  3300] memory[1606] epoch remaining[0:04:21]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[610/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.04101/17.59436, loss_obj_ce: 0.95582/0.71884, obj_class_error: 87.50000/71.66792, loss_verb_ce: 0.86584/0.88149, loss_sub_bbox: 0.42957/0.35877, loss_obj_bbox: 0.30494/0.36625, loss_sub_giou: 0.80970/0.60719, loss_obj_giou: 1.02314/0.91893, obj_cardinality_error: 2.50000/2.25211, loss_obj_ce_0: 0.95130/0.78657, loss_verb_ce_0: 0.81049/0.93434, loss_sub_bbox_0: 0.43548/0.35428, loss_obj_bbox_0: 0.45352/0.36139, loss_sub_giou_0: 0.77520/0.60532, loss_obj_giou_0: 1.34076/0.90767, obj_cardinality_error_0: 1.00000/2.24230, loss_obj_ce_1: 0.92407/0.72851, loss_verb_ce_1: 0.94803/0.89132, loss_sub_bbox_1: 0.45106/0.35614, loss_obj_bbox_1: 0.36574/0.36059, loss_sub_giou_1: 0.85034/0.60596, loss_obj_giou_1: 1.06114/0.90751, obj_cardinality_error_1: 3.00000/2.13686] items per batch[1] items per second[0.93] total items[3310] mini batches[  3310] memory[1606] epoch remaining[0:04:19]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[620/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.09714/17.58773, loss_obj_ce: 1.17049/0.71874, obj_class_error: 80.00000/71.68850, loss_verb_ce: 0.84976/0.88128, loss_sub_bbox: 0.27680/0.35858, loss_obj_bbox: 0.24666/0.36595, loss_sub_giou: 0.56871/0.60691, loss_obj_giou: 1.06862/0.91882, obj_cardinality_error: 1.50000/2.24970, loss_obj_ce_0: 0.84488/0.78593, loss_verb_ce_0: 0.65835/0.93378, loss_sub_bbox_0: 0.29734/0.35424, loss_obj_bbox_0: 0.29647/0.36127, loss_sub_giou_0: 0.65445/0.60529, loss_obj_giou_0: 1.18049/0.90767, obj_cardinality_error_0: 1.00000/2.23886, loss_obj_ce_1: 1.05878/0.72797, loss_verb_ce_1: 0.84300/0.89091, loss_sub_bbox_1: 0.30649/0.35611, loss_obj_bbox_1: 0.24064/0.36032, loss_sub_giou_1: 0.64849/0.60593, loss_obj_giou_1: 1.03899/0.90731, obj_cardinality_error_1: 1.00000/2.13404] items per batch[1] items per second[0.75] total items[3320] mini batches[  3320] memory[1606] epoch remaining[0:04:18]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[630/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.32923/17.58217, loss_obj_ce: 0.53125/0.71826, obj_class_error: 60.00000/71.68035, loss_verb_ce: 0.77483/0.88113, loss_sub_bbox: 0.35026/0.35847, loss_obj_bbox: 0.36636/0.36583, loss_sub_giou: 0.57356/0.60655, loss_obj_giou: 0.84164/0.91853, obj_cardinality_error: 0.50000/2.24685, loss_obj_ce_0: 0.77167/0.78557, loss_verb_ce_0: 0.93548/0.93372, loss_sub_bbox_0: 0.33191/0.35418, loss_obj_bbox_0: 0.35394/0.36127, loss_sub_giou_0: 0.52005/0.60503, loss_obj_giou_0: 0.77386/0.90749, obj_cardinality_error_0: 1.50000/2.23634, loss_obj_ce_1: 0.51533/0.72741, loss_verb_ce_1: 0.76173/0.89061, loss_sub_bbox_1: 0.26497/0.35604, loss_obj_bbox_1: 0.25252/0.36023, loss_sub_giou_1: 0.42978/0.60564, loss_obj_giou_1: 0.62807/0.90675, obj_cardinality_error_1: 1.50000/2.13288] items per batch[1] items per second[0.77] total items[3330] mini batches[  3330] memory[1606] epoch remaining[0:04:17]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[640/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 23.93650/17.57530, loss_obj_ce: 1.11828/0.71791, obj_class_error: 71.42857/71.66071, loss_verb_ce: 0.66293/0.88061, loss_sub_bbox: 0.81679/0.35839, loss_obj_bbox: 0.50482/0.36571, loss_sub_giou: 0.94553/0.60614, loss_obj_giou: 1.32347/0.91839, obj_cardinality_error: 1.50000/2.24506, loss_obj_ce_0: 1.00869/0.78509, loss_verb_ce_0: 0.60265/0.93321, loss_sub_bbox_0: 0.86276/0.35412, loss_obj_bbox_0: 0.50786/0.36119, loss_sub_giou_0: 0.96534/0.60465, loss_obj_giou_0: 1.25806/0.90762, obj_cardinality_error_0: 1.50000/2.23428, loss_obj_ce_1: 1.06927/0.72690, loss_verb_ce_1: 0.65267/0.89012, loss_sub_bbox_1: 0.83773/0.35601, loss_obj_bbox_1: 0.55297/0.36010, loss_sub_giou_1: 0.92822/0.60535, loss_obj_giou_1: 1.27585/0.90658, obj_cardinality_error_1: 0.50000/2.13129] items per batch[1] items per second[0.80] total items[3340] mini batches[  3340] memory[1606] epoch remaining[0:04:16]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[650/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.83280/17.56992, loss_obj_ce: 0.99516/0.71769, obj_class_error: 76.92308/71.68244, loss_verb_ce: 0.69818/0.88040, loss_sub_bbox: 0.46534/0.35821, loss_obj_bbox: 0.23759/0.36539, loss_sub_giou: 0.78081/0.60593, loss_obj_giou: 1.32011/0.91837, obj_cardinality_error: 5.50000/2.24388, loss_obj_ce_0: 1.01920/0.78484, loss_verb_ce_0: 0.70303/0.93298, loss_sub_bbox_0: 0.50307/0.35402, loss_obj_bbox_0: 0.27049/0.36089, loss_sub_giou_0: 0.83895/0.60452, loss_obj_giou_0: 1.41041/0.90775, obj_cardinality_error_0: 4.00000/2.23299, loss_obj_ce_1: 1.15882/0.72668, loss_verb_ce_1: 0.75183/0.88991, loss_sub_bbox_1: 0.50905/0.35588, loss_obj_bbox_1: 0.31000/0.35979, loss_sub_giou_1: 0.78444/0.60516, loss_obj_giou_1: 1.48000/0.90694, obj_cardinality_error_1: 3.50000/2.12925] items per batch[1] items per second[0.77] total items[3350] mini batches[  3350] memory[1606] epoch remaining[0:04:15]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[660/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.17584/17.56062, loss_obj_ce: 0.56288/0.71726, obj_class_error: 50.00000/71.64519, loss_verb_ce: 0.48305/0.87984, loss_sub_bbox: 0.28355/0.35812, loss_obj_bbox: 0.28257/0.36515, loss_sub_giou: 0.52080/0.60558, loss_obj_giou: 1.02723/0.91779, obj_cardinality_error: 2.00000/2.24226, loss_obj_ce_0: 0.58203/0.78431, loss_verb_ce_0: 0.57671/0.93251, loss_sub_bbox_0: 0.24402/0.35397, loss_obj_bbox_0: 0.30205/0.36076, loss_sub_giou_0: 0.41519/0.60410, loss_obj_giou_0: 0.96459/0.90715, obj_cardinality_error_0: 3.50000/2.23155, loss_obj_ce_1: 0.48915/0.72629, loss_verb_ce_1: 0.45705/0.88951, loss_sub_bbox_1: 0.27956/0.35580, loss_obj_bbox_1: 0.26545/0.35956, loss_sub_giou_1: 0.52736/0.60481, loss_obj_giou_1: 0.90998/0.90620, obj_cardinality_error_1: 2.00000/2.12857] items per batch[1] items per second[0.82] total items[3360] mini batches[  3360] memory[1606] epoch remaining[0:04:13]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[670/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.39618/17.55238, loss_obj_ce: 0.57888/0.71664, obj_class_error: 75.00000/71.58549, loss_verb_ce: 0.70604/0.87935, loss_sub_bbox: 0.32631/0.35787, loss_obj_bbox: 0.32881/0.36494, loss_sub_giou: 0.44871/0.60527, loss_obj_giou: 0.95611/0.91806, obj_cardinality_error: 2.50000/2.24258, loss_obj_ce_0: 0.65423/0.78375, loss_verb_ce_0: 0.70023/0.93194, loss_sub_bbox_0: 0.37415/0.35382, loss_obj_bbox_0: 0.33345/0.36053, loss_sub_giou_0: 0.57304/0.60392, loss_obj_giou_0: 0.82523/0.90716, obj_cardinality_error_0: 3.00000/2.23131, loss_obj_ce_1: 0.57996/0.72594, loss_verb_ce_1: 0.64308/0.88922, loss_sub_bbox_1: 0.38958/0.35556, loss_obj_bbox_1: 0.35729/0.35923, loss_sub_giou_1: 0.52216/0.60443, loss_obj_giou_1: 0.88520/0.90630, obj_cardinality_error_1: 3.00000/2.12997] items per batch[1] items per second[0.79] total items[3370] mini batches[  3370] memory[1606] epoch remaining[0:04:12]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[680/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.06809/17.54456, loss_obj_ce: 0.94377/0.71673, obj_class_error: 83.33334/71.57699, loss_verb_ce: 0.75665/0.87867, loss_sub_bbox: 0.31567/0.35770, loss_obj_bbox: 0.28779/0.36476, loss_sub_giou: 0.40707/0.60495, loss_obj_giou: 0.58286/0.91773, obj_cardinality_error: 0.50000/2.23935, loss_obj_ce_0: 0.89187/0.78375, loss_verb_ce_0: 0.71290/0.93112, loss_sub_bbox_0: 0.42554/0.35367, loss_obj_bbox_0: 0.24148/0.36039, loss_sub_giou_0: 0.58455/0.60355, loss_obj_giou_0: 0.44835/0.90690, obj_cardinality_error_0: 2.50000/2.22825, loss_obj_ce_1: 0.84623/0.72615, loss_verb_ce_1: 0.82015/0.88878, loss_sub_bbox_1: 0.30432/0.35537, loss_obj_bbox_1: 0.29919/0.35911, loss_sub_giou_1: 0.43459/0.60408, loss_obj_giou_1: 0.66441/0.90608, obj_cardinality_error_1: 1.50000/2.12766] items per batch[1] items per second[0.82] total items[3380] mini batches[  3380] memory[1606] epoch remaining[0:04:11]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[690/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.75374/17.53960, loss_obj_ce: 0.74130/0.71695, obj_class_error: 100.00000/71.58636, loss_verb_ce: 1.11174/0.87856, loss_sub_bbox: 0.21923/0.35746, loss_obj_bbox: 0.16435/0.36443, loss_sub_giou: 0.63752/0.60477, loss_obj_giou: 1.58997/0.91778, obj_cardinality_error: 0.00000/2.23643, loss_obj_ce_0: 0.72545/0.78369, loss_verb_ce_0: 0.79500/0.93076, loss_sub_bbox_0: 0.27561/0.35358, loss_obj_bbox_0: 0.22408/0.36016, loss_sub_giou_0: 0.82500/0.60353, loss_obj_giou_0: 1.62023/0.90692, obj_cardinality_error_0: 1.00000/2.22847, loss_obj_ce_1: 0.55534/0.72629, loss_verb_ce_1: 0.80304/0.88856, loss_sub_bbox_1: 0.33503/0.35522, loss_obj_bbox_1: 0.17581/0.35875, loss_sub_giou_1: 0.80254/0.60387, loss_obj_giou_1: 1.35159/0.90605, obj_cardinality_error_1: 0.50000/2.12581] items per batch[1] items per second[0.83] total items[3390] mini batches[  3390] memory[1606] epoch remaining[0:04:10]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[700/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.40397/17.53145, loss_obj_ce: 0.30121/0.71629, obj_class_error: 20.00000/71.54800, loss_verb_ce: 0.42158/0.87801, loss_sub_bbox: 0.28019/0.35727, loss_obj_bbox: 0.15852/0.36416, loss_sub_giou: 0.39348/0.60460, loss_obj_giou: 0.72634/0.91808, obj_cardinality_error: 6.00000/2.23662, loss_obj_ce_0: 0.56747/0.78299, loss_verb_ce_0: 0.62247/0.93010, loss_sub_bbox_0: 0.23953/0.35347, loss_obj_bbox_0: 0.27641/0.35999, loss_sub_giou_0: 0.37706/0.60353, loss_obj_giou_0: 0.97582/0.90724, obj_cardinality_error_0: 10.00000/2.23044, loss_obj_ce_1: 0.54106/0.72562, loss_verb_ce_1: 0.56778/0.88794, loss_sub_bbox_1: 0.22788/0.35510, loss_obj_bbox_1: 0.16824/0.35845, loss_sub_giou_1: 0.31958/0.60380, loss_obj_giou_1: 0.60134/0.90608, obj_cardinality_error_1: 10.50000/2.12662] items per batch[1] items per second[0.74] total items[3400] mini batches[  3400] memory[1606] epoch remaining[0:04:09]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[710/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.02142/17.52406, loss_obj_ce: 1.00039/0.71635, obj_class_error: 77.77778/71.55185, loss_verb_ce: 0.65261/0.87764, loss_sub_bbox: 0.37339/0.35709, loss_obj_bbox: 0.44426/0.36385, loss_sub_giou: 0.54084/0.60432, loss_obj_giou: 0.90534/0.91768, obj_cardinality_error: 2.00000/2.24003, loss_obj_ce_0: 1.03125/0.78281, loss_verb_ce_0: 0.65432/0.92950, loss_sub_bbox_0: 0.40304/0.35339, loss_obj_bbox_0: 0.40608/0.35982, loss_sub_giou_0: 0.62616/0.60337, loss_obj_giou_0: 0.91833/0.90718, obj_cardinality_error_0: 2.50000/2.23211, loss_obj_ce_1: 1.14228/0.72561, loss_verb_ce_1: 0.74380/0.88740, loss_sub_bbox_1: 0.40093/0.35495, loss_obj_bbox_1: 0.45024/0.35822, loss_sub_giou_1: 0.58685/0.60353, loss_obj_giou_1: 0.97368/0.90583, obj_cardinality_error_1: 2.50000/2.12830] items per batch[1] items per second[0.73] total items[3410] mini batches[  3410] memory[1606] epoch remaining[0:04:08]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[720/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.06656/17.51984, loss_obj_ce: 0.52290/0.71590, obj_class_error: 66.66667/71.55303, loss_verb_ce: 0.67562/0.87741, loss_sub_bbox: 0.33065/0.35706, loss_obj_bbox: 0.70742/0.36392, loss_sub_giou: 0.33687/0.60393, loss_obj_giou: 0.71502/0.91713, obj_cardinality_error: 0.50000/2.23889, loss_obj_ce_0: 0.53266/0.78216, loss_verb_ce_0: 0.68952/0.92915, loss_sub_bbox_0: 0.45005/0.35355, loss_obj_bbox_0: 0.92330/0.35999, loss_sub_giou_0: 0.37426/0.60325, loss_obj_giou_0: 0.90507/0.90680, obj_cardinality_error_0: 3.00000/2.23304, loss_obj_ce_1: 0.42447/0.72516, loss_verb_ce_1: 0.48649/0.88712, loss_sub_bbox_1: 0.50053/0.35495, loss_obj_bbox_1: 1.16264/0.35836, loss_sub_giou_1: 0.48405/0.60313, loss_obj_giou_1: 0.88148/0.90545, obj_cardinality_error_1: 1.50000/2.12573] items per batch[1] items per second[0.80] total items[3420] mini batches[  3420] memory[1606] epoch remaining[0:04:06]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[730/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 8.95711/17.50971, loss_obj_ce: 0.19790/0.71544, obj_class_error: 0.00000/71.49904, loss_verb_ce: 0.94016/0.87699, loss_sub_bbox: 0.20521/0.35682, loss_obj_bbox: 0.00000/0.36358, loss_sub_giou: 0.27817/0.60360, loss_obj_giou: 0.00000/0.91643, obj_cardinality_error: 1.50000/2.23848, loss_obj_ce_0: 0.15255/0.78156, loss_verb_ce_0: 0.93387/0.92862, loss_sub_bbox_0: 0.37612/0.35350, loss_obj_bbox_0: 0.00000/0.35972, loss_sub_giou_0: 0.48181/0.60301, loss_obj_giou_0: 0.00000/0.90631, obj_cardinality_error_0: 1.00000/2.23207, loss_obj_ce_1: 0.18820/0.72485, loss_verb_ce_1: 0.94625/0.88689, loss_sub_bbox_1: 0.15302/0.35471, loss_obj_bbox_1: 0.00000/0.35807, loss_sub_giou_1: 0.18204/0.60272, loss_obj_giou_1: 0.00000/0.90478, obj_cardinality_error_1: 1.50000/2.12434] items per batch[1] items per second[0.86] total items[3430] mini batches[  3430] memory[1606] epoch remaining[0:04:05]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[740/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.37445/17.50463, loss_obj_ce: 0.51419/0.71522, obj_class_error: 80.00000/71.51476, loss_verb_ce: 0.53032/0.87671, loss_sub_bbox: 0.29811/0.35673, loss_obj_bbox: 0.31966/0.36364, loss_sub_giou: 0.46547/0.60323, loss_obj_giou: 1.02750/0.91619, obj_cardinality_error: 1.00000/2.23605, loss_obj_ce_0: 0.54030/0.78118, loss_verb_ce_0: 0.55361/0.92832, loss_sub_bbox_0: 0.31037/0.35349, loss_obj_bbox_0: 0.20758/0.35973, loss_sub_giou_0: 0.50081/0.60265, loss_obj_giou_0: 0.79453/0.90601, obj_cardinality_error_0: 2.00000/2.23038, loss_obj_ce_1: 0.51269/0.72450, loss_verb_ce_1: 0.42013/0.88656, loss_sub_bbox_1: 0.29117/0.35461, loss_obj_bbox_1: 0.38452/0.35805, loss_sub_giou_1: 0.47588/0.60236, loss_obj_giou_1: 1.00646/0.90448, obj_cardinality_error_1: 0.00000/2.12195] items per batch[1] items per second[0.83] total items[3440] mini batches[  3440] memory[1606] epoch remaining[0:04:04]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[750/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.36679/17.49676, loss_obj_ce: 0.76842/0.71516, obj_class_error: 54.54546/71.50710, loss_verb_ce: 0.67997/0.87632, loss_sub_bbox: 0.19311/0.35633, loss_obj_bbox: 0.25245/0.36355, loss_sub_giou: 0.74043/0.60288, loss_obj_giou: 1.01950/0.91595, obj_cardinality_error: 8.00000/2.23449, loss_obj_ce_0: 0.79940/0.78100, loss_verb_ce_0: 0.55799/0.92778, loss_sub_bbox_0: 0.21954/0.35328, loss_obj_bbox_0: 0.27022/0.35967, loss_sub_giou_0: 0.71239/0.60246, loss_obj_giou_0: 1.13945/0.90579, obj_cardinality_error_0: 1.00000/2.22710, loss_obj_ce_1: 0.62627/0.72448, loss_verb_ce_1: 0.52246/0.88601, loss_sub_bbox_1: 0.21841/0.35429, loss_obj_bbox_1: 0.20360/0.35795, loss_sub_giou_1: 0.75939/0.60198, loss_obj_giou_1: 0.88737/0.90418, obj_cardinality_error_1: 2.00000/2.11971] items per batch[1] items per second[0.76] total items[3450] mini batches[  3450] memory[1606] epoch remaining[0:04:03]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[760/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.63937/17.48735, loss_obj_ce: 0.79423/0.71469, obj_class_error: 80.00000/71.49439, loss_verb_ce: 0.90858/0.87583, loss_sub_bbox: 0.28656/0.35610, loss_obj_bbox: 0.25220/0.36315, loss_sub_giou: 0.45770/0.60287, loss_obj_giou: 0.82728/0.91583, obj_cardinality_error: 1.50000/2.23772, loss_obj_ce_0: 0.69016/0.78037, loss_verb_ce_0: 0.68132/0.92711, loss_sub_bbox_0: 0.31820/0.35310, loss_obj_bbox_0: 0.25721/0.35937, loss_sub_giou_0: 0.51968/0.60247, loss_obj_giou_0: 0.67240/0.90564, obj_cardinality_error_0: 1.00000/2.22370, loss_obj_ce_1: 0.61064/0.72394, loss_verb_ce_1: 0.63742/0.88539, loss_sub_bbox_1: 0.32778/0.35404, loss_obj_bbox_1: 0.24462/0.35766, loss_sub_giou_1: 0.49956/0.60197, loss_obj_giou_1: 0.89666/0.90434, obj_cardinality_error_1: 1.50000/2.11936] items per batch[1] items per second[0.76] total items[3460] mini batches[  3460] memory[1606] epoch remaining[0:04:02]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[770/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.14604/17.47860, loss_obj_ce: 0.76293/0.71419, obj_class_error: 60.00000/71.46637, loss_verb_ce: 0.68040/0.87545, loss_sub_bbox: 0.28349/0.35590, loss_obj_bbox: 0.21664/0.36291, loss_sub_giou: 0.38811/0.60269, loss_obj_giou: 0.83875/0.91534, obj_cardinality_error: 7.00000/2.23674, loss_obj_ce_0: 0.73251/0.77985, loss_verb_ce_0: 0.70430/0.92648, loss_sub_bbox_0: 0.24597/0.35295, loss_obj_bbox_0: 0.28869/0.35926, loss_sub_giou_0: 0.35048/0.60236, loss_obj_giou_0: 0.94037/0.90523, obj_cardinality_error_0: 3.50000/2.22219, loss_obj_ce_1: 0.84599/0.72353, loss_verb_ce_1: 0.69870/0.88500, loss_sub_bbox_1: 0.22903/0.35384, loss_obj_bbox_1: 0.23936/0.35748, loss_sub_giou_1: 0.38065/0.60174, loss_obj_giou_1: 0.98150/0.90396, obj_cardinality_error_1: 3.50000/2.11859] items per batch[1] items per second[0.77] total items[3470] mini batches[  3470] memory[1606] epoch remaining[0:04:00]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[780/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.40432/17.47206, loss_obj_ce: 0.69372/0.71378, obj_class_error: 60.00000/71.44396, loss_verb_ce: 0.89218/0.87511, loss_sub_bbox: 0.27733/0.35583, loss_obj_bbox: 0.38411/0.36271, loss_sub_giou: 0.42184/0.60247, loss_obj_giou: 0.89111/0.91515, obj_cardinality_error: 0.50000/2.23362, loss_obj_ce_0: 0.48472/0.77939, loss_verb_ce_0: 0.79039/0.92599, loss_sub_bbox_0: 0.21586/0.35287, loss_obj_bbox_0: 0.31305/0.35906, loss_sub_giou_0: 0.47277/0.60207, loss_obj_giou_0: 1.12338/0.90523, obj_cardinality_error_0: 2.50000/2.22055, loss_obj_ce_1: 0.56893/0.72312, loss_verb_ce_1: 0.88721/0.88470, loss_sub_bbox_1: 0.27126/0.35379, loss_obj_bbox_1: 0.25109/0.35727, loss_sub_giou_1: 0.43865/0.60151, loss_obj_giou_1: 0.88789/0.90390, obj_cardinality_error_1: 1.00000/2.11652] items per batch[1] items per second[0.91] total items[3480] mini batches[  3480] memory[1606] epoch remaining[0:03:59]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[790/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.66089/17.46361, loss_obj_ce: 0.83768/0.71334, obj_class_error: 33.33334/71.41571, loss_verb_ce: 0.58355/0.87434, loss_sub_bbox: 0.29035/0.35566, loss_obj_bbox: 0.28748/0.36244, loss_sub_giou: 0.54757/0.60244, loss_obj_giou: 0.86825/0.91498, obj_cardinality_error: 4.00000/2.23166, loss_obj_ce_0: 0.91840/0.77905, loss_verb_ce_0: 0.59064/0.92550, loss_sub_bbox_0: 0.28915/0.35274, loss_obj_bbox_0: 0.32638/0.35883, loss_sub_giou_0: 0.55152/0.60199, loss_obj_giou_0: 0.80270/0.90501, obj_cardinality_error_0: 5.00000/2.21834, loss_obj_ce_1: 0.89129/0.72282, loss_verb_ce_1: 0.57215/0.88413, loss_sub_bbox_1: 0.26027/0.35366, loss_obj_bbox_1: 0.30142/0.35706, loss_sub_giou_1: 0.52003/0.60137, loss_obj_giou_1: 0.84315/0.90369, obj_cardinality_error_1: 1.00000/2.11375] items per batch[1] items per second[0.90] total items[3490] mini batches[  3490] memory[1606] epoch remaining[0:03:57]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[800/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.48952/17.45781, loss_obj_ce: 0.44169/0.71290, obj_class_error: 75.00000/71.37960, loss_verb_ce: 0.74882/0.87407, loss_sub_bbox: 0.20014/0.35563, loss_obj_bbox: 0.17949/0.36222, loss_sub_giou: 0.40124/0.60239, loss_obj_giou: 0.97590/0.91426, obj_cardinality_error: 3.50000/2.22900, loss_obj_ce_0: 0.42814/0.77856, loss_verb_ce_0: 0.76902/0.92534, loss_sub_bbox_0: 0.25511/0.35280, loss_obj_bbox_0: 0.27979/0.35874, loss_sub_giou_0: 0.58585/0.60207, loss_obj_giou_0: 1.29893/0.90463, obj_cardinality_error_0: 1.00000/2.21657, loss_obj_ce_1: 0.43628/0.72245, loss_verb_ce_1: 0.78809/0.88395, loss_sub_bbox_1: 0.17822/0.35353, loss_obj_bbox_1: 0.14782/0.35692, loss_sub_giou_1: 0.42296/0.60118, loss_obj_giou_1: 0.78525/0.90308, obj_cardinality_error_1: 2.00000/2.11114] items per batch[1] items per second[0.77] total items[3500] mini batches[  3500] memory[1606] epoch remaining[0:03:56]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[810/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.94426/17.45093, loss_obj_ce: 0.53187/0.71241, obj_class_error: 100.00000/71.37465, loss_verb_ce: 1.00061/0.87388, loss_sub_bbox: 0.23534/0.35547, loss_obj_bbox: 0.29538/0.36199, loss_sub_giou: 0.44285/0.60214, loss_obj_giou: 0.87770/0.91404, obj_cardinality_error: 1.00000/2.23020, loss_obj_ce_0: 0.59962/0.77788, loss_verb_ce_0: 0.83860/0.92506, loss_sub_bbox_0: 0.23081/0.35274, loss_obj_bbox_0: 0.24963/0.35854, loss_sub_giou_0: 0.40076/0.60203, loss_obj_giou_0: 0.64090/0.90444, obj_cardinality_error_0: 1.00000/2.21567, loss_obj_ce_1: 0.60752/0.72190, loss_verb_ce_1: 1.09909/0.88377, loss_sub_bbox_1: 0.21146/0.35340, loss_obj_bbox_1: 0.31143/0.35664, loss_sub_giou_1: 0.34885/0.60092, loss_obj_giou_1: 0.78244/0.90279, obj_cardinality_error_1: 1.00000/2.11197] items per batch[1] items per second[0.89] total items[3510] mini batches[  3510] memory[1606] epoch remaining[0:03:55]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[820/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.75029/17.44390, loss_obj_ce: 0.63491/0.71206, obj_class_error: 50.00000/71.34124, loss_verb_ce: 0.69462/0.87336, loss_sub_bbox: 0.25508/0.35532, loss_obj_bbox: 0.22954/0.36172, loss_sub_giou: 0.29241/0.60210, loss_obj_giou: 0.83879/0.91388, obj_cardinality_error: 1.00000/2.23111, loss_obj_ce_0: 0.54544/0.77728, loss_verb_ce_0: 0.72571/0.92447, loss_sub_bbox_0: 0.24320/0.35263, loss_obj_bbox_0: 0.48834/0.35840, loss_sub_giou_0: 0.35913/0.60208, loss_obj_giou_0: 1.08509/0.90449, obj_cardinality_error_0: 1.50000/2.21463, loss_obj_ce_1: 0.67058/0.72158, loss_verb_ce_1: 0.69557/0.88336, loss_sub_bbox_1: 0.23018/0.35331, loss_obj_bbox_1: 0.19939/0.35637, loss_sub_giou_1: 0.26629/0.60091, loss_obj_giou_1: 0.71155/0.90276, obj_cardinality_error_1: 0.50000/2.11023] items per batch[1] items per second[0.79] total items[3520] mini batches[  3520] memory[1606] epoch remaining[0:03:53]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[830/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.13598/17.43503, loss_obj_ce: 0.31471/0.71158, obj_class_error: 33.33334/71.33171, loss_verb_ce: 0.60201/0.87296, loss_sub_bbox: 0.56629/0.35522, loss_obj_bbox: 0.22733/0.36142, loss_sub_giou: 0.73145/0.60184, loss_obj_giou: 0.75806/0.91349, obj_cardinality_error: 7.00000/2.23031, loss_obj_ce_0: 0.46886/0.77684, loss_verb_ce_0: 0.84690/0.92413, loss_sub_bbox_0: 0.51966/0.35255, loss_obj_bbox_0: 0.20659/0.35817, loss_sub_giou_0: 0.74531/0.60190, loss_obj_giou_0: 0.62346/0.90404, obj_cardinality_error_0: 13.00000/2.21941, loss_obj_ce_1: 0.39967/0.72109, loss_verb_ce_1: 0.69062/0.88293, loss_sub_bbox_1: 0.57204/0.35321, loss_obj_bbox_1: 0.10890/0.35600, loss_sub_giou_1: 0.71908/0.60061, loss_obj_giou_1: 0.59435/0.90220, obj_cardinality_error_1: 12.50000/2.11190] items per batch[1] items per second[0.75] total items[3530] mini batches[  3530] memory[1606] epoch remaining[0:03:52]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[840/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.15695/17.43237, loss_obj_ce: 0.64864/0.71154, obj_class_error: 62.50000/71.31583, loss_verb_ce: 0.56094/0.87246, loss_sub_bbox: 0.31278/0.35508, loss_obj_bbox: 0.21969/0.36128, loss_sub_giou: 0.65852/0.60172, loss_obj_giou: 1.16011/0.91348, obj_cardinality_error: 1.00000/2.23559, loss_obj_ce_0: 0.76809/0.77711, loss_verb_ce_0: 0.65039/0.92401, loss_sub_bbox_0: 0.26824/0.35254, loss_obj_bbox_0: 0.20311/0.35821, loss_sub_giou_0: 0.75072/0.60191, loss_obj_giou_0: 1.24574/0.90419, obj_cardinality_error_0: 1.00000/2.22740, loss_obj_ce_1: 0.68099/0.72107, loss_verb_ce_1: 0.69217/0.88253, loss_sub_bbox_1: 0.31467/0.35314, loss_obj_bbox_1: 0.13684/0.35595, loss_sub_giou_1: 0.78999/0.60051, loss_obj_giou_1: 1.00884/0.90232, obj_cardinality_error_1: 1.00000/2.11667] items per batch[1] items per second[0.84] total items[3540] mini batches[  3540] memory[1606] epoch remaining[0:03:51]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[850/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.31250/17.42883, loss_obj_ce: 0.34624/0.71112, obj_class_error: 66.66667/71.27570, loss_verb_ce: 0.81412/0.87200, loss_sub_bbox: 0.34376/0.35504, loss_obj_bbox: 0.69412/0.36122, loss_sub_giou: 0.60612/0.60196, loss_obj_giou: 0.81166/0.91344, obj_cardinality_error: 2.00000/2.23718, loss_obj_ce_0: 0.73316/0.77701, loss_verb_ce_0: 1.11380/0.92373, loss_sub_bbox_0: 0.29936/0.35245, loss_obj_bbox_0: 0.61601/0.35803, loss_sub_giou_0: 0.50736/0.60214, loss_obj_giou_0: 0.61099/0.90393, obj_cardinality_error_0: 1.00000/2.22662, loss_obj_ce_1: 0.36821/0.72095, loss_verb_ce_1: 0.69961/0.88223, loss_sub_bbox_1: 0.26238/0.35296, loss_obj_bbox_1: 0.75951/0.35593, loss_sub_giou_1: 0.49920/0.60060, loss_obj_giou_1: 1.13662/0.90271, obj_cardinality_error_1: 1.00000/2.11718] items per batch[1] items per second[0.90] total items[3550] mini batches[  3550] memory[1606] epoch remaining[0:03:49]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[860/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.41924/17.41928, loss_obj_ce: 0.33338/0.71067, obj_class_error: 25.00000/71.23219, loss_verb_ce: 0.71853/0.87151, loss_sub_bbox: 0.31693/0.35482, loss_obj_bbox: 0.23109/0.36095, loss_sub_giou: 0.43378/0.60155, loss_obj_giou: 0.54100/0.91277, obj_cardinality_error: 3.00000/2.23624, loss_obj_ce_0: 0.35118/0.77668, loss_verb_ce_0: 0.70611/0.92340, loss_sub_bbox_0: 0.31032/0.35227, loss_obj_bbox_0: 0.35175/0.35781, loss_sub_giou_0: 0.40193/0.60181, loss_obj_giou_0: 0.97730/0.90351, obj_cardinality_error_0: 3.00000/2.22472, loss_obj_ce_1: 0.31623/0.72076, loss_verb_ce_1: 0.72258/0.88197, loss_sub_bbox_1: 0.32687/0.35267, loss_obj_bbox_1: 0.28538/0.35567, loss_sub_giou_1: 0.43336/0.60004, loss_obj_giou_1: 0.78079/0.90222, obj_cardinality_error_1: 2.50000/2.11559] items per batch[1] items per second[0.75] total items[3560] mini batches[  3560] memory[1606] epoch remaining[0:03:48]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[870/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.45008/17.40893, loss_obj_ce: 0.53412/0.70984, obj_class_error: 75.00000/71.20199, loss_verb_ce: 0.82965/0.87082, loss_sub_bbox: 0.26854/0.35461, loss_obj_bbox: 0.27695/0.36081, loss_sub_giou: 0.35687/0.60135, loss_obj_giou: 0.68436/0.91237, obj_cardinality_error: 1.00000/2.23319, loss_obj_ce_0: 0.53261/0.77594, loss_verb_ce_0: 0.92139/0.92303, loss_sub_bbox_0: 0.30781/0.35218, loss_obj_bbox_0: 0.19514/0.35758, loss_sub_giou_0: 0.40360/0.60163, loss_obj_giou_0: 0.44972/0.90296, obj_cardinality_error_0: 0.00000/2.22101, loss_obj_ce_1: 0.49887/0.72007, loss_verb_ce_1: 0.96886/0.88150, loss_sub_bbox_1: 0.22508/0.35247, loss_obj_bbox_1: 0.21193/0.35539, loss_sub_giou_1: 0.31015/0.59978, loss_obj_giou_1: 0.52636/0.90166, obj_cardinality_error_1: 1.00000/2.11232] items per batch[1] items per second[0.81] total items[3570] mini batches[  3570] memory[1606] epoch remaining[0:03:47]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[880/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.11175/17.39929, loss_obj_ce: 0.62874/0.70923, obj_class_error: 71.42857/71.17156, loss_verb_ce: 0.58193/0.87033, loss_sub_bbox: 0.33325/0.35450, loss_obj_bbox: 0.32472/0.36055, loss_sub_giou: 0.60617/0.60125, loss_obj_giou: 1.17579/0.91210, obj_cardinality_error: 0.00000/2.23115, loss_obj_ce_0: 0.78702/0.77542, loss_verb_ce_0: 0.50486/0.92253, loss_sub_bbox_0: 0.34875/0.35204, loss_obj_bbox_0: 0.24621/0.35735, loss_sub_giou_0: 0.59358/0.60137, loss_obj_giou_0: 0.83311/0.90266, obj_cardinality_error_0: 2.00000/2.22011, loss_obj_ce_1: 0.73406/0.71959, loss_verb_ce_1: 0.52396/0.88107, loss_sub_bbox_1: 0.25905/0.35225, loss_obj_bbox_1: 0.18550/0.35503, loss_sub_giou_1: 0.45447/0.59948, loss_obj_giou_1: 0.83362/0.90100, obj_cardinality_error_1: 0.50000/2.11061] items per batch[1] items per second[0.85] total items[3580] mini batches[  3580] memory[1606] epoch remaining[0:03:46]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[890/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.24356/17.38973, loss_obj_ce: 0.27621/0.70862, obj_class_error: 20.00000/71.12164, loss_verb_ce: 0.54161/0.86997, loss_sub_bbox: 0.29141/0.35433, loss_obj_bbox: 0.40553/0.36026, loss_sub_giou: 0.47205/0.60080, loss_obj_giou: 0.78588/0.91162, obj_cardinality_error: 5.00000/2.22897, loss_obj_ce_0: 0.36623/0.77477, loss_verb_ce_0: 0.59742/0.92219, loss_sub_bbox_0: 0.30219/0.35194, loss_obj_bbox_0: 0.35354/0.35703, loss_sub_giou_0: 0.50567/0.60097, loss_obj_giou_0: 0.68158/0.90217, obj_cardinality_error_0: 0.00000/2.21685, loss_obj_ce_1: 0.30057/0.71905, loss_verb_ce_1: 0.56845/0.88080, loss_sub_bbox_1: 0.30150/0.35211, loss_obj_bbox_1: 0.42441/0.35481, loss_sub_giou_1: 0.51073/0.59912, loss_obj_giou_1: 0.73326/0.90050, obj_cardinality_error_1: 0.50000/2.10710] items per batch[1] items per second[0.75] total items[3590] mini batches[  3590] memory[1606] epoch remaining[0:03:45]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[900/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.46771/17.37658, loss_obj_ce: 0.43417/0.70795, obj_class_error: 50.00000/71.08056, loss_verb_ce: 0.77260/0.86943, loss_sub_bbox: 0.26999/0.35403, loss_obj_bbox: 0.27353/0.35986, loss_sub_giou: 0.38493/0.60031, loss_obj_giou: 0.70623/0.91101, obj_cardinality_error: 7.00000/2.23181, loss_obj_ce_0: 0.38064/0.77406, loss_verb_ce_0: 0.56898/0.92159, loss_sub_bbox_0: 0.36410/0.35167, loss_obj_bbox_0: 0.31355/0.35669, loss_sub_giou_0: 0.51373/0.60049, loss_obj_giou_0: 0.72115/0.90183, obj_cardinality_error_0: 0.50000/2.21389, loss_obj_ce_1: 0.50594/0.71844, loss_verb_ce_1: 0.71865/0.88029, loss_sub_bbox_1: 0.26845/0.35179, loss_obj_bbox_1: 0.24738/0.35443, loss_sub_giou_1: 0.44003/0.59860, loss_obj_giou_1: 0.91790/0.90007, obj_cardinality_error_1: 1.00000/2.10528] items per batch[1] items per second[0.82] total items[3600] mini batches[  3600] memory[1606] epoch remaining[0:03:43]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[910/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.26628/17.36645, loss_obj_ce: 0.69278/0.70736, obj_class_error: 50.00000/71.04697, loss_verb_ce: 0.47276/0.86869, loss_sub_bbox: 0.39378/0.35388, loss_obj_bbox: 0.26678/0.35962, loss_sub_giou: 0.59172/0.59998, loss_obj_giou: 0.96271/0.91057, obj_cardinality_error: 4.50000/2.23075, loss_obj_ce_0: 0.76327/0.77364, loss_verb_ce_0: 0.56623/0.92109, loss_sub_bbox_0: 0.44027/0.35161, loss_obj_bbox_0: 0.29967/0.35646, loss_sub_giou_0: 0.65892/0.60027, loss_obj_giou_0: 0.99981/0.90142, obj_cardinality_error_0: 1.50000/2.21053, loss_obj_ce_1: 0.74230/0.71792, loss_verb_ce_1: 0.48401/0.87974, loss_sub_bbox_1: 0.44328/0.35162, loss_obj_bbox_1: 0.26454/0.35416, loss_sub_giou_1: 0.59597/0.59823, loss_obj_giou_1: 0.94201/0.89965, obj_cardinality_error_1: 4.00000/2.10429] items per batch[1] items per second[0.84] total items[3610] mini batches[  3610] memory[1606] epoch remaining[0:03:42]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[920/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.87476/17.36074, loss_obj_ce: 0.41336/0.70683, obj_class_error: 50.00000/70.99266, loss_verb_ce: 0.75047/0.86811, loss_sub_bbox: 0.38551/0.35385, loss_obj_bbox: 0.24515/0.35959, loss_sub_giou: 0.43387/0.59984, loss_obj_giou: 0.56191/0.91043, obj_cardinality_error: 1.50000/2.23135, loss_obj_ce_0: 0.54429/0.77324, loss_verb_ce_0: 0.82072/0.92062, loss_sub_bbox_0: 0.25728/0.35155, loss_obj_bbox_0: 0.40403/0.35656, loss_sub_giou_0: 0.30710/0.60003, loss_obj_giou_0: 0.70805/0.90126, obj_cardinality_error_0: 1.00000/2.20967, loss_obj_ce_1: 0.40793/0.71741, loss_verb_ce_1: 0.69520/0.87917, loss_sub_bbox_1: 0.36698/0.35158, loss_obj_bbox_1: 0.29582/0.35422, loss_sub_giou_1: 0.44924/0.59807, loss_obj_giou_1: 0.62931/0.89946, obj_cardinality_error_1: 1.00000/2.10483] items per batch[1] items per second[0.80] total items[3620] mini batches[  3620] memory[1606] epoch remaining[0:03:41]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[930/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 5.71038/17.35429, loss_obj_ce: 0.13990/0.70654, obj_class_error: 0.00000/70.96081, loss_verb_ce: 0.30559/0.86777, loss_sub_bbox: 0.22458/0.35378, loss_obj_bbox: 0.00000/0.35942, loss_sub_giou: 0.23416/0.59949, loss_obj_giou: 0.00000/0.91012, obj_cardinality_error: 1.50000/2.23154, loss_obj_ce_0: 0.24923/0.77278, loss_verb_ce_0: 0.51339/0.92027, loss_sub_bbox_0: 0.30759/0.35158, loss_obj_bbox_0: 0.00000/0.35642, loss_sub_giou_0: 0.32504/0.59977, loss_obj_giou_0: 0.00000/0.90082, obj_cardinality_error_0: 4.50000/2.20799, loss_obj_ce_1: 0.16023/0.71700, loss_verb_ce_1: 0.33499/0.87881, loss_sub_bbox_1: 0.26054/0.35156, loss_obj_bbox_1: 0.00000/0.35411, loss_sub_giou_1: 0.31208/0.59774, loss_obj_giou_1: 0.00000/0.89913, obj_cardinality_error_1: 1.50000/2.10331] items per batch[1] items per second[0.79] total items[3630] mini batches[  3630] memory[1606] epoch remaining[0:03:40]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[940/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.64166/17.35115, loss_obj_ce: 0.69251/0.70678, obj_class_error: 75.00000/70.96840, loss_verb_ce: 0.73482/0.86752, loss_sub_bbox: 0.30508/0.35368, loss_obj_bbox: 0.11990/0.35928, loss_sub_giou: 0.64076/0.59937, loss_obj_giou: 0.64194/0.91002, obj_cardinality_error: 1.50000/2.23036, loss_obj_ce_0: 0.69916/0.77296, loss_verb_ce_0: 0.75366/0.91997, loss_sub_bbox_0: 0.32672/0.35147, loss_obj_bbox_0: 0.17612/0.35631, loss_sub_giou_0: 0.91751/0.59974, loss_obj_giou_0: 0.87103/0.90089, obj_cardinality_error_0: 2.00000/2.20577, loss_obj_ce_1: 0.84921/0.71724, loss_verb_ce_1: 0.96227/0.87854, loss_sub_bbox_1: 0.22389/0.35145, loss_obj_bbox_1: 0.21416/0.35392, loss_sub_giou_1: 0.80122/0.59770, loss_obj_giou_1: 1.21215/0.89914, obj_cardinality_error_1: 3.00000/2.10165] items per batch[1] items per second[0.80] total items[3640] mini batches[  3640] memory[1606] epoch remaining[0:03:38]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[950/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.71077/17.34577, loss_obj_ce: 0.50204/0.70621, obj_class_error: 60.00000/70.93881, loss_verb_ce: 0.65158/0.86719, loss_sub_bbox: 0.43513/0.35358, loss_obj_bbox: 0.34153/0.35913, loss_sub_giou: 0.64131/0.59927, loss_obj_giou: 0.73685/0.91000, obj_cardinality_error: 1.50000/2.23123, loss_obj_ce_0: 0.66278/0.77244, loss_verb_ce_0: 0.92371/0.91961, loss_sub_bbox_0: 0.47099/0.35139, loss_obj_bbox_0: 0.44460/0.35622, loss_sub_giou_0: 0.58162/0.59968, loss_obj_giou_0: 0.97732/0.90081, obj_cardinality_error_0: 1.50000/2.20301, loss_obj_ce_1: 0.53650/0.71682, loss_verb_ce_1: 0.67340/0.87829, loss_sub_bbox_1: 0.43576/0.35134, loss_obj_bbox_1: 0.34718/0.35377, loss_sub_giou_1: 0.68969/0.59770, loss_obj_giou_1: 0.69732/0.89910, obj_cardinality_error_1: 2.00000/2.10151] items per batch[1] items per second[0.92] total items[3650] mini batches[  3650] memory[1606] epoch remaining[0:03:37]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[960/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.25157/17.33756, loss_obj_ce: 0.46306/0.70580, obj_class_error: 50.00000/70.88995, loss_verb_ce: 0.68662/0.86671, loss_sub_bbox: 0.24075/0.35349, loss_obj_bbox: 0.20021/0.35872, loss_sub_giou: 0.57003/0.59914, loss_obj_giou: 0.69904/0.90961, obj_cardinality_error: 3.00000/2.22787, loss_obj_ce_0: 0.53316/0.77190, loss_verb_ce_0: 0.70311/0.91918, loss_sub_bbox_0: 0.31077/0.35134, loss_obj_bbox_0: 0.25397/0.35598, loss_sub_giou_0: 0.51675/0.59962, loss_obj_giou_0: 0.72312/0.90053, obj_cardinality_error_0: 0.00000/2.19973, loss_obj_ce_1: 0.55306/0.71638, loss_verb_ce_1: 0.66332/0.87776, loss_sub_bbox_1: 0.27936/0.35125, loss_obj_bbox_1: 0.27696/0.35350, loss_sub_giou_1: 0.49083/0.59753, loss_obj_giou_1: 0.69134/0.89906, obj_cardinality_error_1: 2.00000/2.09850] items per batch[1] items per second[0.84] total items[3660] mini batches[  3660] memory[1606] epoch remaining[0:03:35]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[970/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.53452/17.32997, loss_obj_ce: 0.70332/0.70586, obj_class_error: 66.66667/70.88639, loss_verb_ce: 0.83279/0.86619, loss_sub_bbox: 0.17279/0.35318, loss_obj_bbox: 0.14318/0.35855, loss_sub_giou: 0.19750/0.59895, loss_obj_giou: 0.57743/0.90943, obj_cardinality_error: 1.00000/2.22493, loss_obj_ce_0: 0.81670/0.77173, loss_verb_ce_0: 0.87311/0.91853, loss_sub_bbox_0: 0.23425/0.35111, loss_obj_bbox_0: 0.26888/0.35583, loss_sub_giou_0: 0.27796/0.59966, loss_obj_giou_0: 0.76505/0.90029, obj_cardinality_error_0: 1.00000/2.19782, loss_obj_ce_1: 0.78090/0.71642, loss_verb_ce_1: 0.84094/0.87722, loss_sub_bbox_1: 0.24956/0.35095, loss_obj_bbox_1: 0.22422/0.35338, loss_sub_giou_1: 0.34162/0.59737, loss_obj_giou_1: 0.74817/0.89889, obj_cardinality_error_1: 3.50000/2.09782] items per batch[1] items per second[0.89] total items[3670] mini batches[  3670] memory[1606] epoch remaining[0:03:34]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[980/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.57770/17.31804, loss_obj_ce: 0.35145/0.70519, obj_class_error: 50.00000/70.84813, loss_verb_ce: 0.61616/0.86561, loss_sub_bbox: 0.23416/0.35295, loss_obj_bbox: 0.21067/0.35823, loss_sub_giou: 0.21674/0.59859, loss_obj_giou: 0.86846/0.90872, obj_cardinality_error: 0.50000/2.22147, loss_obj_ce_0: 0.49007/0.77106, loss_verb_ce_0: 0.84023/0.91794, loss_sub_bbox_0: 0.16869/0.35090, loss_obj_bbox_0: 0.37064/0.35559, loss_sub_giou_0: 0.17452/0.59926, loss_obj_giou_0: 1.06674/0.89974, obj_cardinality_error_0: 2.50000/2.19633, loss_obj_ce_1: 0.34194/0.71587, loss_verb_ce_1: 0.66338/0.87674, loss_sub_bbox_1: 0.22543/0.35071, loss_obj_bbox_1: 0.19509/0.35309, loss_sub_giou_1: 0.22358/0.59689, loss_obj_giou_1: 1.09295/0.89842, obj_cardinality_error_1: 0.50000/2.09470] items per batch[1] items per second[0.82] total items[3680] mini batches[  3680] memory[1606] epoch remaining[0:03:33]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[990/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.89747/17.31344, loss_obj_ce: 0.69735/0.70504, obj_class_error: 75.00000/70.84283, loss_verb_ce: 1.00154/0.86536, loss_sub_bbox: 0.41074/0.35288, loss_obj_bbox: 0.29537/0.35801, loss_sub_giou: 0.44595/0.59880, loss_obj_giou: 0.64825/0.90825, obj_cardinality_error: 1.50000/2.21978, loss_obj_ce_0: 0.85462/0.77102, loss_verb_ce_0: 1.00146/0.91783, loss_sub_bbox_0: 0.33679/0.35081, loss_obj_bbox_0: 0.36265/0.35539, loss_sub_giou_0: 0.37193/0.59935, loss_obj_giou_0: 0.77276/0.89920, obj_cardinality_error_0: 2.50000/2.20203, loss_obj_ce_1: 0.68362/0.71564, loss_verb_ce_1: 1.05807/0.87643, loss_sub_bbox_1: 0.41545/0.35072, loss_obj_bbox_1: 0.27080/0.35291, loss_sub_giou_1: 0.46324/0.59716, loss_obj_giou_1: 0.60809/0.89795, obj_cardinality_error_1: 1.00000/2.09322] items per batch[1] items per second[0.83] total items[3690] mini batches[  3690] memory[1606] epoch remaining[0:03:31]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1000/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.06553/17.30672, loss_obj_ce: 0.85055/0.70452, obj_class_error: 66.66667/70.81848, loss_verb_ce: 0.68158/0.86470, loss_sub_bbox: 0.35266/0.35280, loss_obj_bbox: 0.27525/0.35792, loss_sub_giou: 0.84009/0.59871, loss_obj_giou: 1.22713/0.90841, obj_cardinality_error: 2.50000/2.21757, loss_obj_ce_0: 1.00279/0.77059, loss_verb_ce_0: 0.82071/0.91735, loss_sub_bbox_0: 0.30978/0.35069, loss_obj_bbox_0: 0.30476/0.35528, loss_sub_giou_0: 0.81332/0.59914, loss_obj_giou_0: 1.23663/0.89911, obj_cardinality_error_0: 1.50000/2.20203, loss_obj_ce_1: 0.89309/0.71511, loss_verb_ce_1: 0.73279/0.87578, loss_sub_bbox_1: 0.30969/0.35063, loss_obj_bbox_1: 0.36072/0.35288, loss_sub_giou_1: 0.77976/0.59701, loss_obj_giou_1: 1.16985/0.89799, obj_cardinality_error_1: 3.50000/2.09149] items per batch[1] items per second[0.88] total items[3700] mini batches[  3700] memory[1606] epoch remaining[0:03:30]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1010/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.67171/17.29924, loss_obj_ce: 0.93375/0.70456, obj_class_error: 75.00000/70.82160, loss_verb_ce: 0.84400/0.86437, loss_sub_bbox: 0.31012/0.35257, loss_obj_bbox: 0.23091/0.35771, loss_sub_giou: 0.71878/0.59832, loss_obj_giou: 0.95355/0.90782, obj_cardinality_error: 2.50000/2.21577, loss_obj_ce_0: 1.15730/0.77063, loss_verb_ce_0: 0.95298/0.91703, loss_sub_bbox_0: 0.34392/0.35051, loss_obj_bbox_0: 0.29634/0.35512, loss_sub_giou_0: 0.63510/0.59882, loss_obj_giou_0: 1.03614/0.89843, obj_cardinality_error_0: 2.00000/2.19987, loss_obj_ce_1: 1.15838/0.71534, loss_verb_ce_1: 0.87269/0.87541, loss_sub_bbox_1: 0.27368/0.35042, loss_obj_bbox_1: 0.23877/0.35273, loss_sub_giou_1: 0.69242/0.59665, loss_obj_giou_1: 0.81256/0.89739, obj_cardinality_error_1: 3.00000/2.09070] items per batch[1] items per second[0.80] total items[3710] mini batches[  3710] memory[1606] epoch remaining[0:03:29]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1020/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.79599/17.29239, loss_obj_ce: 0.70575/0.70439, obj_class_error: 100.00000/70.79590, loss_verb_ce: 1.00565/0.86391, loss_sub_bbox: 0.28134/0.35251, loss_obj_bbox: 0.21649/0.35744, loss_sub_giou: 0.57263/0.59819, loss_obj_giou: 0.83416/0.90772, obj_cardinality_error: 1.00000/2.21573, loss_obj_ce_0: 0.73751/0.77040, loss_verb_ce_0: 0.99566/0.91660, loss_sub_bbox_0: 0.16618/0.35045, loss_obj_bbox_0: 0.15355/0.35483, loss_sub_giou_0: 0.37059/0.59864, loss_obj_giou_0: 0.66188/0.89825, obj_cardinality_error_0: 1.00000/2.19879, loss_obj_ce_1: 0.92919/0.71529, loss_verb_ce_1: 0.96821/0.87495, loss_sub_bbox_1: 0.15048/0.35034, loss_obj_bbox_1: 0.22223/0.35243, loss_sub_giou_1: 0.32974/0.59646, loss_obj_giou_1: 0.73981/0.89714, obj_cardinality_error_1: 0.50000/2.08925] items per batch[1] items per second[0.77] total items[3720] mini batches[  3720] memory[1606] epoch remaining[0:03:28]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1030/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.03307/17.28519, loss_obj_ce: 0.72153/0.70411, obj_class_error: 50.00000/70.72712, loss_verb_ce: 0.50912/0.86339, loss_sub_bbox: 0.25616/0.35229, loss_obj_bbox: 0.16927/0.35725, loss_sub_giou: 1.02165/0.59831, loss_obj_giou: 0.99748/0.90768, obj_cardinality_error: 0.00000/2.21903, loss_obj_ce_0: 0.79247/0.77004, loss_verb_ce_0: 0.72719/0.91628, loss_sub_bbox_0: 0.19310/0.35021, loss_obj_bbox_0: 0.09295/0.35454, loss_sub_giou_0: 0.87333/0.59868, loss_obj_giou_0: 0.64115/0.89782, obj_cardinality_error_0: 0.50000/2.19732, loss_obj_ce_1: 0.86173/0.71514, loss_verb_ce_1: 0.59328/0.87455, loss_sub_bbox_1: 0.25082/0.35012, loss_obj_bbox_1: 0.13175/0.35221, loss_sub_giou_1: 0.86482/0.59651, loss_obj_giou_1: 0.86459/0.89691, obj_cardinality_error_1: 1.00000/2.09115] items per batch[1] items per second[0.85] total items[3730] mini batches[  3730] memory[1606] epoch remaining[0:03:26]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1040/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.73293/17.27941, loss_obj_ce: 0.50695/0.70405, obj_class_error: 60.00000/70.68535, loss_verb_ce: 0.55450/0.86305, loss_sub_bbox: 0.36196/0.35217, loss_obj_bbox: 0.34402/0.35700, loss_sub_giou: 0.58650/0.59834, loss_obj_giou: 0.49462/0.90746, obj_cardinality_error: 3.00000/2.21992, loss_obj_ce_0: 0.73973/0.76991, loss_verb_ce_0: 0.61488/0.91583, loss_sub_bbox_0: 0.36288/0.35017, loss_obj_bbox_0: 0.27879/0.35428, loss_sub_giou_0: 0.57872/0.59881, loss_obj_giou_0: 0.42805/0.89747, obj_cardinality_error_0: 2.50000/2.19519, loss_obj_ce_1: 0.58476/0.71521, loss_verb_ce_1: 0.59925/0.87431, loss_sub_bbox_1: 0.36013/0.34996, loss_obj_bbox_1: 0.38073/0.35192, loss_sub_giou_1: 0.52237/0.59641, loss_obj_giou_1: 0.53265/0.89659, obj_cardinality_error_1: 1.00000/2.09078] items per batch[1] items per second[0.85] total items[3740] mini batches[  3740] memory[1606] epoch remaining[0:03:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1050/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.46713/17.27224, loss_obj_ce: 0.34369/0.70348, obj_class_error: 66.66667/70.66353, loss_verb_ce: 0.56467/0.86272, loss_sub_bbox: 0.35263/0.35200, loss_obj_bbox: 0.35916/0.35691, loss_sub_giou: 0.42153/0.59785, loss_obj_giou: 0.45009/0.90723, obj_cardinality_error: 0.50000/2.21773, loss_obj_ce_0: 0.35762/0.76930, loss_verb_ce_0: 0.74935/0.91543, loss_sub_bbox_0: 0.35500/0.35006, loss_obj_bbox_0: 0.37455/0.35410, loss_sub_giou_0: 0.56556/0.59856, loss_obj_giou_0: 0.61570/0.89719, obj_cardinality_error_0: 2.50000/2.19333, loss_obj_ce_1: 0.28055/0.71460, loss_verb_ce_1: 0.58423/0.87385, loss_sub_bbox_1: 0.32820/0.34985, loss_obj_bbox_1: 0.46671/0.35197, loss_sub_giou_1: 0.46072/0.59606, loss_obj_giou_1: 0.58456/0.89676, obj_cardinality_error_1: 1.50000/2.08893] items per batch[1] items per second[0.79] total items[3750] mini batches[  3750] memory[1606] epoch remaining[0:03:24]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1060/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.32292/17.26366, loss_obj_ce: 0.66520/0.70324, obj_class_error: 42.85714/70.64023, loss_verb_ce: 0.54331/0.86224, loss_sub_bbox: 0.39683/0.35173, loss_obj_bbox: 0.33859/0.35662, loss_sub_giou: 0.45374/0.59756, loss_obj_giou: 0.88589/0.90702, obj_cardinality_error: 0.00000/2.21423, loss_obj_ce_0: 0.60563/0.76911, loss_verb_ce_0: 0.53772/0.91506, loss_sub_bbox_0: 0.41012/0.34982, loss_obj_bbox_0: 0.27965/0.35381, loss_sub_giou_0: 0.50403/0.59827, loss_obj_giou_0: 0.98995/0.89696, obj_cardinality_error_0: 0.50000/2.19016, loss_obj_ce_1: 0.58703/0.71445, loss_verb_ce_1: 0.47591/0.87343, loss_sub_bbox_1: 0.37254/0.34957, loss_obj_bbox_1: 0.22622/0.35172, loss_sub_giou_1: 0.48353/0.59581, loss_obj_giou_1: 0.97418/0.89665, obj_cardinality_error_1: 0.00000/2.08577] items per batch[1] items per second[0.79] total items[3760] mini batches[  3760] memory[1606] epoch remaining[0:03:23]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1070/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.85729/17.26085, loss_obj_ce: 0.64510/0.70356, obj_class_error: 33.33334/70.62851, loss_verb_ce: 0.65510/0.86189, loss_sub_bbox: 0.53745/0.35157, loss_obj_bbox: 0.36160/0.35650, loss_sub_giou: 0.52488/0.59752, loss_obj_giou: 0.61599/0.90686, obj_cardinality_error: 3.50000/2.21233, loss_obj_ce_0: 0.63627/0.76915, loss_verb_ce_0: 0.72002/0.91454, loss_sub_bbox_0: 0.54880/0.34989, loss_obj_bbox_0: 0.38019/0.35372, loss_sub_giou_0: 0.58154/0.59846, loss_obj_giou_0: 0.62567/0.89698, obj_cardinality_error_0: 1.00000/2.18833, loss_obj_ce_1: 0.55404/0.71466, loss_verb_ce_1: 0.61231/0.87300, loss_sub_bbox_1: 0.55655/0.34945, loss_obj_bbox_1: 0.57292/0.35176, loss_sub_giou_1: 0.55275/0.59578, loss_obj_giou_1: 0.75243/0.89681, obj_cardinality_error_1: 2.00000/2.08422] items per batch[1] items per second[0.78] total items[3770] mini batches[  3770] memory[1606] epoch remaining[0:03:21]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1080/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.15808/17.25665, loss_obj_ce: 0.83615/0.70332, obj_class_error: 62.50000/70.59249, loss_verb_ce: 0.67810/0.86156, loss_sub_bbox: 0.30256/0.35156, loss_obj_bbox: 0.35727/0.35636, loss_sub_giou: 0.50927/0.59743, loss_obj_giou: 1.41380/0.90694, obj_cardinality_error: 0.50000/2.21111, loss_obj_ce_0: 0.93514/0.76899, loss_verb_ce_0: 0.81665/0.91439, loss_sub_bbox_0: 0.33253/0.34989, loss_obj_bbox_0: 0.32727/0.35354, loss_sub_giou_0: 0.56002/0.59828, loss_obj_giou_0: 1.39869/0.89686, obj_cardinality_error_0: 1.00000/2.18624, loss_obj_ce_1: 0.77378/0.71451, loss_verb_ce_1: 0.63473/0.87282, loss_sub_bbox_1: 0.31891/0.34937, loss_obj_bbox_1: 0.31316/0.35152, loss_sub_giou_1: 0.49120/0.59552, loss_obj_giou_1: 1.10180/0.89662, obj_cardinality_error_1: 1.50000/2.08280] items per batch[1] items per second[0.88] total items[3780] mini batches[  3780] memory[1606] epoch remaining[0:03:20]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1090/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.01514/17.24866, loss_obj_ce: 0.95433/0.70335, obj_class_error: 100.00000/70.58941, loss_verb_ce: 0.95189/0.86116, loss_sub_bbox: 0.26168/0.35134, loss_obj_bbox: 0.29223/0.35603, loss_sub_giou: 0.36253/0.59717, loss_obj_giou: 0.64954/0.90661, obj_cardinality_error: 1.00000/2.21306, loss_obj_ce_0: 0.99599/0.76913, loss_verb_ce_0: 0.79923/0.91390, loss_sub_bbox_0: 0.32898/0.34974, loss_obj_bbox_0: 0.25761/0.35321, loss_sub_giou_0: 0.44940/0.59806, loss_obj_giou_0: 0.45232/0.89636, obj_cardinality_error_0: 1.50000/2.18496, loss_obj_ce_1: 0.93712/0.71454, loss_verb_ce_1: 0.88667/0.87253, loss_sub_bbox_1: 0.23379/0.34911, loss_obj_bbox_1: 0.27831/0.35127, loss_sub_giou_1: 0.28876/0.59520, loss_obj_giou_1: 0.51805/0.89632, obj_cardinality_error_1: 2.00000/2.08483] items per batch[1] items per second[0.91] total items[3790] mini batches[  3790] memory[1606] epoch remaining[0:03:19]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1100/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.38986/17.23424, loss_obj_ce: 0.42878/0.70266, obj_class_error: 40.00000/70.54510, loss_verb_ce: 0.70459/0.86048, loss_sub_bbox: 0.40731/0.35111, loss_obj_bbox: 0.15568/0.35552, loss_sub_giou: 0.65673/0.59683, loss_obj_giou: 0.87099/0.90591, obj_cardinality_error: 2.00000/2.20961, loss_obj_ce_0: 0.37707/0.76835, loss_verb_ce_0: 0.64680/0.91309, loss_sub_bbox_0: 0.42360/0.34955, loss_obj_bbox_0: 0.22842/0.35281, loss_sub_giou_0: 0.69117/0.59778, loss_obj_giou_0: 1.06619/0.89591, obj_cardinality_error_0: 2.00000/2.18145, loss_obj_ce_1: 0.40358/0.71390, loss_verb_ce_1: 0.68930/0.87190, loss_sub_bbox_1: 0.37672/0.34878, loss_obj_bbox_1: 0.14710/0.35078, loss_sub_giou_1: 0.64181/0.59484, loss_obj_giou_1: 0.82505/0.89576, obj_cardinality_error_1: 2.00000/2.08250] items per batch[1] items per second[0.86] total items[3800] mini batches[  3800] memory[1606] epoch remaining[0:03:17]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1110/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.69102/17.22567, loss_obj_ce: 0.35717/0.70239, obj_class_error: 40.00000/70.51492, loss_verb_ce: 0.59943/0.85998, loss_sub_bbox: 0.37051/0.35088, loss_obj_bbox: 0.24854/0.35519, loss_sub_giou: 0.53276/0.59648, loss_obj_giou: 1.36918/0.90561, obj_cardinality_error: 1.00000/2.20682, loss_obj_ce_0: 0.39340/0.76802, loss_verb_ce_0: 0.58900/0.91252, loss_sub_bbox_0: 0.42269/0.34939, loss_obj_bbox_0: 0.21352/0.35257, loss_sub_giou_0: 0.52904/0.59751, loss_obj_giou_0: 0.87379/0.89590, obj_cardinality_error_0: 1.00000/2.17861, loss_obj_ce_1: 0.30705/0.71359, loss_verb_ce_1: 0.55113/0.87143, loss_sub_bbox_1: 0.41912/0.34860, loss_obj_bbox_1: 0.29133/0.35058, loss_sub_giou_1: 0.59604/0.59456, loss_obj_giou_1: 1.33921/0.89573, obj_cardinality_error_1: 0.50000/2.08005] items per batch[1] items per second[0.83] total items[3810] mini batches[  3810] memory[1606] epoch remaining[0:03:16]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1120/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.71549/17.22206, loss_obj_ce: 0.93491/0.70220, obj_class_error: 70.00000/70.48210, loss_verb_ce: 0.82916/0.85971, loss_sub_bbox: 0.28831/0.35081, loss_obj_bbox: 0.47100/0.35519, loss_sub_giou: 0.45511/0.59647, loss_obj_giou: 1.25488/0.90595, obj_cardinality_error: 1.00000/2.20615, loss_obj_ce_0: 0.75743/0.76767, loss_verb_ce_0: 0.69364/0.91214, loss_sub_bbox_0: 0.27409/0.34928, loss_obj_bbox_0: 0.38956/0.35238, loss_sub_giou_0: 0.41396/0.59755, loss_obj_giou_0: 1.09339/0.89585, obj_cardinality_error_0: 0.50000/2.17605, loss_obj_ce_1: 0.68835/0.71342, loss_verb_ce_1: 0.54648/0.87105, loss_sub_bbox_1: 0.31393/0.34849, loss_obj_bbox_1: 0.40484/0.35055, loss_sub_giou_1: 0.46996/0.59451, loss_obj_giou_1: 1.15462/0.89591, obj_cardinality_error_1: 1.00000/2.07971] items per batch[1] items per second[0.77] total items[3820] mini batches[  3820] memory[1606] epoch remaining[0:03:15]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1130/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.97936/17.21607, loss_obj_ce: 0.63850/0.70180, obj_class_error: 33.33334/70.43139, loss_verb_ce: 0.46563/0.85942, loss_sub_bbox: 0.24471/0.35052, loss_obj_bbox: 0.42575/0.35508, loss_sub_giou: 0.63470/0.59603, loss_obj_giou: 0.91044/0.90576, obj_cardinality_error: 2.00000/2.20574, loss_obj_ce_0: 0.68515/0.76725, loss_verb_ce_0: 0.52170/0.91184, loss_sub_bbox_0: 0.26335/0.34916, loss_obj_bbox_0: 0.44786/0.35229, loss_sub_giou_0: 0.60865/0.59738, loss_obj_giou_0: 1.06295/0.89580, obj_cardinality_error_0: 2.00000/2.17376, loss_obj_ce_1: 0.61732/0.71320, loss_verb_ce_1: 0.49375/0.87093, loss_sub_bbox_1: 0.24643/0.34827, loss_obj_bbox_1: 0.46339/0.35045, loss_sub_giou_1: 0.61081/0.59412, loss_obj_giou_1: 1.01992/0.89590, obj_cardinality_error_1: 2.00000/2.07833] items per batch[1] items per second[0.88] total items[3830] mini batches[  3830] memory[1606] epoch remaining[0:03:13]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1140/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.69930/17.21199, loss_obj_ce: 0.50436/0.70145, obj_class_error: 50.00000/70.41204, loss_verb_ce: 0.57263/0.85912, loss_sub_bbox: 0.46636/0.35042, loss_obj_bbox: 0.46279/0.35491, loss_sub_giou: 0.97234/0.59611, loss_obj_giou: 1.55719/0.90577, obj_cardinality_error: 0.50000/2.20365, loss_obj_ce_0: 0.66839/0.76683, loss_verb_ce_0: 0.71450/0.91161, loss_sub_bbox_0: 0.37613/0.34904, loss_obj_bbox_0: 0.52128/0.35217, loss_sub_giou_0: 0.87471/0.59748, loss_obj_giou_0: 1.64540/0.89589, obj_cardinality_error_0: 1.50000/2.17135, loss_obj_ce_1: 0.48894/0.71288, loss_verb_ce_1: 0.54388/0.87068, loss_sub_bbox_1: 0.40473/0.34816, loss_obj_bbox_1: 0.47291/0.35030, loss_sub_giou_1: 0.90708/0.59427, loss_obj_giou_1: 1.65837/0.89600, obj_cardinality_error_1: 1.00000/2.07656] items per batch[1] items per second[0.78] total items[3840] mini batches[  3840] memory[1606] epoch remaining[0:03:12]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1150/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.69785/17.20549, loss_obj_ce: 0.62193/0.70153, obj_class_error: 75.00000/70.41397, loss_verb_ce: 0.73865/0.85902, loss_sub_bbox: 0.24050/0.35019, loss_obj_bbox: 0.20683/0.35464, loss_sub_giou: 0.39162/0.59622, loss_obj_giou: 0.40857/0.90568, obj_cardinality_error: 4.00000/2.20260, loss_obj_ce_0: 0.68521/0.76652, loss_verb_ce_0: 0.74401/0.91115, loss_sub_bbox_0: 0.27819/0.34877, loss_obj_bbox_0: 0.23753/0.35188, loss_sub_giou_0: 0.42694/0.59758, loss_obj_giou_0: 0.54194/0.89571, obj_cardinality_error_0: 3.00000/2.16883, loss_obj_ce_1: 0.61797/0.71280, loss_verb_ce_1: 0.71065/0.87037, loss_sub_bbox_1: 0.27024/0.34787, loss_obj_bbox_1: 0.24843/0.34999, loss_sub_giou_1: 0.44935/0.59426, loss_obj_giou_1: 0.46341/0.89574, obj_cardinality_error_1: 3.50000/2.07506] items per batch[1] items per second[0.82] total items[3850] mini batches[  3850] memory[1606] epoch remaining[0:03:11]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1160/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.89122/17.19849, loss_obj_ce: 0.93520/0.70136, obj_class_error: 80.00000/70.39229, loss_verb_ce: 0.86963/0.85848, loss_sub_bbox: 0.38064/0.35000, loss_obj_bbox: 0.29720/0.35447, loss_sub_giou: 0.51211/0.59600, loss_obj_giou: 1.15251/0.90545, obj_cardinality_error: 1.00000/2.20039, loss_obj_ce_0: 0.77554/0.76628, loss_verb_ce_0: 0.88517/0.91065, loss_sub_bbox_0: 0.29377/0.34858, loss_obj_bbox_0: 0.36851/0.35177, loss_sub_giou_0: 0.45360/0.59736, loss_obj_giou_0: 1.22749/0.89553, obj_cardinality_error_0: 1.50000/2.16710, loss_obj_ce_1: 0.84010/0.71278, loss_verb_ce_1: 0.83474/0.87002, loss_sub_bbox_1: 0.41995/0.34767, loss_obj_bbox_1: 0.54942/0.34987, loss_sub_giou_1: 0.66514/0.59405, loss_obj_giou_1: 1.37671/0.89548, obj_cardinality_error_1: 1.00000/2.07435] items per batch[1] items per second[0.81] total items[3860] mini batches[  3860] memory[1606] epoch remaining[0:03:10]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1170/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.99140/17.19371, loss_obj_ce: 0.38419/0.70151, obj_class_error: 50.00000/70.37502, loss_verb_ce: 0.57098/0.85822, loss_sub_bbox: 0.16882/0.34989, loss_obj_bbox: 0.27412/0.35425, loss_sub_giou: 0.35550/0.59578, loss_obj_giou: 0.81684/0.90513, obj_cardinality_error: 1.50000/2.19961, loss_obj_ce_0: 0.50076/0.76631, loss_verb_ce_0: 0.87326/0.91033, loss_sub_bbox_0: 0.15761/0.34851, loss_obj_bbox_0: 0.32663/0.35160, loss_sub_giou_0: 0.28302/0.59720, loss_obj_giou_0: 1.23396/0.89523, obj_cardinality_error_0: 1.00000/2.16537, loss_obj_ce_1: 0.41103/0.71311, loss_verb_ce_1: 0.72203/0.86994, loss_sub_bbox_1: 0.16568/0.34752, loss_obj_bbox_1: 0.26490/0.34966, loss_sub_giou_1: 0.46849/0.59382, loss_obj_giou_1: 0.81068/0.89506, obj_cardinality_error_1: 1.00000/2.07519] items per batch[1] items per second[0.85] total items[3870] mini batches[  3870] memory[1606] epoch remaining[0:03:08]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1180/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.40787/17.18850, loss_obj_ce: 0.87650/0.70139, obj_class_error: 55.55556/70.36002, loss_verb_ce: 0.52612/0.85777, loss_sub_bbox: 0.34760/0.34973, loss_obj_bbox: 0.30175/0.35409, loss_sub_giou: 0.44483/0.59562, loss_obj_giou: 0.96693/0.90527, obj_cardinality_error: 1.50000/2.20129, loss_obj_ce_0: 0.95935/0.76623, loss_verb_ce_0: 0.63424/0.90995, loss_sub_bbox_0: 0.27013/0.34838, loss_obj_bbox_0: 0.28936/0.35142, loss_sub_giou_0: 0.40860/0.59714, loss_obj_giou_0: 0.93214/0.89517, obj_cardinality_error_0: 1.00000/2.16559, loss_obj_ce_1: 0.89892/0.71309, loss_verb_ce_1: 0.51658/0.86957, loss_sub_bbox_1: 0.29727/0.34737, loss_obj_bbox_1: 0.22608/0.34942, loss_sub_giou_1: 0.40573/0.59372, loss_obj_giou_1: 0.83049/0.89525, obj_cardinality_error_1: 1.50000/2.07809] items per batch[1] items per second[0.85] total items[3880] mini batches[  3880] memory[1606] epoch remaining[0:03:07]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1190/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.98695/17.18182, loss_obj_ce: 0.55177/0.70130, obj_class_error: 50.00000/70.33025, loss_verb_ce: 0.70616/0.85734, loss_sub_bbox: 0.19366/0.34955, loss_obj_bbox: 0.35409/0.35404, loss_sub_giou: 0.33207/0.59539, loss_obj_giou: 0.61093/0.90506, obj_cardinality_error: 1.50000/2.20540, loss_obj_ce_0: 0.50692/0.76616, loss_verb_ce_0: 0.76218/0.90940, loss_sub_bbox_0: 0.26521/0.34831, loss_obj_bbox_0: 0.22825/0.35124, loss_sub_giou_0: 0.36542/0.59697, loss_obj_giou_0: 0.44292/0.89449, obj_cardinality_error_0: 0.50000/2.16350, loss_obj_ce_1: 0.52624/0.71323, loss_verb_ce_1: 0.63935/0.86913, loss_sub_bbox_1: 0.16825/0.34717, loss_obj_bbox_1: 0.25416/0.34934, loss_sub_giou_1: 0.24790/0.59340, loss_obj_giou_1: 0.52836/0.89492, obj_cardinality_error_1: 2.00000/2.07892] items per batch[1] items per second[0.85] total items[3890] mini batches[  3890] memory[1606] epoch remaining[0:03:06]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1200/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.61858/17.17668, loss_obj_ce: 0.42182/0.70107, obj_class_error: 66.66667/70.30627, loss_verb_ce: 0.66087/0.85698, loss_sub_bbox: 0.39395/0.34943, loss_obj_bbox: 0.28050/0.35384, loss_sub_giou: 0.38969/0.59517, loss_obj_giou: 0.36540/0.90466, obj_cardinality_error: 3.00000/2.20782, loss_obj_ce_0: 0.42664/0.76592, loss_verb_ce_0: 0.64636/0.90908, loss_sub_bbox_0: 0.36995/0.34827, loss_obj_bbox_0: 0.38360/0.35123, loss_sub_giou_0: 0.38740/0.59682, loss_obj_giou_0: 0.43841/0.89455, obj_cardinality_error_0: 0.00000/2.16090, loss_obj_ce_1: 0.37480/0.71309, loss_verb_ce_1: 0.49836/0.86876, loss_sub_bbox_1: 0.37643/0.34710, loss_obj_bbox_1: 0.33182/0.34927, loss_sub_giou_1: 0.40913/0.59321, loss_obj_giou_1: 0.45351/0.89470, obj_cardinality_error_1: 1.00000/2.08308] items per batch[1] items per second[0.85] total items[3900] mini batches[  3900] memory[1606] epoch remaining[0:03:04]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1210/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.91870/17.16872, loss_obj_ce: 0.20415/0.70055, obj_class_error: 66.66667/70.28600, loss_verb_ce: 0.59822/0.85646, loss_sub_bbox: 0.16889/0.34928, loss_obj_bbox: 0.17003/0.35360, loss_sub_giou: 0.60158/0.59510, loss_obj_giou: 0.87431/0.90449, obj_cardinality_error: 1.50000/2.20460, loss_obj_ce_0: 0.29610/0.76544, loss_verb_ce_0: 0.70191/0.90874, loss_sub_bbox_0: 0.19936/0.34813, loss_obj_bbox_0: 0.10465/0.35092, loss_sub_giou_0: 0.60902/0.59672, loss_obj_giou_0: 0.87576/0.89428, obj_cardinality_error_0: 0.50000/2.15780, loss_obj_ce_1: 0.28014/0.71269, loss_verb_ce_1: 0.67390/0.86837, loss_sub_bbox_1: 0.18997/0.34691, loss_obj_bbox_1: 0.19350/0.34904, loss_sub_giou_1: 0.78950/0.59318, loss_obj_giou_1: 0.87405/0.89446, obj_cardinality_error_1: 4.50000/2.08146] items per batch[1] items per second[0.70] total items[3910] mini batches[  3910] memory[1606] epoch remaining[0:03:03]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1220/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.47819/17.16171, loss_obj_ce: 1.18771/0.70034, obj_class_error: 87.50000/70.23389, loss_verb_ce: 0.81089/0.85597, loss_sub_bbox: 0.40317/0.34913, loss_obj_bbox: 0.41041/0.35332, loss_sub_giou: 0.68270/0.59497, loss_obj_giou: 1.24905/0.90420, obj_cardinality_error: 1.50000/2.20446, loss_obj_ce_0: 1.28846/0.76519, loss_verb_ce_0: 0.82489/0.90837, loss_sub_bbox_0: 0.43982/0.34809, loss_obj_bbox_0: 0.34161/0.35063, loss_sub_giou_0: 0.77481/0.59674, loss_obj_giou_0: 1.02386/0.89390, obj_cardinality_error_0: 2.00000/2.15625, loss_obj_ce_1: 1.12211/0.71249, loss_verb_ce_1: 0.76574/0.86797, loss_sub_bbox_1: 0.47127/0.34680, loss_obj_bbox_1: 0.46228/0.34883, loss_sub_giou_1: 0.79103/0.59315, loss_obj_giou_1: 1.23405/0.89411, obj_cardinality_error_1: 1.50000/2.07997] items per batch[1] items per second[0.77] total items[3920] mini batches[  3920] memory[1606] epoch remaining[0:03:02]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1230/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.53040/17.15271, loss_obj_ce: 1.06894/0.69972, obj_class_error: 83.33334/70.20064, loss_verb_ce: 0.89414/0.85540, loss_sub_bbox: 0.24363/0.34887, loss_obj_bbox: 0.32549/0.35320, loss_sub_giou: 0.41072/0.59465, loss_obj_giou: 0.64318/0.90387, obj_cardinality_error: 0.50000/2.20216, loss_obj_ce_0: 0.87981/0.76455, loss_verb_ce_0: 0.72673/0.90777, loss_sub_bbox_0: 0.42369/0.34787, loss_obj_bbox_0: 0.42633/0.35046, loss_sub_giou_0: 0.65857/0.59647, loss_obj_giou_0: 0.96857/0.89357, obj_cardinality_error_0: 1.00000/2.15331, loss_obj_ce_1: 0.86813/0.71203, loss_verb_ce_1: 0.81634/0.86771, loss_sub_bbox_1: 0.39729/0.34656, loss_obj_bbox_1: 0.43001/0.34877, loss_sub_giou_1: 0.63651/0.59278, loss_obj_giou_1: 0.90545/0.89400, obj_cardinality_error_1: 1.00000/2.07799] items per batch[1] items per second[0.87] total items[3930] mini batches[  3930] memory[1606] epoch remaining[0:03:01]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1240/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.32559/17.14799, loss_obj_ce: 0.52274/0.69962, obj_class_error: 60.00000/70.18418, loss_verb_ce: 0.59345/0.85517, loss_sub_bbox: 0.26799/0.34880, loss_obj_bbox: 0.35957/0.35309, loss_sub_giou: 0.46295/0.59436, loss_obj_giou: 0.84489/0.90340, obj_cardinality_error: 0.50000/2.20406, loss_obj_ce_0: 0.59474/0.76433, loss_verb_ce_0: 0.69676/0.90754, loss_sub_bbox_0: 0.18251/0.34783, loss_obj_bbox_0: 0.27906/0.35045, loss_sub_giou_0: 0.48268/0.59634, loss_obj_giou_0: 0.83877/0.89328, obj_cardinality_error_0: 0.50000/2.14975, loss_obj_ce_1: 0.63644/0.71188, loss_verb_ce_1: 0.60383/0.86741, loss_sub_bbox_1: 0.24813/0.34652, loss_obj_bbox_1: 0.23817/0.34867, loss_sub_giou_1: 0.50514/0.59262, loss_obj_giou_1: 0.71061/0.89352, obj_cardinality_error_1: 0.50000/2.07665] items per batch[1] items per second[0.93] total items[3940] mini batches[  3940] memory[1606] epoch remaining[0:03:00]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1250/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.62099/17.14209, loss_obj_ce: 0.57193/0.69943, obj_class_error: 40.00000/70.19010, loss_verb_ce: 0.69344/0.85492, loss_sub_bbox: 0.24293/0.34861, loss_obj_bbox: 0.15229/0.35295, loss_sub_giou: 0.32535/0.59406, loss_obj_giou: 0.46628/0.90314, obj_cardinality_error: 2.00000/2.20380, loss_obj_ce_0: 0.86656/0.76403, loss_verb_ce_0: 1.07594/0.90745, loss_sub_bbox_0: 0.18676/0.34766, loss_obj_bbox_0: 0.17154/0.35034, loss_sub_giou_0: 0.22041/0.59609, loss_obj_giou_0: 0.48589/0.89303, obj_cardinality_error_0: 0.50000/2.14886, loss_obj_ce_1: 0.71269/0.71173, loss_verb_ce_1: 0.87503/0.86730, loss_sub_bbox_1: 0.22610/0.34633, loss_obj_bbox_1: 0.17509/0.34845, loss_sub_giou_1: 0.28350/0.59227, loss_obj_giou_1: 0.51279/0.89313, obj_cardinality_error_1: 1.50000/2.07835] items per batch[1] items per second[0.92] total items[3950] mini batches[  3950] memory[1606] epoch remaining[0:02:58]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1260/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.84435/17.13402, loss_obj_ce: 0.61395/0.69901, obj_class_error: 71.42857/70.15403, loss_verb_ce: 0.68394/0.85447, loss_sub_bbox: 0.30862/0.34845, loss_obj_bbox: 0.28355/0.35280, loss_sub_giou: 0.41003/0.59364, loss_obj_giou: 0.59858/0.90278, obj_cardinality_error: 1.50000/2.20530, loss_obj_ce_0: 0.77037/0.76370, loss_verb_ce_0: 0.71299/0.90700, loss_sub_bbox_0: 0.30022/0.34758, loss_obj_bbox_0: 0.32208/0.35020, loss_sub_giou_0: 0.36286/0.59579, loss_obj_giou_0: 0.57630/0.89265, obj_cardinality_error_0: 1.50000/2.14735, loss_obj_ce_1: 0.61665/0.71143, loss_verb_ce_1: 0.75018/0.86689, loss_sub_bbox_1: 0.31160/0.34615, loss_obj_bbox_1: 0.31876/0.34828, loss_sub_giou_1: 0.34477/0.59178, loss_obj_giou_1: 0.64457/0.89288, obj_cardinality_error_1: 1.50000/2.07715] items per batch[1] items per second[0.94] total items[3960] mini batches[  3960] memory[1606] epoch remaining[0:02:57]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1270/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.15552/17.12711, loss_obj_ce: 0.49953/0.69847, obj_class_error: 60.00000/70.13244, loss_verb_ce: 0.62231/0.85410, loss_sub_bbox: 0.37451/0.34835, loss_obj_bbox: 0.23347/0.35263, loss_sub_giou: 0.60066/0.59341, loss_obj_giou: 0.87517/0.90245, obj_cardinality_error: 1.00000/2.20504, loss_obj_ce_0: 0.70647/0.76322, loss_verb_ce_0: 0.81155/0.90670, loss_sub_bbox_0: 0.36907/0.34746, loss_obj_bbox_0: 0.28438/0.35003, loss_sub_giou_0: 0.51533/0.59558, loss_obj_giou_0: 0.93022/0.89255, obj_cardinality_error_0: 0.50000/2.14660, loss_obj_ce_1: 0.71163/0.71094, loss_verb_ce_1: 0.83518/0.86657, loss_sub_bbox_1: 0.29644/0.34601, loss_obj_bbox_1: 0.24125/0.34813, loss_sub_giou_1: 0.41688/0.59152, loss_obj_giou_1: 0.86376/0.89269, obj_cardinality_error_1: 4.00000/2.07997] items per batch[1] items per second[0.86] total items[3970] mini batches[  3970] memory[1606] epoch remaining[0:02:55]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1280/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.53433/17.12476, loss_obj_ce: 1.40203/0.69881, obj_class_error: 72.72727/70.13758, loss_verb_ce: 0.57212/0.85385, loss_sub_bbox: 0.21803/0.34834, loss_obj_bbox: 0.17452/0.35248, loss_sub_giou: 0.48305/0.59324, loss_obj_giou: 0.85606/0.90245, obj_cardinality_error: 3.50000/2.20465, loss_obj_ce_0: 1.36875/0.76361, loss_verb_ce_0: 0.65665/0.90637, loss_sub_bbox_0: 0.22763/0.34743, loss_obj_bbox_0: 0.17400/0.34998, loss_sub_giou_0: 0.59074/0.59544, loss_obj_giou_0: 0.85615/0.89263, obj_cardinality_error_0: 2.00000/2.14535, loss_obj_ce_1: 1.38166/0.71128, loss_verb_ce_1: 0.57779/0.86626, loss_sub_bbox_1: 0.18747/0.34596, loss_obj_bbox_1: 0.15725/0.34800, loss_sub_giou_1: 0.43912/0.59128, loss_obj_giou_1: 0.69641/0.89260, obj_cardinality_error_1: 3.00000/2.08028] items per batch[1] items per second[0.72] total items[3980] mini batches[  3980] memory[1606] epoch remaining[0:02:54]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1290/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.20090/17.11626, loss_obj_ce: 0.36757/0.69841, obj_class_error: 66.66667/70.12321, loss_verb_ce: 0.61093/0.85349, loss_sub_bbox: 0.22160/0.34811, loss_obj_bbox: 0.21012/0.35232, loss_sub_giou: 0.37320/0.59284, loss_obj_giou: 0.24564/0.90209, obj_cardinality_error: 0.50000/2.20602, loss_obj_ce_0: 0.38257/0.76332, loss_verb_ce_0: 0.66145/0.90601, loss_sub_bbox_0: 0.35832/0.34719, loss_obj_bbox_0: 0.43032/0.34987, loss_sub_giou_0: 0.44556/0.59495, loss_obj_giou_0: 0.39765/0.89237, obj_cardinality_error_0: 0.50000/2.14298, loss_obj_ce_1: 0.31205/0.71100, loss_verb_ce_1: 0.61858/0.86597, loss_sub_bbox_1: 0.20763/0.34569, loss_obj_bbox_1: 0.28614/0.34780, loss_sub_giou_1: 0.34812/0.59082, loss_obj_giou_1: 0.26130/0.89204, obj_cardinality_error_1: 0.50000/2.07970] items per batch[1] items per second[0.74] total items[3990] mini batches[  3990] memory[1606] epoch remaining[0:02:53]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1300/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 10.89692/17.10693, loss_obj_ce: 0.36286/0.69795, obj_class_error: 100.00000/70.11576, loss_verb_ce: 0.62462/0.85286, loss_sub_bbox: 0.16620/0.34798, loss_obj_bbox: 0.18412/0.35213, loss_sub_giou: 0.43026/0.59253, loss_obj_giou: 0.44999/0.90165, obj_cardinality_error: 1.00000/2.20363, loss_obj_ce_0: 0.44908/0.76295, loss_verb_ce_0: 0.66647/0.90557, loss_sub_bbox_0: 0.21580/0.34704, loss_obj_bbox_0: 0.27547/0.34970, loss_sub_giou_0: 0.46879/0.59466, loss_obj_giou_0: 0.55077/0.89205, obj_cardinality_error_0: 0.50000/2.14050, loss_obj_ce_1: 0.41715/0.71061, loss_verb_ce_1: 0.66074/0.86548, loss_sub_bbox_1: 0.15789/0.34550, loss_obj_bbox_1: 0.23348/0.34756, loss_sub_giou_1: 0.33098/0.59049, loss_obj_giou_1: 0.45100/0.89145, obj_cardinality_error_1: 1.00000/2.07737] items per batch[1] items per second[0.77] total items[4000] mini batches[  4000] memory[1606] epoch remaining[0:02:52]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1310/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.22032/17.10260, loss_obj_ce: 0.97148/0.69770, obj_class_error: 71.42857/70.09672, loss_verb_ce: 0.70344/0.85242, loss_sub_bbox: 0.23591/0.34778, loss_obj_bbox: 0.27109/0.35197, loss_sub_giou: 0.81205/0.59236, loss_obj_giou: 1.18573/0.90174, obj_cardinality_error: 1.50000/2.20087, loss_obj_ce_0: 0.86412/0.76282, loss_verb_ce_0: 0.79457/0.90526, loss_sub_bbox_0: 0.41441/0.34702, loss_obj_bbox_0: 0.32212/0.34961, loss_sub_giou_0: 1.05997/0.59468, loss_obj_giou_0: 1.29050/0.89235, obj_cardinality_error_0: 2.00000/2.13915, loss_obj_ce_1: 0.96031/0.71045, loss_verb_ce_1: 0.73777/0.86511, loss_sub_bbox_1: 0.27964/0.34534, loss_obj_bbox_1: 0.23666/0.34741, loss_sub_giou_1: 0.94773/0.59042, loss_obj_giou_1: 1.25729/0.89169, obj_cardinality_error_1: 2.50000/2.07531] items per batch[1] items per second[0.87] total items[4010] mini batches[  4010] memory[1606] epoch remaining[0:02:51]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1320/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.10867/17.09662, loss_obj_ce: 0.89348/0.69731, obj_class_error: 57.14286/70.06728, loss_verb_ce: 0.59358/0.85210, loss_sub_bbox: 0.21173/0.34764, loss_obj_bbox: 0.35574/0.35174, loss_sub_giou: 0.49207/0.59218, loss_obj_giou: 0.92679/0.90161, obj_cardinality_error: 1.50000/2.20037, loss_obj_ce_0: 0.97248/0.76259, loss_verb_ce_0: 0.69613/0.90509, loss_sub_bbox_0: 0.26066/0.34689, loss_obj_bbox_0: 0.31173/0.34937, loss_sub_giou_0: 0.70154/0.59458, loss_obj_giou_0: 0.86713/0.89218, obj_cardinality_error_0: 2.50000/2.14005, loss_obj_ce_1: 1.02134/0.71015, loss_verb_ce_1: 0.68692/0.86487, loss_sub_bbox_1: 0.18822/0.34519, loss_obj_bbox_1: 0.26631/0.34719, loss_sub_giou_1: 0.47686/0.59025, loss_obj_giou_1: 0.81775/0.89158, obj_cardinality_error_1: 3.00000/2.07413] items per batch[1] items per second[0.73] total items[4020] mini batches[  4020] memory[1606] epoch remaining[0:02:50]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1330/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.96789/17.08970, loss_obj_ce: 0.68829/0.69690, obj_class_error: 50.00000/70.00756, loss_verb_ce: 0.57902/0.85146, loss_sub_bbox: 0.37512/0.34756, loss_obj_bbox: 0.26620/0.35166, loss_sub_giou: 0.61853/0.59205, loss_obj_giou: 0.84373/0.90141, obj_cardinality_error: 7.50000/2.20074, loss_obj_ce_0: 0.78945/0.76222, loss_verb_ce_0: 0.65838/0.90463, loss_sub_bbox_0: 0.43329/0.34684, loss_obj_bbox_0: 0.27371/0.34923, loss_sub_giou_0: 0.69893/0.59438, loss_obj_giou_0: 0.99862/0.89198, obj_cardinality_error_0: 1.50000/2.13883, loss_obj_ce_1: 0.73900/0.70983, loss_verb_ce_1: 0.78854/0.86434, loss_sub_bbox_1: 0.34340/0.34506, loss_obj_bbox_1: 0.26397/0.34705, loss_sub_giou_1: 0.67559/0.59007, loss_obj_giou_1: 0.97467/0.89147, obj_cardinality_error_1: 5.50000/2.07308] items per batch[1] items per second[0.80] total items[4030] mini batches[  4030] memory[1606] epoch remaining[0:02:49]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1340/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.56186/17.08138, loss_obj_ce: 0.39354/0.69625, obj_class_error: 42.85714/69.95394, loss_verb_ce: 0.40392/0.85089, loss_sub_bbox: 0.26438/0.34744, loss_obj_bbox: 0.25221/0.35146, loss_sub_giou: 0.71087/0.59191, loss_obj_giou: 0.92302/0.90091, obj_cardinality_error: 3.00000/2.20248, loss_obj_ce_0: 0.81560/0.76175, loss_verb_ce_0: 0.82146/0.90425, loss_sub_bbox_0: 0.21941/0.34675, loss_obj_bbox_0: 0.34875/0.34910, loss_sub_giou_0: 0.63757/0.59423, loss_obj_giou_0: 0.94652/0.89143, obj_cardinality_error_0: 1.00000/2.13713, loss_obj_ce_1: 0.70632/0.70929, loss_verb_ce_1: 0.69411/0.86380, loss_sub_bbox_1: 0.17772/0.34500, loss_obj_bbox_1: 0.35730/0.34697, loss_sub_giou_1: 0.46987/0.58995, loss_obj_giou_1: 1.07014/0.89095, obj_cardinality_error_1: 3.50000/2.07364] items per batch[1] items per second[0.89] total items[4040] mini batches[  4040] memory[1606] epoch remaining[0:02:47]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1350/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 19.24857/17.07297, loss_obj_ce: 1.27762/0.69577, obj_class_error: 80.00000/69.91009, loss_verb_ce: 0.67759/0.85024, loss_sub_bbox: 0.34526/0.34728, loss_obj_bbox: 0.35792/0.35126, loss_sub_giou: 0.86410/0.59184, loss_obj_giou: 1.22294/0.90077, obj_cardinality_error: 4.00000/2.20531, loss_obj_ce_0: 1.46941/0.76118, loss_verb_ce_0: 0.67929/0.90362, loss_sub_bbox_0: 0.29911/0.34670, loss_obj_bbox_0: 0.32684/0.34886, loss_sub_giou_0: 0.73987/0.59430, loss_obj_giou_0: 1.15016/0.89128, obj_cardinality_error_0: 5.00000/2.13605, loss_obj_ce_1: 1.45024/0.70878, loss_verb_ce_1: 0.67441/0.86319, loss_sub_bbox_1: 0.36321/0.34485, loss_obj_bbox_1: 0.32495/0.34675, loss_sub_giou_1: 0.84902/0.58995, loss_obj_giou_1: 1.11943/0.89080, obj_cardinality_error_1: 5.50000/2.07704] items per batch[1] items per second[0.81] total items[4050] mini batches[  4050] memory[1606] epoch remaining[0:02:46]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1360/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.64468/17.06972, loss_obj_ce: 1.04359/0.69556, obj_class_error: 83.33334/69.89512, loss_verb_ce: 0.79262/0.84977, loss_sub_bbox: 0.41764/0.34721, loss_obj_bbox: 0.48668/0.35131, loss_sub_giou: 0.93460/0.59179, loss_obj_giou: 1.11066/0.90087, obj_cardinality_error: 2.00000/2.20296, loss_obj_ce_0: 1.14770/0.76092, loss_verb_ce_0: 1.03962/0.90325, loss_sub_bbox_0: 0.28159/0.34666, loss_obj_bbox_0: 0.52750/0.34888, loss_sub_giou_0: 0.62126/0.59432, loss_obj_giou_0: 1.17785/0.89146, obj_cardinality_error_0: 1.50000/2.13424, loss_obj_ce_1: 0.98511/0.70852, loss_verb_ce_1: 0.72973/0.86273, loss_sub_bbox_1: 0.36488/0.34479, loss_obj_bbox_1: 0.54789/0.34676, loss_sub_giou_1: 0.75890/0.58993, loss_obj_giou_1: 1.17560/0.89085, obj_cardinality_error_1: 4.00000/2.07537] items per batch[1] items per second[0.84] total items[4060] mini batches[  4060] memory[1606] epoch remaining[0:02:45]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1370/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.81985/17.06529, loss_obj_ce: 0.53377/0.69539, obj_class_error: 80.00000/69.89036, loss_verb_ce: 0.76227/0.84952, loss_sub_bbox: 0.22993/0.34709, loss_obj_bbox: 0.20999/0.35122, loss_sub_giou: 0.47750/0.59157, loss_obj_giou: 0.98567/0.90085, obj_cardinality_error: 2.50000/2.20258, loss_obj_ce_0: 0.51699/0.76060, loss_verb_ce_0: 0.73650/0.90299, loss_sub_bbox_0: 0.18999/0.34653, loss_obj_bbox_0: 0.21368/0.34886, loss_sub_giou_0: 0.53847/0.59411, loss_obj_giou_0: 1.08219/0.89150, obj_cardinality_error_0: 0.50000/2.13145, loss_obj_ce_1: 0.56654/0.70832, loss_verb_ce_1: 0.74018/0.86242, loss_sub_bbox_1: 0.24683/0.34468, loss_obj_bbox_1: 0.18954/0.34665, loss_sub_giou_1: 0.56291/0.58969, loss_obj_giou_1: 0.87800/0.89080, obj_cardinality_error_1: 1.50000/2.07457] items per batch[1] items per second[0.82] total items[4070] mini batches[  4070] memory[1606] epoch remaining[0:02:43]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1380/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.98830/17.06013, loss_obj_ce: 0.33190/0.69486, obj_class_error: 50.00000/69.83694, loss_verb_ce: 0.69676/0.84877, loss_sub_bbox: 0.36080/0.34711, loss_obj_bbox: 0.35331/0.35128, loss_sub_giou: 0.51970/0.59149, loss_obj_giou: 1.27744/0.90082, obj_cardinality_error: 4.50000/2.20478, loss_obj_ce_0: 0.37225/0.76024, loss_verb_ce_0: 0.97827/0.90251, loss_sub_bbox_0: 0.27356/0.34647, loss_obj_bbox_0: 0.22285/0.34893, loss_sub_giou_0: 0.61742/0.59394, loss_obj_giou_0: 0.94746/0.89151, obj_cardinality_error_0: 1.00000/2.13174, loss_obj_ce_1: 0.37020/0.70795, loss_verb_ce_1: 0.88665/0.86181, loss_sub_bbox_1: 0.34824/0.34465, loss_obj_bbox_1: 0.36151/0.34669, loss_sub_giou_1: 0.47809/0.58950, loss_obj_giou_1: 1.14983/0.89082, obj_cardinality_error_1: 2.50000/2.07647] items per batch[1] items per second[0.95] total items[4080] mini batches[  4080] memory[1606] epoch remaining[0:02:42]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1390/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.50472/17.05527, loss_obj_ce: 0.63251/0.69442, obj_class_error: 83.33334/69.79936, loss_verb_ce: 0.85665/0.84845, loss_sub_bbox: 0.51685/0.34707, loss_obj_bbox: 0.33127/0.35132, loss_sub_giou: 0.72771/0.59137, loss_obj_giou: 0.46363/0.90050, obj_cardinality_error: 1.50000/2.20513, loss_obj_ce_0: 0.67893/0.75985, loss_verb_ce_0: 1.04801/0.90229, loss_sub_bbox_0: 0.51521/0.34639, loss_obj_bbox_0: 0.33712/0.34888, loss_sub_giou_0: 0.71913/0.59390, loss_obj_giou_0: 0.44400/0.89129, obj_cardinality_error_0: 1.00000/2.13178, loss_obj_ce_1: 0.36905/0.70755, loss_verb_ce_1: 0.63685/0.86140, loss_sub_bbox_1: 0.52631/0.34461, loss_obj_bbox_1: 0.24757/0.34662, loss_sub_giou_1: 0.78102/0.58949, loss_obj_giou_1: 0.41987/0.89040, obj_cardinality_error_1: 2.00000/2.07885] items per batch[1] items per second[0.80] total items[4090] mini batches[  4090] memory[1606] epoch remaining[0:02:41]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1400/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.49240/17.04890, loss_obj_ce: 1.23615/0.69425, obj_class_error: 72.72727/69.77067, loss_verb_ce: 0.79297/0.84790, loss_sub_bbox: 0.29192/0.34697, loss_obj_bbox: 0.38858/0.35118, loss_sub_giou: 0.51420/0.59121, loss_obj_giou: 1.12631/0.90007, obj_cardinality_error: 2.50000/2.20268, loss_obj_ce_0: 1.13705/0.75970, loss_verb_ce_0: 0.74729/0.90180, loss_sub_bbox_0: 0.28139/0.34635, loss_obj_bbox_0: 0.30420/0.34883, loss_sub_giou_0: 0.50740/0.59382, loss_obj_giou_0: 1.05977/0.89103, obj_cardinality_error_0: 2.50000/2.13207, loss_obj_ce_1: 1.15350/0.70745, loss_verb_ce_1: 0.72578/0.86097, loss_sub_bbox_1: 0.25665/0.34442, loss_obj_bbox_1: 0.33371/0.34657, loss_sub_giou_1: 0.53443/0.58923, loss_obj_giou_1: 1.05039/0.88999, obj_cardinality_error_1: 1.00000/2.07720] items per batch[1] items per second[0.77] total items[4100] mini batches[  4100] memory[1606] epoch remaining[0:02:40]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1410/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.46909/17.04304, loss_obj_ce: 0.72153/0.69368, obj_class_error: 66.66667/69.74840, loss_verb_ce: 0.77277/0.84747, loss_sub_bbox: 0.47525/0.34682, loss_obj_bbox: 0.50185/0.35107, loss_sub_giou: 0.57269/0.59103, loss_obj_giou: 1.16164/0.90015, obj_cardinality_error: 1.50000/2.20219, loss_obj_ce_0: 0.66514/0.75909, loss_verb_ce_0: 0.59333/0.90136, loss_sub_bbox_0: 0.48998/0.34627, loss_obj_bbox_0: 0.40652/0.34876, loss_sub_giou_0: 0.69570/0.59379, loss_obj_giou_0: 1.05248/0.89114, obj_cardinality_error_0: 1.50000/2.12920, loss_obj_ce_1: 0.63632/0.70688, loss_verb_ce_1: 0.54310/0.86046, loss_sub_bbox_1: 0.53759/0.34434, loss_obj_bbox_1: 0.54132/0.34649, loss_sub_giou_1: 0.63544/0.58916, loss_obj_giou_1: 1.12846/0.89013, obj_cardinality_error_1: 1.00000/2.07518] items per batch[1] items per second[0.82] total items[4110] mini batches[  4110] memory[1606] epoch remaining[0:02:38]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1420/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.68440/17.03711, loss_obj_ce: 0.48962/0.69333, obj_class_error: 50.00000/69.70596, loss_verb_ce: 0.65849/0.84694, loss_sub_bbox: 0.27073/0.34675, loss_obj_bbox: 0.36475/0.35092, loss_sub_giou: 0.56795/0.59096, loss_obj_giou: 0.66775/0.90013, obj_cardinality_error: 2.50000/2.20510, loss_obj_ce_0: 0.42525/0.75877, loss_verb_ce_0: 0.65810/0.90094, loss_sub_bbox_0: 0.35417/0.34619, loss_obj_bbox_0: 0.29779/0.34859, loss_sub_giou_0: 0.55675/0.59374, loss_obj_giou_0: 0.42631/0.89106, obj_cardinality_error_0: 2.00000/2.12828, loss_obj_ce_1: 0.36036/0.70658, loss_verb_ce_1: 0.70289/0.86013, loss_sub_bbox_1: 0.33093/0.34426, loss_obj_bbox_1: 0.36904/0.34629, loss_sub_giou_1: 0.62931/0.58910, loss_obj_giou_1: 0.55363/0.88996, obj_cardinality_error_1: 2.00000/2.07767] items per batch[1] items per second[0.84] total items[4120] mini batches[  4120] memory[1606] epoch remaining[0:02:37]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1430/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.74205/17.02922, loss_obj_ce: 0.26418/0.69271, obj_class_error: 33.33334/69.69133, loss_verb_ce: 0.58101/0.84638, loss_sub_bbox: 0.20733/0.34658, loss_obj_bbox: 0.47605/0.35072, loss_sub_giou: 0.35784/0.59081, loss_obj_giou: 1.33874/0.90002, obj_cardinality_error: 1.50000/2.20291, loss_obj_ce_0: 0.37173/0.75815, loss_verb_ce_0: 0.66423/0.90054, loss_sub_bbox_0: 0.33306/0.34612, loss_obj_bbox_0: 0.31781/0.34840, loss_sub_giou_0: 0.52564/0.59376, loss_obj_giou_0: 0.87022/0.89075, obj_cardinality_error_0: 0.50000/2.12506, loss_obj_ce_1: 0.29632/0.70596, loss_verb_ce_1: 0.62265/0.85965, loss_sub_bbox_1: 0.28090/0.34413, loss_obj_bbox_1: 0.50182/0.34609, loss_sub_giou_1: 0.51039/0.58910, loss_obj_giou_1: 1.17875/0.88974, obj_cardinality_error_1: 0.00000/2.07627] items per batch[1] items per second[0.78] total items[4130] mini batches[  4130] memory[1606] epoch remaining[0:02:36]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1440/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.79526/17.02563, loss_obj_ce: 0.25769/0.69233, obj_class_error: 66.66667/69.68504, loss_verb_ce: 0.63184/0.84614, loss_sub_bbox: 0.32679/0.34655, loss_obj_bbox: 0.20022/0.35057, loss_sub_giou: 0.35262/0.59085, loss_obj_giou: 0.53184/0.89961, obj_cardinality_error: 1.00000/2.20217, loss_obj_ce_0: 0.32136/0.75771, loss_verb_ce_0: 0.59618/0.90034, loss_sub_bbox_0: 0.35647/0.34609, loss_obj_bbox_0: 0.31776/0.34840, loss_sub_giou_0: 0.43538/0.59390, loss_obj_giou_0: 0.85898/0.89066, obj_cardinality_error_0: 1.00000/2.12391, loss_obj_ce_1: 0.27647/0.70558, loss_verb_ce_1: 0.63040/0.85956, loss_sub_bbox_1: 0.27265/0.34412, loss_obj_bbox_1: 0.18548/0.34598, loss_sub_giou_1: 0.31917/0.58922, loss_obj_giou_1: 0.57648/0.88942, obj_cardinality_error_1: 2.00000/2.07572] items per batch[1] items per second[0.84] total items[4140] mini batches[  4140] memory[1606] epoch remaining[0:02:35]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1450/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 11.99881/17.01936, loss_obj_ce: 0.45457/0.69204, obj_class_error: 75.00000/69.68238, loss_verb_ce: 0.76336/0.84573, loss_sub_bbox: 0.25460/0.34636, loss_obj_bbox: 0.21676/0.35041, loss_sub_giou: 0.33192/0.59065, loss_obj_giou: 0.64632/0.89945, obj_cardinality_error: 4.50000/2.20145, loss_obj_ce_0: 0.45342/0.75738, loss_verb_ce_0: 0.66219/0.89986, loss_sub_bbox_0: 0.27100/0.34598, loss_obj_bbox_0: 0.25556/0.34839, loss_sub_giou_0: 0.35339/0.59377, loss_obj_giou_0: 0.62688/0.89073, obj_cardinality_error_0: 4.00000/2.12325, loss_obj_ce_1: 0.37744/0.70534, loss_verb_ce_1: 0.58776/0.85913, loss_sub_bbox_1: 0.22830/0.34391, loss_obj_bbox_1: 0.24725/0.34586, loss_sub_giou_1: 0.32994/0.58900, loss_obj_giou_1: 0.71469/0.88931, obj_cardinality_error_1: 4.00000/2.07530] items per batch[1] items per second[0.83] total items[4150] mini batches[  4150] memory[1606] epoch remaining[0:02:33]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1460/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 17.00736/17.01427, loss_obj_ce: 0.39910/0.69138, obj_class_error: 100.00000/69.63759, loss_verb_ce: 0.78004/0.84516, loss_sub_bbox: 0.25497/0.34612, loss_obj_bbox: 0.48315/0.35035, loss_sub_giou: 0.78347/0.59071, loss_obj_giou: 1.23354/0.89993, obj_cardinality_error: 5.00000/2.20337, loss_obj_ce_0: 0.36706/0.75664, loss_verb_ce_0: 0.62785/0.89921, loss_sub_bbox_0: 0.32593/0.34589, loss_obj_bbox_0: 0.44437/0.34842, loss_sub_giou_0: 0.64017/0.59387, loss_obj_giou_0: 1.12664/0.89148, obj_cardinality_error_0: 1.00000/2.12308, loss_obj_ce_1: 0.41968/0.70474, loss_verb_ce_1: 0.73495/0.85863, loss_sub_bbox_1: 0.26036/0.34374, loss_obj_bbox_1: 0.51950/0.34580, loss_sub_giou_1: 0.83658/0.58915, loss_obj_giou_1: 1.19475/0.88958, obj_cardinality_error_1: 1.50000/2.07572] items per batch[1] items per second[0.82] total items[4160] mini batches[  4160] memory[1606] epoch remaining[0:02:32]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1470/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.34644/17.00881, loss_obj_ce: 0.49982/0.69117, obj_class_error: 33.33334/69.63246, loss_verb_ce: 0.88831/0.84492, loss_sub_bbox: 0.13568/0.34596, loss_obj_bbox: 0.17379/0.35022, loss_sub_giou: 0.33050/0.59061, loss_obj_giou: 0.62774/0.89944, obj_cardinality_error: 6.50000/2.20612, loss_obj_ce_0: 0.17439/0.75624, loss_verb_ce_0: 0.47180/0.89874, loss_sub_bbox_0: 0.27566/0.34578, loss_obj_bbox_0: 0.35219/0.34840, loss_sub_giou_0: 0.49709/0.59387, loss_obj_giou_0: 1.36953/0.89131, obj_cardinality_error_0: 2.00000/2.12206, loss_obj_ce_1: 0.25108/0.70448, loss_verb_ce_1: 0.47017/0.85827, loss_sub_bbox_1: 0.29201/0.34360, loss_obj_bbox_1: 0.23107/0.34574, loss_sub_giou_1: 0.48867/0.58916, loss_obj_giou_1: 0.79606/0.88944, obj_cardinality_error_1: 5.50000/2.07794] items per batch[1] items per second[0.79] total items[4170] mini batches[  4170] memory[1606] epoch remaining[0:02:31]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1480/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.49775/17.00330, loss_obj_ce: 0.85917/0.69129, obj_class_error: 80.00000/69.60957, loss_verb_ce: 1.02929/0.84456, loss_sub_bbox: 0.36119/0.34577, loss_obj_bbox: 0.27047/0.35001, loss_sub_giou: 0.71934/0.59048, loss_obj_giou: 1.08882/0.89932, obj_cardinality_error: 1.50000/2.20694, loss_obj_ce_0: 0.94498/0.75621, loss_verb_ce_0: 0.94448/0.89820, loss_sub_bbox_0: 0.30512/0.34564, loss_obj_bbox_0: 0.30360/0.34828, loss_sub_giou_0: 0.70338/0.59389, loss_obj_giou_0: 1.17402/0.89130, obj_cardinality_error_0: 4.50000/2.12201, loss_obj_ce_1: 0.81191/0.70455, loss_verb_ce_1: 0.90895/0.85785, loss_sub_bbox_1: 0.29710/0.34339, loss_obj_bbox_1: 0.28052/0.34554, loss_sub_giou_1: 0.74989/0.58906, loss_obj_giou_1: 1.13578/0.88939, obj_cardinality_error_1: 4.50000/2.08194] items per batch[1] items per second[0.79] total items[4180] mini batches[  4180] memory[1606] epoch remaining[0:02:30]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1490/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 20.10888/17.00099, loss_obj_ce: 1.02660/0.69159, obj_class_error: 75.00000/69.58923, loss_verb_ce: 0.77759/0.84427, loss_sub_bbox: 0.36925/0.34569, loss_obj_bbox: 0.46571/0.34997, loss_sub_giou: 0.83400/0.59040, loss_obj_giou: 1.20242/0.89932, obj_cardinality_error: 2.50000/2.20716, loss_obj_ce_0: 1.00244/0.75629, loss_verb_ce_0: 0.77141/0.89761, loss_sub_bbox_0: 0.30106/0.34561, loss_obj_bbox_0: 0.48356/0.34833, loss_sub_giou_0: 0.75877/0.59387, loss_obj_giou_0: 1.29905/0.89136, obj_cardinality_error_0: 3.00000/2.12399, loss_obj_ce_1: 0.94908/0.70483, loss_verb_ce_1: 0.76689/0.85743, loss_sub_bbox_1: 0.34759/0.34330, loss_obj_bbox_1: 0.49974/0.34562, loss_sub_giou_1: 0.90898/0.58896, loss_obj_giou_1: 1.32846/0.88949, obj_cardinality_error_1: 1.00000/2.08508] items per batch[1] items per second[0.84] total items[4190] mini batches[  4190] memory[1606] epoch remaining[0:02:28]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1500/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.71022/16.99266, loss_obj_ce: 0.66272/0.69130, obj_class_error: 66.66667/69.56719, loss_verb_ce: 0.63309/0.84396, loss_sub_bbox: 0.28426/0.34544, loss_obj_bbox: 0.25035/0.34978, loss_sub_giou: 0.33148/0.59000, loss_obj_giou: 0.75555/0.89906, obj_cardinality_error: 2.00000/2.20952, loss_obj_ce_0: 0.76061/0.75581, loss_verb_ce_0: 0.72574/0.89704, loss_sub_bbox_0: 0.22820/0.34543, loss_obj_bbox_0: 0.19303/0.34817, loss_sub_giou_0: 0.30180/0.59360, loss_obj_giou_0: 0.56869/0.89112, obj_cardinality_error_0: 1.00000/2.12381, loss_obj_ce_1: 0.70987/0.70447, loss_verb_ce_1: 0.62643/0.85696, loss_sub_bbox_1: 0.25630/0.34306, loss_obj_bbox_1: 0.21243/0.34549, loss_sub_giou_1: 0.33596/0.58856, loss_obj_giou_1: 0.75160/0.88937, obj_cardinality_error_1: 2.00000/2.08524] items per batch[1] items per second[0.84] total items[4200] mini batches[  4200] memory[1606] epoch remaining[0:02:27]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1510/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.49848/16.98954, loss_obj_ce: 0.30996/0.69123, obj_class_error: 50.00000/69.56296, loss_verb_ce: 0.80353/0.84367, loss_sub_bbox: 0.43810/0.34546, loss_obj_bbox: 0.41613/0.34972, loss_sub_giou: 0.60827/0.59005, loss_obj_giou: 0.64261/0.89899, obj_cardinality_error: 1.50000/2.20891, loss_obj_ce_0: 0.41750/0.75566, loss_verb_ce_0: 0.76791/0.89665, loss_sub_bbox_0: 0.36636/0.34542, loss_obj_bbox_0: 0.31003/0.34802, loss_sub_giou_0: 0.64365/0.59367, loss_obj_giou_0: 0.52456/0.89106, obj_cardinality_error_0: 1.00000/2.12173, loss_obj_ce_1: 0.33013/0.70451, loss_verb_ce_1: 0.73063/0.85676, loss_sub_bbox_1: 0.30439/0.34305, loss_obj_bbox_1: 0.30021/0.34531, loss_sub_giou_1: 0.50788/0.58855, loss_obj_giou_1: 0.57174/0.88919, obj_cardinality_error_1: 0.50000/2.08527] items per batch[1] items per second[0.78] total items[4210] mini batches[  4210] memory[1606] epoch remaining[0:02:26]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1520/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 16.52669/16.98600, loss_obj_ce: 0.81340/0.69103, obj_class_error: 87.50000/69.55947, loss_verb_ce: 0.85580/0.84351, loss_sub_bbox: 0.35007/0.34540, loss_obj_bbox: 0.37720/0.34959, loss_sub_giou: 0.33381/0.58990, loss_obj_giou: 0.62121/0.89881, obj_cardinality_error: 2.50000/2.21126, loss_obj_ce_0: 0.97629/0.75558, loss_verb_ce_0: 0.76227/0.89641, loss_sub_bbox_0: 0.43841/0.34541, loss_obj_bbox_0: 0.37066/0.34788, loss_sub_giou_0: 0.40101/0.59361, loss_obj_giou_0: 0.64103/0.89092, obj_cardinality_error_0: 2.50000/2.12073, loss_obj_ce_1: 0.87129/0.70425, loss_verb_ce_1: 0.78934/0.85654, loss_sub_bbox_1: 0.41362/0.34303, loss_obj_bbox_1: 0.39533/0.34526, loss_sub_giou_1: 0.38905/0.58841, loss_obj_giou_1: 0.80156/0.88909, obj_cardinality_error_1: 2.50000/2.08555] items per batch[1] items per second[0.84] total items[4220] mini batches[  4220] memory[1606] epoch remaining[0:02:25]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1530/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.98814/16.97753, loss_obj_ce: 0.23284/0.69046, obj_class_error: 50.00000/69.52392, loss_verb_ce: 0.61457/0.84305, loss_sub_bbox: 0.36037/0.34528, loss_obj_bbox: 0.22302/0.34930, loss_sub_giou: 0.59564/0.58960, loss_obj_giou: 0.88546/0.89835, obj_cardinality_error: 0.00000/2.21182, loss_obj_ce_0: 0.34218/0.75492, loss_verb_ce_0: 0.42057/0.89585, loss_sub_bbox_0: 0.36631/0.34541, loss_obj_bbox_0: 0.31998/0.34774, loss_sub_giou_0: 0.59987/0.59351, loss_obj_giou_0: 1.48418/0.89092, obj_cardinality_error_0: 0.50000/2.11950, loss_obj_ce_1: 0.40670/0.70365, loss_verb_ce_1: 0.83271/0.85607, loss_sub_bbox_1: 0.23075/0.34289, loss_obj_bbox_1: 0.21809/0.34506, loss_sub_giou_1: 0.54851/0.58810, loss_obj_giou_1: 0.86076/0.88888, obj_cardinality_error_1: 2.00000/2.08747] items per batch[1] items per second[0.85] total items[4230] mini batches[  4230] memory[1606] epoch remaining[0:02:24]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1540/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 13.73657/16.97089, loss_obj_ce: 0.41658/0.69021, obj_class_error: 75.00000/69.51325, loss_verb_ce: 0.77595/0.84284, loss_sub_bbox: 0.26354/0.34507, loss_obj_bbox: 0.17308/0.34910, loss_sub_giou: 0.47682/0.58939, loss_obj_giou: 0.76004/0.89801, obj_cardinality_error: 0.50000/2.21238, loss_obj_ce_0: 0.44077/0.75449, loss_verb_ce_0: 0.72416/0.89550, loss_sub_bbox_0: 0.26820/0.34526, loss_obj_bbox_0: 0.31783/0.34763, loss_sub_giou_0: 0.40584/0.59329, loss_obj_giou_0: 0.72228/0.89056, obj_cardinality_error_0: 0.50000/2.11863, loss_obj_ce_1: 0.50667/0.70334, loss_verb_ce_1: 0.88785/0.85584, loss_sub_bbox_1: 0.22731/0.34271, loss_obj_bbox_1: 0.37086/0.34493, loss_sub_giou_1: 0.36043/0.58783, loss_obj_giou_1: 0.81920/0.88866, obj_cardinality_error_1: 0.50000/2.08986] items per batch[1] items per second[0.88] total items[4240] mini batches[  4240] memory[1606] epoch remaining[0:02:22]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1550/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 14.05729/16.96422, loss_obj_ce: 0.48356/0.68991, obj_class_error: 50.00000/69.48336, loss_verb_ce: 0.48731/0.84244, loss_sub_bbox: 0.38275/0.34497, loss_obj_bbox: 0.37801/0.34891, loss_sub_giou: 0.60947/0.58923, loss_obj_giou: 0.74593/0.89762, obj_cardinality_error: 1.50000/2.21212, loss_obj_ce_0: 0.60432/0.75424, loss_verb_ce_0: 0.61587/0.89515, loss_sub_bbox_0: 0.30514/0.34517, loss_obj_bbox_0: 0.40058/0.34747, loss_sub_giou_0: 0.52322/0.59320, loss_obj_giou_0: 0.77113/0.89022, obj_cardinality_error_0: 1.00000/2.11718, loss_obj_ce_1: 0.56666/0.70308, loss_verb_ce_1: 0.56798/0.85551, loss_sub_bbox_1: 0.29939/0.34259, loss_obj_bbox_1: 0.33919/0.34476, loss_sub_giou_1: 0.46867/0.58764, loss_obj_giou_1: 0.67935/0.88820, obj_cardinality_error_1: 0.50000/2.09141] items per batch[1] items per second[0.81] total items[4250] mini batches[  4250] memory[1606] epoch remaining[0:02:21]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1560/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 18.40577/16.96250, loss_obj_ce: 0.57804/0.68973, obj_class_error: 75.00000/69.47138, loss_verb_ce: 0.97882/0.84228, loss_sub_bbox: 0.36059/0.34493, loss_obj_bbox: 0.27062/0.34884, loss_sub_giou: 0.95766/0.58923, loss_obj_giou: 1.12591/0.89756, obj_cardinality_error: 1.00000/2.20880, loss_obj_ce_0: 0.48747/0.75412, loss_verb_ce_0: 0.82262/0.89513, loss_sub_bbox_0: 0.35661/0.34509, loss_obj_bbox_0: 0.31658/0.34748, loss_sub_giou_0: 1.02762/0.59323, loss_obj_giou_0: 1.35138/0.89031, obj_cardinality_error_0: 1.50000/2.11420, loss_obj_ce_1: 0.47595/0.70296, loss_verb_ce_1: 1.02984/0.85550, loss_sub_bbox_1: 0.29843/0.34250, loss_obj_bbox_1: 0.27373/0.34473, loss_sub_giou_1: 0.97693/0.58755, loss_obj_giou_1: 1.07083/0.88809, obj_cardinality_error_1: 1.00000/2.08803] items per batch[1] items per second[0.76] total items[4260] mini batches[  4260] memory[1606] epoch remaining[0:02:20]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1570/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 12.80331/16.95670, loss_obj_ce: 0.34695/0.68957, obj_class_error: 20.00000/69.43503, loss_verb_ce: 0.54857/0.84172, loss_sub_bbox: 0.28611/0.34481, loss_obj_bbox: 0.27844/0.34871, loss_sub_giou: 0.61128/0.58934, loss_obj_giou: 1.14350/0.89746, obj_cardinality_error: 2.00000/2.20714, loss_obj_ce_0: 0.47815/0.75400, loss_verb_ce_0: 0.57685/0.89465, loss_sub_bbox_0: 0.24413/0.34502, loss_obj_bbox_0: 0.17509/0.34734, loss_sub_giou_0: 0.58585/0.59334, loss_obj_giou_0: 0.76664/0.89012, obj_cardinality_error_0: 1.00000/2.11429, loss_obj_ce_1: 0.40657/0.70274, loss_verb_ce_1: 0.54464/0.85488, loss_sub_bbox_1: 0.28435/0.34240, loss_obj_bbox_1: 0.22370/0.34458, loss_sub_giou_1: 0.59839/0.58766, loss_obj_giou_1: 0.79628/0.88783, obj_cardinality_error_1: 1.50000/2.08630] items per batch[1] items per second[0.76] total items[4270] mini batches[  4270] memory[1606] epoch remaining[0:02:19]\n",
      "INFO:trainer.default_trainer:epochs[     1] optim steps[1580/2700] learning rate[default: 1.00000e-04] train loss[total_loss: 15.13162/16.95290, loss_obj_ce: 0.39528/0.68961, obj_class_error: 50.00000/69.40559, loss_verb_ce: 0.69392/0.84137, loss_sub_bbox: 0.36887/0.34480, loss_obj_bbox: 0.20257/0.34864, loss_sub_giou: 0.73689/0.58923, loss_obj_giou: 1.03270/0.89703, obj_cardinality_error: 1.50000/2.21390, loss_obj_ce_0: 0.51156/0.75401, loss_verb_ce_0: 0.80474/0.89426, loss_sub_bbox_0: 0.31028/0.34509, loss_obj_bbox_0: 0.24763/0.34734, loss_sub_giou_0: 0.79050/0.59327, loss_obj_giou_0: 0.98424/0.88978, obj_cardinality_error_0: 1.50000/2.11449, loss_obj_ce_1: 0.47615/0.70283, loss_verb_ce_1: 0.69780/0.85461, loss_sub_bbox_1: 0.33409/0.34239, loss_obj_bbox_1: 0.18570/0.34444, loss_sub_giou_1: 0.73289/0.58751, loss_obj_giou_1: 0.95563/0.88740, obj_cardinality_error_1: 2.00000/2.09264] items per batch[1] items per second[0.79] total items[4280] mini batches[  4280] memory[1606] epoch remaining[0:02:17]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m HDecoder_Trainer \u001b[39mas\u001b[39;00m Trainer\n\u001b[1;32m      2\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(opt)\n\u001b[0;32m----> 3\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/trainer/default_trainer.py:255\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m prev_total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_params[\u001b[39m'\u001b[39m\u001b[39mtotal_batch_size\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    254\u001b[0m \u001b[39m# update\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(batch)\n\u001b[1;32m    257\u001b[0m current_optim_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_and_validate_current_optim_steps()\n\u001b[1;32m    259\u001b[0m \u001b[39m# logging\u001b[39;00m\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/trainer/default_trainer.py:149\u001b[0m, in \u001b[0;36mDefaultTrainer.train_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    145\u001b[0m total_batch_sample \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m batch_index, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_acc_batches):\n\u001b[1;32m    148\u001b[0m     loss_info, sample_size_info, extra_info \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mforward_step(\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    150\u001b[0m                                 batch,\n\u001b[1;32m    151\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad_acc_batches,\n\u001b[1;32m    152\u001b[0m                                 batch_index,\n\u001b[1;32m    153\u001b[0m                                 is_distributed\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt[\u001b[39m'\u001b[39;49m\u001b[39mworld_size\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m))\n\u001b[1;32m    154\u001b[0m     \u001b[39m# print(loss_info)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loss\u001b[39m.\u001b[39mupdate_iter(loss_info)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/notebooks/../pipeline/HDecoderPipeline.py:103\u001b[0m, in \u001b[0;36mHDecoderPipeline.forward_step\u001b[0;34m(self, trainer, batch, grad_acc_batches, grad_acc_index, is_distributed)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opt[\u001b[39m'\u001b[39m\u001b[39mFP16\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    101\u001b[0m     \u001b[39m# in FP16 mode, DeepSpeed casts the model to FP16, so the input needs to be manually casted to FP16\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     batch \u001b[39m=\u001b[39m cast_batch_to_half(batch)\n\u001b[0;32m--> 103\u001b[0m loss_dict \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mcompute_loss(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func, batch)\n\u001b[1;32m    104\u001b[0m weight_dict \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mmodels[\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcriterion\u001b[39m.\u001b[39mweight_dict\n\u001b[1;32m    106\u001b[0m loss_dict_reduced \u001b[39m=\u001b[39m reduce_dict(loss_dict)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/trainer/default_trainer.py:107\u001b[0m, in \u001b[0;36mDefaultTrainer.compute_loss\u001b[0;34m(self, forward_func, batch)\u001b[0m\n\u001b[1;32m    105\u001b[0m         loss \u001b[39m=\u001b[39m func(trainer, batch)\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n\u001b[0;32m--> 107\u001b[0m loss \u001b[39m=\u001b[39m forward(forward_func, \u001b[39mself\u001b[39;49m, batch)\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/trainer/default_trainer.py:105\u001b[0m, in \u001b[0;36mDefaultTrainer.compute_loss.<locals>.forward\u001b[0;34m(func, trainer, batch)\u001b[0m\n\u001b[1;32m    103\u001b[0m         loss \u001b[39m=\u001b[39m func(trainer, batch)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     loss \u001b[39m=\u001b[39m func(trainer, batch)\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/notebooks/../pipeline/HDecoderPipeline.py:87\u001b[0m, in \u001b[0;36mHDecoderPipeline.forward_func\u001b[0;34m(trainer, batch)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_func\u001b[39m(trainer, batch):\n\u001b[1;32m     86\u001b[0m     \u001b[39m# trainer.models['default'].train()\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mmodels[\u001b[39m'\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m'\u001b[39;49m](batch)\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/BaseModel.py:19\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 19\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/architectures/hoi_model.py:116\u001b[0m, in \u001b[0;36mCDNHOI.forward\u001b[0;34m(self, batched_inputs, mode)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batched_inputs, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvcoco\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m--> 116\u001b[0m         losses_hoi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_hoi(batched_inputs[\u001b[39m\"\u001b[39;49m\u001b[39mvcoco\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    117\u001b[0m         \u001b[39mreturn\u001b[39;00m losses_hoi\n\u001b[1;32m    118\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/architectures/hoi_model.py:134\u001b[0m, in \u001b[0;36mCDNHOI.forward_hoi\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhoid_head(features, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    133\u001b[0m targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_targets(batched_inputs)\n\u001b[0;32m--> 134\u001b[0m losses_hoi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion(out, targets)\n\u001b[1;32m    136\u001b[0m \u001b[39mdel\u001b[39;00m out\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m losses_hoi\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/modules/criterion.py:238\u001b[0m, in \u001b[0;36mSetCriterionHOI.forward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, outputs, targets):\n\u001b[1;32m    236\u001b[0m     outputs_without_aux \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m outputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maux_outputs\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m--> 238\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatcher(outputs_without_aux, targets)\n\u001b[1;32m    240\u001b[0m     num_interactions \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mlen\u001b[39m(t[\u001b[39m'\u001b[39m\u001b[39mobj_labels\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets)\n\u001b[1;32m    241\u001b[0m     num_interactions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor([num_interactions], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39m\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(outputs\u001b[39m.\u001b[39mvalues()))\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/modules/matcher.py:69\u001b[0m, in \u001b[0;36mHungarianMatcherHOI.forward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     66\u001b[0m C \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mview(bs, num_queries, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     68\u001b[0m sizes \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(v[\u001b[39m'\u001b[39m\u001b[39mobj_labels\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m targets]\n\u001b[0;32m---> 69\u001b[0m indices \u001b[39m=\u001b[39m [linear_sum_assignment(c[i]) \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(C\u001b[39m.\u001b[39msplit(sizes, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))]\n\u001b[1;32m     70\u001b[0m \u001b[39mreturn\u001b[39;00m [(torch\u001b[39m.\u001b[39mas_tensor(i, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64), torch\u001b[39m.\u001b[39mas_tensor(j, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)) \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Mygit/X-Decoder/hdecoder/modules/matcher.py:69\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m C \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mview(bs, num_queries, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     68\u001b[0m sizes \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(v[\u001b[39m'\u001b[39m\u001b[39mobj_labels\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m targets]\n\u001b[0;32m---> 69\u001b[0m indices \u001b[39m=\u001b[39m [linear_sum_assignment(c[i]) \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(C\u001b[39m.\u001b[39msplit(sizes, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))]\n\u001b[1;32m     70\u001b[0m \u001b[39mreturn\u001b[39;00m [(torch\u001b[39m.\u001b[39mas_tensor(i, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64), torch\u001b[39m.\u001b[39mas_tensor(j, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)) \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/torch/_tensor.py:972\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "trainer = Trainer(opt)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
