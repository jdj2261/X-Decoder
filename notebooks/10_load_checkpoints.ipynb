{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.arguments:Overrided DONT_LOAD_MODEL from True to False\n"
     ]
    }
   ],
   "source": [
    "from utils.arguments import load_vcoco_opt_command, load_vcoco_parser\n",
    "\n",
    "cmdline_args = load_vcoco_parser()\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco.yaml\")]\n",
    "# cmdline_args.overrides = ['WEIGHT', 'true', 'RESUME_FROM', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "cmdline_args.overrides = ['DONT_LOAD_MODEL', 'false', 'PYLEARN_MODEL', '../data/output/test/00062100/default/raw_model_states.pt'] \n",
    "\n",
    "opt = load_vcoco_opt_command(cmdline_args)\n",
    "opt[\"WEIGHT\"]\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pretrained_pth = os.path.join(opt['RESUME_FROM'])\n",
    "print(pretrained_pth)\n",
    "print(opt['base_path'])\n",
    "print(opt[\"RESUME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as ../data/output/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to ../data/output/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-----------------------------------------------\n",
      "INFO:trainer.default_trainer:Evaluating model ... \n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.136)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.191)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.218)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.245)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.273)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "      (layer_4): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): PostProcessHOI()\n",
      ")\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29]) <-> Ckpt Shape: torch.Size([29])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512]) <-> Ckpt Shape: torch.Size([29, 512])\n",
      "WARNING:utils.model:$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([81])\n",
      "WARNING:utils.model:$UNUSED$ hoid_head.obj_class_embed.bias, Ckpt Shape: torch.Size([81])\n",
      "WARNING:utils.model:$UNUSED$ hoid_head.obj_class_embed.weight, Ckpt Shape: torch.Size([81, 512])\n",
      "WARNING:utils.model:$UNUSED$ hoid_head.query_embed.weight, Ckpt Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:*UNMATCHED* criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([81])\n",
      "WARNING:utils.model:*UNMATCHED* hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([81])\n",
      "WARNING:utils.model:*UNMATCHED* hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512]) <-> Ckpt Shape: torch.Size([81, 512])\n",
      "WARNING:utils.model:*UNMATCHED* hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512]) <-> Ckpt Shape: torch.Size([101, 512])\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.27 MiB\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/4946. Dataloading: 0.0148 s/iter. Inference: 0.2098 s/iter. Eval: 0.0005 s/iter. Total: 0.2251 s/iter. ETA=0:18:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 34/4946. Dataloading: 0.0177 s/iter. Inference: 0.2066 s/iter. Eval: 0.0005 s/iter. Total: 0.2248 s/iter. ETA=0:18:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 55/4946. Dataloading: 0.0192 s/iter. Inference: 0.2119 s/iter. Eval: 0.0005 s/iter. Total: 0.2316 s/iter. ETA=0:18:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 77/4946. Dataloading: 0.0186 s/iter. Inference: 0.2118 s/iter. Eval: 0.0004 s/iter. Total: 0.2310 s/iter. ETA=0:18:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 99/4946. Dataloading: 0.0187 s/iter. Inference: 0.2114 s/iter. Eval: 0.0004 s/iter. Total: 0.2307 s/iter. ETA=0:18:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 121/4946. Dataloading: 0.0186 s/iter. Inference: 0.2109 s/iter. Eval: 0.0004 s/iter. Total: 0.2301 s/iter. ETA=0:18:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 143/4946. Dataloading: 0.0185 s/iter. Inference: 0.2117 s/iter. Eval: 0.0004 s/iter. Total: 0.2307 s/iter. ETA=0:18:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 166/4946. Dataloading: 0.0183 s/iter. Inference: 0.2110 s/iter. Eval: 0.0004 s/iter. Total: 0.2298 s/iter. ETA=0:18:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 187/4946. Dataloading: 0.0186 s/iter. Inference: 0.2117 s/iter. Eval: 0.0004 s/iter. Total: 0.2309 s/iter. ETA=0:18:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 210/4946. Dataloading: 0.0182 s/iter. Inference: 0.2109 s/iter. Eval: 0.0004 s/iter. Total: 0.2297 s/iter. ETA=0:18:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 232/4946. Dataloading: 0.0180 s/iter. Inference: 0.2115 s/iter. Eval: 0.0004 s/iter. Total: 0.2301 s/iter. ETA=0:18:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 254/4946. Dataloading: 0.0182 s/iter. Inference: 0.2118 s/iter. Eval: 0.0004 s/iter. Total: 0.2305 s/iter. ETA=0:18:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 275/4946. Dataloading: 0.0184 s/iter. Inference: 0.2125 s/iter. Eval: 0.0004 s/iter. Total: 0.2314 s/iter. ETA=0:18:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 298/4946. Dataloading: 0.0185 s/iter. Inference: 0.2121 s/iter. Eval: 0.0004 s/iter. Total: 0.2311 s/iter. ETA=0:17:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 319/4946. Dataloading: 0.0186 s/iter. Inference: 0.2125 s/iter. Eval: 0.0004 s/iter. Total: 0.2317 s/iter. ETA=0:17:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 340/4946. Dataloading: 0.0187 s/iter. Inference: 0.2130 s/iter. Eval: 0.0004 s/iter. Total: 0.2322 s/iter. ETA=0:17:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 362/4946. Dataloading: 0.0188 s/iter. Inference: 0.2130 s/iter. Eval: 0.0004 s/iter. Total: 0.2324 s/iter. ETA=0:17:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 384/4946. Dataloading: 0.0188 s/iter. Inference: 0.2133 s/iter. Eval: 0.0004 s/iter. Total: 0.2327 s/iter. ETA=0:17:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 406/4946. Dataloading: 0.0188 s/iter. Inference: 0.2133 s/iter. Eval: 0.0004 s/iter. Total: 0.2327 s/iter. ETA=0:17:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 427/4946. Dataloading: 0.0190 s/iter. Inference: 0.2139 s/iter. Eval: 0.0004 s/iter. Total: 0.2334 s/iter. ETA=0:17:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 449/4946. Dataloading: 0.0190 s/iter. Inference: 0.2138 s/iter. Eval: 0.0004 s/iter. Total: 0.2334 s/iter. ETA=0:17:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 470/4946. Dataloading: 0.0191 s/iter. Inference: 0.2140 s/iter. Eval: 0.0004 s/iter. Total: 0.2336 s/iter. ETA=0:17:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 491/4946. Dataloading: 0.0191 s/iter. Inference: 0.2143 s/iter. Eval: 0.0004 s/iter. Total: 0.2339 s/iter. ETA=0:17:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 512/4946. Dataloading: 0.0192 s/iter. Inference: 0.2145 s/iter. Eval: 0.0004 s/iter. Total: 0.2342 s/iter. ETA=0:17:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 533/4946. Dataloading: 0.0193 s/iter. Inference: 0.2148 s/iter. Eval: 0.0004 s/iter. Total: 0.2346 s/iter. ETA=0:17:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 554/4946. Dataloading: 0.0193 s/iter. Inference: 0.2151 s/iter. Eval: 0.0004 s/iter. Total: 0.2349 s/iter. ETA=0:17:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 575/4946. Dataloading: 0.0194 s/iter. Inference: 0.2153 s/iter. Eval: 0.0004 s/iter. Total: 0.2353 s/iter. ETA=0:17:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 596/4946. Dataloading: 0.0194 s/iter. Inference: 0.2156 s/iter. Eval: 0.0005 s/iter. Total: 0.2356 s/iter. ETA=0:17:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 617/4946. Dataloading: 0.0195 s/iter. Inference: 0.2158 s/iter. Eval: 0.0005 s/iter. Total: 0.2358 s/iter. ETA=0:17:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 638/4946. Dataloading: 0.0195 s/iter. Inference: 0.2158 s/iter. Eval: 0.0005 s/iter. Total: 0.2359 s/iter. ETA=0:16:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 659/4946. Dataloading: 0.0195 s/iter. Inference: 0.2160 s/iter. Eval: 0.0005 s/iter. Total: 0.2360 s/iter. ETA=0:16:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 680/4946. Dataloading: 0.0195 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2363 s/iter. ETA=0:16:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 702/4946. Dataloading: 0.0196 s/iter. Inference: 0.2161 s/iter. Eval: 0.0005 s/iter. Total: 0.2362 s/iter. ETA=0:16:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 724/4946. Dataloading: 0.0196 s/iter. Inference: 0.2160 s/iter. Eval: 0.0005 s/iter. Total: 0.2362 s/iter. ETA=0:16:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 746/4946. Dataloading: 0.0196 s/iter. Inference: 0.2159 s/iter. Eval: 0.0005 s/iter. Total: 0.2361 s/iter. ETA=0:16:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 768/4946. Dataloading: 0.0197 s/iter. Inference: 0.2159 s/iter. Eval: 0.0005 s/iter. Total: 0.2361 s/iter. ETA=0:16:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 789/4946. Dataloading: 0.0197 s/iter. Inference: 0.2161 s/iter. Eval: 0.0005 s/iter. Total: 0.2363 s/iter. ETA=0:16:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 810/4946. Dataloading: 0.0198 s/iter. Inference: 0.2161 s/iter. Eval: 0.0005 s/iter. Total: 0.2364 s/iter. ETA=0:16:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 831/4946. Dataloading: 0.0198 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2366 s/iter. ETA=0:16:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 852/4946. Dataloading: 0.0199 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2367 s/iter. ETA=0:16:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 873/4946. Dataloading: 0.0199 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2368 s/iter. ETA=0:16:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 894/4946. Dataloading: 0.0199 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2369 s/iter. ETA=0:15:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 915/4946. Dataloading: 0.0199 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:15:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 937/4946. Dataloading: 0.0199 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:15:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 958/4946. Dataloading: 0.0200 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:15:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 979/4946. Dataloading: 0.0200 s/iter. Inference: 0.2167 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:15:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1001/4946. Dataloading: 0.0200 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:15:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1022/4946. Dataloading: 0.0201 s/iter. Inference: 0.2167 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:15:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1043/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:15:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1064/4946. Dataloading: 0.0202 s/iter. Inference: 0.2167 s/iter. Eval: 0.0005 s/iter. Total: 0.2375 s/iter. ETA=0:15:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1085/4946. Dataloading: 0.0202 s/iter. Inference: 0.2168 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:15:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1107/4946. Dataloading: 0.0202 s/iter. Inference: 0.2168 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:15:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1128/4946. Dataloading: 0.0202 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2377 s/iter. ETA=0:15:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1150/4946. Dataloading: 0.0202 s/iter. Inference: 0.2168 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:15:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1171/4946. Dataloading: 0.0201 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:14:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1192/4946. Dataloading: 0.0202 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:14:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1214/4946. Dataloading: 0.0202 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:14:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1235/4946. Dataloading: 0.0202 s/iter. Inference: 0.2168 s/iter. Eval: 0.0005 s/iter. Total: 0.2377 s/iter. ETA=0:14:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1256/4946. Dataloading: 0.0202 s/iter. Inference: 0.2170 s/iter. Eval: 0.0005 s/iter. Total: 0.2378 s/iter. ETA=0:14:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1277/4946. Dataloading: 0.0203 s/iter. Inference: 0.2171 s/iter. Eval: 0.0005 s/iter. Total: 0.2380 s/iter. ETA=0:14:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1298/4946. Dataloading: 0.0203 s/iter. Inference: 0.2171 s/iter. Eval: 0.0005 s/iter. Total: 0.2381 s/iter. ETA=0:14:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1319/4946. Dataloading: 0.0203 s/iter. Inference: 0.2172 s/iter. Eval: 0.0005 s/iter. Total: 0.2381 s/iter. ETA=0:14:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1341/4946. Dataloading: 0.0204 s/iter. Inference: 0.2171 s/iter. Eval: 0.0005 s/iter. Total: 0.2381 s/iter. ETA=0:14:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1363/4946. Dataloading: 0.0204 s/iter. Inference: 0.2170 s/iter. Eval: 0.0005 s/iter. Total: 0.2379 s/iter. ETA=0:14:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1384/4946. Dataloading: 0.0204 s/iter. Inference: 0.2170 s/iter. Eval: 0.0005 s/iter. Total: 0.2380 s/iter. ETA=0:14:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1405/4946. Dataloading: 0.0204 s/iter. Inference: 0.2171 s/iter. Eval: 0.0005 s/iter. Total: 0.2380 s/iter. ETA=0:14:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1426/4946. Dataloading: 0.0204 s/iter. Inference: 0.2171 s/iter. Eval: 0.0005 s/iter. Total: 0.2381 s/iter. ETA=0:13:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1449/4946. Dataloading: 0.0204 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2379 s/iter. ETA=0:13:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1471/4946. Dataloading: 0.0204 s/iter. Inference: 0.2169 s/iter. Eval: 0.0005 s/iter. Total: 0.2378 s/iter. ETA=0:13:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1493/4946. Dataloading: 0.0204 s/iter. Inference: 0.2168 s/iter. Eval: 0.0005 s/iter. Total: 0.2377 s/iter. ETA=0:13:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1515/4946. Dataloading: 0.0204 s/iter. Inference: 0.2167 s/iter. Eval: 0.0005 s/iter. Total: 0.2377 s/iter. ETA=0:13:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1537/4946. Dataloading: 0.0204 s/iter. Inference: 0.2167 s/iter. Eval: 0.0005 s/iter. Total: 0.2377 s/iter. ETA=0:13:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1559/4946. Dataloading: 0.0204 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2376 s/iter. ETA=0:13:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1581/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2375 s/iter. ETA=0:13:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1603/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:13:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1625/4946. Dataloading: 0.0204 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:13:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1647/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:13:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1669/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:12:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1691/4946. Dataloading: 0.0203 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:12:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1712/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:12:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1733/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1754/4946. Dataloading: 0.0204 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1776/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1798/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:12:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1819/4946. Dataloading: 0.0204 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1841/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1863/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1884/4946. Dataloading: 0.0204 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:12:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1906/4946. Dataloading: 0.0203 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:12:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1928/4946. Dataloading: 0.0203 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:11:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1949/4946. Dataloading: 0.0203 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:11:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1970/4946. Dataloading: 0.0204 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:11:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1991/4946. Dataloading: 0.0204 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2013/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2035/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:11:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2056/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2077/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2098/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2119/4946. Dataloading: 0.0203 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2375 s/iter. ETA=0:11:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2141/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:11:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2163/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:11:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2185/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:10:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2207/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:10:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2228/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:10:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2250/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:10:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2273/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:10:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2294/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:10:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2317/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:10:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2338/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:10:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2360/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:10:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2382/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:10:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2404/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:10:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2426/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:09:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2448/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:09:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2469/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2491/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:09:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2512/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2533/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2555/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2577/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2599/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2620/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2642/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2664/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:09:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2687/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:08:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2709/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2369 s/iter. ETA=0:08:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2731/4946. Dataloading: 0.0202 s/iter. Inference: 0.2161 s/iter. Eval: 0.0005 s/iter. Total: 0.2369 s/iter. ETA=0:08:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2752/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:08:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2773/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:08:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2794/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:08:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2816/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:08:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2838/4946. Dataloading: 0.0202 s/iter. Inference: 0.2162 s/iter. Eval: 0.0005 s/iter. Total: 0.2370 s/iter. ETA=0:08:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2859/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:08:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2881/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:08:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2903/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:08:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2925/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:07:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2946/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:07:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2967/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2988/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3010/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3031/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3052/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3073/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3095/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3118/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2371 s/iter. ETA=0:07:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3139/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3160/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:07:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3181/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3202/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3224/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3246/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3267/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3288/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3310/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3332/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3354/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3376/4946. Dataloading: 0.0202 s/iter. Inference: 0.2163 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3397/4946. Dataloading: 0.0202 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:06:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3418/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:06:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3439/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3460/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3481/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3503/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3524/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3546/4946. Dataloading: 0.0203 s/iter. Inference: 0.2164 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3566/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:05:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3587/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:05:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3609/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3631/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:05:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3652/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:05:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3674/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:05:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3695/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3716/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3737/4946. Dataloading: 0.0203 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3759/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3781/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3803/4946. Dataloading: 0.0203 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:04:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3825/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:04:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3846/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3868/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3889/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3911/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:04:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3932/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:04:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3954/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:03:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3976/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 3998/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4019/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:03:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4041/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4062/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:03:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4083/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:03:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4105/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:03:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4128/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4150/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4172/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:03:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4193/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4215/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4237/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4258/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4279/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4301/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4322/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4344/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4366/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4388/4946. Dataloading: 0.0202 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4409/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4431/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:02:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4452/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4473/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4495/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4516/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4538/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4559/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4580/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2374 s/iter. ETA=0:01:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4602/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4624/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4645/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4666/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4688/4946. Dataloading: 0.0202 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:01:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4710/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4733/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4754/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4776/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4798/4946. Dataloading: 0.0201 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:00:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4819/4946. Dataloading: 0.0201 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4840/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4861/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4883/4946. Dataloading: 0.0201 s/iter. Inference: 0.2166 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4905/4946. Dataloading: 0.0201 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2372 s/iter. ETA=0:00:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 4926/4946. Dataloading: 0.0201 s/iter. Inference: 0.2165 s/iter. Eval: 0.0005 s/iter. Total: 0.2373 s/iter. ETA=0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "               hold_obj: #GTs = 3608, AP = 0.0455\n",
      "                  stand: #GTs = 4118, AP = 0.0011\n",
      "              sit_instr: #GTs = 1916, AP = 0.0114\n",
      "             ride_instr: #GTs = 0556, AP = 0.0000\n",
      "                   walk: #GTs = 0597, AP = 0.0000\n",
      "               look_obj: #GTs = 3347, AP = 0.0001\n",
      "              hit_instr: #GTs = 0349, AP = 0.0000\n",
      "                hit_obj: #GTs = 0349, AP = 0.0000\n",
      "                eat_obj: #GTs = 0521, AP = 0.0000\n",
      "              eat_instr: #GTs = 0521, AP = 0.0000\n",
      "             jump_instr: #GTs = 0635, AP = 0.0000\n",
      "              lay_instr: #GTs = 0387, AP = 0.0000\n",
      "    talk_on_phone_instr: #GTs = 0285, AP = 0.0000\n",
      "              carry_obj: #GTs = 0472, AP = 0.0000\n",
      "              throw_obj: #GTs = 0244, AP = 0.0000\n",
      "              catch_obj: #GTs = 0246, AP = 0.0000\n",
      "              cut_instr: #GTs = 0269, AP = 0.0000\n",
      "                cut_obj: #GTs = 0269, AP = 0.0000\n",
      "                    run: #GTs = 0687, AP = 0.0000\n",
      " work_on_computer_instr: #GTs = 0410, AP = 0.0000\n",
      "              ski_instr: #GTs = 0424, AP = 0.0000\n",
      "             surf_instr: #GTs = 0486, AP = 0.0000\n",
      "       skateboard_instr: #GTs = 0417, AP = 0.0000\n",
      "                  smile: #GTs = 1415, AP = 0.0007\n",
      "            drink_instr: #GTs = 0082, AP = 0.0000\n",
      "               kick_obj: #GTs = 0180, AP = 0.0000\n",
      "            point_instr: #GTs = 0031, AP = 0.0000\n",
      "               read_obj: #GTs = 0111, AP = 0.0000\n",
      "        snowboard_instr: #GTs = 0277, AP = 0.0000\n",
      "------------------------------------------------------------\n",
      "mAP all: 0.0020 mAP thesis: 0.0024\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.default_trainer:{'vcoco_val/vcoco': {'AP_hold_obj': 0.045454545454545456, 'AP_stand': 0.0011363636363636365, 'AP_sit_instr': 0.011363636363636364, 'AP_ride_instr': 0, 'AP_walk': 0, 'AP_look_obj': 6.879235029064769e-05, 'AP_hit_instr': 0, 'AP_hit_obj': 0, 'AP_eat_obj': 0.0, 'AP_eat_instr': 0, 'AP_jump_instr': 0, 'AP_lay_instr': 0.0, 'AP_talk_on_phone_instr': 0, 'AP_carry_obj': 0.0, 'AP_throw_obj': 0, 'AP_catch_obj': 0, 'AP_cut_instr': 0, 'AP_cut_obj': 0, 'AP_run': 0, 'AP_work_on_computer_instr': 0, 'AP_ski_instr': 0, 'AP_surf_instr': 0, 'AP_skateboard_instr': 0, 'AP_smile': 0.0006887052341597796, 'AP_drink_instr': 0, 'AP_kick_obj': 0, 'AP_point_instr': 0, 'AP_read_obj': 0, 'AP_snowboard_instr': 0, 'mAP_all': 0.0020245532082412373, 'mAP_thesis': 0.0023702905903530197}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vcoco_val/vcoco': {'AP_hold_obj': 0.045454545454545456,\n",
       "  'AP_stand': 0.0011363636363636365,\n",
       "  'AP_sit_instr': 0.011363636363636364,\n",
       "  'AP_ride_instr': 0,\n",
       "  'AP_walk': 0,\n",
       "  'AP_look_obj': 6.879235029064769e-05,\n",
       "  'AP_hit_instr': 0,\n",
       "  'AP_hit_obj': 0,\n",
       "  'AP_eat_obj': 0.0,\n",
       "  'AP_eat_instr': 0,\n",
       "  'AP_jump_instr': 0,\n",
       "  'AP_lay_instr': 0.0,\n",
       "  'AP_talk_on_phone_instr': 0,\n",
       "  'AP_carry_obj': 0.0,\n",
       "  'AP_throw_obj': 0,\n",
       "  'AP_catch_obj': 0,\n",
       "  'AP_cut_instr': 0,\n",
       "  'AP_cut_obj': 0,\n",
       "  'AP_run': 0,\n",
       "  'AP_work_on_computer_instr': 0,\n",
       "  'AP_ski_instr': 0,\n",
       "  'AP_surf_instr': 0,\n",
       "  'AP_skateboard_instr': 0,\n",
       "  'AP_smile': 0.0006887052341597796,\n",
       "  'AP_drink_instr': 0,\n",
       "  'AP_kick_obj': 0,\n",
       "  'AP_point_instr': 0,\n",
       "  'AP_read_obj': 0,\n",
       "  'AP_snowboard_instr': 0,\n",
       "  'mAP_all': 0.0020245532082412373,\n",
       "  'mAP_thesis': 0.0023702905903530197}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "if cmdline_args.user_dir:\n",
    "    absolute_user_dir = os.path.abspath(cmdline_args.user_dir)\n",
    "    opt['base_path'] = absolute_user_dir\n",
    "trainer = Trainer(opt)\n",
    "trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
