{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/djjin/Mygit/X-Decoder/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/djjin/Mygit/X-Decoder/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:wandb.docker.auth:Trying paths: ['/home/djjin/.docker/config.json', '/home/djjin/.dockercfg']\n",
      "DEBUG:wandb.docker.auth:No config file found\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WEIGHT', 'RESUME_FROM'] ['true', '../checkpoints/xdecoder_focalt_best_openseg.pt']\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Pretrain or fine-tune models for NLP tasks.')\n",
    "parser.add_argument('--command', default=\"evaluate\", help='Command: train/evaluate/train-and-evaluate')\n",
    "parser.add_argument('--conf_files', nargs='+', help='Path(s) to the config file(s).')\n",
    "parser.add_argument('--user_dir', help='Path to the user defined module for tasks (models, criteria), optimizers, and lr schedulers.')\n",
    "parser.add_argument('--config_overrides', nargs='*', help='Override parameters on config with a json style string, e.g. {\"<PARAM_NAME_1>\": <PARAM_VALUE_1>, \"<PARAM_GROUP_2>.<PARAM_SUBGROUP_2>.<PARAM_2>\": <PARAM_VALUE_2>}. A key with \".\" updates the object in the corresponding nested dict. Remember to escape \" in command line.')\n",
    "parser.add_argument('--overrides', help='arguments that used to override the config file in cmdline', nargs=argparse.REMAINDER)\n",
    "\n",
    "cmdline_args = parser.parse_args('')\n",
    "# cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/svlp_focalt_lang.yaml\")]\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/vcoco.yaml\")]\n",
    "cmdline_args.overrides = ['WEIGHT', 'true', 'RESUME_FROM', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "\n",
    "opt = load_opt_from_config_files(cmdline_args.conf_files)\n",
    "\n",
    "keys = [cmdline_args.overrides[idx*2] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [cmdline_args.overrides[idx*2+1] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "print(keys, vals)\n",
    "vals = [val.replace('false', '').replace('False','') if len(val.replace(' ', '')) == 5 else val for val in vals]\n",
    "types = []\n",
    "for key in keys:\n",
    "    key = key.split('.')\n",
    "    ele = opt.copy()\n",
    "    while len(key) > 0:\n",
    "        ele = ele[key.pop(0)]\n",
    "    types.append(type(ele))\n",
    "\n",
    "config_dict = {x:z(y) for x,y,z in zip(keys, vals, types)}\n",
    "\n",
    "load_config_dict_to_opt(opt, config_dict)\n",
    "for key, val in cmdline_args.__dict__.items():\n",
    "    if val is not None:\n",
    "        opt[key] = val\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../checkpoints/xdecoder_focalt_best_openseg.pt\n"
     ]
    }
   ],
   "source": [
    "pretrained_pth = os.path.join(opt['RESUME_FROM'])\n",
    "print(pretrained_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_4.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_class_embed.bias, Model Shape: torch.Size([81])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.obj_class_embed.weight, Model Shape: torch.Size([81, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.query_embed.weight, Model Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29])\n",
      "WARNING:utils.model:*UNLOADED* hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512])\n",
      "WARNING:utils.model:$UNUSED$ backbone_proj, Ckpt Shape: torch.Size([768, 512])\n",
      "WARNING:utils.model:$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.caping_embed, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.class_embed, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.decoder_norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.decoder_norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.ln_final.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.positional_embedding, Ckpt Shape: torch.Size([77, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.0.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.1.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.10.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.11.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.2.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.3.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.4.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.5.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.6.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.7.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.8.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_1.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.ln_2.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_fc.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.resblocks.9.mlp.c_proj.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_encoder.token_embedding.weight, Ckpt Shape: torch.Size([49408, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.lang_proj, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.lang_encoder.logit_scale, Ckpt Shape: torch.Size([])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.level_embed.weight, Ckpt Shape: torch.Size([3, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.0.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.0.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.1.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.1.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.mask_embed.layers.2.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_embed.weight, Ckpt Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_feat.weight, Ckpt Shape: torch.Size([101, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.query_feat_caping.weight, Ckpt Shape: torch.Size([77, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.self_attn_mask, Ckpt Shape: torch.Size([1, 178, 178])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear1.bias, Ckpt Shape: torch.Size([2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear1.weight, Ckpt Shape: torch.Size([2048, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear2.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.linear2.weight, Ckpt Shape: torch.Size([512, 2048])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_ffn_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.norm.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.norm.weight, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias, Ckpt Shape: torch.Size([1536])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight, Ckpt Shape: torch.Size([1536, 512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias, Ckpt Shape: torch.Size([512])\n",
      "WARNING:utils.model:$UNUSED$ sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight, Ckpt Shape: torch.Size([512, 512])\n",
      "WARNING:utils.model:*UNMATCHED* criterion.empty_weight, Model Shape: torch.Size([81]) <-> Ckpt Shape: torch.Size([134])\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(opt, build_model(opt)).from_pretrained(pretrained_pth).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.27 MiB\n"
     ]
    }
   ],
   "source": [
    "from datasets import build_evaluator, build_eval_dataloader\n",
    "dataloaders = build_eval_dataloader(opt)\n",
    "dataset_names = opt[\"DATASETS\"][\"TEST\"]\n",
    "opt['GRADIENT_ACCUMULATE_STEP'] = int(opt.get('GRADIENT_ACCUMULATE_STEP', 1))\n",
    "opt['LR_SCHEDULER_PARAMS'] = opt.get('LR_SCHEDULER_PARAMS', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(\n",
    "    dataset_label: str,\n",
    "    is_evaluation: bool\n",
    "):\n",
    "    if is_evaluation:\n",
    "\n",
    "        dataloaders = build_eval_dataloader(opt)\n",
    "        dataloader = dataloaders[0]\n",
    "\n",
    "        # temp solution for lr scheduler\n",
    "        steps_total = len(dataloader)\n",
    "        steps_acc = opt['GRADIENT_ACCUMULATE_STEP']\n",
    "        steps_update = steps_total // steps_acc\n",
    "        opt[\"LR_SCHEDULER_PARAMS\"][\"steps_update_per_epoch\"] = steps_update\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [   0/2473]  eta: 1:07:13    time: 1.6309  data: 0.0333  max mem: 1016\n",
      "Test:  [  10/2473]  eta: 0:26:09    time: 0.6374  data: 0.0323  max mem: 1185\n",
      "Test:  [  20/2473]  eta: 0:24:29    time: 0.5473  data: 0.0318  max mem: 1185\n",
      "Test:  [  30/2473]  eta: 0:23:38    time: 0.5496  data: 0.0328  max mem: 1231\n",
      "Test:  [  40/2473]  eta: 0:22:56    time: 0.5310  data: 0.0336  max mem: 1231\n",
      "Test:  [  50/2473]  eta: 0:22:31    time: 0.5225  data: 0.0324  max mem: 1275\n",
      "Test:  [  60/2473]  eta: 0:22:37    time: 0.5562  data: 0.0324  max mem: 1275\n",
      "Test:  [  70/2473]  eta: 0:22:22    time: 0.5606  data: 0.0333  max mem: 1275\n",
      "Test:  [  80/2473]  eta: 0:21:55    time: 0.5107  data: 0.0326  max mem: 1275\n",
      "Test:  [  90/2473]  eta: 0:21:50    time: 0.5195  data: 0.0324  max mem: 1275\n",
      "Test:  [ 100/2473]  eta: 0:21:40    time: 0.5397  data: 0.0322  max mem: 1275\n",
      "Test:  [ 110/2473]  eta: 0:21:28    time: 0.5245  data: 0.0327  max mem: 1275\n",
      "Test:  [ 120/2473]  eta: 0:21:32    time: 0.5565  data: 0.0336  max mem: 1275\n",
      "Test:  [ 130/2473]  eta: 0:21:18    time: 0.5467  data: 0.0329  max mem: 1275\n",
      "Test:  [ 140/2473]  eta: 0:21:10    time: 0.5164  data: 0.0342  max mem: 1275\n",
      "Test:  [ 150/2473]  eta: 0:20:57    time: 0.5139  data: 0.0341  max mem: 1275\n",
      "Test:  [ 160/2473]  eta: 0:20:56    time: 0.5351  data: 0.0322  max mem: 1275\n",
      "Test:  [ 170/2473]  eta: 0:20:52    time: 0.5614  data: 0.0327  max mem: 1275\n",
      "Test:  [ 180/2473]  eta: 0:20:46    time: 0.5433  data: 0.0333  max mem: 1275\n",
      "Test:  [ 190/2473]  eta: 0:20:38    time: 0.5327  data: 0.0329  max mem: 1275\n",
      "Test:  [ 200/2473]  eta: 0:20:32    time: 0.5313  data: 0.0325  max mem: 1275\n",
      "Test:  [ 210/2473]  eta: 0:20:26    time: 0.5365  data: 0.0324  max mem: 1275\n",
      "Test:  [ 220/2473]  eta: 0:20:20    time: 0.5348  data: 0.0332  max mem: 1275\n",
      "Test:  [ 230/2473]  eta: 0:20:15    time: 0.5388  data: 0.0335  max mem: 1275\n",
      "Test:  [ 240/2473]  eta: 0:20:14    time: 0.5705  data: 0.0344  max mem: 1372\n",
      "Test:  [ 250/2473]  eta: 0:20:08    time: 0.5644  data: 0.0345  max mem: 1372\n",
      "Test:  [ 260/2473]  eta: 0:20:05    time: 0.5535  data: 0.0329  max mem: 1372\n",
      "Test:  [ 270/2473]  eta: 0:20:04    time: 0.5853  data: 0.0335  max mem: 1372\n",
      "Test:  [ 280/2473]  eta: 0:19:58    time: 0.5691  data: 0.0344  max mem: 1372\n",
      "Test:  [ 290/2473]  eta: 0:19:51    time: 0.5373  data: 0.0342  max mem: 1372\n",
      "Test:  [ 300/2473]  eta: 0:19:49    time: 0.5635  data: 0.0335  max mem: 1372\n",
      "Test:  [ 310/2473]  eta: 0:19:42    time: 0.5600  data: 0.0325  max mem: 1372\n",
      "Test:  [ 320/2473]  eta: 0:19:39    time: 0.5507  data: 0.0329  max mem: 1372\n",
      "Test:  [ 330/2473]  eta: 0:19:32    time: 0.5467  data: 0.0329  max mem: 1372\n",
      "Test:  [ 340/2473]  eta: 0:19:28    time: 0.5466  data: 0.0336  max mem: 1372\n",
      "Test:  [ 350/2473]  eta: 0:19:18    time: 0.5292  data: 0.0336  max mem: 1372\n",
      "Test:  [ 360/2473]  eta: 0:19:13    time: 0.5162  data: 0.0334  max mem: 1372\n",
      "Test:  [ 370/2473]  eta: 0:19:05    time: 0.5254  data: 0.0329  max mem: 1372\n",
      "Test:  [ 380/2473]  eta: 0:19:00    time: 0.5300  data: 0.0318  max mem: 1372\n",
      "Test:  [ 390/2473]  eta: 0:18:55    time: 0.5549  data: 0.0328  max mem: 1372\n",
      "Test:  [ 400/2473]  eta: 0:18:49    time: 0.5405  data: 0.0330  max mem: 1372\n",
      "Test:  [ 410/2473]  eta: 0:18:44    time: 0.5457  data: 0.0328  max mem: 1372\n",
      "Test:  [ 420/2473]  eta: 0:18:38    time: 0.5463  data: 0.0340  max mem: 1372\n",
      "Test:  [ 430/2473]  eta: 0:18:31    time: 0.5179  data: 0.0344  max mem: 1372\n",
      "Test:  [ 440/2473]  eta: 0:18:25    time: 0.5192  data: 0.0335  max mem: 1372\n",
      "Test:  [ 450/2473]  eta: 0:18:21    time: 0.5525  data: 0.0327  max mem: 1372\n",
      "Test:  [ 460/2473]  eta: 0:18:14    time: 0.5476  data: 0.0328  max mem: 1372\n",
      "Test:  [ 470/2473]  eta: 0:18:10    time: 0.5503  data: 0.0337  max mem: 1372\n",
      "Test:  [ 480/2473]  eta: 0:18:03    time: 0.5422  data: 0.0327  max mem: 1372\n",
      "Test:  [ 490/2473]  eta: 0:17:59    time: 0.5406  data: 0.0317  max mem: 1372\n",
      "Test:  [ 500/2473]  eta: 0:17:53    time: 0.5461  data: 0.0325  max mem: 1372\n",
      "Test:  [ 510/2473]  eta: 0:17:47    time: 0.5289  data: 0.0327  max mem: 1372\n",
      "Test:  [ 520/2473]  eta: 0:17:42    time: 0.5499  data: 0.0321  max mem: 1372\n",
      "Test:  [ 530/2473]  eta: 0:17:39    time: 0.5831  data: 0.0333  max mem: 1372\n",
      "Test:  [ 540/2473]  eta: 0:17:32    time: 0.5585  data: 0.0339  max mem: 1372\n",
      "Test:  [ 550/2473]  eta: 0:17:26    time: 0.5179  data: 0.0339  max mem: 1372\n",
      "Test:  [ 560/2473]  eta: 0:17:21    time: 0.5440  data: 0.0348  max mem: 1372\n",
      "Test:  [ 570/2473]  eta: 0:17:15    time: 0.5318  data: 0.0342  max mem: 1372\n",
      "Test:  [ 580/2473]  eta: 0:17:09    time: 0.5225  data: 0.0335  max mem: 1372\n",
      "Test:  [ 590/2473]  eta: 0:17:04    time: 0.5412  data: 0.0323  max mem: 1372\n",
      "Test:  [ 600/2473]  eta: 0:16:59    time: 0.5521  data: 0.0331  max mem: 1372\n",
      "Test:  [ 610/2473]  eta: 0:16:53    time: 0.5553  data: 0.0339  max mem: 1372\n",
      "Test:  [ 620/2473]  eta: 0:16:48    time: 0.5435  data: 0.0330  max mem: 1372\n",
      "Test:  [ 630/2473]  eta: 0:16:44    time: 0.5695  data: 0.0333  max mem: 1372\n",
      "Test:  [ 640/2473]  eta: 0:16:41    time: 0.6154  data: 0.0332  max mem: 1372\n",
      "Test:  [ 650/2473]  eta: 0:16:35    time: 0.5845  data: 0.0329  max mem: 1372\n",
      "Test:  [ 660/2473]  eta: 0:16:29    time: 0.5331  data: 0.0326  max mem: 1372\n",
      "Test:  [ 670/2473]  eta: 0:16:23    time: 0.5261  data: 0.0345  max mem: 1372\n",
      "Test:  [ 680/2473]  eta: 0:16:16    time: 0.4976  data: 0.0401  max mem: 1372\n",
      "Test:  [ 690/2473]  eta: 0:16:09    time: 0.4866  data: 0.0398  max mem: 1372\n",
      "Test:  [ 700/2473]  eta: 0:16:05    time: 0.5468  data: 0.0349  max mem: 1372\n",
      "Test:  [ 710/2473]  eta: 0:15:58    time: 0.5416  data: 0.0333  max mem: 1372\n",
      "Test:  [ 720/2473]  eta: 0:15:51    time: 0.4859  data: 0.0321  max mem: 1372\n",
      "Test:  [ 730/2473]  eta: 0:15:46    time: 0.5119  data: 0.0317  max mem: 1372\n",
      "Test:  [ 740/2473]  eta: 0:15:40    time: 0.5400  data: 0.0320  max mem: 1372\n",
      "Test:  [ 750/2473]  eta: 0:15:35    time: 0.5487  data: 0.0329  max mem: 1372\n",
      "Test:  [ 760/2473]  eta: 0:15:29    time: 0.5278  data: 0.0331  max mem: 1372\n",
      "Test:  [ 770/2473]  eta: 0:15:24    time: 0.5328  data: 0.0320  max mem: 1372\n",
      "Test:  [ 780/2473]  eta: 0:15:18    time: 0.5515  data: 0.0315  max mem: 1372\n",
      "Test:  [ 790/2473]  eta: 0:15:13    time: 0.5385  data: 0.0315  max mem: 1372\n",
      "Test:  [ 800/2473]  eta: 0:15:07    time: 0.5388  data: 0.0330  max mem: 1372\n",
      "Test:  [ 810/2473]  eta: 0:15:02    time: 0.5285  data: 0.0337  max mem: 1372\n",
      "Test:  [ 820/2473]  eta: 0:14:55    time: 0.5077  data: 0.0322  max mem: 1372\n",
      "Test:  [ 830/2473]  eta: 0:14:50    time: 0.5170  data: 0.0321  max mem: 1372\n",
      "Test:  [ 840/2473]  eta: 0:14:45    time: 0.5536  data: 0.0333  max mem: 1372\n",
      "Test:  [ 850/2473]  eta: 0:14:40    time: 0.5597  data: 0.0332  max mem: 1372\n",
      "Test:  [ 860/2473]  eta: 0:14:34    time: 0.5551  data: 0.0328  max mem: 1372\n",
      "Test:  [ 870/2473]  eta: 0:14:29    time: 0.5586  data: 0.0324  max mem: 1372\n",
      "Test:  [ 880/2473]  eta: 0:14:23    time: 0.5312  data: 0.0343  max mem: 1372\n",
      "Test:  [ 890/2473]  eta: 0:14:18    time: 0.5282  data: 0.0349  max mem: 1372\n",
      "Test:  [ 900/2473]  eta: 0:14:12    time: 0.5322  data: 0.0330  max mem: 1372\n",
      "Test:  [ 910/2473]  eta: 0:14:08    time: 0.5594  data: 0.0545  max mem: 1372\n",
      "Test:  [ 920/2473]  eta: 0:14:03    time: 0.5923  data: 0.0667  max mem: 1372\n",
      "Test:  [ 930/2473]  eta: 0:13:57    time: 0.5512  data: 0.0509  max mem: 1372\n",
      "Test:  [ 940/2473]  eta: 0:13:52    time: 0.5439  data: 0.0381  max mem: 1372\n",
      "Test:  [ 950/2473]  eta: 0:13:46    time: 0.5333  data: 0.0313  max mem: 1372\n",
      "Test:  [ 960/2473]  eta: 0:13:40    time: 0.5214  data: 0.0321  max mem: 1372\n",
      "Test:  [ 970/2473]  eta: 0:13:35    time: 0.5451  data: 0.0336  max mem: 1372\n",
      "Test:  [ 980/2473]  eta: 0:13:30    time: 0.5568  data: 0.0329  max mem: 1372\n",
      "Test:  [ 990/2473]  eta: 0:13:24    time: 0.5438  data: 0.0328  max mem: 1372\n",
      "Test:  [1000/2473]  eta: 0:13:19    time: 0.5256  data: 0.0322  max mem: 1372\n",
      "Test:  [1010/2473]  eta: 0:13:13    time: 0.5375  data: 0.0308  max mem: 1372\n",
      "Test:  [1020/2473]  eta: 0:13:08    time: 0.5421  data: 0.0318  max mem: 1372\n",
      "Test:  [1030/2473]  eta: 0:13:02    time: 0.5396  data: 0.0327  max mem: 1372\n",
      "Test:  [1040/2473]  eta: 0:12:56    time: 0.5250  data: 0.0327  max mem: 1372\n",
      "Test:  [1050/2473]  eta: 0:12:51    time: 0.5179  data: 0.0328  max mem: 1372\n",
      "Test:  [1060/2473]  eta: 0:12:46    time: 0.5691  data: 0.0323  max mem: 1372\n",
      "Test:  [1070/2473]  eta: 0:12:41    time: 0.5680  data: 0.0317  max mem: 1372\n",
      "Test:  [1080/2473]  eta: 0:12:35    time: 0.5401  data: 0.0316  max mem: 1372\n",
      "Test:  [1090/2473]  eta: 0:12:30    time: 0.5465  data: 0.0317  max mem: 1372\n",
      "Test:  [1100/2473]  eta: 0:12:25    time: 0.5473  data: 0.0317  max mem: 1372\n",
      "Test:  [1110/2473]  eta: 0:12:19    time: 0.5528  data: 0.0318  max mem: 1372\n",
      "Test:  [1120/2473]  eta: 0:12:15    time: 0.5879  data: 0.0322  max mem: 1372\n",
      "Test:  [1130/2473]  eta: 0:12:09    time: 0.5769  data: 0.0316  max mem: 1372\n",
      "Test:  [1140/2473]  eta: 0:12:04    time: 0.5465  data: 0.0311  max mem: 1372\n",
      "Test:  [1150/2473]  eta: 0:11:59    time: 0.5578  data: 0.0320  max mem: 1372\n",
      "Test:  [1160/2473]  eta: 0:11:53    time: 0.5148  data: 0.0318  max mem: 1372\n",
      "Test:  [1170/2473]  eta: 0:11:47    time: 0.5101  data: 0.0315  max mem: 1372\n",
      "Test:  [1180/2473]  eta: 0:11:42    time: 0.5422  data: 0.0316  max mem: 1372\n",
      "Test:  [1190/2473]  eta: 0:11:36    time: 0.5416  data: 0.0328  max mem: 1372\n",
      "Test:  [1200/2473]  eta: 0:11:30    time: 0.5150  data: 0.0336  max mem: 1372\n",
      "Test:  [1210/2473]  eta: 0:11:25    time: 0.5193  data: 0.0329  max mem: 1372\n",
      "Test:  [1220/2473]  eta: 0:11:20    time: 0.5578  data: 0.0330  max mem: 1372\n",
      "Test:  [1230/2473]  eta: 0:11:14    time: 0.5374  data: 0.0325  max mem: 1372\n",
      "Test:  [1240/2473]  eta: 0:11:09    time: 0.5275  data: 0.0325  max mem: 1372\n",
      "Test:  [1250/2473]  eta: 0:11:03    time: 0.5214  data: 0.0326  max mem: 1372\n",
      "Test:  [1260/2473]  eta: 0:10:57    time: 0.5303  data: 0.0321  max mem: 1372\n",
      "Test:  [1270/2473]  eta: 0:10:52    time: 0.5334  data: 0.0323  max mem: 1372\n",
      "Test:  [1280/2473]  eta: 0:10:46    time: 0.5136  data: 0.0327  max mem: 1372\n",
      "Test:  [1290/2473]  eta: 0:10:41    time: 0.5509  data: 0.0334  max mem: 1372\n",
      "Test:  [1300/2473]  eta: 0:10:36    time: 0.5608  data: 0.0341  max mem: 1372\n",
      "Test:  [1310/2473]  eta: 0:10:30    time: 0.5556  data: 0.0349  max mem: 1372\n",
      "Test:  [1320/2473]  eta: 0:10:25    time: 0.5366  data: 0.0336  max mem: 1372\n",
      "Test:  [1330/2473]  eta: 0:10:19    time: 0.5084  data: 0.0322  max mem: 1372\n",
      "Test:  [1340/2473]  eta: 0:10:13    time: 0.5151  data: 0.0325  max mem: 1372\n",
      "Test:  [1350/2473]  eta: 0:10:08    time: 0.5256  data: 0.0325  max mem: 1372\n",
      "Test:  [1360/2473]  eta: 0:10:02    time: 0.5115  data: 0.0335  max mem: 1372\n",
      "Test:  [1370/2473]  eta: 0:09:57    time: 0.5251  data: 0.0344  max mem: 1372\n",
      "Test:  [1380/2473]  eta: 0:09:51    time: 0.5502  data: 0.0338  max mem: 1372\n",
      "Test:  [1390/2473]  eta: 0:09:46    time: 0.5476  data: 0.0328  max mem: 1372\n",
      "Test:  [1400/2473]  eta: 0:09:41    time: 0.5444  data: 0.0329  max mem: 1372\n",
      "Test:  [1410/2473]  eta: 0:09:35    time: 0.5181  data: 0.0336  max mem: 1372\n",
      "Test:  [1420/2473]  eta: 0:09:29    time: 0.5063  data: 0.0356  max mem: 1372\n",
      "Test:  [1430/2473]  eta: 0:09:24    time: 0.5331  data: 0.0370  max mem: 1372\n",
      "Test:  [1440/2473]  eta: 0:09:19    time: 0.5655  data: 0.0383  max mem: 1372\n",
      "Test:  [1450/2473]  eta: 0:09:13    time: 0.5537  data: 0.0375  max mem: 1372\n",
      "Test:  [1460/2473]  eta: 0:09:08    time: 0.5338  data: 0.0356  max mem: 1372\n",
      "Test:  [1470/2473]  eta: 0:09:03    time: 0.5656  data: 0.0357  max mem: 1372\n",
      "Test:  [1480/2473]  eta: 0:08:57    time: 0.5631  data: 0.0357  max mem: 1372\n",
      "Test:  [1490/2473]  eta: 0:08:52    time: 0.5491  data: 0.0342  max mem: 1372\n",
      "Test:  [1500/2473]  eta: 0:08:47    time: 0.5590  data: 0.0363  max mem: 1372\n",
      "Test:  [1510/2473]  eta: 0:08:41    time: 0.5395  data: 0.0398  max mem: 1372\n",
      "Test:  [1520/2473]  eta: 0:08:36    time: 0.5575  data: 0.0367  max mem: 1372\n",
      "Test:  [1530/2473]  eta: 0:08:30    time: 0.5481  data: 0.0341  max mem: 1372\n",
      "Test:  [1540/2473]  eta: 0:08:25    time: 0.5200  data: 0.0332  max mem: 1372\n",
      "Test:  [1550/2473]  eta: 0:08:19    time: 0.5210  data: 0.0327  max mem: 1372\n",
      "Test:  [1560/2473]  eta: 0:08:14    time: 0.5042  data: 0.0326  max mem: 1372\n",
      "Test:  [1570/2473]  eta: 0:08:08    time: 0.5003  data: 0.0328  max mem: 1372\n",
      "Test:  [1580/2473]  eta: 0:08:03    time: 0.5181  data: 0.0326  max mem: 1372\n",
      "Test:  [1590/2473]  eta: 0:07:57    time: 0.5189  data: 0.0322  max mem: 1372\n",
      "Test:  [1600/2473]  eta: 0:07:52    time: 0.5381  data: 0.0332  max mem: 1372\n",
      "Test:  [1610/2473]  eta: 0:07:46    time: 0.5613  data: 0.0336  max mem: 1372\n",
      "Test:  [1620/2473]  eta: 0:07:41    time: 0.5312  data: 0.0343  max mem: 1372\n",
      "Test:  [1630/2473]  eta: 0:07:36    time: 0.5740  data: 0.0357  max mem: 1372\n",
      "Test:  [1640/2473]  eta: 0:07:30    time: 0.5829  data: 0.0352  max mem: 1372\n",
      "Test:  [1650/2473]  eta: 0:07:25    time: 0.5398  data: 0.0341  max mem: 1372\n",
      "Test:  [1660/2473]  eta: 0:07:20    time: 0.5410  data: 0.0333  max mem: 1372\n",
      "Test:  [1670/2473]  eta: 0:07:14    time: 0.5158  data: 0.0321  max mem: 1372\n",
      "Test:  [1680/2473]  eta: 0:07:09    time: 0.5241  data: 0.0321  max mem: 1372\n",
      "Test:  [1690/2473]  eta: 0:07:03    time: 0.5309  data: 0.0333  max mem: 1372\n",
      "Test:  [1700/2473]  eta: 0:06:58    time: 0.5286  data: 0.0329  max mem: 1372\n",
      "Test:  [1710/2473]  eta: 0:06:52    time: 0.5482  data: 0.0330  max mem: 1372\n",
      "Test:  [1720/2473]  eta: 0:06:47    time: 0.5534  data: 0.0336  max mem: 1372\n",
      "Test:  [1730/2473]  eta: 0:06:42    time: 0.5465  data: 0.0334  max mem: 1372\n",
      "Test:  [1740/2473]  eta: 0:06:36    time: 0.5551  data: 0.0331  max mem: 1372\n",
      "Test:  [1750/2473]  eta: 0:06:31    time: 0.5468  data: 0.0337  max mem: 1372\n",
      "Test:  [1760/2473]  eta: 0:06:25    time: 0.5368  data: 0.0339  max mem: 1372\n",
      "Test:  [1770/2473]  eta: 0:06:20    time: 0.5331  data: 0.0327  max mem: 1372\n",
      "Test:  [1780/2473]  eta: 0:06:15    time: 0.5506  data: 0.0325  max mem: 1372\n",
      "Test:  [1790/2473]  eta: 0:06:09    time: 0.5609  data: 0.0328  max mem: 1372\n",
      "Test:  [1800/2473]  eta: 0:06:04    time: 0.5394  data: 0.0328  max mem: 1372\n",
      "Test:  [1810/2473]  eta: 0:05:58    time: 0.5220  data: 0.0321  max mem: 1372\n",
      "Test:  [1820/2473]  eta: 0:05:53    time: 0.5237  data: 0.0319  max mem: 1372\n",
      "Test:  [1830/2473]  eta: 0:05:48    time: 0.5582  data: 0.0330  max mem: 1372\n",
      "Test:  [1840/2473]  eta: 0:05:42    time: 0.5366  data: 0.0324  max mem: 1372\n",
      "Test:  [1850/2473]  eta: 0:05:36    time: 0.4944  data: 0.0319  max mem: 1372\n",
      "Test:  [1860/2473]  eta: 0:05:31    time: 0.5134  data: 0.0324  max mem: 1372\n",
      "Test:  [1870/2473]  eta: 0:05:26    time: 0.5485  data: 0.0330  max mem: 1372\n",
      "Test:  [1880/2473]  eta: 0:05:20    time: 0.5207  data: 0.0331  max mem: 1372\n",
      "Test:  [1890/2473]  eta: 0:05:15    time: 0.5164  data: 0.0317  max mem: 1372\n",
      "Test:  [1900/2473]  eta: 0:05:09    time: 0.5450  data: 0.0309  max mem: 1372\n",
      "Test:  [1910/2473]  eta: 0:05:04    time: 0.5456  data: 0.0318  max mem: 1372\n",
      "Test:  [1920/2473]  eta: 0:04:58    time: 0.5341  data: 0.0324  max mem: 1372\n",
      "Test:  [1930/2473]  eta: 0:04:53    time: 0.5381  data: 0.0328  max mem: 1372\n",
      "Test:  [1940/2473]  eta: 0:04:48    time: 0.5476  data: 0.0327  max mem: 1372\n",
      "Test:  [1950/2473]  eta: 0:04:42    time: 0.5486  data: 0.0323  max mem: 1372\n",
      "Test:  [1960/2473]  eta: 0:04:37    time: 0.5375  data: 0.0313  max mem: 1372\n",
      "Test:  [1970/2473]  eta: 0:04:31    time: 0.5366  data: 0.0307  max mem: 1372\n",
      "Test:  [1980/2473]  eta: 0:04:26    time: 0.5564  data: 0.0316  max mem: 1372\n",
      "Test:  [1990/2473]  eta: 0:04:21    time: 0.5388  data: 0.0322  max mem: 1372\n",
      "Test:  [2000/2473]  eta: 0:04:15    time: 0.5368  data: 0.0320  max mem: 1372\n",
      "Test:  [2010/2473]  eta: 0:04:10    time: 0.5535  data: 0.0403  max mem: 1372\n",
      "Test:  [2020/2473]  eta: 0:04:04    time: 0.5499  data: 0.0407  max mem: 1372\n",
      "Test:  [2030/2473]  eta: 0:03:59    time: 0.5206  data: 0.0328  max mem: 1372\n",
      "Test:  [2040/2473]  eta: 0:03:54    time: 0.5174  data: 0.0341  max mem: 1372\n",
      "Test:  [2050/2473]  eta: 0:03:48    time: 0.5409  data: 0.0338  max mem: 1372\n",
      "Test:  [2060/2473]  eta: 0:03:43    time: 0.5497  data: 0.0313  max mem: 1372\n",
      "Test:  [2070/2473]  eta: 0:03:37    time: 0.5544  data: 0.0306  max mem: 1372\n",
      "Test:  [2080/2473]  eta: 0:03:32    time: 0.5277  data: 0.0316  max mem: 1372\n",
      "Test:  [2090/2473]  eta: 0:03:27    time: 0.5254  data: 0.0330  max mem: 1372\n",
      "Test:  [2100/2473]  eta: 0:03:21    time: 0.5564  data: 0.0342  max mem: 1372\n",
      "Test:  [2110/2473]  eta: 0:03:16    time: 0.5316  data: 0.0328  max mem: 1372\n",
      "Test:  [2120/2473]  eta: 0:03:10    time: 0.5384  data: 0.0323  max mem: 1372\n",
      "Test:  [2130/2473]  eta: 0:03:05    time: 0.5663  data: 0.0328  max mem: 1372\n",
      "Test:  [2140/2473]  eta: 0:02:59    time: 0.5318  data: 0.0321  max mem: 1372\n",
      "Test:  [2150/2473]  eta: 0:02:54    time: 0.5196  data: 0.0323  max mem: 1372\n",
      "Test:  [2160/2473]  eta: 0:02:49    time: 0.5683  data: 0.0320  max mem: 1372\n",
      "Test:  [2170/2473]  eta: 0:02:43    time: 0.5630  data: 0.0313  max mem: 1372\n",
      "Test:  [2180/2473]  eta: 0:02:38    time: 0.5234  data: 0.0313  max mem: 1372\n",
      "Test:  [2190/2473]  eta: 0:02:32    time: 0.5298  data: 0.0309  max mem: 1372\n",
      "Test:  [2200/2473]  eta: 0:02:27    time: 0.5406  data: 0.0324  max mem: 1372\n",
      "Test:  [2210/2473]  eta: 0:02:22    time: 0.5497  data: 0.0326  max mem: 1372\n",
      "Test:  [2220/2473]  eta: 0:02:16    time: 0.5680  data: 0.0319  max mem: 1372\n",
      "Test:  [2230/2473]  eta: 0:02:11    time: 0.5805  data: 0.0326  max mem: 1372\n",
      "Test:  [2240/2473]  eta: 0:02:06    time: 0.5565  data: 0.0323  max mem: 1372\n",
      "Test:  [2250/2473]  eta: 0:02:00    time: 0.5444  data: 0.0315  max mem: 1372\n",
      "Test:  [2260/2473]  eta: 0:01:55    time: 0.5328  data: 0.0312  max mem: 1372\n",
      "Test:  [2270/2473]  eta: 0:01:49    time: 0.5047  data: 0.0321  max mem: 1372\n",
      "Test:  [2280/2473]  eta: 0:01:44    time: 0.4944  data: 0.0325  max mem: 1372\n",
      "Test:  [2290/2473]  eta: 0:01:38    time: 0.4960  data: 0.0317  max mem: 1372\n",
      "Test:  [2300/2473]  eta: 0:01:33    time: 0.5446  data: 0.0311  max mem: 1372\n",
      "Test:  [2310/2473]  eta: 0:01:28    time: 0.5755  data: 0.0312  max mem: 1372\n",
      "Test:  [2320/2473]  eta: 0:01:22    time: 0.5419  data: 0.0314  max mem: 1372\n",
      "Test:  [2330/2473]  eta: 0:01:17    time: 0.5357  data: 0.0315  max mem: 1372\n",
      "Test:  [2340/2473]  eta: 0:01:11    time: 0.5528  data: 0.0319  max mem: 1372\n",
      "Test:  [2350/2473]  eta: 0:01:06    time: 0.5423  data: 0.0319  max mem: 1372\n",
      "Test:  [2360/2473]  eta: 0:01:01    time: 0.5467  data: 0.0312  max mem: 1372\n",
      "Test:  [2370/2473]  eta: 0:00:55    time: 0.5402  data: 0.0307  max mem: 1372\n",
      "Test:  [2380/2473]  eta: 0:00:50    time: 0.5348  data: 0.0309  max mem: 1372\n",
      "Test:  [2390/2473]  eta: 0:00:44    time: 0.5758  data: 0.0317  max mem: 1372\n",
      "Test:  [2400/2473]  eta: 0:00:39    time: 0.5670  data: 0.0311  max mem: 1372\n",
      "Test:  [2410/2473]  eta: 0:00:34    time: 0.5343  data: 0.0315  max mem: 1372\n",
      "Test:  [2420/2473]  eta: 0:00:28    time: 0.5524  data: 0.0325  max mem: 1372\n",
      "Test:  [2430/2473]  eta: 0:00:23    time: 0.5619  data: 0.0321  max mem: 1372\n",
      "Test:  [2440/2473]  eta: 0:00:17    time: 0.5294  data: 0.0312  max mem: 1372\n",
      "Test:  [2450/2473]  eta: 0:00:12    time: 0.5212  data: 0.0308  max mem: 1372\n",
      "Test:  [2460/2473]  eta: 0:00:07    time: 0.5467  data: 0.0312  max mem: 1372\n",
      "Test:  [2470/2473]  eta: 0:00:01    time: 0.5571  data: 0.0316  max mem: 1372\n",
      "Test:  [2472/2473]  eta: 0:00:00    time: 0.5533  data: 0.0317  max mem: 1372\n",
      "Test: Total time: 0:22:18 (0.5411 s / it)\n",
      "------------------------------------------------------------\n",
      "               hold_obj: #GTs = 3608, AP = 0.0000\n",
      "                  stand: #GTs = 4118, AP = 0.0002\n",
      "              sit_instr: #GTs = 1916, AP = 0.0000\n",
      "             ride_instr: #GTs = 0556, AP = 0.0000\n",
      "                   walk: #GTs = 0597, AP = 0.0000\n",
      "               look_obj: #GTs = 3347, AP = 0.0000\n",
      "              hit_instr: #GTs = 0349, AP = 0.0000\n",
      "                hit_obj: #GTs = 0349, AP = 0.0000\n",
      "                eat_obj: #GTs = 0521, AP = 0.0000\n",
      "              eat_instr: #GTs = 0521, AP = 0.0000\n",
      "             jump_instr: #GTs = 0635, AP = 0.0000\n",
      "              lay_instr: #GTs = 0387, AP = 0.0000\n",
      "    talk_on_phone_instr: #GTs = 0285, AP = 0.0000\n",
      "              carry_obj: #GTs = 0472, AP = 0.0000\n",
      "              throw_obj: #GTs = 0244, AP = 0.0000\n",
      "              catch_obj: #GTs = 0246, AP = 0.0000\n",
      "              cut_instr: #GTs = 0269, AP = 0.0000\n",
      "                cut_obj: #GTs = 0269, AP = 0.0000\n",
      "                    run: #GTs = 0687, AP = 0.0000\n",
      " work_on_computer_instr: #GTs = 0410, AP = 0.0000\n",
      "              ski_instr: #GTs = 0424, AP = 0.0000\n",
      "             surf_instr: #GTs = 0486, AP = 0.0000\n",
      "       skateboard_instr: #GTs = 0417, AP = 0.0000\n",
      "                  smile: #GTs = 1415, AP = 0.0000\n",
      "            drink_instr: #GTs = 0082, AP = 0.0000\n",
      "               kick_obj: #GTs = 0180, AP = 0.0000\n",
      "            point_instr: #GTs = 0031, AP = 0.0000\n",
      "               read_obj: #GTs = 0111, AP = 0.0000\n",
      "        snowboard_instr: #GTs = 0277, AP = 0.0000\n",
      "------------------------------------------------------------\n",
      "mAP all: 0.0000 mAP thesis: 0.0000\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# init metadata\n",
    "from datasets.evaluation import VCOCOEvaluator\n",
    "from trainer.utils.misc import move_batch_to_device, cast_batch_to_half\n",
    "from datasets.utils.misc import all_gather\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from detectron2.data import MetadataCatalog\n",
    "from collections import defaultdict\n",
    "from datasets.utils.misc import all_gather, MetricLogger\n",
    "\n",
    "scores = {}\n",
    "summary = {}\n",
    "evaluator = VCOCOEvaluator(opt[\"DATASETS\"][\"TEST\"][0], \n",
    "                           correct_mat_dir=MetadataCatalog.get(opt[\"DATASETS\"][\"TEST\"][0]).correct_mat_dir,\n",
    "                           output_dir=opt[\"SAVE_DIR\"])\n",
    "\n",
    "\n",
    "eval_type = model.model.metadata.evaluator_type\n",
    "evaluator.reset()\n",
    "\n",
    "metric_logger = MetricLogger(delimiter=\"  \")\n",
    "header = 'Test:'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(metric_logger.log_every(dataloaders[0], 10, header)):\n",
    "        outputs = model(batch, mode=eval_type)\n",
    "        evaluator.process(batch, outputs)\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "map = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP_hold_obj': 0,\n",
       " 'AP_stand': 0.00018254837531945964,\n",
       " 'AP_sit_instr': 0,\n",
       " 'AP_ride_instr': 0,\n",
       " 'AP_walk': 0,\n",
       " 'AP_look_obj': 0.0,\n",
       " 'AP_hit_instr': 0,\n",
       " 'AP_hit_obj': 0,\n",
       " 'AP_eat_obj': 0,\n",
       " 'AP_eat_instr': 0.0,\n",
       " 'AP_jump_instr': 0,\n",
       " 'AP_lay_instr': 0,\n",
       " 'AP_talk_on_phone_instr': 0,\n",
       " 'AP_carry_obj': 0.0,\n",
       " 'AP_throw_obj': 0,\n",
       " 'AP_catch_obj': 0,\n",
       " 'AP_cut_instr': 0,\n",
       " 'AP_cut_obj': 0,\n",
       " 'AP_run': 0.0,\n",
       " 'AP_work_on_computer_instr': 0,\n",
       " 'AP_ski_instr': 0.0,\n",
       " 'AP_surf_instr': 0,\n",
       " 'AP_skateboard_instr': 0,\n",
       " 'AP_smile': 0,\n",
       " 'AP_drink_instr': 0,\n",
       " 'AP_kick_obj': 0,\n",
       " 'AP_point_instr': 0.0,\n",
       " 'AP_read_obj': 0,\n",
       " 'AP_snowboard_instr': 0.0,\n",
       " 'mAP_all': 6.294771562739988e-06,\n",
       " 'mAP_thesis': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CUDA_VISIBLE_DEVICES=0 python entry.py evaluate \\\n",
    "            --conf_files configs/xdecoder/segvlp_focalt_lang.yaml \\\n",
    "            --overrides \\\n",
    "            COCO.INPUT.IMAGE_SIZE 1024 \\\n",
    "            MODEL.DECODER.CAPTIONING.ENABLED True \\\n",
    "            MODEL.DECODER.RETRIEVAL.ENABLED True \\\n",
    "            MODEL.DECODER.GROUNDING.ENABLED True \\\n",
    "            COCO.TEST.BATCH_SIZE_TOTAL 1 \\\n",
    "            COCO.TRAIN.BATCH_SIZE_TOTAL 1 \\\n",
    "            COCO.TRAIN.BATCH_SIZE_PER_GPU 1 \\\n",
    "            ADE20K.TEST.BATCH_SIZE_TOTAL 1 \\\n",
    "            VLP.TEST.BATCH_SIZE_TOTAL 32 \\\n",
    "            VLP.TRAIN.BATCH_SIZE_TOTAL 32 \\\n",
    "            VLP.TRAIN.BATCH_SIZE_PER_GPU 32 \\\n",
    "            MODEL.DECODER.HIDDEN_DIM 512 \\\n",
    "            MODEL.ENCODER.CONVS_DIM 512 \\\n",
    "            MODEL.ENCODER.MASK_DIM 512 \\\n",
    "            FP16 True \\\n",
    "            DONT_LOAD_MODEL False \\\n",
    "            PYLEARN_MODEL checkpoints/xdecoder_focalt_last.pt \\\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
