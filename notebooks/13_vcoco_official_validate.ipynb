{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt\n",
    "from utils.misc import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.arguments:Overrided DONT_LOAD_MODEL from True to False\n"
     ]
    }
   ],
   "source": [
    "from utils.arguments import load_vcoco_opt_command, load_vcoco_parser\n",
    "\n",
    "cmdline_args = load_vcoco_parser()\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco.yaml\")]\n",
    "\n",
    "model_path = '../data/output/test/00205200/default/raw_model_states.pt'\n",
    "cmdline_args.overrides = ['DONT_LOAD_MODEL', 'false', 'PYLEARN_MODEL', model_path] \n",
    "\n",
    "opt = load_vcoco_opt_command(cmdline_args)\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(opt['base_path'])\n",
    "print(opt[\"RESUME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as data/output/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to data/output/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-----------------------------------------------\n",
      "INFO:trainer.default_trainer:Evaluating model ... \n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.136)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.191)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.218)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.245)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.273)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): OfficialPostProcessHOI()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using use_nms_filter:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512]) <-> Ckpt Shape: torch.Size([82, 512])\n",
      "INFO:utils.model:Loaded hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512]) <-> Ckpt Shape: torch.Size([100, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29]) <-> Ckpt Shape: torch.Size([29])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512]) <-> Ckpt Shape: torch.Size([29, 512])\n",
      "WARNING:utils.model:*UNLOADED* postprocessors.correct_mat, Model Shape: torch.Size([29, 81])\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.69 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.81s)\n",
      "creating index...\n",
      "index created!\n",
      "loading vcoco annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/2473. Dataloading: 0.0311 s/iter. Inference: 0.4881 s/iter. Eval: 0.0715 s/iter. Total: 0.5907 s/iter. ETA=0:24:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 21/2473. Dataloading: 0.0355 s/iter. Inference: 0.4903 s/iter. Eval: 0.0327 s/iter. Total: 0.5586 s/iter. ETA=0:22:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 31/2473. Dataloading: 0.0379 s/iter. Inference: 0.4917 s/iter. Eval: 0.0238 s/iter. Total: 0.5536 s/iter. ETA=0:22:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 40/2473. Dataloading: 0.0384 s/iter. Inference: 0.4951 s/iter. Eval: 0.0207 s/iter. Total: 0.5543 s/iter. ETA=0:22:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 49/2473. Dataloading: 0.0420 s/iter. Inference: 0.4965 s/iter. Eval: 0.0187 s/iter. Total: 0.5574 s/iter. ETA=0:22:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 58/2473. Dataloading: 0.0401 s/iter. Inference: 0.4964 s/iter. Eval: 0.0249 s/iter. Total: 0.5616 s/iter. ETA=0:22:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 68/2473. Dataloading: 0.0392 s/iter. Inference: 0.4966 s/iter. Eval: 0.0222 s/iter. Total: 0.5582 s/iter. ETA=0:22:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 78/2473. Dataloading: 0.0385 s/iter. Inference: 0.4970 s/iter. Eval: 0.0201 s/iter. Total: 0.5558 s/iter. ETA=0:22:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 88/2473. Dataloading: 0.0380 s/iter. Inference: 0.4977 s/iter. Eval: 0.0187 s/iter. Total: 0.5546 s/iter. ETA=0:22:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 97/2473. Dataloading: 0.0388 s/iter. Inference: 0.4988 s/iter. Eval: 0.0178 s/iter. Total: 0.5557 s/iter. ETA=0:22:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 107/2473. Dataloading: 0.0387 s/iter. Inference: 0.4994 s/iter. Eval: 0.0169 s/iter. Total: 0.5552 s/iter. ETA=0:21:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 116/2473. Dataloading: 0.0395 s/iter. Inference: 0.5001 s/iter. Eval: 0.0163 s/iter. Total: 0.5561 s/iter. ETA=0:21:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 124/2473. Dataloading: 0.0394 s/iter. Inference: 0.5006 s/iter. Eval: 0.0214 s/iter. Total: 0.5615 s/iter. ETA=0:21:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 134/2473. Dataloading: 0.0391 s/iter. Inference: 0.5009 s/iter. Eval: 0.0203 s/iter. Total: 0.5605 s/iter. ETA=0:21:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 144/2473. Dataloading: 0.0387 s/iter. Inference: 0.5010 s/iter. Eval: 0.0194 s/iter. Total: 0.5593 s/iter. ETA=0:21:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 153/2473. Dataloading: 0.0389 s/iter. Inference: 0.5014 s/iter. Eval: 0.0188 s/iter. Total: 0.5593 s/iter. ETA=0:21:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 163/2473. Dataloading: 0.0388 s/iter. Inference: 0.5018 s/iter. Eval: 0.0182 s/iter. Total: 0.5589 s/iter. ETA=0:21:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 173/2473. Dataloading: 0.0387 s/iter. Inference: 0.5020 s/iter. Eval: 0.0176 s/iter. Total: 0.5585 s/iter. ETA=0:21:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 182/2473. Dataloading: 0.0388 s/iter. Inference: 0.5023 s/iter. Eval: 0.0172 s/iter. Total: 0.5584 s/iter. ETA=0:21:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 191/2473. Dataloading: 0.0388 s/iter. Inference: 0.5026 s/iter. Eval: 0.0168 s/iter. Total: 0.5584 s/iter. ETA=0:21:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 199/2473. Dataloading: 0.0387 s/iter. Inference: 0.5028 s/iter. Eval: 0.0199 s/iter. Total: 0.5617 s/iter. ETA=0:21:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 208/2473. Dataloading: 0.0387 s/iter. Inference: 0.5031 s/iter. Eval: 0.0195 s/iter. Total: 0.5615 s/iter. ETA=0:21:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 217/2473. Dataloading: 0.0388 s/iter. Inference: 0.5034 s/iter. Eval: 0.0191 s/iter. Total: 0.5615 s/iter. ETA=0:21:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 226/2473. Dataloading: 0.0389 s/iter. Inference: 0.5036 s/iter. Eval: 0.0186 s/iter. Total: 0.5613 s/iter. ETA=0:21:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 235/2473. Dataloading: 0.0389 s/iter. Inference: 0.5038 s/iter. Eval: 0.0182 s/iter. Total: 0.5611 s/iter. ETA=0:20:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 244/2473. Dataloading: 0.0388 s/iter. Inference: 0.5041 s/iter. Eval: 0.0178 s/iter. Total: 0.5609 s/iter. ETA=0:20:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 253/2473. Dataloading: 0.0388 s/iter. Inference: 0.5043 s/iter. Eval: 0.0175 s/iter. Total: 0.5607 s/iter. ETA=0:20:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 263/2473. Dataloading: 0.0387 s/iter. Inference: 0.5045 s/iter. Eval: 0.0171 s/iter. Total: 0.5605 s/iter. ETA=0:20:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 273/2473. Dataloading: 0.0387 s/iter. Inference: 0.5046 s/iter. Eval: 0.0168 s/iter. Total: 0.5603 s/iter. ETA=0:20:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 283/2473. Dataloading: 0.0386 s/iter. Inference: 0.5048 s/iter. Eval: 0.0165 s/iter. Total: 0.5601 s/iter. ETA=0:20:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 291/2473. Dataloading: 0.0386 s/iter. Inference: 0.5049 s/iter. Eval: 0.0185 s/iter. Total: 0.5622 s/iter. ETA=0:20:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 300/2473. Dataloading: 0.0386 s/iter. Inference: 0.5051 s/iter. Eval: 0.0182 s/iter. Total: 0.5622 s/iter. ETA=0:20:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 309/2473. Dataloading: 0.0386 s/iter. Inference: 0.5053 s/iter. Eval: 0.0179 s/iter. Total: 0.5621 s/iter. ETA=0:20:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 318/2473. Dataloading: 0.0387 s/iter. Inference: 0.5055 s/iter. Eval: 0.0177 s/iter. Total: 0.5620 s/iter. ETA=0:20:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 327/2473. Dataloading: 0.0387 s/iter. Inference: 0.5057 s/iter. Eval: 0.0174 s/iter. Total: 0.5620 s/iter. ETA=0:20:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 336/2473. Dataloading: 0.0388 s/iter. Inference: 0.5059 s/iter. Eval: 0.0172 s/iter. Total: 0.5621 s/iter. ETA=0:20:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 345/2473. Dataloading: 0.0389 s/iter. Inference: 0.5061 s/iter. Eval: 0.0170 s/iter. Total: 0.5622 s/iter. ETA=0:19:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 354/2473. Dataloading: 0.0390 s/iter. Inference: 0.5063 s/iter. Eval: 0.0168 s/iter. Total: 0.5622 s/iter. ETA=0:19:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 363/2473. Dataloading: 0.0391 s/iter. Inference: 0.5064 s/iter. Eval: 0.0166 s/iter. Total: 0.5622 s/iter. ETA=0:19:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 372/2473. Dataloading: 0.0391 s/iter. Inference: 0.5065 s/iter. Eval: 0.0164 s/iter. Total: 0.5622 s/iter. ETA=0:19:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 381/2473. Dataloading: 0.0392 s/iter. Inference: 0.5067 s/iter. Eval: 0.0162 s/iter. Total: 0.5622 s/iter. ETA=0:19:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 390/2473. Dataloading: 0.0392 s/iter. Inference: 0.5069 s/iter. Eval: 0.0160 s/iter. Total: 0.5622 s/iter. ETA=0:19:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 399/2473. Dataloading: 0.0392 s/iter. Inference: 0.5070 s/iter. Eval: 0.0158 s/iter. Total: 0.5623 s/iter. ETA=0:19:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 408/2473. Dataloading: 0.0392 s/iter. Inference: 0.5072 s/iter. Eval: 0.0157 s/iter. Total: 0.5623 s/iter. ETA=0:19:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 416/2473. Dataloading: 0.0392 s/iter. Inference: 0.5073 s/iter. Eval: 0.0174 s/iter. Total: 0.5641 s/iter. ETA=0:19:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 425/2473. Dataloading: 0.0391 s/iter. Inference: 0.5075 s/iter. Eval: 0.0172 s/iter. Total: 0.5640 s/iter. ETA=0:19:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 434/2473. Dataloading: 0.0392 s/iter. Inference: 0.5076 s/iter. Eval: 0.0170 s/iter. Total: 0.5640 s/iter. ETA=0:19:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 443/2473. Dataloading: 0.0391 s/iter. Inference: 0.5077 s/iter. Eval: 0.0168 s/iter. Total: 0.5638 s/iter. ETA=0:19:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 452/2473. Dataloading: 0.0391 s/iter. Inference: 0.5078 s/iter. Eval: 0.0167 s/iter. Total: 0.5637 s/iter. ETA=0:18:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 461/2473. Dataloading: 0.0391 s/iter. Inference: 0.5078 s/iter. Eval: 0.0165 s/iter. Total: 0.5636 s/iter. ETA=0:18:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 470/2473. Dataloading: 0.0391 s/iter. Inference: 0.5079 s/iter. Eval: 0.0163 s/iter. Total: 0.5636 s/iter. ETA=0:18:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 479/2473. Dataloading: 0.0390 s/iter. Inference: 0.5081 s/iter. Eval: 0.0162 s/iter. Total: 0.5635 s/iter. ETA=0:18:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 488/2473. Dataloading: 0.0391 s/iter. Inference: 0.5082 s/iter. Eval: 0.0161 s/iter. Total: 0.5635 s/iter. ETA=0:18:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 497/2473. Dataloading: 0.0392 s/iter. Inference: 0.5083 s/iter. Eval: 0.0159 s/iter. Total: 0.5636 s/iter. ETA=0:18:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 506/2473. Dataloading: 0.0392 s/iter. Inference: 0.5085 s/iter. Eval: 0.0158 s/iter. Total: 0.5637 s/iter. ETA=0:18:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 515/2473. Dataloading: 0.0393 s/iter. Inference: 0.5086 s/iter. Eval: 0.0157 s/iter. Total: 0.5638 s/iter. ETA=0:18:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 524/2473. Dataloading: 0.0393 s/iter. Inference: 0.5087 s/iter. Eval: 0.0156 s/iter. Total: 0.5637 s/iter. ETA=0:18:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 533/2473. Dataloading: 0.0392 s/iter. Inference: 0.5087 s/iter. Eval: 0.0155 s/iter. Total: 0.5636 s/iter. ETA=0:18:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 542/2473. Dataloading: 0.0392 s/iter. Inference: 0.5088 s/iter. Eval: 0.0153 s/iter. Total: 0.5636 s/iter. ETA=0:18:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 551/2473. Dataloading: 0.0392 s/iter. Inference: 0.5089 s/iter. Eval: 0.0152 s/iter. Total: 0.5636 s/iter. ETA=0:18:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 559/2473. Dataloading: 0.0392 s/iter. Inference: 0.5108 s/iter. Eval: 0.0151 s/iter. Total: 0.5653 s/iter. ETA=0:18:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 568/2473. Dataloading: 0.0391 s/iter. Inference: 0.5108 s/iter. Eval: 0.0150 s/iter. Total: 0.5652 s/iter. ETA=0:17:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 577/2473. Dataloading: 0.0391 s/iter. Inference: 0.5108 s/iter. Eval: 0.0149 s/iter. Total: 0.5651 s/iter. ETA=0:17:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 586/2473. Dataloading: 0.0391 s/iter. Inference: 0.5109 s/iter. Eval: 0.0148 s/iter. Total: 0.5649 s/iter. ETA=0:17:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 595/2473. Dataloading: 0.0391 s/iter. Inference: 0.5109 s/iter. Eval: 0.0147 s/iter. Total: 0.5649 s/iter. ETA=0:17:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 604/2473. Dataloading: 0.0391 s/iter. Inference: 0.5109 s/iter. Eval: 0.0146 s/iter. Total: 0.5649 s/iter. ETA=0:17:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 613/2473. Dataloading: 0.0391 s/iter. Inference: 0.5110 s/iter. Eval: 0.0145 s/iter. Total: 0.5648 s/iter. ETA=0:17:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 622/2473. Dataloading: 0.0391 s/iter. Inference: 0.5110 s/iter. Eval: 0.0144 s/iter. Total: 0.5648 s/iter. ETA=0:17:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 631/2473. Dataloading: 0.0391 s/iter. Inference: 0.5111 s/iter. Eval: 0.0143 s/iter. Total: 0.5648 s/iter. ETA=0:17:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 640/2473. Dataloading: 0.0391 s/iter. Inference: 0.5111 s/iter. Eval: 0.0143 s/iter. Total: 0.5647 s/iter. ETA=0:17:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 649/2473. Dataloading: 0.0391 s/iter. Inference: 0.5112 s/iter. Eval: 0.0142 s/iter. Total: 0.5646 s/iter. ETA=0:17:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 658/2473. Dataloading: 0.0390 s/iter. Inference: 0.5112 s/iter. Eval: 0.0141 s/iter. Total: 0.5645 s/iter. ETA=0:17:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 668/2473. Dataloading: 0.0390 s/iter. Inference: 0.5112 s/iter. Eval: 0.0140 s/iter. Total: 0.5644 s/iter. ETA=0:16:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 677/2473. Dataloading: 0.0390 s/iter. Inference: 0.5112 s/iter. Eval: 0.0139 s/iter. Total: 0.5643 s/iter. ETA=0:16:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 686/2473. Dataloading: 0.0390 s/iter. Inference: 0.5112 s/iter. Eval: 0.0139 s/iter. Total: 0.5643 s/iter. ETA=0:16:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 695/2473. Dataloading: 0.0390 s/iter. Inference: 0.5113 s/iter. Eval: 0.0138 s/iter. Total: 0.5642 s/iter. ETA=0:16:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 704/2473. Dataloading: 0.0389 s/iter. Inference: 0.5113 s/iter. Eval: 0.0137 s/iter. Total: 0.5642 s/iter. ETA=0:16:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 713/2473. Dataloading: 0.0389 s/iter. Inference: 0.5113 s/iter. Eval: 0.0137 s/iter. Total: 0.5641 s/iter. ETA=0:16:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 722/2473. Dataloading: 0.0389 s/iter. Inference: 0.5114 s/iter. Eval: 0.0136 s/iter. Total: 0.5641 s/iter. ETA=0:16:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 731/2473. Dataloading: 0.0389 s/iter. Inference: 0.5114 s/iter. Eval: 0.0135 s/iter. Total: 0.5640 s/iter. ETA=0:16:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 740/2473. Dataloading: 0.0389 s/iter. Inference: 0.5114 s/iter. Eval: 0.0148 s/iter. Total: 0.5653 s/iter. ETA=0:16:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 750/2473. Dataloading: 0.0389 s/iter. Inference: 0.5114 s/iter. Eval: 0.0147 s/iter. Total: 0.5652 s/iter. ETA=0:16:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 759/2473. Dataloading: 0.0388 s/iter. Inference: 0.5115 s/iter. Eval: 0.0146 s/iter. Total: 0.5651 s/iter. ETA=0:16:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 768/2473. Dataloading: 0.0388 s/iter. Inference: 0.5115 s/iter. Eval: 0.0145 s/iter. Total: 0.5650 s/iter. ETA=0:16:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 777/2473. Dataloading: 0.0388 s/iter. Inference: 0.5115 s/iter. Eval: 0.0144 s/iter. Total: 0.5649 s/iter. ETA=0:15:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 786/2473. Dataloading: 0.0388 s/iter. Inference: 0.5115 s/iter. Eval: 0.0144 s/iter. Total: 0.5649 s/iter. ETA=0:15:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 796/2473. Dataloading: 0.0387 s/iter. Inference: 0.5115 s/iter. Eval: 0.0143 s/iter. Total: 0.5647 s/iter. ETA=0:15:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 805/2473. Dataloading: 0.0387 s/iter. Inference: 0.5115 s/iter. Eval: 0.0142 s/iter. Total: 0.5647 s/iter. ETA=0:15:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 814/2473. Dataloading: 0.0387 s/iter. Inference: 0.5116 s/iter. Eval: 0.0142 s/iter. Total: 0.5646 s/iter. ETA=0:15:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 823/2473. Dataloading: 0.0387 s/iter. Inference: 0.5116 s/iter. Eval: 0.0141 s/iter. Total: 0.5645 s/iter. ETA=0:15:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 832/2473. Dataloading: 0.0386 s/iter. Inference: 0.5116 s/iter. Eval: 0.0140 s/iter. Total: 0.5645 s/iter. ETA=0:15:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 841/2473. Dataloading: 0.0387 s/iter. Inference: 0.5116 s/iter. Eval: 0.0140 s/iter. Total: 0.5645 s/iter. ETA=0:15:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 850/2473. Dataloading: 0.0386 s/iter. Inference: 0.5117 s/iter. Eval: 0.0139 s/iter. Total: 0.5644 s/iter. ETA=0:15:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 859/2473. Dataloading: 0.0386 s/iter. Inference: 0.5117 s/iter. Eval: 0.0139 s/iter. Total: 0.5644 s/iter. ETA=0:15:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 868/2473. Dataloading: 0.0386 s/iter. Inference: 0.5117 s/iter. Eval: 0.0138 s/iter. Total: 0.5643 s/iter. ETA=0:15:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 877/2473. Dataloading: 0.0386 s/iter. Inference: 0.5117 s/iter. Eval: 0.0138 s/iter. Total: 0.5643 s/iter. ETA=0:15:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 886/2473. Dataloading: 0.0386 s/iter. Inference: 0.5118 s/iter. Eval: 0.0137 s/iter. Total: 0.5643 s/iter. ETA=0:14:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 895/2473. Dataloading: 0.0386 s/iter. Inference: 0.5118 s/iter. Eval: 0.0137 s/iter. Total: 0.5643 s/iter. ETA=0:14:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 904/2473. Dataloading: 0.0386 s/iter. Inference: 0.5118 s/iter. Eval: 0.0136 s/iter. Total: 0.5643 s/iter. ETA=0:14:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 913/2473. Dataloading: 0.0386 s/iter. Inference: 0.5119 s/iter. Eval: 0.0135 s/iter. Total: 0.5642 s/iter. ETA=0:14:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 923/2473. Dataloading: 0.0385 s/iter. Inference: 0.5119 s/iter. Eval: 0.0135 s/iter. Total: 0.5641 s/iter. ETA=0:14:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 932/2473. Dataloading: 0.0385 s/iter. Inference: 0.5119 s/iter. Eval: 0.0134 s/iter. Total: 0.5640 s/iter. ETA=0:14:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 941/2473. Dataloading: 0.0385 s/iter. Inference: 0.5119 s/iter. Eval: 0.0134 s/iter. Total: 0.5640 s/iter. ETA=0:14:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 950/2473. Dataloading: 0.0385 s/iter. Inference: 0.5120 s/iter. Eval: 0.0133 s/iter. Total: 0.5640 s/iter. ETA=0:14:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 959/2473. Dataloading: 0.0385 s/iter. Inference: 0.5120 s/iter. Eval: 0.0133 s/iter. Total: 0.5640 s/iter. ETA=0:14:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 968/2473. Dataloading: 0.0385 s/iter. Inference: 0.5120 s/iter. Eval: 0.0133 s/iter. Total: 0.5640 s/iter. ETA=0:14:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 975/2473. Dataloading: 0.0385 s/iter. Inference: 0.5120 s/iter. Eval: 0.0145 s/iter. Total: 0.5653 s/iter. ETA=0:14:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 984/2473. Dataloading: 0.0385 s/iter. Inference: 0.5120 s/iter. Eval: 0.0145 s/iter. Total: 0.5652 s/iter. ETA=0:14:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 993/2473. Dataloading: 0.0385 s/iter. Inference: 0.5121 s/iter. Eval: 0.0144 s/iter. Total: 0.5652 s/iter. ETA=0:13:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1003/2473. Dataloading: 0.0385 s/iter. Inference: 0.5121 s/iter. Eval: 0.0144 s/iter. Total: 0.5651 s/iter. ETA=0:13:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1012/2473. Dataloading: 0.0384 s/iter. Inference: 0.5121 s/iter. Eval: 0.0143 s/iter. Total: 0.5650 s/iter. ETA=0:13:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1021/2473. Dataloading: 0.0384 s/iter. Inference: 0.5121 s/iter. Eval: 0.0142 s/iter. Total: 0.5650 s/iter. ETA=0:13:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1030/2473. Dataloading: 0.0384 s/iter. Inference: 0.5122 s/iter. Eval: 0.0142 s/iter. Total: 0.5650 s/iter. ETA=0:13:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1039/2473. Dataloading: 0.0384 s/iter. Inference: 0.5122 s/iter. Eval: 0.0142 s/iter. Total: 0.5650 s/iter. ETA=0:13:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1048/2473. Dataloading: 0.0384 s/iter. Inference: 0.5122 s/iter. Eval: 0.0141 s/iter. Total: 0.5650 s/iter. ETA=0:13:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1057/2473. Dataloading: 0.0384 s/iter. Inference: 0.5123 s/iter. Eval: 0.0141 s/iter. Total: 0.5649 s/iter. ETA=0:13:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1066/2473. Dataloading: 0.0384 s/iter. Inference: 0.5123 s/iter. Eval: 0.0140 s/iter. Total: 0.5649 s/iter. ETA=0:13:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1075/2473. Dataloading: 0.0384 s/iter. Inference: 0.5123 s/iter. Eval: 0.0140 s/iter. Total: 0.5649 s/iter. ETA=0:13:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1084/2473. Dataloading: 0.0385 s/iter. Inference: 0.5123 s/iter. Eval: 0.0139 s/iter. Total: 0.5649 s/iter. ETA=0:13:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1093/2473. Dataloading: 0.0385 s/iter. Inference: 0.5124 s/iter. Eval: 0.0139 s/iter. Total: 0.5649 s/iter. ETA=0:12:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1102/2473. Dataloading: 0.0385 s/iter. Inference: 0.5124 s/iter. Eval: 0.0138 s/iter. Total: 0.5649 s/iter. ETA=0:12:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1111/2473. Dataloading: 0.0385 s/iter. Inference: 0.5124 s/iter. Eval: 0.0138 s/iter. Total: 0.5649 s/iter. ETA=0:12:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1120/2473. Dataloading: 0.0385 s/iter. Inference: 0.5124 s/iter. Eval: 0.0137 s/iter. Total: 0.5649 s/iter. ETA=0:12:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1129/2473. Dataloading: 0.0385 s/iter. Inference: 0.5124 s/iter. Eval: 0.0137 s/iter. Total: 0.5648 s/iter. ETA=0:12:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1138/2473. Dataloading: 0.0385 s/iter. Inference: 0.5125 s/iter. Eval: 0.0137 s/iter. Total: 0.5648 s/iter. ETA=0:12:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1147/2473. Dataloading: 0.0384 s/iter. Inference: 0.5125 s/iter. Eval: 0.0136 s/iter. Total: 0.5647 s/iter. ETA=0:12:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1156/2473. Dataloading: 0.0385 s/iter. Inference: 0.5125 s/iter. Eval: 0.0136 s/iter. Total: 0.5647 s/iter. ETA=0:12:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1165/2473. Dataloading: 0.0385 s/iter. Inference: 0.5125 s/iter. Eval: 0.0135 s/iter. Total: 0.5647 s/iter. ETA=0:12:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1174/2473. Dataloading: 0.0384 s/iter. Inference: 0.5125 s/iter. Eval: 0.0135 s/iter. Total: 0.5647 s/iter. ETA=0:12:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1183/2473. Dataloading: 0.0385 s/iter. Inference: 0.5126 s/iter. Eval: 0.0135 s/iter. Total: 0.5647 s/iter. ETA=0:12:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1192/2473. Dataloading: 0.0385 s/iter. Inference: 0.5126 s/iter. Eval: 0.0134 s/iter. Total: 0.5647 s/iter. ETA=0:12:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1201/2473. Dataloading: 0.0385 s/iter. Inference: 0.5126 s/iter. Eval: 0.0134 s/iter. Total: 0.5647 s/iter. ETA=0:11:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1210/2473. Dataloading: 0.0384 s/iter. Inference: 0.5126 s/iter. Eval: 0.0134 s/iter. Total: 0.5646 s/iter. ETA=0:11:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1219/2473. Dataloading: 0.0384 s/iter. Inference: 0.5126 s/iter. Eval: 0.0133 s/iter. Total: 0.5646 s/iter. ETA=0:11:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1228/2473. Dataloading: 0.0385 s/iter. Inference: 0.5127 s/iter. Eval: 0.0133 s/iter. Total: 0.5646 s/iter. ETA=0:11:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1237/2473. Dataloading: 0.0385 s/iter. Inference: 0.5127 s/iter. Eval: 0.0133 s/iter. Total: 0.5646 s/iter. ETA=0:11:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1246/2473. Dataloading: 0.0385 s/iter. Inference: 0.5127 s/iter. Eval: 0.0132 s/iter. Total: 0.5646 s/iter. ETA=0:11:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1253/2473. Dataloading: 0.0385 s/iter. Inference: 0.5127 s/iter. Eval: 0.0144 s/iter. Total: 0.5658 s/iter. ETA=0:11:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1262/2473. Dataloading: 0.0385 s/iter. Inference: 0.5127 s/iter. Eval: 0.0143 s/iter. Total: 0.5657 s/iter. ETA=0:11:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1271/2473. Dataloading: 0.0384 s/iter. Inference: 0.5127 s/iter. Eval: 0.0143 s/iter. Total: 0.5657 s/iter. ETA=0:11:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1280/2473. Dataloading: 0.0385 s/iter. Inference: 0.5128 s/iter. Eval: 0.0143 s/iter. Total: 0.5657 s/iter. ETA=0:11:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1289/2473. Dataloading: 0.0385 s/iter. Inference: 0.5128 s/iter. Eval: 0.0142 s/iter. Total: 0.5657 s/iter. ETA=0:11:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1298/2473. Dataloading: 0.0385 s/iter. Inference: 0.5128 s/iter. Eval: 0.0142 s/iter. Total: 0.5657 s/iter. ETA=0:11:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1307/2473. Dataloading: 0.0385 s/iter. Inference: 0.5128 s/iter. Eval: 0.0141 s/iter. Total: 0.5656 s/iter. ETA=0:10:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1316/2473. Dataloading: 0.0384 s/iter. Inference: 0.5128 s/iter. Eval: 0.0141 s/iter. Total: 0.5656 s/iter. ETA=0:10:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1325/2473. Dataloading: 0.0384 s/iter. Inference: 0.5129 s/iter. Eval: 0.0141 s/iter. Total: 0.5656 s/iter. ETA=0:10:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1334/2473. Dataloading: 0.0384 s/iter. Inference: 0.5129 s/iter. Eval: 0.0140 s/iter. Total: 0.5656 s/iter. ETA=0:10:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1343/2473. Dataloading: 0.0385 s/iter. Inference: 0.5129 s/iter. Eval: 0.0140 s/iter. Total: 0.5656 s/iter. ETA=0:10:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1352/2473. Dataloading: 0.0385 s/iter. Inference: 0.5129 s/iter. Eval: 0.0139 s/iter. Total: 0.5656 s/iter. ETA=0:10:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1361/2473. Dataloading: 0.0385 s/iter. Inference: 0.5130 s/iter. Eval: 0.0139 s/iter. Total: 0.5656 s/iter. ETA=0:10:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1370/2473. Dataloading: 0.0385 s/iter. Inference: 0.5130 s/iter. Eval: 0.0139 s/iter. Total: 0.5655 s/iter. ETA=0:10:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1379/2473. Dataloading: 0.0385 s/iter. Inference: 0.5130 s/iter. Eval: 0.0138 s/iter. Total: 0.5655 s/iter. ETA=0:10:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1388/2473. Dataloading: 0.0385 s/iter. Inference: 0.5130 s/iter. Eval: 0.0138 s/iter. Total: 0.5655 s/iter. ETA=0:10:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1397/2473. Dataloading: 0.0385 s/iter. Inference: 0.5130 s/iter. Eval: 0.0138 s/iter. Total: 0.5655 s/iter. ETA=0:10:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1406/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0137 s/iter. Total: 0.5655 s/iter. ETA=0:10:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1415/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0137 s/iter. Total: 0.5655 s/iter. ETA=0:09:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1424/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0137 s/iter. Total: 0.5655 s/iter. ETA=0:09:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1433/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0136 s/iter. Total: 0.5654 s/iter. ETA=0:09:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1442/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0136 s/iter. Total: 0.5654 s/iter. ETA=0:09:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1451/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0136 s/iter. Total: 0.5654 s/iter. ETA=0:09:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1460/2473. Dataloading: 0.0385 s/iter. Inference: 0.5131 s/iter. Eval: 0.0135 s/iter. Total: 0.5654 s/iter. ETA=0:09:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1469/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0135 s/iter. Total: 0.5654 s/iter. ETA=0:09:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1478/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0135 s/iter. Total: 0.5654 s/iter. ETA=0:09:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1487/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0134 s/iter. Total: 0.5653 s/iter. ETA=0:09:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1496/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0134 s/iter. Total: 0.5653 s/iter. ETA=0:09:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1505/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0134 s/iter. Total: 0.5654 s/iter. ETA=0:09:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1514/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0134 s/iter. Total: 0.5653 s/iter. ETA=0:09:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1523/2473. Dataloading: 0.0385 s/iter. Inference: 0.5132 s/iter. Eval: 0.0133 s/iter. Total: 0.5653 s/iter. ETA=0:08:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1532/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0133 s/iter. Total: 0.5653 s/iter. ETA=0:08:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1541/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0133 s/iter. Total: 0.5653 s/iter. ETA=0:08:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1550/2473. Dataloading: 0.0386 s/iter. Inference: 0.5133 s/iter. Eval: 0.0132 s/iter. Total: 0.5653 s/iter. ETA=0:08:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1559/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0132 s/iter. Total: 0.5653 s/iter. ETA=0:08:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1568/2473. Dataloading: 0.0386 s/iter. Inference: 0.5133 s/iter. Eval: 0.0132 s/iter. Total: 0.5653 s/iter. ETA=0:08:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1577/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0132 s/iter. Total: 0.5652 s/iter. ETA=0:08:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1586/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0131 s/iter. Total: 0.5652 s/iter. ETA=0:08:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1595/2473. Dataloading: 0.0385 s/iter. Inference: 0.5133 s/iter. Eval: 0.0131 s/iter. Total: 0.5652 s/iter. ETA=0:08:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1604/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0131 s/iter. Total: 0.5652 s/iter. ETA=0:08:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1610/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0142 s/iter. Total: 0.5663 s/iter. ETA=0:08:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1619/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0142 s/iter. Total: 0.5663 s/iter. ETA=0:08:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1628/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0142 s/iter. Total: 0.5663 s/iter. ETA=0:07:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1637/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0141 s/iter. Total: 0.5663 s/iter. ETA=0:07:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1646/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0141 s/iter. Total: 0.5662 s/iter. ETA=0:07:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1655/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0141 s/iter. Total: 0.5662 s/iter. ETA=0:07:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1664/2473. Dataloading: 0.0385 s/iter. Inference: 0.5134 s/iter. Eval: 0.0140 s/iter. Total: 0.5662 s/iter. ETA=0:07:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1673/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0140 s/iter. Total: 0.5662 s/iter. ETA=0:07:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1682/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0140 s/iter. Total: 0.5662 s/iter. ETA=0:07:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1691/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0140 s/iter. Total: 0.5662 s/iter. ETA=0:07:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1700/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0139 s/iter. Total: 0.5662 s/iter. ETA=0:07:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1709/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0139 s/iter. Total: 0.5661 s/iter. ETA=0:07:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1718/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0139 s/iter. Total: 0.5662 s/iter. ETA=0:07:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1727/2473. Dataloading: 0.0385 s/iter. Inference: 0.5135 s/iter. Eval: 0.0139 s/iter. Total: 0.5662 s/iter. ETA=0:07:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1736/2473. Dataloading: 0.0385 s/iter. Inference: 0.5136 s/iter. Eval: 0.0138 s/iter. Total: 0.5662 s/iter. ETA=0:06:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1745/2473. Dataloading: 0.0386 s/iter. Inference: 0.5136 s/iter. Eval: 0.0138 s/iter. Total: 0.5662 s/iter. ETA=0:06:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1754/2473. Dataloading: 0.0386 s/iter. Inference: 0.5136 s/iter. Eval: 0.0138 s/iter. Total: 0.5662 s/iter. ETA=0:06:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1763/2473. Dataloading: 0.0386 s/iter. Inference: 0.5136 s/iter. Eval: 0.0138 s/iter. Total: 0.5662 s/iter. ETA=0:06:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1772/2473. Dataloading: 0.0386 s/iter. Inference: 0.5136 s/iter. Eval: 0.0137 s/iter. Total: 0.5662 s/iter. ETA=0:06:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1781/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0137 s/iter. Total: 0.5662 s/iter. ETA=0:06:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1790/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0137 s/iter. Total: 0.5662 s/iter. ETA=0:06:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1799/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0137 s/iter. Total: 0.5662 s/iter. ETA=0:06:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1808/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0137 s/iter. Total: 0.5662 s/iter. ETA=0:06:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1817/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0136 s/iter. Total: 0.5662 s/iter. ETA=0:06:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1826/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0136 s/iter. Total: 0.5662 s/iter. ETA=0:06:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1835/2473. Dataloading: 0.0386 s/iter. Inference: 0.5137 s/iter. Eval: 0.0136 s/iter. Total: 0.5662 s/iter. ETA=0:06:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1844/2473. Dataloading: 0.0386 s/iter. Inference: 0.5138 s/iter. Eval: 0.0136 s/iter. Total: 0.5662 s/iter. ETA=0:05:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1853/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0135 s/iter. Total: 0.5662 s/iter. ETA=0:05:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1862/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0135 s/iter. Total: 0.5662 s/iter. ETA=0:05:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1871/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0135 s/iter. Total: 0.5661 s/iter. ETA=0:05:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1880/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0135 s/iter. Total: 0.5661 s/iter. ETA=0:05:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1889/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0135 s/iter. Total: 0.5661 s/iter. ETA=0:05:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1898/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0134 s/iter. Total: 0.5661 s/iter. ETA=0:05:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1907/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0134 s/iter. Total: 0.5661 s/iter. ETA=0:05:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1916/2473. Dataloading: 0.0387 s/iter. Inference: 0.5138 s/iter. Eval: 0.0134 s/iter. Total: 0.5661 s/iter. ETA=0:05:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1925/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0134 s/iter. Total: 0.5661 s/iter. ETA=0:05:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1934/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0133 s/iter. Total: 0.5661 s/iter. ETA=0:05:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1943/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0133 s/iter. Total: 0.5661 s/iter. ETA=0:05:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1952/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0133 s/iter. Total: 0.5661 s/iter. ETA=0:04:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1961/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0133 s/iter. Total: 0.5660 s/iter. ETA=0:04:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1970/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0132 s/iter. Total: 0.5660 s/iter. ETA=0:04:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1979/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0132 s/iter. Total: 0.5660 s/iter. ETA=0:04:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1988/2473. Dataloading: 0.0386 s/iter. Inference: 0.5139 s/iter. Eval: 0.0132 s/iter. Total: 0.5660 s/iter. ETA=0:04:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1997/2473. Dataloading: 0.0386 s/iter. Inference: 0.5139 s/iter. Eval: 0.0132 s/iter. Total: 0.5659 s/iter. ETA=0:04:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2006/2473. Dataloading: 0.0386 s/iter. Inference: 0.5139 s/iter. Eval: 0.0132 s/iter. Total: 0.5659 s/iter. ETA=0:04:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2015/2473. Dataloading: 0.0386 s/iter. Inference: 0.5139 s/iter. Eval: 0.0131 s/iter. Total: 0.5659 s/iter. ETA=0:04:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2024/2473. Dataloading: 0.0387 s/iter. Inference: 0.5139 s/iter. Eval: 0.0131 s/iter. Total: 0.5659 s/iter. ETA=0:04:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2033/2473. Dataloading: 0.0387 s/iter. Inference: 0.5140 s/iter. Eval: 0.0131 s/iter. Total: 0.5659 s/iter. ETA=0:04:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2042/2473. Dataloading: 0.0387 s/iter. Inference: 0.5140 s/iter. Eval: 0.0131 s/iter. Total: 0.5659 s/iter. ETA=0:04:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2048/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0131 s/iter. Total: 0.5672 s/iter. ETA=0:04:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2057/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0130 s/iter. Total: 0.5672 s/iter. ETA=0:03:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2066/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0130 s/iter. Total: 0.5672 s/iter. ETA=0:03:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2075/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0130 s/iter. Total: 0.5672 s/iter. ETA=0:03:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2084/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0130 s/iter. Total: 0.5672 s/iter. ETA=0:03:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2093/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0130 s/iter. Total: 0.5671 s/iter. ETA=0:03:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2102/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5671 s/iter. ETA=0:03:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2111/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5671 s/iter. ETA=0:03:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2120/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5671 s/iter. ETA=0:03:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2129/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5671 s/iter. ETA=0:03:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2138/2473. Dataloading: 0.0386 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5670 s/iter. ETA=0:03:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2147/2473. Dataloading: 0.0386 s/iter. Inference: 0.5153 s/iter. Eval: 0.0129 s/iter. Total: 0.5670 s/iter. ETA=0:03:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2156/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0128 s/iter. Total: 0.5670 s/iter. ETA=0:02:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2165/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0128 s/iter. Total: 0.5670 s/iter. ETA=0:02:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2174/2473. Dataloading: 0.0386 s/iter. Inference: 0.5153 s/iter. Eval: 0.0128 s/iter. Total: 0.5670 s/iter. ETA=0:02:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2183/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0128 s/iter. Total: 0.5670 s/iter. ETA=0:02:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2192/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0128 s/iter. Total: 0.5670 s/iter. ETA=0:02:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2201/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2210/2473. Dataloading: 0.0386 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2219/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2228/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2237/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2246/2473. Dataloading: 0.0387 s/iter. Inference: 0.5153 s/iter. Eval: 0.0127 s/iter. Total: 0.5669 s/iter. ETA=0:02:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2255/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5669 s/iter. ETA=0:02:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2264/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5669 s/iter. ETA=0:01:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2273/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5668 s/iter. ETA=0:01:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2282/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5668 s/iter. ETA=0:01:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2291/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5668 s/iter. ETA=0:01:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2300/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0126 s/iter. Total: 0.5668 s/iter. ETA=0:01:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2309/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2318/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2327/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2336/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2345/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2354/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0125 s/iter. Total: 0.5668 s/iter. ETA=0:01:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2363/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0124 s/iter. Total: 0.5668 s/iter. ETA=0:01:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2372/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0124 s/iter. Total: 0.5668 s/iter. ETA=0:00:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2381/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0124 s/iter. Total: 0.5668 s/iter. ETA=0:00:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2390/2473. Dataloading: 0.0387 s/iter. Inference: 0.5154 s/iter. Eval: 0.0124 s/iter. Total: 0.5667 s/iter. ETA=0:00:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2399/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0124 s/iter. Total: 0.5667 s/iter. ETA=0:00:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2408/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0124 s/iter. Total: 0.5667 s/iter. ETA=0:00:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2417/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5667 s/iter. ETA=0:00:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2426/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5667 s/iter. ETA=0:00:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2435/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5667 s/iter. ETA=0:00:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2444/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5667 s/iter. ETA=0:00:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2453/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5666 s/iter. ETA=0:00:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2462/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5666 s/iter. ETA=0:00:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2471/2473. Dataloading: 0.0387 s/iter. Inference: 0.5155 s/iter. Eval: 0.0123 s/iter. Total: 0.5666 s/iter. ETA=0:00:01\n",
      "INFO:trainer.default_trainer:{'vcoco_val/vcoco': {'AP_scenario_1': 0.41517952}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Reporting Role AP (%)------------------\n",
      "               hold-obj: AP = 31.71 (#pos = 3608)\n",
      "              sit-instr: AP = 39.27 (#pos = 1916)\n",
      "             ride-instr: AP = 51.76 (#pos = 556)\n",
      "               look-obj: AP = 27.79 (#pos = 3347)\n",
      "              hit-instr: AP = 50.30 (#pos = 349)\n",
      "                hit-obj: AP = 13.79 (#pos = 349)\n",
      "                eat-obj: AP = 48.91 (#pos = 521)\n",
      "              eat-instr: AP = 67.07 (#pos = 521)\n",
      "             jump-instr: AP = 67.53 (#pos = 635)\n",
      "              lay-instr: AP = 49.58 (#pos = 387)\n",
      "    talk_on_phone-instr: AP = 16.76 (#pos = 285)\n",
      "              carry-obj: AP = 27.92 (#pos = 472)\n",
      "              throw-obj: AP = 20.37 (#pos = 244)\n",
      "              catch-obj: AP = 22.81 (#pos = 246)\n",
      "              cut-instr: AP = 14.50 (#pos = 269)\n",
      "                cut-obj: AP = 53.14 (#pos = 269)\n",
      " work_on_computer-instr: AP = 57.38 (#pos = 410)\n",
      "              ski-instr: AP = 23.67 (#pos = 424)\n",
      "             surf-instr: AP = 60.20 (#pos = 486)\n",
      "       skateboard-instr: AP = 65.30 (#pos = 417)\n",
      "            drink-instr: AP = 26.83 (#pos = 82)\n",
      "               kick-obj: AP = 64.59 (#pos = 180)\n",
      "            point-instr: AP = 1.24 (#pos = 31)\n",
      "               read-obj: AP = 37.37 (#pos = 111)\n",
      "        snowboard-instr: AP = 57.85 (#pos = 277)\n",
      "Average Role [scenario_1] AP = 39.91\n",
      "---------------------------------------------\n",
      "Average Role [scenario_1] AP = 41.52, omitting the action \"point\"\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vcoco_val/vcoco': {'AP_scenario_1': 0.41517952}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "if cmdline_args.user_dir:\n",
    "    absolute_user_dir = os.path.abspath(cmdline_args.user_dir)\n",
    "    opt['base_path'] = absolute_user_dir\n",
    "trainer = Trainer(opt)\n",
    "trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
