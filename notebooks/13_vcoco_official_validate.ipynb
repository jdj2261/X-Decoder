{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt\n",
    "from utils.misc import MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.arguments:Overrided DONT_LOAD_MODEL from True to False\n"
     ]
    }
   ],
   "source": [
    "from utils.arguments import load_vcoco_opt_command, load_vcoco_parser\n",
    "\n",
    "cmdline_args = load_vcoco_parser()\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco.yaml\")]\n",
    "\n",
    "model_path = '../data/output/test/00205200/default/raw_model_states.pt'\n",
    "cmdline_args.overrides = ['DONT_LOAD_MODEL', 'false', 'PYLEARN_MODEL', model_path] \n",
    "\n",
    "opt = load_vcoco_opt_command(cmdline_args)\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(opt['base_path'])\n",
    "print(opt[\"RESUME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as data/output/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to data/output/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-----------------------------------------------\n",
      "INFO:trainer.default_trainer:Evaluating model ... \n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.136)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.191)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.218)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.245)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.273)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): PostProcessHOI()\n",
      ")\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512]) <-> Ckpt Shape: torch.Size([82, 512])\n",
      "INFO:utils.model:Loaded hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512]) <-> Ckpt Shape: torch.Size([100, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29]) <-> Ckpt Shape: torch.Size([29])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512]) <-> Ckpt Shape: torch.Size([29, 512])\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.69 MiB\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/2473. Dataloading: 0.0247 s/iter. Inference: 0.4678 s/iter. Eval: 0.0005 s/iter. Total: 0.4930 s/iter. ETA=0:20:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 22/2473. Dataloading: 0.0274 s/iter. Inference: 0.4684 s/iter. Eval: 0.0004 s/iter. Total: 0.4963 s/iter. ETA=0:20:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 32/2473. Dataloading: 0.0295 s/iter. Inference: 0.4692 s/iter. Eval: 0.0004 s/iter. Total: 0.4992 s/iter. ETA=0:20:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 42/2473. Dataloading: 0.0300 s/iter. Inference: 0.4706 s/iter. Eval: 0.0004 s/iter. Total: 0.5011 s/iter. ETA=0:20:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 52/2473. Dataloading: 0.0296 s/iter. Inference: 0.4716 s/iter. Eval: 0.0004 s/iter. Total: 0.5018 s/iter. ETA=0:20:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 62/2473. Dataloading: 0.0323 s/iter. Inference: 0.4738 s/iter. Eval: 0.0006 s/iter. Total: 0.5068 s/iter. ETA=0:20:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 71/2473. Dataloading: 0.0397 s/iter. Inference: 0.4752 s/iter. Eval: 0.0006 s/iter. Total: 0.5158 s/iter. ETA=0:20:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 81/2473. Dataloading: 0.0383 s/iter. Inference: 0.4758 s/iter. Eval: 0.0006 s/iter. Total: 0.5149 s/iter. ETA=0:20:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 91/2473. Dataloading: 0.0370 s/iter. Inference: 0.4763 s/iter. Eval: 0.0006 s/iter. Total: 0.5140 s/iter. ETA=0:20:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 101/2473. Dataloading: 0.0366 s/iter. Inference: 0.4766 s/iter. Eval: 0.0006 s/iter. Total: 0.5140 s/iter. ETA=0:20:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 111/2473. Dataloading: 0.0360 s/iter. Inference: 0.4770 s/iter. Eval: 0.0006 s/iter. Total: 0.5137 s/iter. ETA=0:20:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 121/2473. Dataloading: 0.0357 s/iter. Inference: 0.4774 s/iter. Eval: 0.0006 s/iter. Total: 0.5138 s/iter. ETA=0:20:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 131/2473. Dataloading: 0.0352 s/iter. Inference: 0.4778 s/iter. Eval: 0.0006 s/iter. Total: 0.5137 s/iter. ETA=0:20:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 141/2473. Dataloading: 0.0347 s/iter. Inference: 0.4781 s/iter. Eval: 0.0005 s/iter. Total: 0.5134 s/iter. ETA=0:19:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 151/2473. Dataloading: 0.0342 s/iter. Inference: 0.4784 s/iter. Eval: 0.0005 s/iter. Total: 0.5133 s/iter. ETA=0:19:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 161/2473. Dataloading: 0.0340 s/iter. Inference: 0.4787 s/iter. Eval: 0.0005 s/iter. Total: 0.5134 s/iter. ETA=0:19:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 171/2473. Dataloading: 0.0336 s/iter. Inference: 0.4789 s/iter. Eval: 0.0005 s/iter. Total: 0.5133 s/iter. ETA=0:19:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 181/2473. Dataloading: 0.0334 s/iter. Inference: 0.4792 s/iter. Eval: 0.0005 s/iter. Total: 0.5133 s/iter. ETA=0:19:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 191/2473. Dataloading: 0.0333 s/iter. Inference: 0.4795 s/iter. Eval: 0.0005 s/iter. Total: 0.5135 s/iter. ETA=0:19:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 201/2473. Dataloading: 0.0332 s/iter. Inference: 0.4798 s/iter. Eval: 0.0005 s/iter. Total: 0.5136 s/iter. ETA=0:19:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 211/2473. Dataloading: 0.0331 s/iter. Inference: 0.4800 s/iter. Eval: 0.0005 s/iter. Total: 0.5138 s/iter. ETA=0:19:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 221/2473. Dataloading: 0.0329 s/iter. Inference: 0.4803 s/iter. Eval: 0.0005 s/iter. Total: 0.5139 s/iter. ETA=0:19:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 231/2473. Dataloading: 0.0327 s/iter. Inference: 0.4805 s/iter. Eval: 0.0005 s/iter. Total: 0.5139 s/iter. ETA=0:19:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 241/2473. Dataloading: 0.0325 s/iter. Inference: 0.4807 s/iter. Eval: 0.0005 s/iter. Total: 0.5139 s/iter. ETA=0:19:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 251/2473. Dataloading: 0.0324 s/iter. Inference: 0.4809 s/iter. Eval: 0.0005 s/iter. Total: 0.5139 s/iter. ETA=0:19:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 261/2473. Dataloading: 0.0324 s/iter. Inference: 0.4810 s/iter. Eval: 0.0005 s/iter. Total: 0.5140 s/iter. ETA=0:18:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 271/2473. Dataloading: 0.0322 s/iter. Inference: 0.4812 s/iter. Eval: 0.0005 s/iter. Total: 0.5140 s/iter. ETA=0:18:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 281/2473. Dataloading: 0.0322 s/iter. Inference: 0.4813 s/iter. Eval: 0.0005 s/iter. Total: 0.5142 s/iter. ETA=0:18:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 291/2473. Dataloading: 0.0322 s/iter. Inference: 0.4814 s/iter. Eval: 0.0005 s/iter. Total: 0.5143 s/iter. ETA=0:18:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 301/2473. Dataloading: 0.0322 s/iter. Inference: 0.4816 s/iter. Eval: 0.0005 s/iter. Total: 0.5144 s/iter. ETA=0:18:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 311/2473. Dataloading: 0.0321 s/iter. Inference: 0.4817 s/iter. Eval: 0.0005 s/iter. Total: 0.5145 s/iter. ETA=0:18:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 321/2473. Dataloading: 0.0321 s/iter. Inference: 0.4819 s/iter. Eval: 0.0005 s/iter. Total: 0.5146 s/iter. ETA=0:18:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 331/2473. Dataloading: 0.0320 s/iter. Inference: 0.4820 s/iter. Eval: 0.0005 s/iter. Total: 0.5147 s/iter. ETA=0:18:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 341/2473. Dataloading: 0.0319 s/iter. Inference: 0.4822 s/iter. Eval: 0.0005 s/iter. Total: 0.5147 s/iter. ETA=0:18:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 351/2473. Dataloading: 0.0319 s/iter. Inference: 0.4823 s/iter. Eval: 0.0005 s/iter. Total: 0.5148 s/iter. ETA=0:18:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 361/2473. Dataloading: 0.0319 s/iter. Inference: 0.4825 s/iter. Eval: 0.0005 s/iter. Total: 0.5149 s/iter. ETA=0:18:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 371/2473. Dataloading: 0.0319 s/iter. Inference: 0.4826 s/iter. Eval: 0.0005 s/iter. Total: 0.5151 s/iter. ETA=0:18:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 381/2473. Dataloading: 0.0319 s/iter. Inference: 0.4827 s/iter. Eval: 0.0005 s/iter. Total: 0.5152 s/iter. ETA=0:17:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 391/2473. Dataloading: 0.0319 s/iter. Inference: 0.4829 s/iter. Eval: 0.0005 s/iter. Total: 0.5154 s/iter. ETA=0:17:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 401/2473. Dataloading: 0.0319 s/iter. Inference: 0.4830 s/iter. Eval: 0.0005 s/iter. Total: 0.5155 s/iter. ETA=0:17:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 411/2473. Dataloading: 0.0318 s/iter. Inference: 0.4831 s/iter. Eval: 0.0005 s/iter. Total: 0.5155 s/iter. ETA=0:17:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 421/2473. Dataloading: 0.0318 s/iter. Inference: 0.4833 s/iter. Eval: 0.0005 s/iter. Total: 0.5156 s/iter. ETA=0:17:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 431/2473. Dataloading: 0.0316 s/iter. Inference: 0.4834 s/iter. Eval: 0.0005 s/iter. Total: 0.5156 s/iter. ETA=0:17:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 441/2473. Dataloading: 0.0316 s/iter. Inference: 0.4835 s/iter. Eval: 0.0005 s/iter. Total: 0.5157 s/iter. ETA=0:17:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 451/2473. Dataloading: 0.0315 s/iter. Inference: 0.4836 s/iter. Eval: 0.0005 s/iter. Total: 0.5157 s/iter. ETA=0:17:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 461/2473. Dataloading: 0.0314 s/iter. Inference: 0.4836 s/iter. Eval: 0.0005 s/iter. Total: 0.5157 s/iter. ETA=0:17:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 471/2473. Dataloading: 0.0314 s/iter. Inference: 0.4837 s/iter. Eval: 0.0005 s/iter. Total: 0.5157 s/iter. ETA=0:17:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 481/2473. Dataloading: 0.0314 s/iter. Inference: 0.4838 s/iter. Eval: 0.0005 s/iter. Total: 0.5158 s/iter. ETA=0:17:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 491/2473. Dataloading: 0.0314 s/iter. Inference: 0.4839 s/iter. Eval: 0.0005 s/iter. Total: 0.5159 s/iter. ETA=0:17:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 501/2473. Dataloading: 0.0314 s/iter. Inference: 0.4840 s/iter. Eval: 0.0005 s/iter. Total: 0.5160 s/iter. ETA=0:16:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 511/2473. Dataloading: 0.0314 s/iter. Inference: 0.4841 s/iter. Eval: 0.0005 s/iter. Total: 0.5161 s/iter. ETA=0:16:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 521/2473. Dataloading: 0.0314 s/iter. Inference: 0.4842 s/iter. Eval: 0.0005 s/iter. Total: 0.5162 s/iter. ETA=0:16:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 531/2473. Dataloading: 0.0315 s/iter. Inference: 0.4843 s/iter. Eval: 0.0005 s/iter. Total: 0.5164 s/iter. ETA=0:16:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 541/2473. Dataloading: 0.0314 s/iter. Inference: 0.4844 s/iter. Eval: 0.0005 s/iter. Total: 0.5165 s/iter. ETA=0:16:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 551/2473. Dataloading: 0.0314 s/iter. Inference: 0.4845 s/iter. Eval: 0.0005 s/iter. Total: 0.5166 s/iter. ETA=0:16:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 561/2473. Dataloading: 0.0314 s/iter. Inference: 0.4847 s/iter. Eval: 0.0005 s/iter. Total: 0.5166 s/iter. ETA=0:16:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 571/2473. Dataloading: 0.0314 s/iter. Inference: 0.4848 s/iter. Eval: 0.0005 s/iter. Total: 0.5167 s/iter. ETA=0:16:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 581/2473. Dataloading: 0.0314 s/iter. Inference: 0.4848 s/iter. Eval: 0.0005 s/iter. Total: 0.5168 s/iter. ETA=0:16:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 591/2473. Dataloading: 0.0313 s/iter. Inference: 0.4849 s/iter. Eval: 0.0005 s/iter. Total: 0.5169 s/iter. ETA=0:16:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 601/2473. Dataloading: 0.0313 s/iter. Inference: 0.4850 s/iter. Eval: 0.0005 s/iter. Total: 0.5169 s/iter. ETA=0:16:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 611/2473. Dataloading: 0.0313 s/iter. Inference: 0.4851 s/iter. Eval: 0.0005 s/iter. Total: 0.5170 s/iter. ETA=0:16:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 621/2473. Dataloading: 0.0313 s/iter. Inference: 0.4851 s/iter. Eval: 0.0005 s/iter. Total: 0.5170 s/iter. ETA=0:15:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 631/2473. Dataloading: 0.0313 s/iter. Inference: 0.4852 s/iter. Eval: 0.0005 s/iter. Total: 0.5171 s/iter. ETA=0:15:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 641/2473. Dataloading: 0.0312 s/iter. Inference: 0.4853 s/iter. Eval: 0.0005 s/iter. Total: 0.5171 s/iter. ETA=0:15:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 651/2473. Dataloading: 0.0312 s/iter. Inference: 0.4853 s/iter. Eval: 0.0005 s/iter. Total: 0.5171 s/iter. ETA=0:15:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 661/2473. Dataloading: 0.0311 s/iter. Inference: 0.4853 s/iter. Eval: 0.0005 s/iter. Total: 0.5171 s/iter. ETA=0:15:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 671/2473. Dataloading: 0.0312 s/iter. Inference: 0.4854 s/iter. Eval: 0.0005 s/iter. Total: 0.5172 s/iter. ETA=0:15:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 681/2473. Dataloading: 0.0314 s/iter. Inference: 0.4855 s/iter. Eval: 0.0005 s/iter. Total: 0.5175 s/iter. ETA=0:15:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 691/2473. Dataloading: 0.0316 s/iter. Inference: 0.4857 s/iter. Eval: 0.0005 s/iter. Total: 0.5179 s/iter. ETA=0:15:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 701/2473. Dataloading: 0.0318 s/iter. Inference: 0.4858 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:15:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 711/2473. Dataloading: 0.0319 s/iter. Inference: 0.4859 s/iter. Eval: 0.0005 s/iter. Total: 0.5184 s/iter. ETA=0:15:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 721/2473. Dataloading: 0.0319 s/iter. Inference: 0.4860 s/iter. Eval: 0.0005 s/iter. Total: 0.5186 s/iter. ETA=0:15:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 731/2473. Dataloading: 0.0321 s/iter. Inference: 0.4861 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:15:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 741/2473. Dataloading: 0.0320 s/iter. Inference: 0.4861 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 751/2473. Dataloading: 0.0320 s/iter. Inference: 0.4862 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 761/2473. Dataloading: 0.0319 s/iter. Inference: 0.4862 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 771/2473. Dataloading: 0.0319 s/iter. Inference: 0.4862 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 781/2473. Dataloading: 0.0319 s/iter. Inference: 0.4863 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 791/2473. Dataloading: 0.0318 s/iter. Inference: 0.4863 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 801/2473. Dataloading: 0.0318 s/iter. Inference: 0.4863 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 811/2473. Dataloading: 0.0317 s/iter. Inference: 0.4864 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 821/2473. Dataloading: 0.0317 s/iter. Inference: 0.4864 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 831/2473. Dataloading: 0.0317 s/iter. Inference: 0.4864 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 841/2473. Dataloading: 0.0317 s/iter. Inference: 0.4864 s/iter. Eval: 0.0005 s/iter. Total: 0.5188 s/iter. ETA=0:14:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 851/2473. Dataloading: 0.0316 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:14:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 861/2473. Dataloading: 0.0316 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:13:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 871/2473. Dataloading: 0.0316 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:13:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 881/2473. Dataloading: 0.0315 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:13:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 891/2473. Dataloading: 0.0315 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:13:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 901/2473. Dataloading: 0.0315 s/iter. Inference: 0.4865 s/iter. Eval: 0.0005 s/iter. Total: 0.5186 s/iter. ETA=0:13:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 911/2473. Dataloading: 0.0314 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5186 s/iter. ETA=0:13:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 921/2473. Dataloading: 0.0314 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5186 s/iter. ETA=0:13:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 931/2473. Dataloading: 0.0313 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5186 s/iter. ETA=0:13:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 941/2473. Dataloading: 0.0313 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:13:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 951/2473. Dataloading: 0.0313 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:13:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 961/2473. Dataloading: 0.0313 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:13:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 971/2473. Dataloading: 0.0312 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:12:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 981/2473. Dataloading: 0.0312 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:12:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 991/2473. Dataloading: 0.0312 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:12:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1001/2473. Dataloading: 0.0312 s/iter. Inference: 0.4866 s/iter. Eval: 0.0005 s/iter. Total: 0.5184 s/iter. ETA=0:12:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1011/2473. Dataloading: 0.0311 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5184 s/iter. ETA=0:12:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1021/2473. Dataloading: 0.0311 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5184 s/iter. ETA=0:12:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1031/2473. Dataloading: 0.0311 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5184 s/iter. ETA=0:12:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1041/2473. Dataloading: 0.0310 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5183 s/iter. ETA=0:12:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1051/2473. Dataloading: 0.0310 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5183 s/iter. ETA=0:12:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1061/2473. Dataloading: 0.0310 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5183 s/iter. ETA=0:12:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1071/2473. Dataloading: 0.0309 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5183 s/iter. ETA=0:12:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1081/2473. Dataloading: 0.0309 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:12:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1091/2473. Dataloading: 0.0309 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:11:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1101/2473. Dataloading: 0.0309 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:11:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1111/2473. Dataloading: 0.0308 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:11:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1121/2473. Dataloading: 0.0308 s/iter. Inference: 0.4867 s/iter. Eval: 0.0005 s/iter. Total: 0.5182 s/iter. ETA=0:11:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1131/2473. Dataloading: 0.0308 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5181 s/iter. ETA=0:11:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1141/2473. Dataloading: 0.0307 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5181 s/iter. ETA=0:11:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1151/2473. Dataloading: 0.0307 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5181 s/iter. ETA=0:11:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1161/2473. Dataloading: 0.0307 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5181 s/iter. ETA=0:11:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1171/2473. Dataloading: 0.0306 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5180 s/iter. ETA=0:11:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1181/2473. Dataloading: 0.0306 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5180 s/iter. ETA=0:11:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1191/2473. Dataloading: 0.0306 s/iter. Inference: 0.4868 s/iter. Eval: 0.0005 s/iter. Total: 0.5180 s/iter. ETA=0:11:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1201/2473. Dataloading: 0.0306 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:10:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1211/2473. Dataloading: 0.0305 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1221/2473. Dataloading: 0.0305 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1231/2473. Dataloading: 0.0305 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1241/2473. Dataloading: 0.0305 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1251/2473. Dataloading: 0.0304 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1261/2473. Dataloading: 0.0304 s/iter. Inference: 0.4868 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1271/2473. Dataloading: 0.0304 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5178 s/iter. ETA=0:10:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1281/2473. Dataloading: 0.0304 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5178 s/iter. ETA=0:10:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1291/2473. Dataloading: 0.0304 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5178 s/iter. ETA=0:10:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1301/2473. Dataloading: 0.0303 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5178 s/iter. ETA=0:10:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1311/2473. Dataloading: 0.0303 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:10:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1321/2473. Dataloading: 0.0303 s/iter. Inference: 0.4869 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:09:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1331/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:09:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1341/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:09:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1351/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5179 s/iter. ETA=0:09:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1361/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1371/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1381/2473. Dataloading: 0.0303 s/iter. Inference: 0.4870 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1391/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1401/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1411/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1421/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:09:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1431/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:08:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1441/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:08:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1451/2473. Dataloading: 0.0303 s/iter. Inference: 0.4871 s/iter. Eval: 0.0004 s/iter. Total: 0.5180 s/iter. ETA=0:08:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1461/2473. Dataloading: 0.0303 s/iter. Inference: 0.4872 s/iter. Eval: 0.0004 s/iter. Total: 0.5181 s/iter. ETA=0:08:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1471/2473. Dataloading: 0.0304 s/iter. Inference: 0.4872 s/iter. Eval: 0.0004 s/iter. Total: 0.5182 s/iter. ETA=0:08:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1481/2473. Dataloading: 0.0305 s/iter. Inference: 0.4872 s/iter. Eval: 0.0004 s/iter. Total: 0.5183 s/iter. ETA=0:08:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1491/2473. Dataloading: 0.0306 s/iter. Inference: 0.4873 s/iter. Eval: 0.0005 s/iter. Total: 0.5185 s/iter. ETA=0:08:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1501/2473. Dataloading: 0.0307 s/iter. Inference: 0.4874 s/iter. Eval: 0.0005 s/iter. Total: 0.5187 s/iter. ETA=0:08:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1511/2473. Dataloading: 0.0308 s/iter. Inference: 0.4874 s/iter. Eval: 0.0005 s/iter. Total: 0.5189 s/iter. ETA=0:08:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1521/2473. Dataloading: 0.0309 s/iter. Inference: 0.4875 s/iter. Eval: 0.0005 s/iter. Total: 0.5190 s/iter. ETA=0:08:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1531/2473. Dataloading: 0.0310 s/iter. Inference: 0.4875 s/iter. Eval: 0.0005 s/iter. Total: 0.5191 s/iter. ETA=0:08:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1541/2473. Dataloading: 0.0310 s/iter. Inference: 0.4875 s/iter. Eval: 0.0005 s/iter. Total: 0.5191 s/iter. ETA=0:08:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1551/2473. Dataloading: 0.0310 s/iter. Inference: 0.4876 s/iter. Eval: 0.0005 s/iter. Total: 0.5192 s/iter. ETA=0:07:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1561/2473. Dataloading: 0.0310 s/iter. Inference: 0.4876 s/iter. Eval: 0.0005 s/iter. Total: 0.5192 s/iter. ETA=0:07:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1571/2473. Dataloading: 0.0310 s/iter. Inference: 0.4876 s/iter. Eval: 0.0005 s/iter. Total: 0.5192 s/iter. ETA=0:07:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1581/2473. Dataloading: 0.0310 s/iter. Inference: 0.4877 s/iter. Eval: 0.0005 s/iter. Total: 0.5193 s/iter. ETA=0:07:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1591/2473. Dataloading: 0.0310 s/iter. Inference: 0.4877 s/iter. Eval: 0.0005 s/iter. Total: 0.5193 s/iter. ETA=0:07:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1601/2473. Dataloading: 0.0310 s/iter. Inference: 0.4877 s/iter. Eval: 0.0005 s/iter. Total: 0.5194 s/iter. ETA=0:07:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1611/2473. Dataloading: 0.0311 s/iter. Inference: 0.4878 s/iter. Eval: 0.0005 s/iter. Total: 0.5195 s/iter. ETA=0:07:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1621/2473. Dataloading: 0.0311 s/iter. Inference: 0.4878 s/iter. Eval: 0.0005 s/iter. Total: 0.5195 s/iter. ETA=0:07:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1631/2473. Dataloading: 0.0311 s/iter. Inference: 0.4879 s/iter. Eval: 0.0005 s/iter. Total: 0.5196 s/iter. ETA=0:07:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1641/2473. Dataloading: 0.0311 s/iter. Inference: 0.4879 s/iter. Eval: 0.0005 s/iter. Total: 0.5196 s/iter. ETA=0:07:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1651/2473. Dataloading: 0.0311 s/iter. Inference: 0.4879 s/iter. Eval: 0.0005 s/iter. Total: 0.5197 s/iter. ETA=0:07:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1661/2473. Dataloading: 0.0311 s/iter. Inference: 0.4879 s/iter. Eval: 0.0005 s/iter. Total: 0.5197 s/iter. ETA=0:07:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1671/2473. Dataloading: 0.0311 s/iter. Inference: 0.4880 s/iter. Eval: 0.0005 s/iter. Total: 0.5197 s/iter. ETA=0:06:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1681/2473. Dataloading: 0.0311 s/iter. Inference: 0.4880 s/iter. Eval: 0.0005 s/iter. Total: 0.5198 s/iter. ETA=0:06:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1691/2473. Dataloading: 0.0311 s/iter. Inference: 0.4880 s/iter. Eval: 0.0005 s/iter. Total: 0.5198 s/iter. ETA=0:06:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1701/2473. Dataloading: 0.0312 s/iter. Inference: 0.4881 s/iter. Eval: 0.0005 s/iter. Total: 0.5198 s/iter. ETA=0:06:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1711/2473. Dataloading: 0.0312 s/iter. Inference: 0.4881 s/iter. Eval: 0.0005 s/iter. Total: 0.5199 s/iter. ETA=0:06:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1721/2473. Dataloading: 0.0312 s/iter. Inference: 0.4881 s/iter. Eval: 0.0005 s/iter. Total: 0.5199 s/iter. ETA=0:06:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1731/2473. Dataloading: 0.0311 s/iter. Inference: 0.4882 s/iter. Eval: 0.0005 s/iter. Total: 0.5199 s/iter. ETA=0:06:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1741/2473. Dataloading: 0.0312 s/iter. Inference: 0.4882 s/iter. Eval: 0.0005 s/iter. Total: 0.5200 s/iter. ETA=0:06:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1750/2473. Dataloading: 0.0313 s/iter. Inference: 0.4883 s/iter. Eval: 0.0005 s/iter. Total: 0.5202 s/iter. ETA=0:06:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1760/2473. Dataloading: 0.0314 s/iter. Inference: 0.4883 s/iter. Eval: 0.0005 s/iter. Total: 0.5203 s/iter. ETA=0:06:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1769/2473. Dataloading: 0.0315 s/iter. Inference: 0.4884 s/iter. Eval: 0.0005 s/iter. Total: 0.5206 s/iter. ETA=0:06:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1779/2473. Dataloading: 0.0316 s/iter. Inference: 0.4884 s/iter. Eval: 0.0005 s/iter. Total: 0.5207 s/iter. ETA=0:06:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1789/2473. Dataloading: 0.0317 s/iter. Inference: 0.4885 s/iter. Eval: 0.0005 s/iter. Total: 0.5208 s/iter. ETA=0:05:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1799/2473. Dataloading: 0.0316 s/iter. Inference: 0.4885 s/iter. Eval: 0.0005 s/iter. Total: 0.5208 s/iter. ETA=0:05:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1809/2473. Dataloading: 0.0316 s/iter. Inference: 0.4885 s/iter. Eval: 0.0005 s/iter. Total: 0.5208 s/iter. ETA=0:05:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1819/2473. Dataloading: 0.0317 s/iter. Inference: 0.4886 s/iter. Eval: 0.0005 s/iter. Total: 0.5209 s/iter. ETA=0:05:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1829/2473. Dataloading: 0.0317 s/iter. Inference: 0.4886 s/iter. Eval: 0.0005 s/iter. Total: 0.5209 s/iter. ETA=0:05:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1839/2473. Dataloading: 0.0317 s/iter. Inference: 0.4886 s/iter. Eval: 0.0005 s/iter. Total: 0.5210 s/iter. ETA=0:05:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1849/2473. Dataloading: 0.0317 s/iter. Inference: 0.4887 s/iter. Eval: 0.0005 s/iter. Total: 0.5210 s/iter. ETA=0:05:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1859/2473. Dataloading: 0.0317 s/iter. Inference: 0.4887 s/iter. Eval: 0.0005 s/iter. Total: 0.5210 s/iter. ETA=0:05:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1869/2473. Dataloading: 0.0317 s/iter. Inference: 0.4887 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:05:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1879/2473. Dataloading: 0.0317 s/iter. Inference: 0.4887 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:05:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1889/2473. Dataloading: 0.0317 s/iter. Inference: 0.4888 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:05:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1899/2473. Dataloading: 0.0317 s/iter. Inference: 0.4888 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:04:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1909/2473. Dataloading: 0.0317 s/iter. Inference: 0.4888 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:04:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1919/2473. Dataloading: 0.0317 s/iter. Inference: 0.4888 s/iter. Eval: 0.0005 s/iter. Total: 0.5211 s/iter. ETA=0:04:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1929/2473. Dataloading: 0.0317 s/iter. Inference: 0.4888 s/iter. Eval: 0.0005 s/iter. Total: 0.5212 s/iter. ETA=0:04:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1939/2473. Dataloading: 0.0317 s/iter. Inference: 0.4889 s/iter. Eval: 0.0005 s/iter. Total: 0.5212 s/iter. ETA=0:04:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1949/2473. Dataloading: 0.0317 s/iter. Inference: 0.4889 s/iter. Eval: 0.0005 s/iter. Total: 0.5213 s/iter. ETA=0:04:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1959/2473. Dataloading: 0.0317 s/iter. Inference: 0.4889 s/iter. Eval: 0.0005 s/iter. Total: 0.5213 s/iter. ETA=0:04:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1969/2473. Dataloading: 0.0317 s/iter. Inference: 0.4890 s/iter. Eval: 0.0005 s/iter. Total: 0.5213 s/iter. ETA=0:04:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1979/2473. Dataloading: 0.0317 s/iter. Inference: 0.4890 s/iter. Eval: 0.0005 s/iter. Total: 0.5214 s/iter. ETA=0:04:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1989/2473. Dataloading: 0.0317 s/iter. Inference: 0.4890 s/iter. Eval: 0.0005 s/iter. Total: 0.5214 s/iter. ETA=0:04:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1999/2473. Dataloading: 0.0317 s/iter. Inference: 0.4891 s/iter. Eval: 0.0005 s/iter. Total: 0.5214 s/iter. ETA=0:04:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2009/2473. Dataloading: 0.0317 s/iter. Inference: 0.4891 s/iter. Eval: 0.0005 s/iter. Total: 0.5215 s/iter. ETA=0:04:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2019/2473. Dataloading: 0.0317 s/iter. Inference: 0.4891 s/iter. Eval: 0.0005 s/iter. Total: 0.5215 s/iter. ETA=0:03:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2029/2473. Dataloading: 0.0317 s/iter. Inference: 0.4892 s/iter. Eval: 0.0005 s/iter. Total: 0.5215 s/iter. ETA=0:03:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2039/2473. Dataloading: 0.0318 s/iter. Inference: 0.4892 s/iter. Eval: 0.0005 s/iter. Total: 0.5216 s/iter. ETA=0:03:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2049/2473. Dataloading: 0.0318 s/iter. Inference: 0.4892 s/iter. Eval: 0.0005 s/iter. Total: 0.5216 s/iter. ETA=0:03:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2059/2473. Dataloading: 0.0318 s/iter. Inference: 0.4892 s/iter. Eval: 0.0005 s/iter. Total: 0.5217 s/iter. ETA=0:03:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2069/2473. Dataloading: 0.0318 s/iter. Inference: 0.4893 s/iter. Eval: 0.0005 s/iter. Total: 0.5217 s/iter. ETA=0:03:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2079/2473. Dataloading: 0.0318 s/iter. Inference: 0.4893 s/iter. Eval: 0.0005 s/iter. Total: 0.5217 s/iter. ETA=0:03:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2089/2473. Dataloading: 0.0318 s/iter. Inference: 0.4893 s/iter. Eval: 0.0005 s/iter. Total: 0.5218 s/iter. ETA=0:03:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2099/2473. Dataloading: 0.0318 s/iter. Inference: 0.4893 s/iter. Eval: 0.0005 s/iter. Total: 0.5218 s/iter. ETA=0:03:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2109/2473. Dataloading: 0.0318 s/iter. Inference: 0.4894 s/iter. Eval: 0.0005 s/iter. Total: 0.5218 s/iter. ETA=0:03:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2119/2473. Dataloading: 0.0318 s/iter. Inference: 0.4894 s/iter. Eval: 0.0005 s/iter. Total: 0.5219 s/iter. ETA=0:03:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2129/2473. Dataloading: 0.0318 s/iter. Inference: 0.4894 s/iter. Eval: 0.0005 s/iter. Total: 0.5219 s/iter. ETA=0:02:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2139/2473. Dataloading: 0.0319 s/iter. Inference: 0.4894 s/iter. Eval: 0.0005 s/iter. Total: 0.5219 s/iter. ETA=0:02:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2149/2473. Dataloading: 0.0319 s/iter. Inference: 0.4895 s/iter. Eval: 0.0005 s/iter. Total: 0.5220 s/iter. ETA=0:02:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2159/2473. Dataloading: 0.0319 s/iter. Inference: 0.4895 s/iter. Eval: 0.0005 s/iter. Total: 0.5220 s/iter. ETA=0:02:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2169/2473. Dataloading: 0.0319 s/iter. Inference: 0.4895 s/iter. Eval: 0.0005 s/iter. Total: 0.5220 s/iter. ETA=0:02:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2179/2473. Dataloading: 0.0319 s/iter. Inference: 0.4895 s/iter. Eval: 0.0005 s/iter. Total: 0.5221 s/iter. ETA=0:02:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2189/2473. Dataloading: 0.0319 s/iter. Inference: 0.4896 s/iter. Eval: 0.0005 s/iter. Total: 0.5221 s/iter. ETA=0:02:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2199/2473. Dataloading: 0.0319 s/iter. Inference: 0.4896 s/iter. Eval: 0.0005 s/iter. Total: 0.5221 s/iter. ETA=0:02:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2209/2473. Dataloading: 0.0319 s/iter. Inference: 0.4896 s/iter. Eval: 0.0005 s/iter. Total: 0.5222 s/iter. ETA=0:02:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2219/2473. Dataloading: 0.0319 s/iter. Inference: 0.4896 s/iter. Eval: 0.0005 s/iter. Total: 0.5222 s/iter. ETA=0:02:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2229/2473. Dataloading: 0.0319 s/iter. Inference: 0.4897 s/iter. Eval: 0.0005 s/iter. Total: 0.5222 s/iter. ETA=0:02:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2239/2473. Dataloading: 0.0319 s/iter. Inference: 0.4897 s/iter. Eval: 0.0005 s/iter. Total: 0.5222 s/iter. ETA=0:02:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2249/2473. Dataloading: 0.0319 s/iter. Inference: 0.4897 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2259/2473. Dataloading: 0.0319 s/iter. Inference: 0.4897 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2269/2473. Dataloading: 0.0319 s/iter. Inference: 0.4897 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2279/2473. Dataloading: 0.0319 s/iter. Inference: 0.4898 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2289/2473. Dataloading: 0.0319 s/iter. Inference: 0.4898 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2299/2473. Dataloading: 0.0319 s/iter. Inference: 0.4898 s/iter. Eval: 0.0005 s/iter. Total: 0.5223 s/iter. ETA=0:01:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2309/2473. Dataloading: 0.0319 s/iter. Inference: 0.4898 s/iter. Eval: 0.0005 s/iter. Total: 0.5224 s/iter. ETA=0:01:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2319/2473. Dataloading: 0.0319 s/iter. Inference: 0.4898 s/iter. Eval: 0.0005 s/iter. Total: 0.5224 s/iter. ETA=0:01:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2329/2473. Dataloading: 0.0319 s/iter. Inference: 0.4899 s/iter. Eval: 0.0005 s/iter. Total: 0.5224 s/iter. ETA=0:01:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2339/2473. Dataloading: 0.0319 s/iter. Inference: 0.4899 s/iter. Eval: 0.0005 s/iter. Total: 0.5225 s/iter. ETA=0:01:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2349/2473. Dataloading: 0.0319 s/iter. Inference: 0.4899 s/iter. Eval: 0.0005 s/iter. Total: 0.5225 s/iter. ETA=0:01:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2359/2473. Dataloading: 0.0320 s/iter. Inference: 0.4899 s/iter. Eval: 0.0005 s/iter. Total: 0.5225 s/iter. ETA=0:00:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2369/2473. Dataloading: 0.0319 s/iter. Inference: 0.4899 s/iter. Eval: 0.0005 s/iter. Total: 0.5225 s/iter. ETA=0:00:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2379/2473. Dataloading: 0.0320 s/iter. Inference: 0.4900 s/iter. Eval: 0.0005 s/iter. Total: 0.5226 s/iter. ETA=0:00:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2389/2473. Dataloading: 0.0320 s/iter. Inference: 0.4900 s/iter. Eval: 0.0005 s/iter. Total: 0.5226 s/iter. ETA=0:00:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2399/2473. Dataloading: 0.0320 s/iter. Inference: 0.4900 s/iter. Eval: 0.0005 s/iter. Total: 0.5227 s/iter. ETA=0:00:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2409/2473. Dataloading: 0.0320 s/iter. Inference: 0.4900 s/iter. Eval: 0.0005 s/iter. Total: 0.5227 s/iter. ETA=0:00:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2419/2473. Dataloading: 0.0320 s/iter. Inference: 0.4901 s/iter. Eval: 0.0005 s/iter. Total: 0.5227 s/iter. ETA=0:00:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2429/2473. Dataloading: 0.0320 s/iter. Inference: 0.4901 s/iter. Eval: 0.0005 s/iter. Total: 0.5227 s/iter. ETA=0:00:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2439/2473. Dataloading: 0.0320 s/iter. Inference: 0.4901 s/iter. Eval: 0.0005 s/iter. Total: 0.5228 s/iter. ETA=0:00:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2449/2473. Dataloading: 0.0320 s/iter. Inference: 0.4901 s/iter. Eval: 0.0005 s/iter. Total: 0.5228 s/iter. ETA=0:00:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2459/2473. Dataloading: 0.0320 s/iter. Inference: 0.4902 s/iter. Eval: 0.0005 s/iter. Total: 0.5228 s/iter. ETA=0:00:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2469/2473. Dataloading: 0.0320 s/iter. Inference: 0.4902 s/iter. Eval: 0.0005 s/iter. Total: 0.5229 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "               hold_obj: #GTs = 3608, AP = 0.3483\n",
      "                  stand: #GTs = 4118, AP = 0.7491\n",
      "              sit_instr: #GTs = 1916, AP = 0.3896\n",
      "             ride_instr: #GTs = 0556, AP = 0.4844\n",
      "                   walk: #GTs = 0597, AP = 0.4764\n",
      "               look_obj: #GTs = 3347, AP = 0.3360\n",
      "              hit_instr: #GTs = 0349, AP = 0.5331\n",
      "                hit_obj: #GTs = 0349, AP = 0.1892\n",
      "                eat_obj: #GTs = 0521, AP = 0.4527\n",
      "              eat_instr: #GTs = 0521, AP = 0.6312\n",
      "             jump_instr: #GTs = 0635, AP = 0.6612\n",
      "              lay_instr: #GTs = 0387, AP = 0.4775\n",
      "    talk_on_phone_instr: #GTs = 0285, AP = 0.2361\n",
      "              carry_obj: #GTs = 0472, AP = 0.2927\n",
      "              throw_obj: #GTs = 0244, AP = 0.2757\n",
      "              catch_obj: #GTs = 0246, AP = 0.3038\n",
      "              cut_instr: #GTs = 0269, AP = 0.1759\n",
      "                cut_obj: #GTs = 0269, AP = 0.5231\n",
      "                    run: #GTs = 0687, AP = 0.6768\n",
      " work_on_computer_instr: #GTs = 0410, AP = 0.5922\n",
      "              ski_instr: #GTs = 0424, AP = 0.3109\n",
      "             surf_instr: #GTs = 0486, AP = 0.6234\n",
      "       skateboard_instr: #GTs = 0417, AP = 0.6590\n",
      "                  smile: #GTs = 1415, AP = 0.7306\n",
      "            drink_instr: #GTs = 0082, AP = 0.2989\n",
      "               kick_obj: #GTs = 0180, AP = 0.6910\n",
      "            point_instr: #GTs = 0031, AP = 0.0117\n",
      "               read_obj: #GTs = 0111, AP = 0.3874\n",
      "        snowboard_instr: #GTs = 0277, AP = 0.6247\n",
      "------------------------------------------------------------\n",
      "mAP all: 0.4532 mAP thesis: 0.4374\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.default_trainer:{'vcoco_val/vcoco': {'AP_hold_obj': 0.3483403578158819, 'AP_stand': 0.749058574769091, 'AP_sit_instr': 0.3896438485535703, 'AP_ride_instr': 0.4843836571324491, 'AP_walk': 0.4763679007195397, 'AP_look_obj': 0.33598909310510644, 'AP_hit_instr': 0.5331438806295269, 'AP_hit_obj': 0.18923280115333918, 'AP_eat_obj': 0.4526988889337091, 'AP_eat_instr': 0.6312347122923342, 'AP_jump_instr': 0.6612438295423342, 'AP_lay_instr': 0.47753235134313365, 'AP_talk_on_phone_instr': 0.23609793073657673, 'AP_carry_obj': 0.29266659048476573, 'AP_throw_obj': 0.2756762000676301, 'AP_catch_obj': 0.30381678458873074, 'AP_cut_instr': 0.1758579932948957, 'AP_cut_obj': 0.5231306868206864, 'AP_run': 0.6767946793527677, 'AP_work_on_computer_instr': 0.5922039848335071, 'AP_ski_instr': 0.31092090684402635, 'AP_surf_instr': 0.6234337146248906, 'AP_skateboard_instr': 0.6589723199908812, 'AP_smile': 0.7306451894241708, 'AP_drink_instr': 0.2989242329683353, 'AP_kick_obj': 0.690995501189503, 'AP_point_instr': 0.011657605892414748, 'AP_read_obj': 0.38738099282896704, 'AP_snowboard_instr': 0.6246960504151235, 'mAP_all': 0.45319797449475485, 'mAP_thesis': 0.4374257212579127}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vcoco_val/vcoco': {'AP_hold_obj': 0.3483403578158819,\n",
       "  'AP_stand': 0.749058574769091,\n",
       "  'AP_sit_instr': 0.3896438485535703,\n",
       "  'AP_ride_instr': 0.4843836571324491,\n",
       "  'AP_walk': 0.4763679007195397,\n",
       "  'AP_look_obj': 0.33598909310510644,\n",
       "  'AP_hit_instr': 0.5331438806295269,\n",
       "  'AP_hit_obj': 0.18923280115333918,\n",
       "  'AP_eat_obj': 0.4526988889337091,\n",
       "  'AP_eat_instr': 0.6312347122923342,\n",
       "  'AP_jump_instr': 0.6612438295423342,\n",
       "  'AP_lay_instr': 0.47753235134313365,\n",
       "  'AP_talk_on_phone_instr': 0.23609793073657673,\n",
       "  'AP_carry_obj': 0.29266659048476573,\n",
       "  'AP_throw_obj': 0.2756762000676301,\n",
       "  'AP_catch_obj': 0.30381678458873074,\n",
       "  'AP_cut_instr': 0.1758579932948957,\n",
       "  'AP_cut_obj': 0.5231306868206864,\n",
       "  'AP_run': 0.6767946793527677,\n",
       "  'AP_work_on_computer_instr': 0.5922039848335071,\n",
       "  'AP_ski_instr': 0.31092090684402635,\n",
       "  'AP_surf_instr': 0.6234337146248906,\n",
       "  'AP_skateboard_instr': 0.6589723199908812,\n",
       "  'AP_smile': 0.7306451894241708,\n",
       "  'AP_drink_instr': 0.2989242329683353,\n",
       "  'AP_kick_obj': 0.690995501189503,\n",
       "  'AP_point_instr': 0.011657605892414748,\n",
       "  'AP_read_obj': 0.38738099282896704,\n",
       "  'AP_snowboard_instr': 0.6246960504151235,\n",
       "  'mAP_all': 0.45319797449475485,\n",
       "  'mAP_thesis': 0.4374257212579127}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "if cmdline_args.user_dir:\n",
    "    absolute_user_dir = os.path.abspath(cmdline_args.user_dir)\n",
    "    opt['base_path'] = absolute_user_dir\n",
    "trainer = Trainer(opt)\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, post_processor, data_loader, device, verb_classes, missing_category_id):\n",
    "    model.eval()\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    header = 'Generate:'\n",
    "\n",
    "    detections = []\n",
    "    for samples, targets in metric_logger.log_every(data_loader, 10, header):\n",
    "        samples = samples.to(device)\n",
    "\n",
    "        outputs = model(samples)\n",
    "        orig_target_sizes = torch.stack([t[\"orig_size\"] for t in targets], dim=0)\n",
    "\n",
    "        results = post_processor(outputs, orig_target_sizes)\n",
    "\n",
    "        for img_results, img_targets in zip(results, targets):\n",
    "            for hoi in img_results['hoi_prediction']:\n",
    "                detection = {\n",
    "                    'image_id': img_targets['img_id'],\n",
    "                    'person_box': img_results['predictions'][hoi['subject_id']]['bbox'].tolist()\n",
    "                }\n",
    "                if img_results['predictions'][hoi['object_id']]['category_id'] == missing_category_id:\n",
    "                    object_box = [np.nan, np.nan, np.nan, np.nan]\n",
    "                else:\n",
    "                    object_box = img_results['predictions'][hoi['object_id']]['bbox'].tolist()\n",
    "                cut_agent = 0\n",
    "                hit_agent = 0\n",
    "                eat_agent = 0\n",
    "                for idx, score in zip(hoi['category_id'], hoi['score']):\n",
    "                    verb_class = verb_classes[idx]\n",
    "                    score = score.item()\n",
    "                    if len(verb_class.split('_')) == 1:\n",
    "                        detection['{}_agent'.format(verb_class)] = score\n",
    "                    elif 'cut_' in verb_class:\n",
    "                        detection[verb_class] = object_box + [score]\n",
    "                        cut_agent = score if score > cut_agent else cut_agent\n",
    "                    elif 'hit_' in verb_class:\n",
    "                        detection[verb_class] = object_box + [score]\n",
    "                        hit_agent = score if score > hit_agent else hit_agent\n",
    "                    elif 'eat_' in verb_class:\n",
    "                        detection[verb_class] = object_box + [score]\n",
    "                        eat_agent = score if score > eat_agent else eat_agent\n",
    "                    else:\n",
    "                        detection[verb_class] = object_box + [score]\n",
    "                        detection['{}_agent'.format(\n",
    "                            verb_class.replace('_obj', '').replace('_instr', ''))] = score\n",
    "                detection['cut_agent'] = cut_agent\n",
    "                detection['hit_agent'] = hit_agent\n",
    "                detection['eat_agent'] = eat_agent\n",
    "                detections.append(detection)\n",
    "\n",
    "    return detections\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
