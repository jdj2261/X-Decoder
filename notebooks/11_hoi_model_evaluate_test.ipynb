{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_visual_HPE/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING:datasets.registration.register_vlp_datasets:WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.arguments:Overrided DONT_LOAD_MODEL from True to False\n"
     ]
    }
   ],
   "source": [
    "from utils.arguments import load_vcoco_opt_command, load_vcoco_parser\n",
    "\n",
    "cmdline_args = load_vcoco_parser()\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco.yaml\")]\n",
    "\n",
    "model_path = '../data/output/test/00089100/default/raw_model_states.pt'\n",
    "cmdline_args.overrides = ['DONT_LOAD_MODEL', 'false', 'PYLEARN_MODEL', model_path] \n",
    "\n",
    "opt = load_vcoco_opt_command(cmdline_args)\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(opt['base_path'])\n",
    "print(opt[\"RESUME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as data/output/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to data/output/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-----------------------------------------------\n",
      "INFO:trainer.default_trainer:Evaluating model ... \n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=96, out_features=196, bias=True)\n",
      "              (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (drop_path): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=388, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "            (drop_path): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.109)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.136)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.164)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.191)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.218)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=772, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "            (drop_path): DropPath(drop_prob=0.245)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.273)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1540, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
      "            (drop_path): DropPath(drop_prob=0.300)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): PostProcessHOI()\n",
      ")\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw1.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.dw2.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([384, 96]) <-> Ckpt Shape: torch.Size([384, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([96, 384]) <-> Ckpt Shape: torch.Size([96, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([196]) <-> Ckpt Shape: torch.Size([196])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([196, 96]) <-> Ckpt Shape: torch.Size([196, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([96, 1, 3, 3]) <-> Ckpt Shape: torch.Size([96, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([96, 1, 5, 5]) <-> Ckpt Shape: torch.Size([96, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([96, 1, 7, 7]) <-> Ckpt Shape: torch.Size([96, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([96, 96, 1, 1]) <-> Ckpt Shape: torch.Size([96, 96, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([96, 96]) <-> Ckpt Shape: torch.Size([96, 96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([192, 96, 3, 3]) <-> Ckpt Shape: torch.Size([192, 96, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw1.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.dw2.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([388]) <-> Ckpt Shape: torch.Size([388])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([388, 192]) <-> Ckpt Shape: torch.Size([388, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw1.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.dw2.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([772]) <-> Ckpt Shape: torch.Size([772])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([772, 384]) <-> Ckpt Shape: torch.Size([772, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw1.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.dw2.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([1540]) <-> Ckpt Shape: torch.Size([1540])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([1540, 768]) <-> Ckpt Shape: torch.Size([1540, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([96]) <-> Ckpt Shape: torch.Size([96])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([96, 3, 7, 7]) <-> Ckpt Shape: torch.Size([96, 3, 7, 7])\n",
      "INFO:utils.model:Loaded criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 96, 1, 1]) <-> Ckpt Shape: torch.Size([512, 96, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512]) <-> Ckpt Shape: torch.Size([82, 512])\n",
      "INFO:utils.model:Loaded hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512]) <-> Ckpt Shape: torch.Size([100, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29]) <-> Ckpt Shape: torch.Size([29])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512]) <-> Ckpt Shape: torch.Size([29, 512])\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.69 MiB\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/2473. Dataloading: 0.1034 s/iter. Inference: 0.4816 s/iter. Eval: 0.0013 s/iter. Total: 0.5863 s/iter. ETA=0:24:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 20/2473. Dataloading: 0.0859 s/iter. Inference: 0.4807 s/iter. Eval: 0.0015 s/iter. Total: 0.5683 s/iter. ETA=0:23:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 29/2473. Dataloading: 0.0823 s/iter. Inference: 0.4816 s/iter. Eval: 0.0013 s/iter. Total: 0.5658 s/iter. ETA=0:23:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 39/2473. Dataloading: 0.0682 s/iter. Inference: 0.4811 s/iter. Eval: 0.0011 s/iter. Total: 0.5509 s/iter. ETA=0:22:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 49/2473. Dataloading: 0.0603 s/iter. Inference: 0.4815 s/iter. Eval: 0.0010 s/iter. Total: 0.5432 s/iter. ETA=0:21:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 59/2473. Dataloading: 0.0551 s/iter. Inference: 0.4820 s/iter. Eval: 0.0009 s/iter. Total: 0.5383 s/iter. ETA=0:21:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 69/2473. Dataloading: 0.0514 s/iter. Inference: 0.4825 s/iter. Eval: 0.0008 s/iter. Total: 0.5350 s/iter. ETA=0:21:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 79/2473. Dataloading: 0.0487 s/iter. Inference: 0.4830 s/iter. Eval: 0.0008 s/iter. Total: 0.5328 s/iter. ETA=0:21:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 89/2473. Dataloading: 0.0468 s/iter. Inference: 0.4836 s/iter. Eval: 0.0007 s/iter. Total: 0.5314 s/iter. ETA=0:21:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 99/2473. Dataloading: 0.0455 s/iter. Inference: 0.4841 s/iter. Eval: 0.0007 s/iter. Total: 0.5306 s/iter. ETA=0:20:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 109/2473. Dataloading: 0.0444 s/iter. Inference: 0.4846 s/iter. Eval: 0.0007 s/iter. Total: 0.5300 s/iter. ETA=0:20:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 119/2473. Dataloading: 0.0432 s/iter. Inference: 0.4852 s/iter. Eval: 0.0007 s/iter. Total: 0.5294 s/iter. ETA=0:20:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 129/2473. Dataloading: 0.0423 s/iter. Inference: 0.4856 s/iter. Eval: 0.0007 s/iter. Total: 0.5289 s/iter. ETA=0:20:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 139/2473. Dataloading: 0.0416 s/iter. Inference: 0.4861 s/iter. Eval: 0.0007 s/iter. Total: 0.5286 s/iter. ETA=0:20:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 149/2473. Dataloading: 0.0409 s/iter. Inference: 0.4865 s/iter. Eval: 0.0007 s/iter. Total: 0.5282 s/iter. ETA=0:20:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 159/2473. Dataloading: 0.0404 s/iter. Inference: 0.4868 s/iter. Eval: 0.0007 s/iter. Total: 0.5280 s/iter. ETA=0:20:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 169/2473. Dataloading: 0.0398 s/iter. Inference: 0.4871 s/iter. Eval: 0.0007 s/iter. Total: 0.5277 s/iter. ETA=0:20:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 179/2473. Dataloading: 0.0395 s/iter. Inference: 0.4874 s/iter. Eval: 0.0007 s/iter. Total: 0.5278 s/iter. ETA=0:20:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 189/2473. Dataloading: 0.0393 s/iter. Inference: 0.4877 s/iter. Eval: 0.0007 s/iter. Total: 0.5279 s/iter. ETA=0:20:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 199/2473. Dataloading: 0.0392 s/iter. Inference: 0.4880 s/iter. Eval: 0.0007 s/iter. Total: 0.5280 s/iter. ETA=0:20:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 209/2473. Dataloading: 0.0392 s/iter. Inference: 0.4883 s/iter. Eval: 0.0007 s/iter. Total: 0.5284 s/iter. ETA=0:19:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 219/2473. Dataloading: 0.0391 s/iter. Inference: 0.4886 s/iter. Eval: 0.0007 s/iter. Total: 0.5285 s/iter. ETA=0:19:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 229/2473. Dataloading: 0.0390 s/iter. Inference: 0.4888 s/iter. Eval: 0.0007 s/iter. Total: 0.5287 s/iter. ETA=0:19:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 239/2473. Dataloading: 0.0387 s/iter. Inference: 0.4891 s/iter. Eval: 0.0007 s/iter. Total: 0.5287 s/iter. ETA=0:19:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 249/2473. Dataloading: 0.0386 s/iter. Inference: 0.4894 s/iter. Eval: 0.0007 s/iter. Total: 0.5289 s/iter. ETA=0:19:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 259/2473. Dataloading: 0.0385 s/iter. Inference: 0.4897 s/iter. Eval: 0.0007 s/iter. Total: 0.5290 s/iter. ETA=0:19:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 269/2473. Dataloading: 0.0382 s/iter. Inference: 0.4899 s/iter. Eval: 0.0007 s/iter. Total: 0.5290 s/iter. ETA=0:19:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 279/2473. Dataloading: 0.0380 s/iter. Inference: 0.4901 s/iter. Eval: 0.0006 s/iter. Total: 0.5290 s/iter. ETA=0:19:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 289/2473. Dataloading: 0.0377 s/iter. Inference: 0.4903 s/iter. Eval: 0.0006 s/iter. Total: 0.5288 s/iter. ETA=0:19:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 299/2473. Dataloading: 0.0374 s/iter. Inference: 0.4904 s/iter. Eval: 0.0006 s/iter. Total: 0.5287 s/iter. ETA=0:19:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 309/2473. Dataloading: 0.0371 s/iter. Inference: 0.4905 s/iter. Eval: 0.0006 s/iter. Total: 0.5285 s/iter. ETA=0:19:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 319/2473. Dataloading: 0.0369 s/iter. Inference: 0.4906 s/iter. Eval: 0.0006 s/iter. Total: 0.5283 s/iter. ETA=0:18:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 329/2473. Dataloading: 0.0368 s/iter. Inference: 0.4907 s/iter. Eval: 0.0006 s/iter. Total: 0.5284 s/iter. ETA=0:18:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 339/2473. Dataloading: 0.0369 s/iter. Inference: 0.4908 s/iter. Eval: 0.0006 s/iter. Total: 0.5285 s/iter. ETA=0:18:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 349/2473. Dataloading: 0.0369 s/iter. Inference: 0.4910 s/iter. Eval: 0.0006 s/iter. Total: 0.5288 s/iter. ETA=0:18:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 359/2473. Dataloading: 0.0369 s/iter. Inference: 0.4912 s/iter. Eval: 0.0006 s/iter. Total: 0.5289 s/iter. ETA=0:18:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 369/2473. Dataloading: 0.0366 s/iter. Inference: 0.4913 s/iter. Eval: 0.0006 s/iter. Total: 0.5287 s/iter. ETA=0:18:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 379/2473. Dataloading: 0.0363 s/iter. Inference: 0.4914 s/iter. Eval: 0.0006 s/iter. Total: 0.5286 s/iter. ETA=0:18:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 389/2473. Dataloading: 0.0360 s/iter. Inference: 0.4915 s/iter. Eval: 0.0006 s/iter. Total: 0.5284 s/iter. ETA=0:18:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 399/2473. Dataloading: 0.0358 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5281 s/iter. ETA=0:18:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 409/2473. Dataloading: 0.0355 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5279 s/iter. ETA=0:18:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 419/2473. Dataloading: 0.0353 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5277 s/iter. ETA=0:18:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 429/2473. Dataloading: 0.0350 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5275 s/iter. ETA=0:17:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 439/2473. Dataloading: 0.0348 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5273 s/iter. ETA=0:17:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 449/2473. Dataloading: 0.0346 s/iter. Inference: 0.4916 s/iter. Eval: 0.0006 s/iter. Total: 0.5271 s/iter. ETA=0:17:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 459/2473. Dataloading: 0.0346 s/iter. Inference: 0.4917 s/iter. Eval: 0.0006 s/iter. Total: 0.5270 s/iter. ETA=0:17:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 469/2473. Dataloading: 0.0344 s/iter. Inference: 0.4917 s/iter. Eval: 0.0006 s/iter. Total: 0.5268 s/iter. ETA=0:17:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 479/2473. Dataloading: 0.0343 s/iter. Inference: 0.4917 s/iter. Eval: 0.0006 s/iter. Total: 0.5267 s/iter. ETA=0:17:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 489/2473. Dataloading: 0.0342 s/iter. Inference: 0.4917 s/iter. Eval: 0.0006 s/iter. Total: 0.5267 s/iter. ETA=0:17:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 499/2473. Dataloading: 0.0342 s/iter. Inference: 0.4918 s/iter. Eval: 0.0006 s/iter. Total: 0.5267 s/iter. ETA=0:17:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 509/2473. Dataloading: 0.0341 s/iter. Inference: 0.4918 s/iter. Eval: 0.0006 s/iter. Total: 0.5266 s/iter. ETA=0:17:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 519/2473. Dataloading: 0.0341 s/iter. Inference: 0.4918 s/iter. Eval: 0.0006 s/iter. Total: 0.5266 s/iter. ETA=0:17:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 529/2473. Dataloading: 0.0340 s/iter. Inference: 0.4918 s/iter. Eval: 0.0006 s/iter. Total: 0.5266 s/iter. ETA=0:17:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 539/2473. Dataloading: 0.0339 s/iter. Inference: 0.4919 s/iter. Eval: 0.0006 s/iter. Total: 0.5265 s/iter. ETA=0:16:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 549/2473. Dataloading: 0.0337 s/iter. Inference: 0.4919 s/iter. Eval: 0.0006 s/iter. Total: 0.5264 s/iter. ETA=0:16:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 559/2473. Dataloading: 0.0337 s/iter. Inference: 0.4919 s/iter. Eval: 0.0006 s/iter. Total: 0.5264 s/iter. ETA=0:16:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 569/2473. Dataloading: 0.0336 s/iter. Inference: 0.4920 s/iter. Eval: 0.0006 s/iter. Total: 0.5263 s/iter. ETA=0:16:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 579/2473. Dataloading: 0.0335 s/iter. Inference: 0.4920 s/iter. Eval: 0.0006 s/iter. Total: 0.5263 s/iter. ETA=0:16:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 589/2473. Dataloading: 0.0335 s/iter. Inference: 0.4920 s/iter. Eval: 0.0006 s/iter. Total: 0.5263 s/iter. ETA=0:16:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 599/2473. Dataloading: 0.0334 s/iter. Inference: 0.4921 s/iter. Eval: 0.0006 s/iter. Total: 0.5262 s/iter. ETA=0:16:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 609/2473. Dataloading: 0.0333 s/iter. Inference: 0.4921 s/iter. Eval: 0.0006 s/iter. Total: 0.5262 s/iter. ETA=0:16:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 619/2473. Dataloading: 0.0332 s/iter. Inference: 0.4922 s/iter. Eval: 0.0006 s/iter. Total: 0.5261 s/iter. ETA=0:16:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 629/2473. Dataloading: 0.0332 s/iter. Inference: 0.4922 s/iter. Eval: 0.0006 s/iter. Total: 0.5261 s/iter. ETA=0:16:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 639/2473. Dataloading: 0.0331 s/iter. Inference: 0.4922 s/iter. Eval: 0.0006 s/iter. Total: 0.5261 s/iter. ETA=0:16:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 649/2473. Dataloading: 0.0330 s/iter. Inference: 0.4923 s/iter. Eval: 0.0006 s/iter. Total: 0.5260 s/iter. ETA=0:15:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 659/2473. Dataloading: 0.0329 s/iter. Inference: 0.4923 s/iter. Eval: 0.0006 s/iter. Total: 0.5260 s/iter. ETA=0:15:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 669/2473. Dataloading: 0.0329 s/iter. Inference: 0.4923 s/iter. Eval: 0.0006 s/iter. Total: 0.5259 s/iter. ETA=0:15:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 679/2473. Dataloading: 0.0328 s/iter. Inference: 0.4924 s/iter. Eval: 0.0006 s/iter. Total: 0.5259 s/iter. ETA=0:15:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 689/2473. Dataloading: 0.0328 s/iter. Inference: 0.4924 s/iter. Eval: 0.0006 s/iter. Total: 0.5259 s/iter. ETA=0:15:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 699/2473. Dataloading: 0.0327 s/iter. Inference: 0.4924 s/iter. Eval: 0.0006 s/iter. Total: 0.5258 s/iter. ETA=0:15:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 709/2473. Dataloading: 0.0327 s/iter. Inference: 0.4925 s/iter. Eval: 0.0006 s/iter. Total: 0.5259 s/iter. ETA=0:15:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 719/2473. Dataloading: 0.0327 s/iter. Inference: 0.4925 s/iter. Eval: 0.0006 s/iter. Total: 0.5260 s/iter. ETA=0:15:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 729/2473. Dataloading: 0.0328 s/iter. Inference: 0.4925 s/iter. Eval: 0.0006 s/iter. Total: 0.5261 s/iter. ETA=0:15:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 739/2473. Dataloading: 0.0329 s/iter. Inference: 0.4926 s/iter. Eval: 0.0006 s/iter. Total: 0.5262 s/iter. ETA=0:15:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 749/2473. Dataloading: 0.0331 s/iter. Inference: 0.4927 s/iter. Eval: 0.0006 s/iter. Total: 0.5265 s/iter. ETA=0:15:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 759/2473. Dataloading: 0.0331 s/iter. Inference: 0.4928 s/iter. Eval: 0.0006 s/iter. Total: 0.5266 s/iter. ETA=0:15:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 769/2473. Dataloading: 0.0332 s/iter. Inference: 0.4928 s/iter. Eval: 0.0006 s/iter. Total: 0.5268 s/iter. ETA=0:14:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 779/2473. Dataloading: 0.0333 s/iter. Inference: 0.4929 s/iter. Eval: 0.0006 s/iter. Total: 0.5269 s/iter. ETA=0:14:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 789/2473. Dataloading: 0.0333 s/iter. Inference: 0.4930 s/iter. Eval: 0.0006 s/iter. Total: 0.5270 s/iter. ETA=0:14:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 799/2473. Dataloading: 0.0332 s/iter. Inference: 0.4931 s/iter. Eval: 0.0006 s/iter. Total: 0.5271 s/iter. ETA=0:14:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 809/2473. Dataloading: 0.0333 s/iter. Inference: 0.4932 s/iter. Eval: 0.0006 s/iter. Total: 0.5272 s/iter. ETA=0:14:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 819/2473. Dataloading: 0.0333 s/iter. Inference: 0.4932 s/iter. Eval: 0.0006 s/iter. Total: 0.5273 s/iter. ETA=0:14:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 829/2473. Dataloading: 0.0333 s/iter. Inference: 0.4933 s/iter. Eval: 0.0006 s/iter. Total: 0.5274 s/iter. ETA=0:14:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 839/2473. Dataloading: 0.0334 s/iter. Inference: 0.4934 s/iter. Eval: 0.0006 s/iter. Total: 0.5275 s/iter. ETA=0:14:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 849/2473. Dataloading: 0.0335 s/iter. Inference: 0.4934 s/iter. Eval: 0.0006 s/iter. Total: 0.5276 s/iter. ETA=0:14:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 859/2473. Dataloading: 0.0335 s/iter. Inference: 0.4935 s/iter. Eval: 0.0006 s/iter. Total: 0.5277 s/iter. ETA=0:14:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 869/2473. Dataloading: 0.0336 s/iter. Inference: 0.4935 s/iter. Eval: 0.0006 s/iter. Total: 0.5279 s/iter. ETA=0:14:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 879/2473. Dataloading: 0.0336 s/iter. Inference: 0.4936 s/iter. Eval: 0.0006 s/iter. Total: 0.5280 s/iter. ETA=0:14:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 889/2473. Dataloading: 0.0336 s/iter. Inference: 0.4937 s/iter. Eval: 0.0006 s/iter. Total: 0.5281 s/iter. ETA=0:13:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 899/2473. Dataloading: 0.0337 s/iter. Inference: 0.4938 s/iter. Eval: 0.0006 s/iter. Total: 0.5282 s/iter. ETA=0:13:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 909/2473. Dataloading: 0.0337 s/iter. Inference: 0.4939 s/iter. Eval: 0.0006 s/iter. Total: 0.5283 s/iter. ETA=0:13:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 919/2473. Dataloading: 0.0338 s/iter. Inference: 0.4939 s/iter. Eval: 0.0006 s/iter. Total: 0.5284 s/iter. ETA=0:13:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 929/2473. Dataloading: 0.0338 s/iter. Inference: 0.4940 s/iter. Eval: 0.0006 s/iter. Total: 0.5286 s/iter. ETA=0:13:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 939/2473. Dataloading: 0.0339 s/iter. Inference: 0.4941 s/iter. Eval: 0.0006 s/iter. Total: 0.5288 s/iter. ETA=0:13:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 949/2473. Dataloading: 0.0339 s/iter. Inference: 0.4942 s/iter. Eval: 0.0006 s/iter. Total: 0.5289 s/iter. ETA=0:13:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 959/2473. Dataloading: 0.0340 s/iter. Inference: 0.4943 s/iter. Eval: 0.0006 s/iter. Total: 0.5290 s/iter. ETA=0:13:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 969/2473. Dataloading: 0.0340 s/iter. Inference: 0.4944 s/iter. Eval: 0.0006 s/iter. Total: 0.5292 s/iter. ETA=0:13:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 979/2473. Dataloading: 0.0341 s/iter. Inference: 0.4945 s/iter. Eval: 0.0006 s/iter. Total: 0.5293 s/iter. ETA=0:13:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 989/2473. Dataloading: 0.0342 s/iter. Inference: 0.4946 s/iter. Eval: 0.0006 s/iter. Total: 0.5295 s/iter. ETA=0:13:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 999/2473. Dataloading: 0.0343 s/iter. Inference: 0.4947 s/iter. Eval: 0.0006 s/iter. Total: 0.5297 s/iter. ETA=0:13:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1009/2473. Dataloading: 0.0343 s/iter. Inference: 0.4947 s/iter. Eval: 0.0006 s/iter. Total: 0.5298 s/iter. ETA=0:12:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1019/2473. Dataloading: 0.0344 s/iter. Inference: 0.4948 s/iter. Eval: 0.0006 s/iter. Total: 0.5300 s/iter. ETA=0:12:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1029/2473. Dataloading: 0.0345 s/iter. Inference: 0.4949 s/iter. Eval: 0.0006 s/iter. Total: 0.5301 s/iter. ETA=0:12:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1039/2473. Dataloading: 0.0345 s/iter. Inference: 0.4950 s/iter. Eval: 0.0006 s/iter. Total: 0.5303 s/iter. ETA=0:12:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1049/2473. Dataloading: 0.0347 s/iter. Inference: 0.4951 s/iter. Eval: 0.0006 s/iter. Total: 0.5305 s/iter. ETA=0:12:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1059/2473. Dataloading: 0.0347 s/iter. Inference: 0.4952 s/iter. Eval: 0.0006 s/iter. Total: 0.5306 s/iter. ETA=0:12:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1069/2473. Dataloading: 0.0348 s/iter. Inference: 0.4953 s/iter. Eval: 0.0006 s/iter. Total: 0.5308 s/iter. ETA=0:12:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1079/2473. Dataloading: 0.0348 s/iter. Inference: 0.4953 s/iter. Eval: 0.0006 s/iter. Total: 0.5309 s/iter. ETA=0:12:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1089/2473. Dataloading: 0.0349 s/iter. Inference: 0.4954 s/iter. Eval: 0.0006 s/iter. Total: 0.5310 s/iter. ETA=0:12:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1099/2473. Dataloading: 0.0349 s/iter. Inference: 0.4955 s/iter. Eval: 0.0006 s/iter. Total: 0.5311 s/iter. ETA=0:12:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1109/2473. Dataloading: 0.0349 s/iter. Inference: 0.4956 s/iter. Eval: 0.0006 s/iter. Total: 0.5312 s/iter. ETA=0:12:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1119/2473. Dataloading: 0.0350 s/iter. Inference: 0.4956 s/iter. Eval: 0.0006 s/iter. Total: 0.5314 s/iter. ETA=0:11:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1129/2473. Dataloading: 0.0350 s/iter. Inference: 0.4957 s/iter. Eval: 0.0006 s/iter. Total: 0.5315 s/iter. ETA=0:11:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1139/2473. Dataloading: 0.0351 s/iter. Inference: 0.4958 s/iter. Eval: 0.0006 s/iter. Total: 0.5316 s/iter. ETA=0:11:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1149/2473. Dataloading: 0.0351 s/iter. Inference: 0.4959 s/iter. Eval: 0.0006 s/iter. Total: 0.5317 s/iter. ETA=0:11:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1158/2473. Dataloading: 0.0354 s/iter. Inference: 0.4959 s/iter. Eval: 0.0006 s/iter. Total: 0.5320 s/iter. ETA=0:11:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1167/2473. Dataloading: 0.0355 s/iter. Inference: 0.4960 s/iter. Eval: 0.0006 s/iter. Total: 0.5322 s/iter. ETA=0:11:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1176/2473. Dataloading: 0.0357 s/iter. Inference: 0.4960 s/iter. Eval: 0.0006 s/iter. Total: 0.5326 s/iter. ETA=0:11:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1185/2473. Dataloading: 0.0359 s/iter. Inference: 0.4961 s/iter. Eval: 0.0006 s/iter. Total: 0.5328 s/iter. ETA=0:11:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1195/2473. Dataloading: 0.0359 s/iter. Inference: 0.4962 s/iter. Eval: 0.0006 s/iter. Total: 0.5329 s/iter. ETA=0:11:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1204/2473. Dataloading: 0.0360 s/iter. Inference: 0.4963 s/iter. Eval: 0.0006 s/iter. Total: 0.5331 s/iter. ETA=0:11:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1214/2473. Dataloading: 0.0361 s/iter. Inference: 0.4964 s/iter. Eval: 0.0006 s/iter. Total: 0.5332 s/iter. ETA=0:11:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1223/2473. Dataloading: 0.0363 s/iter. Inference: 0.4964 s/iter. Eval: 0.0006 s/iter. Total: 0.5335 s/iter. ETA=0:11:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1232/2473. Dataloading: 0.0364 s/iter. Inference: 0.4965 s/iter. Eval: 0.0006 s/iter. Total: 0.5337 s/iter. ETA=0:11:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1241/2473. Dataloading: 0.0366 s/iter. Inference: 0.4966 s/iter. Eval: 0.0006 s/iter. Total: 0.5339 s/iter. ETA=0:10:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1250/2473. Dataloading: 0.0367 s/iter. Inference: 0.4967 s/iter. Eval: 0.0006 s/iter. Total: 0.5342 s/iter. ETA=0:10:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1259/2473. Dataloading: 0.0369 s/iter. Inference: 0.4967 s/iter. Eval: 0.0006 s/iter. Total: 0.5344 s/iter. ETA=0:10:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1269/2473. Dataloading: 0.0369 s/iter. Inference: 0.4968 s/iter. Eval: 0.0006 s/iter. Total: 0.5345 s/iter. ETA=0:10:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1279/2473. Dataloading: 0.0370 s/iter. Inference: 0.4969 s/iter. Eval: 0.0006 s/iter. Total: 0.5347 s/iter. ETA=0:10:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1288/2473. Dataloading: 0.0371 s/iter. Inference: 0.4970 s/iter. Eval: 0.0006 s/iter. Total: 0.5348 s/iter. ETA=0:10:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1297/2473. Dataloading: 0.0371 s/iter. Inference: 0.4971 s/iter. Eval: 0.0006 s/iter. Total: 0.5350 s/iter. ETA=0:10:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1307/2473. Dataloading: 0.0372 s/iter. Inference: 0.4971 s/iter. Eval: 0.0006 s/iter. Total: 0.5351 s/iter. ETA=0:10:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1316/2473. Dataloading: 0.0374 s/iter. Inference: 0.4972 s/iter. Eval: 0.0006 s/iter. Total: 0.5354 s/iter. ETA=0:10:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1325/2473. Dataloading: 0.0375 s/iter. Inference: 0.4972 s/iter. Eval: 0.0006 s/iter. Total: 0.5356 s/iter. ETA=0:10:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1334/2473. Dataloading: 0.0377 s/iter. Inference: 0.4973 s/iter. Eval: 0.0006 s/iter. Total: 0.5358 s/iter. ETA=0:10:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1343/2473. Dataloading: 0.0378 s/iter. Inference: 0.4974 s/iter. Eval: 0.0006 s/iter. Total: 0.5359 s/iter. ETA=0:10:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1352/2473. Dataloading: 0.0379 s/iter. Inference: 0.4974 s/iter. Eval: 0.0006 s/iter. Total: 0.5361 s/iter. ETA=0:10:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1361/2473. Dataloading: 0.0380 s/iter. Inference: 0.4975 s/iter. Eval: 0.0006 s/iter. Total: 0.5363 s/iter. ETA=0:09:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1370/2473. Dataloading: 0.0380 s/iter. Inference: 0.4976 s/iter. Eval: 0.0006 s/iter. Total: 0.5364 s/iter. ETA=0:09:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1380/2473. Dataloading: 0.0381 s/iter. Inference: 0.4976 s/iter. Eval: 0.0006 s/iter. Total: 0.5366 s/iter. ETA=0:09:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1389/2473. Dataloading: 0.0382 s/iter. Inference: 0.4977 s/iter. Eval: 0.0006 s/iter. Total: 0.5367 s/iter. ETA=0:09:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1398/2473. Dataloading: 0.0383 s/iter. Inference: 0.4978 s/iter. Eval: 0.0006 s/iter. Total: 0.5369 s/iter. ETA=0:09:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1407/2473. Dataloading: 0.0384 s/iter. Inference: 0.4978 s/iter. Eval: 0.0006 s/iter. Total: 0.5371 s/iter. ETA=0:09:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1416/2473. Dataloading: 0.0385 s/iter. Inference: 0.4979 s/iter. Eval: 0.0006 s/iter. Total: 0.5372 s/iter. ETA=0:09:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1425/2473. Dataloading: 0.0386 s/iter. Inference: 0.4980 s/iter. Eval: 0.0006 s/iter. Total: 0.5374 s/iter. ETA=0:09:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1434/2473. Dataloading: 0.0388 s/iter. Inference: 0.4980 s/iter. Eval: 0.0006 s/iter. Total: 0.5376 s/iter. ETA=0:09:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1443/2473. Dataloading: 0.0389 s/iter. Inference: 0.4981 s/iter. Eval: 0.0006 s/iter. Total: 0.5379 s/iter. ETA=0:09:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1452/2473. Dataloading: 0.0391 s/iter. Inference: 0.4982 s/iter. Eval: 0.0007 s/iter. Total: 0.5381 s/iter. ETA=0:09:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1461/2473. Dataloading: 0.0392 s/iter. Inference: 0.4982 s/iter. Eval: 0.0007 s/iter. Total: 0.5382 s/iter. ETA=0:09:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1470/2473. Dataloading: 0.0393 s/iter. Inference: 0.4983 s/iter. Eval: 0.0007 s/iter. Total: 0.5384 s/iter. ETA=0:09:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1479/2473. Dataloading: 0.0394 s/iter. Inference: 0.4983 s/iter. Eval: 0.0007 s/iter. Total: 0.5385 s/iter. ETA=0:08:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1488/2473. Dataloading: 0.0396 s/iter. Inference: 0.4984 s/iter. Eval: 0.0007 s/iter. Total: 0.5389 s/iter. ETA=0:08:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1497/2473. Dataloading: 0.0398 s/iter. Inference: 0.4984 s/iter. Eval: 0.0007 s/iter. Total: 0.5391 s/iter. ETA=0:08:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1506/2473. Dataloading: 0.0399 s/iter. Inference: 0.4985 s/iter. Eval: 0.0007 s/iter. Total: 0.5393 s/iter. ETA=0:08:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1515/2473. Dataloading: 0.0400 s/iter. Inference: 0.4986 s/iter. Eval: 0.0007 s/iter. Total: 0.5394 s/iter. ETA=0:08:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1524/2473. Dataloading: 0.0401 s/iter. Inference: 0.4986 s/iter. Eval: 0.0007 s/iter. Total: 0.5396 s/iter. ETA=0:08:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1533/2473. Dataloading: 0.0403 s/iter. Inference: 0.4987 s/iter. Eval: 0.0007 s/iter. Total: 0.5398 s/iter. ETA=0:08:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1542/2473. Dataloading: 0.0403 s/iter. Inference: 0.4987 s/iter. Eval: 0.0007 s/iter. Total: 0.5399 s/iter. ETA=0:08:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1552/2473. Dataloading: 0.0404 s/iter. Inference: 0.4988 s/iter. Eval: 0.0007 s/iter. Total: 0.5400 s/iter. ETA=0:08:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1561/2473. Dataloading: 0.0404 s/iter. Inference: 0.4989 s/iter. Eval: 0.0007 s/iter. Total: 0.5401 s/iter. ETA=0:08:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1570/2473. Dataloading: 0.0405 s/iter. Inference: 0.4989 s/iter. Eval: 0.0007 s/iter. Total: 0.5402 s/iter. ETA=0:08:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1579/2473. Dataloading: 0.0406 s/iter. Inference: 0.4990 s/iter. Eval: 0.0007 s/iter. Total: 0.5404 s/iter. ETA=0:08:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1588/2473. Dataloading: 0.0407 s/iter. Inference: 0.4990 s/iter. Eval: 0.0007 s/iter. Total: 0.5406 s/iter. ETA=0:07:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1597/2473. Dataloading: 0.0407 s/iter. Inference: 0.4991 s/iter. Eval: 0.0007 s/iter. Total: 0.5407 s/iter. ETA=0:07:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1606/2473. Dataloading: 0.0408 s/iter. Inference: 0.4991 s/iter. Eval: 0.0007 s/iter. Total: 0.5408 s/iter. ETA=0:07:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1615/2473. Dataloading: 0.0410 s/iter. Inference: 0.4992 s/iter. Eval: 0.0007 s/iter. Total: 0.5410 s/iter. ETA=0:07:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1624/2473. Dataloading: 0.0411 s/iter. Inference: 0.4992 s/iter. Eval: 0.0007 s/iter. Total: 0.5412 s/iter. ETA=0:07:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1633/2473. Dataloading: 0.0413 s/iter. Inference: 0.4992 s/iter. Eval: 0.0007 s/iter. Total: 0.5415 s/iter. ETA=0:07:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1642/2473. Dataloading: 0.0414 s/iter. Inference: 0.4993 s/iter. Eval: 0.0007 s/iter. Total: 0.5415 s/iter. ETA=0:07:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1651/2473. Dataloading: 0.0414 s/iter. Inference: 0.4994 s/iter. Eval: 0.0007 s/iter. Total: 0.5416 s/iter. ETA=0:07:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1661/2473. Dataloading: 0.0414 s/iter. Inference: 0.4994 s/iter. Eval: 0.0007 s/iter. Total: 0.5417 s/iter. ETA=0:07:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1670/2473. Dataloading: 0.0415 s/iter. Inference: 0.4995 s/iter. Eval: 0.0007 s/iter. Total: 0.5418 s/iter. ETA=0:07:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1679/2473. Dataloading: 0.0415 s/iter. Inference: 0.4995 s/iter. Eval: 0.0007 s/iter. Total: 0.5419 s/iter. ETA=0:07:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1688/2473. Dataloading: 0.0416 s/iter. Inference: 0.4996 s/iter. Eval: 0.0007 s/iter. Total: 0.5420 s/iter. ETA=0:07:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1697/2473. Dataloading: 0.0418 s/iter. Inference: 0.4996 s/iter. Eval: 0.0007 s/iter. Total: 0.5423 s/iter. ETA=0:07:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1706/2473. Dataloading: 0.0418 s/iter. Inference: 0.4997 s/iter. Eval: 0.0007 s/iter. Total: 0.5424 s/iter. ETA=0:06:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1716/2473. Dataloading: 0.0418 s/iter. Inference: 0.4997 s/iter. Eval: 0.0007 s/iter. Total: 0.5424 s/iter. ETA=0:06:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1725/2473. Dataloading: 0.0419 s/iter. Inference: 0.4997 s/iter. Eval: 0.0007 s/iter. Total: 0.5426 s/iter. ETA=0:06:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1734/2473. Dataloading: 0.0420 s/iter. Inference: 0.4998 s/iter. Eval: 0.0007 s/iter. Total: 0.5427 s/iter. ETA=0:06:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1743/2473. Dataloading: 0.0421 s/iter. Inference: 0.4998 s/iter. Eval: 0.0007 s/iter. Total: 0.5428 s/iter. ETA=0:06:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1752/2473. Dataloading: 0.0422 s/iter. Inference: 0.4999 s/iter. Eval: 0.0007 s/iter. Total: 0.5429 s/iter. ETA=0:06:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1762/2473. Dataloading: 0.0422 s/iter. Inference: 0.4999 s/iter. Eval: 0.0007 s/iter. Total: 0.5430 s/iter. ETA=0:06:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1771/2473. Dataloading: 0.0423 s/iter. Inference: 0.5000 s/iter. Eval: 0.0007 s/iter. Total: 0.5432 s/iter. ETA=0:06:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1780/2473. Dataloading: 0.0426 s/iter. Inference: 0.5000 s/iter. Eval: 0.0007 s/iter. Total: 0.5435 s/iter. ETA=0:06:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1789/2473. Dataloading: 0.0428 s/iter. Inference: 0.5000 s/iter. Eval: 0.0007 s/iter. Total: 0.5437 s/iter. ETA=0:06:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1798/2473. Dataloading: 0.0429 s/iter. Inference: 0.5001 s/iter. Eval: 0.0007 s/iter. Total: 0.5439 s/iter. ETA=0:06:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1807/2473. Dataloading: 0.0431 s/iter. Inference: 0.5001 s/iter. Eval: 0.0007 s/iter. Total: 0.5441 s/iter. ETA=0:06:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1816/2473. Dataloading: 0.0432 s/iter. Inference: 0.5001 s/iter. Eval: 0.0007 s/iter. Total: 0.5442 s/iter. ETA=0:05:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1825/2473. Dataloading: 0.0432 s/iter. Inference: 0.5002 s/iter. Eval: 0.0007 s/iter. Total: 0.5443 s/iter. ETA=0:05:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1834/2473. Dataloading: 0.0433 s/iter. Inference: 0.5002 s/iter. Eval: 0.0007 s/iter. Total: 0.5444 s/iter. ETA=0:05:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1843/2473. Dataloading: 0.0434 s/iter. Inference: 0.5003 s/iter. Eval: 0.0007 s/iter. Total: 0.5446 s/iter. ETA=0:05:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1853/2473. Dataloading: 0.0434 s/iter. Inference: 0.5003 s/iter. Eval: 0.0007 s/iter. Total: 0.5446 s/iter. ETA=0:05:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1863/2473. Dataloading: 0.0434 s/iter. Inference: 0.5004 s/iter. Eval: 0.0007 s/iter. Total: 0.5446 s/iter. ETA=0:05:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1873/2473. Dataloading: 0.0434 s/iter. Inference: 0.5004 s/iter. Eval: 0.0007 s/iter. Total: 0.5447 s/iter. ETA=0:05:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1883/2473. Dataloading: 0.0434 s/iter. Inference: 0.5004 s/iter. Eval: 0.0007 s/iter. Total: 0.5447 s/iter. ETA=0:05:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1893/2473. Dataloading: 0.0434 s/iter. Inference: 0.5005 s/iter. Eval: 0.0007 s/iter. Total: 0.5448 s/iter. ETA=0:05:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1902/2473. Dataloading: 0.0435 s/iter. Inference: 0.5005 s/iter. Eval: 0.0007 s/iter. Total: 0.5449 s/iter. ETA=0:05:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1911/2473. Dataloading: 0.0435 s/iter. Inference: 0.5005 s/iter. Eval: 0.0007 s/iter. Total: 0.5449 s/iter. ETA=0:05:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1921/2473. Dataloading: 0.0435 s/iter. Inference: 0.5006 s/iter. Eval: 0.0007 s/iter. Total: 0.5450 s/iter. ETA=0:05:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1931/2473. Dataloading: 0.0435 s/iter. Inference: 0.5006 s/iter. Eval: 0.0007 s/iter. Total: 0.5450 s/iter. ETA=0:04:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1940/2473. Dataloading: 0.0436 s/iter. Inference: 0.5007 s/iter. Eval: 0.0007 s/iter. Total: 0.5451 s/iter. ETA=0:04:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1949/2473. Dataloading: 0.0436 s/iter. Inference: 0.5007 s/iter. Eval: 0.0007 s/iter. Total: 0.5452 s/iter. ETA=0:04:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1958/2473. Dataloading: 0.0436 s/iter. Inference: 0.5007 s/iter. Eval: 0.0007 s/iter. Total: 0.5453 s/iter. ETA=0:04:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1967/2473. Dataloading: 0.0437 s/iter. Inference: 0.5008 s/iter. Eval: 0.0007 s/iter. Total: 0.5453 s/iter. ETA=0:04:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1977/2473. Dataloading: 0.0437 s/iter. Inference: 0.5008 s/iter. Eval: 0.0007 s/iter. Total: 0.5454 s/iter. ETA=0:04:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1987/2473. Dataloading: 0.0437 s/iter. Inference: 0.5008 s/iter. Eval: 0.0007 s/iter. Total: 0.5454 s/iter. ETA=0:04:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1997/2473. Dataloading: 0.0437 s/iter. Inference: 0.5009 s/iter. Eval: 0.0007 s/iter. Total: 0.5454 s/iter. ETA=0:04:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2007/2473. Dataloading: 0.0437 s/iter. Inference: 0.5009 s/iter. Eval: 0.0007 s/iter. Total: 0.5455 s/iter. ETA=0:04:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2016/2473. Dataloading: 0.0437 s/iter. Inference: 0.5009 s/iter. Eval: 0.0007 s/iter. Total: 0.5456 s/iter. ETA=0:04:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2025/2473. Dataloading: 0.0438 s/iter. Inference: 0.5010 s/iter. Eval: 0.0007 s/iter. Total: 0.5456 s/iter. ETA=0:04:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2034/2473. Dataloading: 0.0438 s/iter. Inference: 0.5010 s/iter. Eval: 0.0007 s/iter. Total: 0.5457 s/iter. ETA=0:03:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2043/2473. Dataloading: 0.0439 s/iter. Inference: 0.5010 s/iter. Eval: 0.0007 s/iter. Total: 0.5458 s/iter. ETA=0:03:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2052/2473. Dataloading: 0.0439 s/iter. Inference: 0.5010 s/iter. Eval: 0.0007 s/iter. Total: 0.5459 s/iter. ETA=0:03:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2061/2473. Dataloading: 0.0439 s/iter. Inference: 0.5011 s/iter. Eval: 0.0007 s/iter. Total: 0.5459 s/iter. ETA=0:03:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2071/2473. Dataloading: 0.0439 s/iter. Inference: 0.5011 s/iter. Eval: 0.0007 s/iter. Total: 0.5459 s/iter. ETA=0:03:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2081/2473. Dataloading: 0.0439 s/iter. Inference: 0.5011 s/iter. Eval: 0.0007 s/iter. Total: 0.5460 s/iter. ETA=0:03:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2090/2473. Dataloading: 0.0440 s/iter. Inference: 0.5012 s/iter. Eval: 0.0007 s/iter. Total: 0.5461 s/iter. ETA=0:03:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2099/2473. Dataloading: 0.0441 s/iter. Inference: 0.5012 s/iter. Eval: 0.0007 s/iter. Total: 0.5462 s/iter. ETA=0:03:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2108/2473. Dataloading: 0.0442 s/iter. Inference: 0.5012 s/iter. Eval: 0.0007 s/iter. Total: 0.5463 s/iter. ETA=0:03:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2117/2473. Dataloading: 0.0444 s/iter. Inference: 0.5013 s/iter. Eval: 0.0007 s/iter. Total: 0.5465 s/iter. ETA=0:03:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2126/2473. Dataloading: 0.0445 s/iter. Inference: 0.5013 s/iter. Eval: 0.0007 s/iter. Total: 0.5467 s/iter. ETA=0:03:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2135/2473. Dataloading: 0.0446 s/iter. Inference: 0.5013 s/iter. Eval: 0.0007 s/iter. Total: 0.5469 s/iter. ETA=0:03:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2144/2473. Dataloading: 0.0447 s/iter. Inference: 0.5013 s/iter. Eval: 0.0007 s/iter. Total: 0.5469 s/iter. ETA=0:02:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2153/2473. Dataloading: 0.0447 s/iter. Inference: 0.5014 s/iter. Eval: 0.0007 s/iter. Total: 0.5470 s/iter. ETA=0:02:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2162/2473. Dataloading: 0.0447 s/iter. Inference: 0.5014 s/iter. Eval: 0.0007 s/iter. Total: 0.5471 s/iter. ETA=0:02:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2171/2473. Dataloading: 0.0448 s/iter. Inference: 0.5014 s/iter. Eval: 0.0007 s/iter. Total: 0.5472 s/iter. ETA=0:02:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2180/2473. Dataloading: 0.0448 s/iter. Inference: 0.5015 s/iter. Eval: 0.0007 s/iter. Total: 0.5472 s/iter. ETA=0:02:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2189/2473. Dataloading: 0.0449 s/iter. Inference: 0.5015 s/iter. Eval: 0.0007 s/iter. Total: 0.5473 s/iter. ETA=0:02:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2198/2473. Dataloading: 0.0449 s/iter. Inference: 0.5015 s/iter. Eval: 0.0007 s/iter. Total: 0.5474 s/iter. ETA=0:02:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2208/2473. Dataloading: 0.0449 s/iter. Inference: 0.5016 s/iter. Eval: 0.0007 s/iter. Total: 0.5474 s/iter. ETA=0:02:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2217/2473. Dataloading: 0.0449 s/iter. Inference: 0.5016 s/iter. Eval: 0.0007 s/iter. Total: 0.5474 s/iter. ETA=0:02:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2226/2473. Dataloading: 0.0449 s/iter. Inference: 0.5016 s/iter. Eval: 0.0007 s/iter. Total: 0.5475 s/iter. ETA=0:02:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2236/2473. Dataloading: 0.0449 s/iter. Inference: 0.5016 s/iter. Eval: 0.0007 s/iter. Total: 0.5475 s/iter. ETA=0:02:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2246/2473. Dataloading: 0.0449 s/iter. Inference: 0.5017 s/iter. Eval: 0.0007 s/iter. Total: 0.5475 s/iter. ETA=0:02:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2256/2473. Dataloading: 0.0449 s/iter. Inference: 0.5017 s/iter. Eval: 0.0007 s/iter. Total: 0.5475 s/iter. ETA=0:01:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2265/2473. Dataloading: 0.0449 s/iter. Inference: 0.5017 s/iter. Eval: 0.0007 s/iter. Total: 0.5476 s/iter. ETA=0:01:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2275/2473. Dataloading: 0.0449 s/iter. Inference: 0.5018 s/iter. Eval: 0.0007 s/iter. Total: 0.5476 s/iter. ETA=0:01:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2284/2473. Dataloading: 0.0449 s/iter. Inference: 0.5018 s/iter. Eval: 0.0007 s/iter. Total: 0.5477 s/iter. ETA=0:01:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2294/2473. Dataloading: 0.0449 s/iter. Inference: 0.5018 s/iter. Eval: 0.0007 s/iter. Total: 0.5477 s/iter. ETA=0:01:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2304/2473. Dataloading: 0.0449 s/iter. Inference: 0.5018 s/iter. Eval: 0.0007 s/iter. Total: 0.5477 s/iter. ETA=0:01:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2313/2473. Dataloading: 0.0450 s/iter. Inference: 0.5019 s/iter. Eval: 0.0007 s/iter. Total: 0.5478 s/iter. ETA=0:01:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2322/2473. Dataloading: 0.0452 s/iter. Inference: 0.5019 s/iter. Eval: 0.0007 s/iter. Total: 0.5480 s/iter. ETA=0:01:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2332/2473. Dataloading: 0.0452 s/iter. Inference: 0.5019 s/iter. Eval: 0.0007 s/iter. Total: 0.5480 s/iter. ETA=0:01:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2341/2473. Dataloading: 0.0452 s/iter. Inference: 0.5019 s/iter. Eval: 0.0007 s/iter. Total: 0.5481 s/iter. ETA=0:01:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2350/2473. Dataloading: 0.0453 s/iter. Inference: 0.5020 s/iter. Eval: 0.0007 s/iter. Total: 0.5482 s/iter. ETA=0:01:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2359/2473. Dataloading: 0.0453 s/iter. Inference: 0.5020 s/iter. Eval: 0.0007 s/iter. Total: 0.5482 s/iter. ETA=0:01:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2368/2473. Dataloading: 0.0453 s/iter. Inference: 0.5020 s/iter. Eval: 0.0007 s/iter. Total: 0.5483 s/iter. ETA=0:00:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2377/2473. Dataloading: 0.0454 s/iter. Inference: 0.5020 s/iter. Eval: 0.0007 s/iter. Total: 0.5484 s/iter. ETA=0:00:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2386/2473. Dataloading: 0.0454 s/iter. Inference: 0.5021 s/iter. Eval: 0.0007 s/iter. Total: 0.5484 s/iter. ETA=0:00:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2395/2473. Dataloading: 0.0454 s/iter. Inference: 0.5021 s/iter. Eval: 0.0007 s/iter. Total: 0.5485 s/iter. ETA=0:00:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2405/2473. Dataloading: 0.0454 s/iter. Inference: 0.5021 s/iter. Eval: 0.0007 s/iter. Total: 0.5485 s/iter. ETA=0:00:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2414/2473. Dataloading: 0.0454 s/iter. Inference: 0.5021 s/iter. Eval: 0.0007 s/iter. Total: 0.5485 s/iter. ETA=0:00:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2424/2473. Dataloading: 0.0454 s/iter. Inference: 0.5022 s/iter. Eval: 0.0007 s/iter. Total: 0.5485 s/iter. ETA=0:00:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2433/2473. Dataloading: 0.0455 s/iter. Inference: 0.5022 s/iter. Eval: 0.0007 s/iter. Total: 0.5486 s/iter. ETA=0:00:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2443/2473. Dataloading: 0.0455 s/iter. Inference: 0.5022 s/iter. Eval: 0.0007 s/iter. Total: 0.5486 s/iter. ETA=0:00:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2452/2473. Dataloading: 0.0455 s/iter. Inference: 0.5022 s/iter. Eval: 0.0007 s/iter. Total: 0.5487 s/iter. ETA=0:00:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2461/2473. Dataloading: 0.0455 s/iter. Inference: 0.5023 s/iter. Eval: 0.0007 s/iter. Total: 0.5487 s/iter. ETA=0:00:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2470/2473. Dataloading: 0.0455 s/iter. Inference: 0.5023 s/iter. Eval: 0.0007 s/iter. Total: 0.5488 s/iter. ETA=0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "               hold_obj: #GTs = 3608, AP = 0.1372\n",
      "                  stand: #GTs = 4118, AP = 0.5446\n",
      "              sit_instr: #GTs = 1916, AP = 0.2500\n",
      "             ride_instr: #GTs = 0556, AP = 0.1327\n",
      "                   walk: #GTs = 0597, AP = 0.2402\n",
      "               look_obj: #GTs = 3347, AP = 0.1159\n",
      "              hit_instr: #GTs = 0349, AP = 0.0177\n",
      "                hit_obj: #GTs = 0349, AP = 0.2360\n",
      "                eat_obj: #GTs = 0521, AP = 0.2390\n",
      "              eat_instr: #GTs = 0521, AP = 0.6010\n",
      "             jump_instr: #GTs = 0635, AP = 0.1913\n",
      "              lay_instr: #GTs = 0387, AP = 0.3289\n",
      "    talk_on_phone_instr: #GTs = 0285, AP = 0.1017\n",
      "              carry_obj: #GTs = 0472, AP = 0.1138\n",
      "              throw_obj: #GTs = 0244, AP = 0.0265\n",
      "              catch_obj: #GTs = 0246, AP = 0.0121\n",
      "              cut_instr: #GTs = 0269, AP = 0.0465\n",
      "                cut_obj: #GTs = 0269, AP = 0.2535\n",
      "                    run: #GTs = 0687, AP = 0.5151\n",
      " work_on_computer_instr: #GTs = 0410, AP = 0.2780\n",
      "              ski_instr: #GTs = 0424, AP = 0.1146\n",
      "             surf_instr: #GTs = 0486, AP = 0.1070\n",
      "       skateboard_instr: #GTs = 0417, AP = 0.1089\n",
      "                  smile: #GTs = 1415, AP = 0.6167\n",
      "            drink_instr: #GTs = 0082, AP = 0.0268\n",
      "               kick_obj: #GTs = 0180, AP = 0.0546\n",
      "            point_instr: #GTs = 0031, AP = 0.0065\n",
      "               read_obj: #GTs = 0111, AP = 0.1176\n",
      "        snowboard_instr: #GTs = 0277, AP = 0.1587\n",
      "------------------------------------------------------------\n",
      "mAP all: 0.1963 mAP thesis: 0.1571\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.default_trainer:{'vcoco_val/vcoco': {'AP_hold_obj': 0.13720505068818348, 'AP_stand': 0.5446213234397418, 'AP_sit_instr': 0.2500329011634043, 'AP_ride_instr': 0.13268171046272628, 'AP_walk': 0.2402128412508539, 'AP_look_obj': 0.11590145811398322, 'AP_hit_instr': 0.017744378089550532, 'AP_hit_obj': 0.23601558192896133, 'AP_eat_obj': 0.23899265935844424, 'AP_eat_instr': 0.6010053453029219, 'AP_jump_instr': 0.19125173963277112, 'AP_lay_instr': 0.3288826483516966, 'AP_talk_on_phone_instr': 0.1017181858613769, 'AP_carry_obj': 0.11376401838228342, 'AP_throw_obj': 0.026523249714054745, 'AP_catch_obj': 0.012100259291270527, 'AP_cut_instr': 0.046546918829667175, 'AP_cut_obj': 0.25348648755798203, 'AP_run': 0.5151156075768426, 'AP_work_on_computer_instr': 0.2780225058311563, 'AP_ski_instr': 0.11460309604333362, 'AP_surf_instr': 0.10701007746462292, 'AP_skateboard_instr': 0.10890864136986861, 'AP_smile': 0.6167012046166761, 'AP_drink_instr': 0.026769705199094346, 'AP_kick_obj': 0.054639381383974006, 'AP_point_instr': 0.006499564370059558, 'AP_read_obj': 0.11755996486732836, 'AP_snowboard_instr': 0.1586670261433713, 'mAP_all': 0.19631667352711038, 'mAP_thesis': 0.1570847079596678}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vcoco_val/vcoco': {'AP_hold_obj': 0.13720505068818348,\n",
       "  'AP_stand': 0.5446213234397418,\n",
       "  'AP_sit_instr': 0.2500329011634043,\n",
       "  'AP_ride_instr': 0.13268171046272628,\n",
       "  'AP_walk': 0.2402128412508539,\n",
       "  'AP_look_obj': 0.11590145811398322,\n",
       "  'AP_hit_instr': 0.017744378089550532,\n",
       "  'AP_hit_obj': 0.23601558192896133,\n",
       "  'AP_eat_obj': 0.23899265935844424,\n",
       "  'AP_eat_instr': 0.6010053453029219,\n",
       "  'AP_jump_instr': 0.19125173963277112,\n",
       "  'AP_lay_instr': 0.3288826483516966,\n",
       "  'AP_talk_on_phone_instr': 0.1017181858613769,\n",
       "  'AP_carry_obj': 0.11376401838228342,\n",
       "  'AP_throw_obj': 0.026523249714054745,\n",
       "  'AP_catch_obj': 0.012100259291270527,\n",
       "  'AP_cut_instr': 0.046546918829667175,\n",
       "  'AP_cut_obj': 0.25348648755798203,\n",
       "  'AP_run': 0.5151156075768426,\n",
       "  'AP_work_on_computer_instr': 0.2780225058311563,\n",
       "  'AP_ski_instr': 0.11460309604333362,\n",
       "  'AP_surf_instr': 0.10701007746462292,\n",
       "  'AP_skateboard_instr': 0.10890864136986861,\n",
       "  'AP_smile': 0.6167012046166761,\n",
       "  'AP_drink_instr': 0.026769705199094346,\n",
       "  'AP_kick_obj': 0.054639381383974006,\n",
       "  'AP_point_instr': 0.006499564370059558,\n",
       "  'AP_read_obj': 0.11755996486732836,\n",
       "  'AP_snowboard_instr': 0.1586670261433713,\n",
       "  'mAP_all': 0.19631667352711038,\n",
       "  'mAP_thesis': 0.1570847079596678}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "if cmdline_args.user_dir:\n",
    "    absolute_user_dir = os.path.abspath(cmdline_args.user_dir)\n",
    "    opt['base_path'] = absolute_user_dir\n",
    "trainer = Trainer(opt)\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
