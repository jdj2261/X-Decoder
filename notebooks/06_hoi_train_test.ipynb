{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.colormap import random_color\n",
    "from detectron2.structures import Boxes, ImageList, Instances, BitMasks, BoxMode\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "\n",
    "from utils.arguments import load_opt_command\n",
    "from utils.misc import hook_metadata, hook_switcher, hook_opt\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Pretrain or fine-tune models for NLP tasks.')\n",
    "parser.add_argument('--command', default=\"evaluate\", help='Command: train/evaluate/train-and-evaluate')\n",
    "parser.add_argument('--conf_files', nargs='+', help='Path(s) to the config file(s).')\n",
    "parser.add_argument('--user_dir', help='Path to the user defined module for tasks (models, criteria), optimizers, and lr schedulers.')\n",
    "parser.add_argument('--config_overrides', nargs='*', help='Override parameters on config with a json style string, e.g. {\"<PARAM_NAME_1>\": <PARAM_VALUE_1>, \"<PARAM_GROUP_2>.<PARAM_SUBGROUP_2>.<PARAM_2>\": <PARAM_VALUE_2>}. A key with \".\" updates the object in the corresponding nested dict. Remember to escape \" in command line.')\n",
    "parser.add_argument('--overrides', help='arguments that used to override the config file in cmdline', nargs=argparse.REMAINDER)\n",
    "\n",
    "cmdline_args = parser.parse_args('')\n",
    "# cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/svlp_focalt_lang.yaml\")]\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/vcoco.yaml\")]\n",
    "cmdline_args.overrides = ['WEIGHT', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "cmdline_args.overrides\n",
    "\n",
    "opt = load_opt_from_config_files(cmdline_args.conf_files)\n",
    "\n",
    "keys = [cmdline_args.overrides[idx*2] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [cmdline_args.overrides[idx*2+1] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [val.replace('false', '').replace('False','') if len(val.replace(' ', '')) == 5 else val for val in vals]\n",
    "types = []\n",
    "for key in keys:\n",
    "    key = key.split('.')\n",
    "    ele = opt.copy()\n",
    "    while len(key) > 0:\n",
    "        ele = ele[key.pop(0)]\n",
    "    types.append(type(ele))\n",
    "\n",
    "config_dict = {x:z(y) for x,y,z in zip(keys, vals, types)}\n",
    "config_dict\n",
    "\n",
    "load_config_dict_to_opt(opt, config_dict)\n",
    "for key, val in cmdline_args.__dict__.items():\n",
    "    if val is not None:\n",
    "        opt[key] = val\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(opt, build_model(opt)).train().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (model): CDNHOI(\n",
       "    (backbone): D2FocalNet(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): FocalModulationBlock(\n",
       "              (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=96, out_features=196, bias=True)\n",
       "                (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FocalModulationBlock(\n",
       "              (dw1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=96, out_features=196, bias=True)\n",
       "                (h): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (drop_path): DropPath(drop_prob=0.027)\n",
       "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchEmbed(\n",
       "            (proj): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): FocalModulationBlock(\n",
       "              (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=192, out_features=388, bias=True)\n",
       "                (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (drop_path): DropPath(drop_prob=0.055)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FocalModulationBlock(\n",
       "              (dw1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=192, out_features=388, bias=True)\n",
       "                (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "              (drop_path): DropPath(drop_prob=0.082)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchEmbed(\n",
       "            (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.109)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.136)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.164)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.191)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.218)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): FocalModulationBlock(\n",
       "              (dw1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=384, out_features=772, bias=True)\n",
       "                (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "              (drop_path): DropPath(drop_prob=0.245)\n",
       "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): PatchEmbed(\n",
       "            (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): BasicLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): FocalModulationBlock(\n",
       "              (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=768, out_features=1540, bias=True)\n",
       "                (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (drop_path): DropPath(drop_prob=0.273)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FocalModulationBlock(\n",
       "              (dw1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (modulation): FocalModulation(\n",
       "                (f): Linear(in_features=768, out_features=1540, bias=True)\n",
       "                (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): GELU(approximate='none')\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (focal_layers): ModuleList(\n",
       "                  (0): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (1): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                  (2): Sequential(\n",
       "                    (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                    (1): GELU(approximate='none')\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (dw2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "              (drop_path): DropPath(drop_prob=0.300)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (hoid_head): CDN(\n",
       "      (encoder): TransformerEncoderHOI(\n",
       "        (adapter_1): Conv2d(\n",
       "          96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (layer_1): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (adapter_2): Conv2d(\n",
       "          192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (layer_2): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (adapter_3): Conv2d(\n",
       "          384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (layer_3): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (input_proj): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer): TransformerEncoderOnly(\n",
       "          (encoder): TransformerEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-5): 6 x TransformerEncoderLayer(\n",
       "                (self_attn): MultiheadAttention(\n",
       "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                )\n",
       "                (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pe_layer): Positional encoding PositionEmbeddingSine\n",
       "            num_pos_feats: 256\n",
       "            temperature: 10000\n",
       "            normalize: True\n",
       "            scale: 6.283185307179586\n",
       "        (layer_4): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (hoi_decoder): HDecoder(\n",
       "        (hopd_decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (interaction_decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-2): 3 x TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterionHOI(\n",
       "      (matcher): HungarianMatcherHOI()\n",
       "    )\n",
       "    (query_embed): Embedding(101, 512)\n",
       "    (obj_class_embed): Linear(in_features=512, out_features=81, bias=True)\n",
       "    (verb_class_embed): Linear(in_features=512, out_features=27, bias=True)\n",
       "    (sub_bbox_embed): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (obj_bbox_embed): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling forward() may cause unpredicted behavior of PixelDecoder module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_obj_logits': tensor([[[ 0.2708,  0.8102,  0.0560,  ...,  0.1979, -0.2894,  0.5397],\n",
      "         [ 0.4842,  0.9740,  0.0050,  ..., -0.0348, -0.5324,  0.5344],\n",
      "         [ 0.4247,  1.3230,  0.0921,  ...,  0.0657, -0.7571,  0.3034],\n",
      "         ...,\n",
      "         [ 0.3730,  0.7890, -0.0562,  ..., -0.0504, -0.4359,  0.2787],\n",
      "         [ 0.7168,  0.9968, -0.0635,  ...,  0.3093, -0.3467,  0.3416],\n",
      "         [ 0.4348,  0.7422, -0.1290,  ...,  0.4767, -0.3645,  0.3547]]],\n",
      "       device='cuda:0'), 'pred_verb_logits': tensor([[[-0.8402, -0.0145, -1.1549,  ..., -0.7912, -0.7599,  0.5445],\n",
      "         [-0.9658, -0.2393, -1.2318,  ..., -0.8057, -0.4699,  0.5005],\n",
      "         [-0.5325, -0.2734, -1.1044,  ..., -0.7634, -0.5131,  0.4343],\n",
      "         ...,\n",
      "         [-0.5592, -0.2885, -1.0356,  ..., -0.8988, -0.3973,  0.7178],\n",
      "         [-0.6580,  0.0652, -1.0405,  ..., -1.0146, -0.5080,  0.7786],\n",
      "         [-0.7376, -0.1507, -0.9025,  ..., -0.8933, -0.3404,  0.4627]]],\n",
      "       device='cuda:0'), 'pred_sub_boxes': tensor([[[0.5488, 0.4610, 0.4810, 0.5039],\n",
      "         [0.5467, 0.4601, 0.4779, 0.5041],\n",
      "         [0.5538, 0.4463, 0.4852, 0.5008],\n",
      "         [0.5593, 0.4575, 0.4744, 0.5136],\n",
      "         [0.5338, 0.4566, 0.4770, 0.4946],\n",
      "         [0.5348, 0.4506, 0.4751, 0.5037],\n",
      "         [0.5557, 0.4552, 0.4798, 0.5062],\n",
      "         [0.5501, 0.4579, 0.4738, 0.5096],\n",
      "         [0.5548, 0.4494, 0.4754, 0.5065],\n",
      "         [0.5496, 0.4590, 0.4825, 0.5008],\n",
      "         [0.5415, 0.4610, 0.4688, 0.5132],\n",
      "         [0.5436, 0.4458, 0.4806, 0.5054],\n",
      "         [0.5514, 0.4454, 0.4791, 0.5051],\n",
      "         [0.5346, 0.4501, 0.4823, 0.5021],\n",
      "         [0.5463, 0.4490, 0.4812, 0.5222],\n",
      "         [0.5462, 0.4599, 0.4863, 0.5042],\n",
      "         [0.5549, 0.4603, 0.4779, 0.5090],\n",
      "         [0.5408, 0.4501, 0.4750, 0.4967],\n",
      "         [0.5435, 0.4719, 0.4851, 0.5102],\n",
      "         [0.5423, 0.4424, 0.4795, 0.4983],\n",
      "         [0.5437, 0.4529, 0.4779, 0.5058],\n",
      "         [0.5469, 0.4513, 0.4739, 0.5045],\n",
      "         [0.5466, 0.4613, 0.4718, 0.5090],\n",
      "         [0.5515, 0.4495, 0.4747, 0.4993],\n",
      "         [0.5429, 0.4542, 0.4784, 0.5037],\n",
      "         [0.5438, 0.4530, 0.4768, 0.5182],\n",
      "         [0.5524, 0.4582, 0.4812, 0.5062],\n",
      "         [0.5404, 0.4519, 0.4785, 0.5044],\n",
      "         [0.5532, 0.4493, 0.4742, 0.5087],\n",
      "         [0.5606, 0.4543, 0.4790, 0.5082],\n",
      "         [0.5548, 0.4638, 0.4737, 0.5006],\n",
      "         [0.5435, 0.4584, 0.4823, 0.5138],\n",
      "         [0.5519, 0.4450, 0.4770, 0.5012],\n",
      "         [0.5436, 0.4529, 0.4784, 0.4993],\n",
      "         [0.5470, 0.4531, 0.4806, 0.5019],\n",
      "         [0.5421, 0.4609, 0.4707, 0.5027],\n",
      "         [0.5449, 0.4543, 0.4731, 0.5104],\n",
      "         [0.5428, 0.4637, 0.4796, 0.5042],\n",
      "         [0.5496, 0.4491, 0.4798, 0.4987],\n",
      "         [0.5479, 0.4548, 0.4751, 0.5060],\n",
      "         [0.5543, 0.4561, 0.4867, 0.5063],\n",
      "         [0.5512, 0.4598, 0.4764, 0.4972],\n",
      "         [0.5521, 0.4629, 0.4652, 0.5078],\n",
      "         [0.5465, 0.4557, 0.4913, 0.4971],\n",
      "         [0.5586, 0.4573, 0.4710, 0.4982],\n",
      "         [0.5513, 0.4564, 0.4749, 0.5153],\n",
      "         [0.5410, 0.4472, 0.4796, 0.5067],\n",
      "         [0.5395, 0.4544, 0.4834, 0.4902],\n",
      "         [0.5452, 0.4538, 0.4782, 0.5119],\n",
      "         [0.5447, 0.4486, 0.4751, 0.5120],\n",
      "         [0.5476, 0.4547, 0.4770, 0.4945],\n",
      "         [0.5519, 0.4638, 0.4891, 0.5171],\n",
      "         [0.5365, 0.4492, 0.4701, 0.5045],\n",
      "         [0.5516, 0.4545, 0.4784, 0.5052],\n",
      "         [0.5500, 0.4604, 0.4685, 0.5129],\n",
      "         [0.5473, 0.4572, 0.4747, 0.5130],\n",
      "         [0.5401, 0.4567, 0.4665, 0.5082],\n",
      "         [0.5441, 0.4549, 0.4743, 0.5116],\n",
      "         [0.5497, 0.4527, 0.4773, 0.5162],\n",
      "         [0.5461, 0.4640, 0.4813, 0.5140],\n",
      "         [0.5440, 0.4501, 0.4791, 0.5077],\n",
      "         [0.5483, 0.4603, 0.4751, 0.5029],\n",
      "         [0.5475, 0.4626, 0.4812, 0.5101],\n",
      "         [0.5479, 0.4533, 0.4855, 0.5013],\n",
      "         [0.5504, 0.4639, 0.4766, 0.4923],\n",
      "         [0.5531, 0.4561, 0.4750, 0.5062],\n",
      "         [0.5432, 0.4518, 0.4795, 0.5064],\n",
      "         [0.5357, 0.4454, 0.4774, 0.5012],\n",
      "         [0.5445, 0.4585, 0.4813, 0.5008],\n",
      "         [0.5411, 0.4607, 0.4719, 0.5095],\n",
      "         [0.5467, 0.4487, 0.4775, 0.4938],\n",
      "         [0.5409, 0.4526, 0.4723, 0.4946],\n",
      "         [0.5560, 0.4501, 0.4714, 0.5051],\n",
      "         [0.5450, 0.4516, 0.4850, 0.4958],\n",
      "         [0.5508, 0.4549, 0.4848, 0.5022],\n",
      "         [0.5497, 0.4430, 0.4821, 0.4999],\n",
      "         [0.5513, 0.4447, 0.4870, 0.5063],\n",
      "         [0.5409, 0.4513, 0.4775, 0.5096],\n",
      "         [0.5443, 0.4635, 0.4726, 0.5138],\n",
      "         [0.5460, 0.4578, 0.4828, 0.5102],\n",
      "         [0.5474, 0.4567, 0.4841, 0.4986],\n",
      "         [0.5529, 0.4603, 0.4761, 0.4995],\n",
      "         [0.5538, 0.4537, 0.4847, 0.4992],\n",
      "         [0.5437, 0.4604, 0.4779, 0.5106],\n",
      "         [0.5476, 0.4501, 0.4822, 0.5127],\n",
      "         [0.5501, 0.4416, 0.4808, 0.5098],\n",
      "         [0.5460, 0.4584, 0.4879, 0.5045],\n",
      "         [0.5463, 0.4559, 0.4754, 0.4983],\n",
      "         [0.5435, 0.4614, 0.4788, 0.5109],\n",
      "         [0.5533, 0.4617, 0.4774, 0.5029],\n",
      "         [0.5416, 0.4475, 0.4835, 0.5022],\n",
      "         [0.5422, 0.4554, 0.4792, 0.5057],\n",
      "         [0.5417, 0.4546, 0.4742, 0.4989],\n",
      "         [0.5525, 0.4545, 0.4776, 0.4985],\n",
      "         [0.5457, 0.4528, 0.4794, 0.5143],\n",
      "         [0.5547, 0.4463, 0.4892, 0.4973],\n",
      "         [0.5475, 0.4469, 0.4713, 0.5110],\n",
      "         [0.5476, 0.4575, 0.4759, 0.5076],\n",
      "         [0.5466, 0.4512, 0.4861, 0.4986],\n",
      "         [0.5384, 0.4585, 0.4743, 0.4947],\n",
      "         [0.5538, 0.4612, 0.4758, 0.5148]]], device='cuda:0'), 'pred_obj_boxes': tensor([[[0.5141, 0.4344, 0.4805, 0.5106],\n",
      "         [0.5188, 0.4330, 0.4835, 0.5145],\n",
      "         [0.5095, 0.4357, 0.4644, 0.5139],\n",
      "         [0.5098, 0.4309, 0.4863, 0.5130],\n",
      "         [0.5078, 0.4318, 0.4612, 0.5083],\n",
      "         [0.5137, 0.4286, 0.4820, 0.5157],\n",
      "         [0.5029, 0.4280, 0.4729, 0.5040],\n",
      "         [0.5132, 0.4402, 0.4767, 0.5125],\n",
      "         [0.5114, 0.4300, 0.4871, 0.5017],\n",
      "         [0.5179, 0.4285, 0.4781, 0.5133],\n",
      "         [0.5061, 0.4357, 0.4784, 0.5080],\n",
      "         [0.5035, 0.4348, 0.4790, 0.4991],\n",
      "         [0.5199, 0.4320, 0.4826, 0.5091],\n",
      "         [0.5101, 0.4295, 0.4793, 0.5118],\n",
      "         [0.5140, 0.4355, 0.4761, 0.5126],\n",
      "         [0.5164, 0.4268, 0.4721, 0.5094],\n",
      "         [0.5182, 0.4313, 0.4702, 0.5079],\n",
      "         [0.5148, 0.4367, 0.4825, 0.5141],\n",
      "         [0.5235, 0.4224, 0.4795, 0.5029],\n",
      "         [0.5123, 0.4246, 0.4834, 0.5109],\n",
      "         [0.5021, 0.4345, 0.4737, 0.4978],\n",
      "         [0.5203, 0.4327, 0.4803, 0.5059],\n",
      "         [0.5078, 0.4386, 0.4737, 0.5175],\n",
      "         [0.5193, 0.4382, 0.4733, 0.5173],\n",
      "         [0.5191, 0.4328, 0.4808, 0.5005],\n",
      "         [0.5145, 0.4360, 0.4760, 0.5150],\n",
      "         [0.5103, 0.4336, 0.4861, 0.5177],\n",
      "         [0.5122, 0.4323, 0.4687, 0.5145],\n",
      "         [0.5120, 0.4338, 0.4722, 0.5071],\n",
      "         [0.5138, 0.4405, 0.4790, 0.5105],\n",
      "         [0.5165, 0.4278, 0.4668, 0.5163],\n",
      "         [0.4966, 0.4288, 0.4762, 0.5138],\n",
      "         [0.5120, 0.4304, 0.4869, 0.5061],\n",
      "         [0.5084, 0.4380, 0.4687, 0.5155],\n",
      "         [0.5143, 0.4325, 0.4789, 0.5064],\n",
      "         [0.5089, 0.4321, 0.4755, 0.5077],\n",
      "         [0.5119, 0.4327, 0.4813, 0.5120],\n",
      "         [0.5137, 0.4443, 0.4849, 0.4964],\n",
      "         [0.5219, 0.4370, 0.4700, 0.5206],\n",
      "         [0.5114, 0.4278, 0.4869, 0.5097],\n",
      "         [0.5124, 0.4290, 0.4817, 0.5126],\n",
      "         [0.5118, 0.4289, 0.4777, 0.5113],\n",
      "         [0.5165, 0.4307, 0.4653, 0.5126],\n",
      "         [0.5156, 0.4276, 0.4789, 0.5127],\n",
      "         [0.5089, 0.4339, 0.4729, 0.5216],\n",
      "         [0.5052, 0.4339, 0.4816, 0.4986],\n",
      "         [0.5132, 0.4274, 0.4783, 0.5056],\n",
      "         [0.5106, 0.4341, 0.4747, 0.5085],\n",
      "         [0.5147, 0.4264, 0.4815, 0.5102],\n",
      "         [0.5101, 0.4328, 0.4875, 0.4986],\n",
      "         [0.5107, 0.4328, 0.4721, 0.5165],\n",
      "         [0.5215, 0.4350, 0.4863, 0.4955],\n",
      "         [0.5104, 0.4253, 0.4832, 0.5115],\n",
      "         [0.5104, 0.4349, 0.4804, 0.5095],\n",
      "         [0.5102, 0.4335, 0.4694, 0.5067],\n",
      "         [0.5101, 0.4270, 0.4756, 0.5056],\n",
      "         [0.5200, 0.4254, 0.4708, 0.5088],\n",
      "         [0.5159, 0.4328, 0.4734, 0.5084],\n",
      "         [0.5248, 0.4492, 0.4722, 0.5083],\n",
      "         [0.5147, 0.4321, 0.4806, 0.5090],\n",
      "         [0.5178, 0.4327, 0.4751, 0.5062],\n",
      "         [0.5164, 0.4333, 0.4836, 0.5092],\n",
      "         [0.5104, 0.4246, 0.4831, 0.5124],\n",
      "         [0.5120, 0.4363, 0.4780, 0.5098],\n",
      "         [0.5127, 0.4419, 0.4732, 0.5107],\n",
      "         [0.5184, 0.4357, 0.4840, 0.5034],\n",
      "         [0.5080, 0.4233, 0.4722, 0.5023],\n",
      "         [0.5129, 0.4233, 0.4677, 0.5120],\n",
      "         [0.5082, 0.4283, 0.4702, 0.5029],\n",
      "         [0.5179, 0.4330, 0.4776, 0.5135],\n",
      "         [0.5127, 0.4358, 0.4678, 0.5101],\n",
      "         [0.5250, 0.4344, 0.4773, 0.5131],\n",
      "         [0.5065, 0.4257, 0.4779, 0.5256],\n",
      "         [0.5097, 0.4344, 0.4726, 0.5067],\n",
      "         [0.5194, 0.4316, 0.4754, 0.5024],\n",
      "         [0.5199, 0.4320, 0.4816, 0.5188],\n",
      "         [0.5157, 0.4227, 0.4747, 0.5094],\n",
      "         [0.5147, 0.4366, 0.4805, 0.5036],\n",
      "         [0.5133, 0.4312, 0.4777, 0.5160],\n",
      "         [0.5077, 0.4387, 0.4804, 0.5092],\n",
      "         [0.5100, 0.4300, 0.4786, 0.5179],\n",
      "         [0.5167, 0.4395, 0.4765, 0.5124],\n",
      "         [0.5051, 0.4289, 0.4836, 0.4998],\n",
      "         [0.4987, 0.4253, 0.4764, 0.5171],\n",
      "         [0.5067, 0.4314, 0.4794, 0.5041],\n",
      "         [0.5123, 0.4329, 0.4858, 0.5064],\n",
      "         [0.5235, 0.4240, 0.4881, 0.4998],\n",
      "         [0.5129, 0.4258, 0.4848, 0.4968],\n",
      "         [0.5207, 0.4342, 0.4843, 0.5067],\n",
      "         [0.5166, 0.4299, 0.4802, 0.5080],\n",
      "         [0.5064, 0.4324, 0.4799, 0.4997],\n",
      "         [0.5127, 0.4306, 0.4897, 0.4976],\n",
      "         [0.5055, 0.4200, 0.4747, 0.5218],\n",
      "         [0.5137, 0.4302, 0.4724, 0.5086],\n",
      "         [0.5133, 0.4387, 0.4736, 0.5167],\n",
      "         [0.5247, 0.4407, 0.4748, 0.5150],\n",
      "         [0.5222, 0.4341, 0.4770, 0.5032],\n",
      "         [0.5082, 0.4279, 0.4714, 0.5157],\n",
      "         [0.5133, 0.4317, 0.4673, 0.5077],\n",
      "         [0.5119, 0.4369, 0.4825, 0.5121],\n",
      "         [0.5076, 0.4401, 0.4790, 0.5086]]], device='cuda:0'), 'aux_outputs': []}\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "t.append(transforms.Resize(800, interpolation=Image.BICUBIC))\n",
    "transform = transforms.Compose(t)\n",
    "pixel_mean = torch.Tensor([123.675, 116.280, 103.530]).view(-1, 1, 1).cuda()\n",
    "pixel_std = torch.Tensor([58.395, 57.120, 57.375]).view(-1, 1, 1).cuda()\n",
    "image_pth = '../images/animals.png'\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_ori = Image.open(image_pth).convert('RGB')\n",
    "    width = image_ori.size[0]\n",
    "    height = image_ori.size[1]\n",
    "    image = transform(image_ori)\n",
    "    image = np.asarray(image)\n",
    "    image_ori = np.asarray(image_ori)\n",
    "    images = torch.from_numpy(image.copy()).permute(2,0,1).cuda()\n",
    "    batch_inputs = [{'image': images, 'height': height, 'width': width}]\n",
    "    out = model.forward(batch_inputs)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
