{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/X-Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.colormap import random_color\n",
    "from detectron2.structures import Boxes, ImageList, Instances, BitMasks, BoxMode\n",
    "\n",
    "from xdecoder.BaseModel import BaseModel\n",
    "from xdecoder import build_model\n",
    "\n",
    "from utils.arguments import load_opt_command\n",
    "from utils.misc import hook_metadata, hook_switcher, hook_opt\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Pretrain or fine-tune models for NLP tasks.')\n",
    "parser.add_argument('--command', default=\"evaluate\", help='Command: train/evaluate/train-and-evaluate')\n",
    "parser.add_argument('--conf_files', nargs='+', help='Path(s) to the config file(s).')\n",
    "parser.add_argument('--user_dir', help='Path to the user defined module for tasks (models, criteria), optimizers, and lr schedulers.')\n",
    "parser.add_argument('--config_overrides', nargs='*', help='Override parameters on config with a json style string, e.g. {\"<PARAM_NAME_1>\": <PARAM_VALUE_1>, \"<PARAM_GROUP_2>.<PARAM_SUBGROUP_2>.<PARAM_2>\": <PARAM_VALUE_2>}. A key with \".\" updates the object in the corresponding nested dict. Remember to escape \" in command line.')\n",
    "parser.add_argument('--overrides', help='arguments that used to override the config file in cmdline', nargs=argparse.REMAINDER)\n",
    "\n",
    "cmdline_args = parser.parse_args('')\n",
    "# cmdline_args.conf_files = [os.path.join(home_dir, \"configs/xdecoder/svlp_focalt_lang.yaml\")]\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/test_vcoco.yaml\")]\n",
    "cmdline_args.overrides = ['WEIGHT', '../checkpoints/xdecoder_focalt_best_openseg.pt'] \n",
    "cmdline_args.overrides\n",
    "\n",
    "opt = load_opt_from_config_files(cmdline_args.conf_files)\n",
    "\n",
    "keys = [cmdline_args.overrides[idx*2] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [cmdline_args.overrides[idx*2+1] for idx in range(len(cmdline_args.overrides)//2)]\n",
    "vals = [val.replace('false', '').replace('False','') if len(val.replace(' ', '')) == 5 else val for val in vals]\n",
    "types = []\n",
    "for key in keys:\n",
    "    key = key.split('.')\n",
    "    ele = opt.copy()\n",
    "    while len(key) > 0:\n",
    "        ele = ele[key.pop(0)]\n",
    "    types.append(type(ele))\n",
    "\n",
    "config_dict = {x:z(y) for x,y,z in zip(keys, vals, types)}\n",
    "config_dict\n",
    "\n",
    "load_config_dict_to_opt(opt, config_dict)\n",
    "for key, val in cmdline_args.__dict__.items():\n",
    "    if val is not None:\n",
    "        opt[key] = val\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../checkpoints/xdecoder_focalt_best_openseg.pt\n"
     ]
    }
   ],
   "source": [
    "pretrained_pth = os.path.join(opt['WEIGHT'])\n",
    "output_root = './output'\n",
    "image_pth = '../images/animals.png'\n",
    "print(pretrained_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*UNLOADED* sem_seg_head.predictor.pos_embed_caping.weight, Model Shape: torch.Size([77, 512])\n",
      "$UNUSED$ criterion.empty_weight, Ckpt Shape: torch.Size([134])\n",
      "$UNUSED$ sem_seg_head.predictor.query_feat_caping.weight, Ckpt Shape: torch.Size([77, 512])\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(opt, build_model(opt)).from_pretrained(pretrained_pth).eval().cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone (FocalNet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n",
      "WARNING: Cannot find VLPreDataset. Make sure datasets are accessible if you want to use them for training or evaluation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hdecoder.body.encoder.transformer_encoder_hoi import TransformerEncoderHOI\n",
    "from hdecoder.body.encoder.registry import register_encoder\n",
    "\n",
    "hoi_encoder = TransformerEncoderHOI(opt, backbone.output_shape()).cuda()\n",
    "state_dict = model.model.sem_seg_head.pixel_decoder.state_dict()\n",
    "hoi_encoder.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdecoder.body.decoder.hdecoder import HDecoder\n",
    "hoi_decoder = HDecoder(opt, return_intermediate_dec=True).cuda()\n",
    "hidden_dim = hoi_decoder.d_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "query_embed = nn.Embedding(100, hidden_dim).cuda()\n",
    "query_embed.weight.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdecoder.body.decoder.modules import MLP\n",
    "num_obj_classes = 81\n",
    "num_verb_classes = 29\n",
    "\n",
    "obj_class_embed = nn.Linear(hidden_dim, num_obj_classes + 1).cuda()\n",
    "verb_class_embed = nn.Linear(hidden_dim, num_verb_classes).cuda()\n",
    "sub_bbox_embed = MLP(hidden_dim, hidden_dim, 4, 3).cuda()\n",
    "obj_bbox_embed = MLP(hidden_dim, hidden_dim, 4, 3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_layers_hopd = 3\n",
    "dec_layers_interaction = 3\n",
    "@torch.jit.unused\n",
    "def _set_aux_loss(outputs_obj_class, outputs_verb_class, outputs_sub_coord, outputs_obj_coord, outputs_matching=None):\n",
    "    min_dec_layers_num = min(dec_layers_hopd, dec_layers_interaction)\n",
    "    return [{'pred_obj_logits': a, 'pred_verb_logits': b, 'pred_sub_boxes': c, 'pred_obj_boxes': d}\n",
    "            for a, b, c, d in zip(outputs_obj_class[-min_dec_layers_num : -1], outputs_verb_class[-min_dec_layers_num : -1], \\\n",
    "                                    outputs_sub_coord[-min_dec_layers_num : -1], outputs_obj_coord[-min_dec_layers_num : -1])]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch import nn\n",
    "\n",
    "from utils.box_ops import box_cxcywh_to_xyxy, generalized_box_iou\n",
    "\n",
    "class HungarianMatcherHOI(nn.Module):\n",
    "    def __init__(self, cost_obj_class: float = 1, cost_verb_class: float = 1, cost_bbox: float = 1,\n",
    "                 cost_giou: float = 1, cost_matching: float = 1, use_matching: bool = False):\n",
    "        super().__init__()\n",
    "        self.cost_obj_class = cost_obj_class\n",
    "        self.cost_verb_class = cost_verb_class\n",
    "        self.cost_bbox = cost_bbox\n",
    "        self.cost_giou = cost_giou\n",
    "        self.cost_matching = cost_matching\n",
    "        self.use_matching = use_matching\n",
    "        assert cost_obj_class != 0 or cost_verb_class != 0 or cost_bbox != 0 or cost_giou != 0 or cost_matching != 0, 'all costs cant be 0'\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, outputs, targets):\n",
    "        bs, num_queries = outputs['pred_obj_logits'].shape[:2]\n",
    "        out_obj_prob = outputs['pred_obj_logits'].flatten(0, 1).softmax(-1)\n",
    "        out_verb_prob = outputs['pred_verb_logits'].flatten(0, 1).sigmoid()\n",
    "        out_sub_bbox = outputs['pred_sub_boxes'].flatten(0, 1)\n",
    "        out_obj_bbox = outputs['pred_obj_boxes'].flatten(0, 1)\n",
    "\n",
    "        tgt_obj_labels = torch.cat([v['obj_labels'] for v in targets])\n",
    "        tgt_verb_labels = torch.cat([v['verb_labels'] for v in targets])\n",
    "        tgt_verb_labels_permute = tgt_verb_labels.permute(1, 0)\n",
    "        tgt_sub_boxes = torch.cat([v['sub_boxes'] for v in targets])\n",
    "        tgt_obj_boxes = torch.cat([v['obj_boxes'] for v in targets])\n",
    "\n",
    "        cost_obj_class = -out_obj_prob[:, tgt_obj_labels]\n",
    "\n",
    "        tgt_verb_labels_permute = tgt_verb_labels.permute(1, 0)\n",
    "        cost_verb_class = -(out_verb_prob.matmul(tgt_verb_labels_permute) / \\\n",
    "                            (tgt_verb_labels_permute.sum(dim=0, keepdim=True) + 1e-4) + \\\n",
    "                            (1 - out_verb_prob).matmul(1 - tgt_verb_labels_permute) / \\\n",
    "                            ((1 - tgt_verb_labels_permute).sum(dim=0, keepdim=True) + 1e-4)) / 2\n",
    "\n",
    "        cost_sub_bbox = torch.cdist(out_sub_bbox, tgt_sub_boxes, p=1)\n",
    "        cost_obj_bbox = torch.cdist(out_obj_bbox, tgt_obj_boxes, p=1) * (tgt_obj_boxes != 0).any(dim=1).unsqueeze(0)\n",
    "        if cost_sub_bbox.shape[1] == 0:\n",
    "            cost_bbox = cost_sub_bbox\n",
    "        else:\n",
    "            cost_bbox = torch.stack((cost_sub_bbox, cost_obj_bbox)).max(dim=0)[0]\n",
    "\n",
    "        cost_sub_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_sub_bbox), box_cxcywh_to_xyxy(tgt_sub_boxes))\n",
    "        cost_obj_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_obj_bbox), box_cxcywh_to_xyxy(tgt_obj_boxes)) + \\\n",
    "                        cost_sub_giou * (tgt_obj_boxes == 0).all(dim=1).unsqueeze(0)\n",
    "        if cost_sub_giou.shape[1] == 0:\n",
    "            cost_giou = cost_sub_giou\n",
    "        else:\n",
    "            cost_giou = torch.stack((cost_sub_giou, cost_obj_giou)).max(dim=0)[0]\n",
    "\n",
    "        C = self.cost_obj_class * cost_obj_class + self.cost_verb_class * cost_verb_class + \\\n",
    "            self.cost_bbox * cost_bbox + self.cost_giou * cost_giou\n",
    "\n",
    "        if self.use_matching:\n",
    "            tgt_matching_labels = torch.cat([v['matching_labels'] for v in targets])\n",
    "            out_matching_prob = outputs['pred_matching_logits'].flatten(0, 1).softmax(-1)\n",
    "            cost_matching = -out_matching_prob[:, tgt_matching_labels]\n",
    "            C += self.cost_matching * cost_matching\n",
    "\n",
    "\n",
    "        C = C.view(bs, num_queries, -1).cpu()\n",
    "\n",
    "        sizes = [len(v['obj_labels']) for v in targets]\n",
    "        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]\n",
    "        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = HungarianMatcherHOI(\n",
    "    cost_obj_class=1, \n",
    "    cost_verb_class=1,\n",
    "    cost_bbox=2.5, \n",
    "    cost_giou=1, \n",
    "    cost_matching=1)\n",
    "\n",
    "weight_dict = {}\n",
    "weight_dict['loss_obj_ce'] = 1\n",
    "weight_dict['loss_verb_ce'] = 2\n",
    "weight_dict['loss_sub_bbox'] = 2.5\n",
    "weight_dict['loss_obj_bbox'] = 2.5\n",
    "weight_dict['loss_sub_giou'] = 1\n",
    "weight_dict['loss_obj_giou'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dec_layers_num = min(dec_layers_hopd, dec_layers_interaction)\n",
    "aux_weight_dict = {}\n",
    "for i in range(min_dec_layers_num - 1):\n",
    "    aux_weight_dict.update({k + f'_{i}': v for k, v in weight_dict.items()})\n",
    "weight_dict.update(aux_weight_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "import math\n",
    "from utils.misc import accuracy, is_dist_avail_and_initialized, get_world_size\n",
    "\n",
    "class SetCriterionHOI(nn.Module):\n",
    "\n",
    "    def __init__(self, num_obj_classes, num_queries, num_verb_classes, matcher, weight_dict, eos_coef, losses):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_obj_classes = num_obj_classes\n",
    "        self.num_queries = num_queries\n",
    "        self.num_verb_classes = num_verb_classes\n",
    "        self.matcher = matcher\n",
    "        self.weight_dict = weight_dict\n",
    "        self.eos_coef = eos_coef\n",
    "        self.losses = losses\n",
    "        empty_weight = torch.ones(self.num_obj_classes + 1)\n",
    "        empty_weight[-1] = self.eos_coef\n",
    "        self.register_buffer('empty_weight', empty_weight)\n",
    "\n",
    "        self.alpha = 0.5\n",
    "        self.obj_nums_init = [5397, 238, 332, 321, 5, 6, 45, 90, 59, 20, \\\n",
    "                                13, 5, 6, 313, 28, 25, 46, 277, 20, 16, \\\n",
    "                                154, 0, 7, 13, 356, 191, 458, 66, 337, 1364, \\\n",
    "                                1382, 958, 1166, 68, 258, 221, 1317, 1428, 759, 201, \\\n",
    "                                190, 444, 274, 587, 124, 107, 102, 37, 226, 16, \\\n",
    "                                30, 22, 187, 320, 222, 465, 893, 213, 56, 322, \\\n",
    "                                306, 13, 55, 834, 23, 104, 38, 861, 11, 27, \\\n",
    "                                0, 16, 22, 405, 50, 14, 145, 63, 9, 11]\n",
    "\n",
    "\n",
    "        self.obj_nums_init.append(3 * sum(self.obj_nums_init))  # 3 times fg for bg init\n",
    "        self.verb_nums_init = [4001, 4598, 1989, 488, 656, 3825, 367, 367, 677, 677, \\\n",
    "                                700, 471, 354, 498, 300, 313, 300, 300, 622, 458, \\\n",
    "                                500, 498, 489, 1545, 133, 142, 38, 116, 388]\n",
    "\n",
    "\n",
    "        self.verb_nums_init.append(3 * sum(self.verb_nums_init))\n",
    "\n",
    "        self.obj_reweight = False\n",
    "        self.verb_reweight = False\n",
    "        self.use_static_weights = False\n",
    "        \n",
    "        Maxsize = 4704*1.0\n",
    "\n",
    "        if self.obj_reweight:\n",
    "            self.q_obj = Queue(maxsize=Maxsize)\n",
    "            self.p_obj = 0.7\n",
    "            self.obj_weights_init = self.cal_weights(self.obj_nums_init, p=self.p_obj)\n",
    "\n",
    "        if self.verb_reweight:\n",
    "            self.q_verb = Queue(maxsize=Maxsize)\n",
    "            self.p_verb = 0.7\n",
    "            self.verb_weights_init = self.cal_weights(self.verb_nums_init, p=self.p_verb)\n",
    "\n",
    "    def cal_weights(self, label_nums, p=0.5):\n",
    "        num_fgs = len(label_nums[:-1])\n",
    "        weight = [0] * (num_fgs + 1)\n",
    "        num_all = sum(label_nums[:-1])\n",
    "\n",
    "        for index in range(num_fgs):\n",
    "            if label_nums[index] == 0: continue\n",
    "            weight[index] = np.power(num_all/label_nums[index], p)\n",
    "\n",
    "        weight = np.array(weight)\n",
    "        weight = weight / np.mean(weight[weight>0])\n",
    "\n",
    "        weight[-1] = np.power(num_all/label_nums[-1], p) if label_nums[-1] != 0 else 0\n",
    "\n",
    "        weight = torch.FloatTensor(weight).cuda()\n",
    "        return weight\n",
    "\n",
    "    def loss_obj_labels(self, outputs, targets, indices, num_interactions, log=True):\n",
    "        assert 'pred_obj_logits' in outputs\n",
    "        src_logits = outputs['pred_obj_logits']\n",
    "\n",
    "        idx = self._get_src_permutation_idx(indices)\n",
    "        target_classes_o = torch.cat([t['obj_labels'][J] for t, (_, J) in zip(targets, indices)])\n",
    "        target_classes = torch.full(src_logits.shape[:2], self.num_obj_classes,\n",
    "                                    dtype=torch.int64, device=src_logits.device)\n",
    "        target_classes[idx] = target_classes_o\n",
    "\n",
    "        if not self.obj_reweight:\n",
    "            obj_weights = self.empty_weight\n",
    "        elif self.use_static_weights:\n",
    "            obj_weights = self.obj_weights_init\n",
    "        else:\n",
    "            obj_label_nums_in_batch = [0] * (self.num_obj_classes + 1)\n",
    "            for target_class in target_classes:\n",
    "                for label in target_class:\n",
    "                    obj_label_nums_in_batch[label] += 1\n",
    "\n",
    "            if self.q_obj.full(): self.q_obj.get()\n",
    "            self.q_obj.put(np.array(obj_label_nums_in_batch))\n",
    "            accumulated_obj_label_nums = np.sum(self.q_obj.queue, axis=0)\n",
    "            obj_weights = self.cal_weights(accumulated_obj_label_nums, p=self.p_obj)\n",
    "\n",
    "            aphal = min(math.pow(0.999, self.q_obj.qsize()),0.9)\n",
    "            obj_weights = aphal * self.obj_weights_init + (1 - aphal) * obj_weights\n",
    "\n",
    "        loss_obj_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, obj_weights)\n",
    "        losses = {'loss_obj_ce': loss_obj_ce}\n",
    "\n",
    "        if log:\n",
    "            losses['obj_class_error'] = 100 - accuracy(src_logits[idx], target_classes_o)[0]\n",
    "        return losses\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def loss_obj_cardinality(self, outputs, targets, indices, num_interactions):\n",
    "        pred_logits = outputs['pred_obj_logits']\n",
    "        device = pred_logits.device\n",
    "        tgt_lengths = torch.as_tensor([len(v['obj_labels']) for v in targets], device=device)\n",
    "        card_pred = (pred_logits.argmax(-1) != pred_logits.shape[-1] - 1).sum(1)\n",
    "        card_err = F.l1_loss(card_pred.float(), tgt_lengths.float())\n",
    "        losses = {'obj_cardinality_error': card_err}\n",
    "        return losses\n",
    "\n",
    "    def loss_verb_labels(self, outputs, targets, indices, num_interactions):\n",
    "        assert 'pred_verb_logits' in outputs\n",
    "        src_logits = outputs['pred_verb_logits']\n",
    "\n",
    "        idx = self._get_src_permutation_idx(indices)\n",
    "        target_classes_o = torch.cat([t['verb_labels'][J] for t, (_, J) in zip(targets, indices)])\n",
    "        target_classes = torch.zeros_like(src_logits)\n",
    "        target_classes[idx] = target_classes_o\n",
    "\n",
    "        if not self.verb_reweight:\n",
    "            verb_weights = None\n",
    "        elif self.use_static_weights:\n",
    "            verb_weights = self.verb_weights_init\n",
    "        else:\n",
    "            verb_label_nums_in_batch = [0] * (self.num_verb_classes + 1)\n",
    "            for target_class in target_classes:\n",
    "                for label in target_class:\n",
    "                    label_classes = torch.where(label > 0)[0]\n",
    "                    if len(label_classes) == 0:\n",
    "                        verb_label_nums_in_batch[-1] += 1\n",
    "                    else:\n",
    "                        for label_class in label_classes:\n",
    "                            verb_label_nums_in_batch[label_class] += 1\n",
    "\n",
    "            if self.q_verb.full(): self.q_verb.get()\n",
    "            self.q_verb.put(np.array(verb_label_nums_in_batch))\n",
    "            accumulated_verb_label_nums = np.sum(self.q_verb.queue, axis=0)\n",
    "            verb_weights = self.cal_weights(accumulated_verb_label_nums, p=self.p_verb)\n",
    "\n",
    "            aphal = min(math.pow(0.999, self.q_verb.qsize()),0.9)\n",
    "            verb_weights = aphal * self.verb_weights_init + (1 - aphal) * verb_weights\n",
    "\n",
    "        src_logits = src_logits.sigmoid()\n",
    "        loss_verb_ce = self._neg_loss(src_logits, target_classes, weights=verb_weights, alpha=self.alpha)\n",
    "\n",
    "        losses = {'loss_verb_ce': loss_verb_ce}\n",
    "        return losses\n",
    "\n",
    "    def loss_sub_obj_boxes(self, outputs, targets, indices, num_interactions):\n",
    "        assert 'pred_sub_boxes' in outputs and 'pred_obj_boxes' in outputs\n",
    "        idx = self._get_src_permutation_idx(indices)\n",
    "        src_sub_boxes = outputs['pred_sub_boxes'][idx]\n",
    "        src_obj_boxes = outputs['pred_obj_boxes'][idx]\n",
    "        target_sub_boxes = torch.cat([t['sub_boxes'][i] for t, (_, i) in zip(targets, indices)], dim=0)\n",
    "        target_obj_boxes = torch.cat([t['obj_boxes'][i] for t, (_, i) in zip(targets, indices)], dim=0)\n",
    "\n",
    "        exist_obj_boxes = (target_obj_boxes != 0).any(dim=1)\n",
    "\n",
    "        losses = {}\n",
    "        if src_sub_boxes.shape[0] == 0:\n",
    "            losses['loss_sub_bbox'] = src_sub_boxes.sum()\n",
    "            losses['loss_obj_bbox'] = src_obj_boxes.sum()\n",
    "            losses['loss_sub_giou'] = src_sub_boxes.sum()\n",
    "            losses['loss_obj_giou'] = src_obj_boxes.sum()\n",
    "        else:\n",
    "            loss_sub_bbox = F.l1_loss(src_sub_boxes, target_sub_boxes, reduction='none')\n",
    "            loss_obj_bbox = F.l1_loss(src_obj_boxes, target_obj_boxes, reduction='none')\n",
    "            losses['loss_sub_bbox'] = loss_sub_bbox.sum() / num_interactions\n",
    "            losses['loss_obj_bbox'] = (loss_obj_bbox * exist_obj_boxes.unsqueeze(1)).sum() / (exist_obj_boxes.sum() + 1e-4)\n",
    "            loss_sub_giou = 1 - torch.diag(generalized_box_iou(box_cxcywh_to_xyxy(src_sub_boxes),\n",
    "                                                               box_cxcywh_to_xyxy(target_sub_boxes)))\n",
    "            loss_obj_giou = 1 - torch.diag(generalized_box_iou(box_cxcywh_to_xyxy(src_obj_boxes),\n",
    "                                                               box_cxcywh_to_xyxy(target_obj_boxes)))\n",
    "            losses['loss_sub_giou'] = loss_sub_giou.sum() / num_interactions\n",
    "            losses['loss_obj_giou'] = (loss_obj_giou * exist_obj_boxes).sum() / (exist_obj_boxes.sum() + 1e-4)\n",
    "        return losses\n",
    "\n",
    "    def loss_matching_labels(self, outputs, targets, indices, num_interactions, log=True):\n",
    "        assert 'pred_matching_logits' in outputs\n",
    "        src_logits = outputs['pred_matching_logits']\n",
    "\n",
    "        idx = self._get_src_permutation_idx(indices)\n",
    "        target_classes_o = torch.cat([t['matching_labels'][J] for t, (_, J) in zip(targets, indices)])\n",
    "        target_classes = torch.full(src_logits.shape[:2], 0,\n",
    "                                    dtype=torch.int64, device=src_logits.device)\n",
    "        target_classes[idx] = target_classes_o\n",
    "\n",
    "        loss_matching = F.cross_entropy(src_logits.transpose(1, 2), target_classes)\n",
    "        losses = {'loss_matching': loss_matching}\n",
    "\n",
    "        if log:\n",
    "            losses['matching_error'] = 100 - accuracy(src_logits[idx], target_classes_o)[0]\n",
    "        return losses\n",
    "\n",
    "    def _neg_loss(self, pred, gt, weights=None, alpha=0.25):\n",
    "        pos_inds = gt.eq(1).float()\n",
    "        neg_inds = gt.lt(1).float()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        pos_loss = alpha * torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "        if weights is not None:\n",
    "            pos_loss = pos_loss * weights[:-1]\n",
    "\n",
    "        neg_loss = (1 - alpha) * torch.log(1 - pred) * torch.pow(pred, 2) * neg_inds\n",
    "\n",
    "        num_pos  = pos_inds.float().sum()\n",
    "        pos_loss = pos_loss.sum()\n",
    "        neg_loss = neg_loss.sum()\n",
    "\n",
    "        if num_pos == 0:\n",
    "            loss = loss - neg_loss\n",
    "        else:\n",
    "            loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "        return loss\n",
    "\n",
    "    def _get_src_permutation_idx(self, indices):\n",
    "        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n",
    "        src_idx = torch.cat([src for (src, _) in indices])\n",
    "        return batch_idx, src_idx\n",
    "\n",
    "    def _get_tgt_permutation_idx(self, indices):\n",
    "        batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])\n",
    "        tgt_idx = torch.cat([tgt for (_, tgt) in indices])\n",
    "        return batch_idx, tgt_idx\n",
    "\n",
    "    def get_loss(self, loss, outputs, targets, indices, num, **kwargs):\n",
    "        loss_map = {\n",
    "            'obj_labels': self.loss_obj_labels,\n",
    "            'obj_cardinality': self.loss_obj_cardinality,\n",
    "            'verb_labels': self.loss_verb_labels,\n",
    "            'sub_obj_boxes': self.loss_sub_obj_boxes,\n",
    "            'matching_labels': self.loss_matching_labels\n",
    "        }\n",
    "        assert loss in loss_map, f'do you really want to compute {loss} loss?'\n",
    "        return loss_map[loss](outputs, targets, indices, num, **kwargs)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        outputs_without_aux = {k: v for k, v in outputs.items() if k != 'aux_outputs'}\n",
    "\n",
    "        indices = self.matcher(outputs_without_aux, targets)\n",
    "\n",
    "        num_interactions = sum(len(t['obj_labels']) for t in targets)\n",
    "        num_interactions = torch.as_tensor([num_interactions], dtype=torch.float, device=next(iter(outputs.values())).device)\n",
    "        if is_dist_avail_and_initialized():\n",
    "            torch.distributed.all_reduce(num_interactions)\n",
    "        num_interactions = torch.clamp(num_interactions / get_world_size(), min=1).item()\n",
    "\n",
    "        losses = {}\n",
    "        for loss in self.losses:\n",
    "            losses.update(self.get_loss(loss, outputs, targets, indices, num_interactions))\n",
    "\n",
    "        if 'aux_outputs' in outputs:\n",
    "            for i, aux_outputs in enumerate(outputs['aux_outputs']):\n",
    "                indices = self.matcher(aux_outputs, targets)\n",
    "                for loss in self.losses:\n",
    "                    kwargs = {}\n",
    "                    if loss == 'obj_labels':\n",
    "                        kwargs = {'log': False}\n",
    "                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_interactions, **kwargs)\n",
    "                    l_dict = {k + f'_{i}': v for k, v in l_dict.items()}\n",
    "                    losses.update(l_dict)\n",
    "\n",
    "        return losses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostProcessHOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessHOI(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.subject_category_id = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, outputs, target_sizes):\n",
    "        out_obj_logits = outputs['pred_obj_logits']\n",
    "        out_verb_logits = outputs['pred_verb_logits']\n",
    "        out_sub_boxes = outputs['pred_sub_boxes']\n",
    "        out_obj_boxes = outputs['pred_obj_boxes']\n",
    "\n",
    "        assert len(out_obj_logits) == len(target_sizes)\n",
    "        assert target_sizes.shape[1] == 2\n",
    "\n",
    "        obj_prob = F.softmax(out_obj_logits, -1)\n",
    "        obj_scores, obj_labels = obj_prob[..., :-1].max(-1)\n",
    "\n",
    "        verb_scores = out_verb_logits.sigmoid()\n",
    "\n",
    "        img_h, img_w = target_sizes.unbind(1)\n",
    "        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(verb_scores.device)\n",
    "        sub_boxes = box_cxcywh_to_xyxy(out_sub_boxes)\n",
    "        sub_boxes = sub_boxes * scale_fct[:, None, :]\n",
    "        obj_boxes = box_cxcywh_to_xyxy(out_obj_boxes)\n",
    "        obj_boxes = obj_boxes * scale_fct[:, None, :]\n",
    "\n",
    "        results = []\n",
    "        for index in range(len(obj_scores)):\n",
    "            os, ol, vs, sb, ob =  obj_scores[index], obj_labels[index], verb_scores[index], sub_boxes[index], obj_boxes[index]\n",
    "            sl = torch.full_like(ol, self.subject_category_id)\n",
    "            l = torch.cat((sl, ol))\n",
    "            b = torch.cat((sb, ob))\n",
    "            results.append({'labels': l.to('cpu'), 'boxes': b.to('cpu')})\n",
    "\n",
    "            vs = vs * os.unsqueeze(1)\n",
    "            ids = torch.arange(b.shape[0])\n",
    "\n",
    "            results[-1].update({'verb_scores': vs.to('cpu'), 'sub_ids': ids[:ids.shape[0] // 2],\n",
    "                                'obj_ids': ids[ids.shape[0] // 2:]})\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = ['obj_labels', 'verb_labels', 'sub_obj_boxes', 'obj_cardinality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obj_classes = 80\n",
    "num_queries = 100\n",
    "num_verb_classes = 27\n",
    "eos_coef = 0.1\n",
    "\n",
    "criterion = SetCriterionHOI(num_obj_classes, num_queries, num_verb_classes, matcher=matcher,\n",
    "                            weight_dict=weight_dict, eos_coef=eos_coef, losses=losses)\n",
    "criterion.to('cuda')\n",
    "postprocessors = {'hoi': PostProcessHOI()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, criterion, postprocessors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_obj_logits': tensor([[[ 0.4069, -0.7388, -1.1195,  ...,  1.2186,  0.0463, -0.8967],\n",
      "         [ 0.1011, -0.4452, -1.0915,  ...,  0.8161, -0.0646, -0.8410],\n",
      "         [ 0.3581, -0.3547, -1.2532,  ...,  0.9195,  0.2502, -0.4877],\n",
      "         ...,\n",
      "         [ 0.3642, -0.6016, -1.1984,  ...,  1.0076,  0.1251, -0.7826],\n",
      "         [ 0.4027, -0.7535, -1.3923,  ...,  1.1560,  0.1017, -0.5479],\n",
      "         [ 0.3033, -0.6127, -1.3077,  ...,  1.3301,  0.4290, -0.6307]]],\n",
      "       device='cuda:0'), 'pred_verb_logits': tensor([[[ 1.0872e-03, -1.1454e+00,  1.7906e-01,  ...,  7.4256e-01,\n",
      "          -3.7168e-02,  6.7809e-02],\n",
      "         [ 4.8286e-02, -8.7118e-01,  3.1757e-01,  ...,  1.0989e+00,\n",
      "          -1.7957e-01,  8.5403e-02],\n",
      "         [ 6.4983e-02, -1.0013e+00,  1.4836e-01,  ...,  1.1264e+00,\n",
      "          -1.1955e-01,  1.7476e-01],\n",
      "         ...,\n",
      "         [ 2.2820e-01, -8.1646e-01,  1.2968e-01,  ...,  1.0931e+00,\n",
      "          -1.5743e-01, -4.7397e-02],\n",
      "         [-7.5525e-02, -9.0131e-01,  1.2192e-01,  ...,  1.0395e+00,\n",
      "          -1.2015e-01, -4.0901e-02],\n",
      "         [-9.1109e-02, -1.0433e+00,  9.7430e-02,  ...,  1.2129e+00,\n",
      "          -1.0719e-01, -5.7496e-02]]], device='cuda:0'), 'pred_sub_boxes': tensor([[[0.5073, 0.4692, 0.5112, 0.4897],\n",
      "         [0.5076, 0.4638, 0.4979, 0.5091],\n",
      "         [0.5043, 0.4538, 0.4898, 0.5103],\n",
      "         [0.5180, 0.4657, 0.4941, 0.5070],\n",
      "         [0.5000, 0.4688, 0.4854, 0.5031],\n",
      "         [0.5103, 0.4660, 0.4865, 0.4980],\n",
      "         [0.5135, 0.4621, 0.4987, 0.4940],\n",
      "         [0.4959, 0.4628, 0.4952, 0.5021],\n",
      "         [0.5006, 0.4624, 0.5018, 0.5004],\n",
      "         [0.4987, 0.4660, 0.4954, 0.5013],\n",
      "         [0.5051, 0.4662, 0.4894, 0.5023],\n",
      "         [0.5092, 0.4711, 0.4992, 0.4889],\n",
      "         [0.5076, 0.4658, 0.5018, 0.5080],\n",
      "         [0.4930, 0.4687, 0.4965, 0.5008],\n",
      "         [0.5080, 0.4768, 0.4831, 0.5049],\n",
      "         [0.5055, 0.4657, 0.4969, 0.5005],\n",
      "         [0.5054, 0.4649, 0.4868, 0.5003],\n",
      "         [0.5083, 0.4619, 0.4876, 0.5054],\n",
      "         [0.4949, 0.4608, 0.4948, 0.5078],\n",
      "         [0.5084, 0.4587, 0.4988, 0.5055],\n",
      "         [0.5002, 0.4524, 0.5040, 0.5101],\n",
      "         [0.5067, 0.4642, 0.5018, 0.5008],\n",
      "         [0.4979, 0.4645, 0.4895, 0.5014],\n",
      "         [0.5054, 0.4693, 0.4962, 0.5031],\n",
      "         [0.4947, 0.4723, 0.4934, 0.5085],\n",
      "         [0.4985, 0.4682, 0.4867, 0.5117],\n",
      "         [0.5067, 0.4628, 0.4954, 0.4979],\n",
      "         [0.4976, 0.4671, 0.4974, 0.5010],\n",
      "         [0.5122, 0.4635, 0.4821, 0.5110],\n",
      "         [0.4974, 0.4630, 0.4993, 0.5045],\n",
      "         [0.4897, 0.4734, 0.4869, 0.5030],\n",
      "         [0.5144, 0.4716, 0.5068, 0.4972],\n",
      "         [0.4965, 0.4677, 0.4964, 0.5135],\n",
      "         [0.5073, 0.4762, 0.4908, 0.5011],\n",
      "         [0.4984, 0.4655, 0.4880, 0.5139],\n",
      "         [0.5098, 0.4536, 0.4949, 0.5089],\n",
      "         [0.4964, 0.4643, 0.4873, 0.5084],\n",
      "         [0.4955, 0.4788, 0.4972, 0.4960],\n",
      "         [0.5103, 0.4658, 0.4978, 0.5007],\n",
      "         [0.5090, 0.4621, 0.4944, 0.5053],\n",
      "         [0.5075, 0.4686, 0.4898, 0.5058],\n",
      "         [0.4983, 0.4701, 0.4911, 0.4983],\n",
      "         [0.5148, 0.4614, 0.4996, 0.5004],\n",
      "         [0.4906, 0.4668, 0.5014, 0.5052],\n",
      "         [0.5074, 0.4729, 0.4925, 0.5030],\n",
      "         [0.4953, 0.4576, 0.4841, 0.5091],\n",
      "         [0.5106, 0.4608, 0.4921, 0.5078],\n",
      "         [0.4991, 0.4648, 0.4920, 0.5081],\n",
      "         [0.5177, 0.4816, 0.4984, 0.4925],\n",
      "         [0.5100, 0.4651, 0.4902, 0.4973],\n",
      "         [0.5053, 0.4596, 0.4876, 0.5108],\n",
      "         [0.4914, 0.4595, 0.4927, 0.5038],\n",
      "         [0.4960, 0.4576, 0.4854, 0.5043],\n",
      "         [0.5020, 0.4683, 0.4946, 0.5018],\n",
      "         [0.4960, 0.4616, 0.4865, 0.5076],\n",
      "         [0.5031, 0.4678, 0.4961, 0.5077],\n",
      "         [0.5056, 0.4668, 0.4935, 0.5019],\n",
      "         [0.5008, 0.4687, 0.4902, 0.4990],\n",
      "         [0.5076, 0.4689, 0.4970, 0.5006],\n",
      "         [0.5118, 0.4769, 0.4923, 0.4958],\n",
      "         [0.5000, 0.4535, 0.4951, 0.5064],\n",
      "         [0.5011, 0.4674, 0.4932, 0.5069],\n",
      "         [0.5026, 0.4650, 0.4959, 0.5065],\n",
      "         [0.4908, 0.4668, 0.4936, 0.5107],\n",
      "         [0.5084, 0.4639, 0.4950, 0.5012],\n",
      "         [0.5091, 0.4703, 0.4948, 0.5030],\n",
      "         [0.5006, 0.4707, 0.5071, 0.5048],\n",
      "         [0.5110, 0.4637, 0.4848, 0.5048],\n",
      "         [0.5182, 0.4647, 0.4905, 0.5057],\n",
      "         [0.5023, 0.4626, 0.4968, 0.5011],\n",
      "         [0.5025, 0.4660, 0.4913, 0.5037],\n",
      "         [0.5075, 0.4657, 0.4941, 0.5075],\n",
      "         [0.5074, 0.4656, 0.4859, 0.5046],\n",
      "         [0.5085, 0.4597, 0.4899, 0.4992],\n",
      "         [0.5035, 0.4668, 0.4933, 0.5048],\n",
      "         [0.5110, 0.4762, 0.4902, 0.5031],\n",
      "         [0.5034, 0.4715, 0.4844, 0.4978],\n",
      "         [0.5143, 0.4586, 0.5029, 0.4984],\n",
      "         [0.5134, 0.4602, 0.4872, 0.4972],\n",
      "         [0.4949, 0.4754, 0.4978, 0.4959],\n",
      "         [0.5070, 0.4666, 0.4961, 0.5032],\n",
      "         [0.5034, 0.4630, 0.4965, 0.5123],\n",
      "         [0.4930, 0.4673, 0.4932, 0.5096],\n",
      "         [0.5082, 0.4627, 0.4822, 0.5028],\n",
      "         [0.5046, 0.4666, 0.4984, 0.5054],\n",
      "         [0.5102, 0.4710, 0.4879, 0.5021],\n",
      "         [0.5054, 0.4739, 0.4908, 0.4927],\n",
      "         [0.5119, 0.4728, 0.4944, 0.5054],\n",
      "         [0.4988, 0.4716, 0.4919, 0.5012],\n",
      "         [0.5023, 0.4643, 0.4975, 0.5008],\n",
      "         [0.5014, 0.4591, 0.4862, 0.5044],\n",
      "         [0.5013, 0.4538, 0.4997, 0.5078],\n",
      "         [0.5160, 0.4698, 0.4903, 0.5057],\n",
      "         [0.4980, 0.4643, 0.4984, 0.5016],\n",
      "         [0.5091, 0.4675, 0.5033, 0.5010],\n",
      "         [0.5050, 0.4739, 0.4952, 0.5009],\n",
      "         [0.5070, 0.4668, 0.4986, 0.5092],\n",
      "         [0.5060, 0.4652, 0.4918, 0.4992],\n",
      "         [0.4930, 0.4692, 0.4788, 0.5122],\n",
      "         [0.5024, 0.4694, 0.5010, 0.5049]]], device='cuda:0'), 'pred_obj_boxes': tensor([[[0.4832, 0.5062, 0.5205, 0.4900],\n",
      "         [0.4966, 0.5104, 0.5140, 0.4885],\n",
      "         [0.4996, 0.5096, 0.5216, 0.4964],\n",
      "         [0.4879, 0.4924, 0.5281, 0.4960],\n",
      "         [0.4863, 0.5045, 0.5183, 0.4973],\n",
      "         [0.5071, 0.5018, 0.5211, 0.4781],\n",
      "         [0.4834, 0.5032, 0.5169, 0.4862],\n",
      "         [0.4847, 0.4928, 0.5144, 0.4905],\n",
      "         [0.4985, 0.5010, 0.5124, 0.4968],\n",
      "         [0.5071, 0.4932, 0.5263, 0.4861],\n",
      "         [0.5027, 0.4894, 0.5144, 0.4852],\n",
      "         [0.4876, 0.5073, 0.5162, 0.4917],\n",
      "         [0.4879, 0.5029, 0.5095, 0.4886],\n",
      "         [0.4982, 0.5097, 0.5086, 0.4941],\n",
      "         [0.5023, 0.5011, 0.5181, 0.4784],\n",
      "         [0.4919, 0.5040, 0.5164, 0.4936],\n",
      "         [0.5025, 0.4964, 0.5111, 0.5062],\n",
      "         [0.4925, 0.5064, 0.5170, 0.4824],\n",
      "         [0.4969, 0.5038, 0.5159, 0.4936],\n",
      "         [0.5005, 0.5060, 0.5179, 0.4956],\n",
      "         [0.4978, 0.5010, 0.5258, 0.4891],\n",
      "         [0.5010, 0.4958, 0.5204, 0.4776],\n",
      "         [0.4936, 0.4959, 0.5116, 0.4917],\n",
      "         [0.4892, 0.5022, 0.5211, 0.4814],\n",
      "         [0.4931, 0.5021, 0.5150, 0.5006],\n",
      "         [0.4925, 0.5030, 0.5106, 0.4915],\n",
      "         [0.4897, 0.5017, 0.5203, 0.4900],\n",
      "         [0.4842, 0.4949, 0.5155, 0.4811],\n",
      "         [0.4986, 0.4930, 0.5087, 0.4952],\n",
      "         [0.4863, 0.5065, 0.5133, 0.4906],\n",
      "         [0.4957, 0.5018, 0.5207, 0.4863],\n",
      "         [0.4911, 0.4960, 0.5202, 0.4862],\n",
      "         [0.4902, 0.5034, 0.5167, 0.4919],\n",
      "         [0.4963, 0.4951, 0.5138, 0.4972],\n",
      "         [0.5108, 0.4952, 0.5159, 0.4908],\n",
      "         [0.4918, 0.4909, 0.5186, 0.5031],\n",
      "         [0.4959, 0.4996, 0.5063, 0.4885],\n",
      "         [0.4961, 0.5025, 0.5232, 0.4892],\n",
      "         [0.4916, 0.4939, 0.5166, 0.4918],\n",
      "         [0.5020, 0.5100, 0.5266, 0.5020],\n",
      "         [0.4900, 0.5074, 0.5195, 0.4921],\n",
      "         [0.4896, 0.4974, 0.5229, 0.4813],\n",
      "         [0.4905, 0.5018, 0.5219, 0.4829],\n",
      "         [0.4999, 0.4991, 0.5220, 0.4939],\n",
      "         [0.4902, 0.5033, 0.5157, 0.4959],\n",
      "         [0.4946, 0.5019, 0.5106, 0.4830],\n",
      "         [0.4899, 0.5061, 0.5230, 0.4968],\n",
      "         [0.4989, 0.5006, 0.5161, 0.4936],\n",
      "         [0.4817, 0.4978, 0.5169, 0.4935],\n",
      "         [0.4795, 0.4883, 0.5147, 0.4974],\n",
      "         [0.5082, 0.5016, 0.5074, 0.4920],\n",
      "         [0.4922, 0.4915, 0.5156, 0.4970],\n",
      "         [0.4833, 0.5021, 0.5226, 0.4930],\n",
      "         [0.5071, 0.5124, 0.5148, 0.4831],\n",
      "         [0.4821, 0.4968, 0.5209, 0.4901],\n",
      "         [0.4963, 0.5025, 0.5158, 0.4924],\n",
      "         [0.4951, 0.5012, 0.5156, 0.4920],\n",
      "         [0.4879, 0.4948, 0.5171, 0.4950],\n",
      "         [0.4881, 0.5025, 0.5185, 0.4953],\n",
      "         [0.4936, 0.4994, 0.5092, 0.4837],\n",
      "         [0.4948, 0.5028, 0.5170, 0.4953],\n",
      "         [0.4901, 0.4979, 0.5034, 0.4958],\n",
      "         [0.5004, 0.5006, 0.5089, 0.4958],\n",
      "         [0.5005, 0.4953, 0.5219, 0.4969],\n",
      "         [0.4915, 0.5067, 0.5178, 0.4857],\n",
      "         [0.4860, 0.5025, 0.5210, 0.4937],\n",
      "         [0.4892, 0.5010, 0.5171, 0.4906],\n",
      "         [0.5143, 0.5029, 0.5131, 0.4820],\n",
      "         [0.4905, 0.4950, 0.5187, 0.4909],\n",
      "         [0.4853, 0.5041, 0.5271, 0.4924],\n",
      "         [0.4881, 0.5009, 0.5195, 0.4913],\n",
      "         [0.5003, 0.5019, 0.5123, 0.5000],\n",
      "         [0.4862, 0.4931, 0.5196, 0.4979],\n",
      "         [0.4851, 0.4992, 0.5209, 0.4877],\n",
      "         [0.4862, 0.4952, 0.5175, 0.4843],\n",
      "         [0.4958, 0.5058, 0.5143, 0.4837],\n",
      "         [0.4963, 0.4983, 0.5080, 0.4964],\n",
      "         [0.4865, 0.4931, 0.5225, 0.4866],\n",
      "         [0.4913, 0.4965, 0.5136, 0.4925],\n",
      "         [0.5004, 0.4991, 0.5214, 0.4829],\n",
      "         [0.4959, 0.5056, 0.5188, 0.4881],\n",
      "         [0.4959, 0.4977, 0.5071, 0.4996],\n",
      "         [0.4949, 0.5023, 0.5149, 0.4841],\n",
      "         [0.5008, 0.4941, 0.5232, 0.4928],\n",
      "         [0.4909, 0.4965, 0.5223, 0.4999],\n",
      "         [0.4980, 0.5052, 0.5173, 0.4926],\n",
      "         [0.4916, 0.5020, 0.5173, 0.4890],\n",
      "         [0.4995, 0.4936, 0.5094, 0.4946],\n",
      "         [0.4914, 0.5018, 0.5233, 0.4848],\n",
      "         [0.4914, 0.4939, 0.5045, 0.4899],\n",
      "         [0.5020, 0.4978, 0.5173, 0.4946],\n",
      "         [0.4898, 0.4973, 0.5157, 0.4998],\n",
      "         [0.4972, 0.5044, 0.5140, 0.4885],\n",
      "         [0.4944, 0.5023, 0.5206, 0.4933],\n",
      "         [0.5000, 0.5169, 0.5143, 0.4941],\n",
      "         [0.4834, 0.5016, 0.5130, 0.4939],\n",
      "         [0.4950, 0.5070, 0.5215, 0.4869],\n",
      "         [0.4920, 0.4983, 0.5102, 0.4918],\n",
      "         [0.4986, 0.4993, 0.5140, 0.4999],\n",
      "         [0.5037, 0.4985, 0.5217, 0.4925]]], device='cuda:0'), 'aux_outputs': [{'pred_obj_logits': tensor([[[ 0.8548, -0.5134, -0.8006,  ...,  0.5911, -0.0461, -0.9973],\n",
      "         [ 0.6713, -0.2550, -0.6937,  ...,  0.4657, -0.3227, -1.1490],\n",
      "         [ 0.9301, -0.4057, -0.7256,  ...,  0.2016,  0.2807, -0.7161],\n",
      "         ...,\n",
      "         [ 0.6548, -0.5633, -0.7406,  ...,  0.5593,  0.0616, -0.9192],\n",
      "         [ 0.9350, -0.6219, -1.1765,  ...,  0.5640,  0.1014, -0.5670],\n",
      "         [ 0.6513, -0.9494, -1.0497,  ...,  0.8280, -0.0679, -0.8674]]],\n",
      "       device='cuda:0'), 'pred_verb_logits': tensor([[[-1.9327e-02, -1.3133e+00,  1.6277e-01,  ...,  8.9138e-01,\n",
      "          -5.9585e-02, -4.4359e-01],\n",
      "         [-1.6991e-01, -1.3017e+00,  2.6719e-01,  ...,  1.4231e+00,\n",
      "          -3.3289e-01, -1.2836e-01],\n",
      "         [-5.8595e-02, -1.1164e+00, -1.1681e-01,  ...,  1.1954e+00,\n",
      "          -2.9487e-01, -1.8405e-01],\n",
      "         ...,\n",
      "         [ 1.7125e-01, -1.2142e+00, -3.0646e-02,  ...,  1.2649e+00,\n",
      "          -4.0233e-01, -4.2666e-01],\n",
      "         [-2.9412e-01, -1.2633e+00, -6.0488e-04,  ...,  1.1879e+00,\n",
      "          -4.8867e-01, -1.9038e-01],\n",
      "         [-2.1670e-01, -1.2447e+00, -4.7901e-02,  ...,  9.9497e-01,\n",
      "          -3.1299e-01, -5.2720e-02]]], device='cuda:0'), 'pred_sub_boxes': tensor([[[0.5023, 0.4747, 0.5043, 0.4864],\n",
      "         [0.4870, 0.4645, 0.5058, 0.5068],\n",
      "         [0.4888, 0.4576, 0.4817, 0.5202],\n",
      "         [0.5013, 0.4748, 0.4890, 0.5036],\n",
      "         [0.4878, 0.4725, 0.4801, 0.5085],\n",
      "         [0.4886, 0.4752, 0.4811, 0.5004],\n",
      "         [0.4966, 0.4652, 0.4992, 0.5017],\n",
      "         [0.4778, 0.4672, 0.4829, 0.5027],\n",
      "         [0.4830, 0.4672, 0.5008, 0.5059],\n",
      "         [0.4917, 0.4688, 0.4846, 0.5090],\n",
      "         [0.4884, 0.4755, 0.4934, 0.5022],\n",
      "         [0.4914, 0.4733, 0.4859, 0.5001],\n",
      "         [0.4821, 0.4648, 0.5006, 0.5250],\n",
      "         [0.4867, 0.4741, 0.4881, 0.5008],\n",
      "         [0.5050, 0.4704, 0.4883, 0.5017],\n",
      "         [0.4927, 0.4636, 0.4885, 0.5021],\n",
      "         [0.4895, 0.4634, 0.4798, 0.5040],\n",
      "         [0.4913, 0.4621, 0.4862, 0.4986],\n",
      "         [0.4776, 0.4702, 0.4803, 0.5162],\n",
      "         [0.4945, 0.4602, 0.4802, 0.5128],\n",
      "         [0.4863, 0.4623, 0.4939, 0.5085],\n",
      "         [0.4967, 0.4710, 0.4870, 0.4869],\n",
      "         [0.4906, 0.4821, 0.4807, 0.5089],\n",
      "         [0.5012, 0.4760, 0.4939, 0.5051],\n",
      "         [0.4788, 0.4863, 0.4836, 0.5090],\n",
      "         [0.4970, 0.4742, 0.4858, 0.5071],\n",
      "         [0.4869, 0.4626, 0.4757, 0.5072],\n",
      "         [0.4924, 0.4660, 0.4979, 0.5036],\n",
      "         [0.4907, 0.4582, 0.4834, 0.5112],\n",
      "         [0.4920, 0.4641, 0.4806, 0.5055],\n",
      "         [0.4736, 0.4751, 0.4736, 0.5144],\n",
      "         [0.5005, 0.4784, 0.4869, 0.4986],\n",
      "         [0.4842, 0.4634, 0.4878, 0.5162],\n",
      "         [0.4839, 0.4764, 0.4969, 0.5005],\n",
      "         [0.4873, 0.4670, 0.4785, 0.5205],\n",
      "         [0.4889, 0.4672, 0.4975, 0.5129],\n",
      "         [0.4824, 0.4659, 0.4801, 0.5208],\n",
      "         [0.4780, 0.4803, 0.4835, 0.5091],\n",
      "         [0.5041, 0.4725, 0.5014, 0.5068],\n",
      "         [0.5049, 0.4736, 0.4909, 0.5088],\n",
      "         [0.4856, 0.4724, 0.4815, 0.5047],\n",
      "         [0.4793, 0.4727, 0.4769, 0.4960],\n",
      "         [0.4959, 0.4659, 0.4860, 0.5037],\n",
      "         [0.4767, 0.4756, 0.4866, 0.4978],\n",
      "         [0.4937, 0.4773, 0.4960, 0.5003],\n",
      "         [0.4923, 0.4726, 0.4789, 0.5080],\n",
      "         [0.4940, 0.4653, 0.4905, 0.5044],\n",
      "         [0.4879, 0.4619, 0.4815, 0.5099],\n",
      "         [0.5003, 0.4918, 0.5002, 0.4963],\n",
      "         [0.5001, 0.4667, 0.4817, 0.4995],\n",
      "         [0.4786, 0.4665, 0.4757, 0.5252],\n",
      "         [0.4817, 0.4662, 0.4868, 0.5040],\n",
      "         [0.4890, 0.4772, 0.4786, 0.5096],\n",
      "         [0.4886, 0.4735, 0.4807, 0.5054],\n",
      "         [0.4801, 0.4606, 0.4819, 0.5153],\n",
      "         [0.4868, 0.4660, 0.5000, 0.5045],\n",
      "         [0.4755, 0.4696, 0.4856, 0.4957],\n",
      "         [0.4857, 0.4892, 0.4805, 0.4939],\n",
      "         [0.4941, 0.4763, 0.4853, 0.5112],\n",
      "         [0.4841, 0.4813, 0.4881, 0.5039],\n",
      "         [0.4886, 0.4724, 0.4847, 0.5085],\n",
      "         [0.4850, 0.4700, 0.5010, 0.5048],\n",
      "         [0.4861, 0.4696, 0.4878, 0.5144],\n",
      "         [0.4843, 0.4516, 0.4918, 0.5221],\n",
      "         [0.4990, 0.4736, 0.4947, 0.4950],\n",
      "         [0.4914, 0.4781, 0.4831, 0.5009],\n",
      "         [0.4737, 0.4807, 0.4960, 0.5061],\n",
      "         [0.4933, 0.4603, 0.4901, 0.5173],\n",
      "         [0.4937, 0.4685, 0.4930, 0.5018],\n",
      "         [0.4828, 0.4598, 0.4764, 0.5014],\n",
      "         [0.4731, 0.4799, 0.4808, 0.5052],\n",
      "         [0.4859, 0.4701, 0.4878, 0.5000],\n",
      "         [0.4960, 0.4760, 0.4816, 0.5100],\n",
      "         [0.4945, 0.4806, 0.4853, 0.4964],\n",
      "         [0.4913, 0.4665, 0.4888, 0.5123],\n",
      "         [0.4851, 0.4670, 0.4858, 0.5041],\n",
      "         [0.4887, 0.4817, 0.4803, 0.4914],\n",
      "         [0.5068, 0.4652, 0.4968, 0.4993],\n",
      "         [0.4924, 0.4714, 0.4856, 0.4970],\n",
      "         [0.4771, 0.4673, 0.4833, 0.5054],\n",
      "         [0.5015, 0.4821, 0.4896, 0.5073],\n",
      "         [0.4835, 0.4641, 0.4862, 0.5125],\n",
      "         [0.4795, 0.4623, 0.4858, 0.5143],\n",
      "         [0.4887, 0.4696, 0.4809, 0.5066],\n",
      "         [0.4856, 0.4791, 0.4836, 0.5088],\n",
      "         [0.4903, 0.4706, 0.4803, 0.5114],\n",
      "         [0.4958, 0.4751, 0.4779, 0.5068],\n",
      "         [0.4948, 0.4599, 0.4777, 0.5055],\n",
      "         [0.4867, 0.4775, 0.4881, 0.5002],\n",
      "         [0.4984, 0.4643, 0.4932, 0.5031],\n",
      "         [0.4911, 0.4630, 0.4832, 0.5103],\n",
      "         [0.4899, 0.4671, 0.4888, 0.5124],\n",
      "         [0.5040, 0.4720, 0.4828, 0.5146],\n",
      "         [0.4819, 0.4682, 0.4843, 0.5001],\n",
      "         [0.4965, 0.4727, 0.4974, 0.5048],\n",
      "         [0.4999, 0.4677, 0.4945, 0.5057],\n",
      "         [0.4871, 0.4628, 0.4897, 0.5068],\n",
      "         [0.4889, 0.4701, 0.4932, 0.5004],\n",
      "         [0.4824, 0.4619, 0.4773, 0.5146],\n",
      "         [0.4958, 0.4673, 0.4927, 0.4996]]], device='cuda:0'), 'pred_obj_boxes': tensor([[[0.4959, 0.5052, 0.5228, 0.4898],\n",
      "         [0.4829, 0.5119, 0.5206, 0.4997],\n",
      "         [0.4906, 0.5200, 0.5244, 0.5003],\n",
      "         [0.4907, 0.5026, 0.5179, 0.5045],\n",
      "         [0.4931, 0.5111, 0.5357, 0.5104],\n",
      "         [0.4969, 0.5028, 0.5263, 0.5001],\n",
      "         [0.4787, 0.5013, 0.5168, 0.4959],\n",
      "         [0.4851, 0.5113, 0.5136, 0.4967],\n",
      "         [0.4983, 0.5106, 0.5125, 0.5093],\n",
      "         [0.4926, 0.5002, 0.5176, 0.4960],\n",
      "         [0.4962, 0.4839, 0.5112, 0.4990],\n",
      "         [0.4833, 0.5061, 0.5155, 0.5059],\n",
      "         [0.4913, 0.4994, 0.5191, 0.4996],\n",
      "         [0.5045, 0.5090, 0.5080, 0.5077],\n",
      "         [0.4979, 0.4958, 0.5185, 0.4855],\n",
      "         [0.4993, 0.5015, 0.5171, 0.4989],\n",
      "         [0.5014, 0.5005, 0.5187, 0.5127],\n",
      "         [0.4943, 0.5077, 0.5147, 0.4939],\n",
      "         [0.4976, 0.4953, 0.5227, 0.5020],\n",
      "         [0.4935, 0.5118, 0.5193, 0.5050],\n",
      "         [0.4914, 0.4987, 0.5255, 0.5055],\n",
      "         [0.4995, 0.4864, 0.5241, 0.4824],\n",
      "         [0.5013, 0.5029, 0.5085, 0.4949],\n",
      "         [0.4965, 0.4985, 0.5071, 0.5012],\n",
      "         [0.5007, 0.5047, 0.5163, 0.5055],\n",
      "         [0.4976, 0.5050, 0.5145, 0.5057],\n",
      "         [0.4910, 0.5037, 0.5293, 0.4989],\n",
      "         [0.4801, 0.4998, 0.5151, 0.5084],\n",
      "         [0.4920, 0.5065, 0.5185, 0.5040],\n",
      "         [0.4877, 0.5091, 0.5052, 0.5031],\n",
      "         [0.4875, 0.5120, 0.5190, 0.5084],\n",
      "         [0.4931, 0.5150, 0.5211, 0.4912],\n",
      "         [0.4955, 0.5055, 0.5197, 0.5015],\n",
      "         [0.4968, 0.5061, 0.5116, 0.5034],\n",
      "         [0.5122, 0.5024, 0.5191, 0.4987],\n",
      "         [0.4988, 0.4930, 0.4989, 0.5103],\n",
      "         [0.4974, 0.5010, 0.5148, 0.5117],\n",
      "         [0.5014, 0.5056, 0.5202, 0.5008],\n",
      "         [0.4985, 0.4977, 0.5176, 0.4967],\n",
      "         [0.5047, 0.5109, 0.5109, 0.5051],\n",
      "         [0.5026, 0.5037, 0.5246, 0.5067],\n",
      "         [0.4900, 0.4822, 0.5248, 0.4769],\n",
      "         [0.4935, 0.5104, 0.5221, 0.4950],\n",
      "         [0.4872, 0.5043, 0.5142, 0.5133],\n",
      "         [0.4900, 0.5123, 0.5217, 0.5037],\n",
      "         [0.4986, 0.5063, 0.5117, 0.5076],\n",
      "         [0.4904, 0.5087, 0.5050, 0.4908],\n",
      "         [0.5066, 0.5093, 0.5127, 0.5036],\n",
      "         [0.4801, 0.5002, 0.5270, 0.4994],\n",
      "         [0.4863, 0.4970, 0.5158, 0.5014],\n",
      "         [0.5099, 0.5014, 0.5147, 0.5156],\n",
      "         [0.4858, 0.5010, 0.5095, 0.5060],\n",
      "         [0.4955, 0.4952, 0.5166, 0.4998],\n",
      "         [0.5105, 0.5065, 0.5183, 0.4896],\n",
      "         [0.4972, 0.5214, 0.5177, 0.5041],\n",
      "         [0.4866, 0.5011, 0.5034, 0.5021],\n",
      "         [0.4832, 0.5079, 0.5096, 0.4977],\n",
      "         [0.4958, 0.4998, 0.5090, 0.5111],\n",
      "         [0.5084, 0.5058, 0.5225, 0.5058],\n",
      "         [0.4983, 0.5063, 0.5187, 0.4934],\n",
      "         [0.4855, 0.5151, 0.5230, 0.4971],\n",
      "         [0.4960, 0.4987, 0.5093, 0.5034],\n",
      "         [0.4994, 0.5001, 0.5130, 0.5053],\n",
      "         [0.4991, 0.4987, 0.5286, 0.5108],\n",
      "         [0.4896, 0.5011, 0.5308, 0.4929],\n",
      "         [0.4884, 0.5032, 0.5169, 0.5093],\n",
      "         [0.4823, 0.5069, 0.5172, 0.5019],\n",
      "         [0.5073, 0.5026, 0.5118, 0.5025],\n",
      "         [0.4872, 0.4984, 0.5113, 0.4934],\n",
      "         [0.4970, 0.5159, 0.5274, 0.5030],\n",
      "         [0.4924, 0.5133, 0.5077, 0.5083],\n",
      "         [0.4936, 0.5039, 0.5049, 0.5026],\n",
      "         [0.4864, 0.4910, 0.5234, 0.4989],\n",
      "         [0.4827, 0.5032, 0.5133, 0.4948],\n",
      "         [0.4836, 0.5032, 0.5080, 0.5037],\n",
      "         [0.4815, 0.5038, 0.5107, 0.4894],\n",
      "         [0.4945, 0.4999, 0.5153, 0.5096],\n",
      "         [0.4872, 0.4894, 0.5272, 0.5044],\n",
      "         [0.4865, 0.5032, 0.5184, 0.5019],\n",
      "         [0.4951, 0.5029, 0.5256, 0.4897],\n",
      "         [0.4935, 0.4992, 0.5195, 0.4902],\n",
      "         [0.4995, 0.5150, 0.5181, 0.5040],\n",
      "         [0.4848, 0.5088, 0.5258, 0.5002],\n",
      "         [0.4971, 0.5031, 0.5184, 0.5015],\n",
      "         [0.5021, 0.5025, 0.5180, 0.5076],\n",
      "         [0.4890, 0.4977, 0.5251, 0.5113],\n",
      "         [0.4906, 0.4919, 0.5150, 0.4883],\n",
      "         [0.4948, 0.4839, 0.5126, 0.4994],\n",
      "         [0.4990, 0.5025, 0.5216, 0.4976],\n",
      "         [0.4952, 0.4983, 0.5131, 0.5016],\n",
      "         [0.4983, 0.5093, 0.5122, 0.5022],\n",
      "         [0.4888, 0.5088, 0.5178, 0.5091],\n",
      "         [0.5038, 0.5046, 0.5230, 0.5066],\n",
      "         [0.5002, 0.4935, 0.5088, 0.5008],\n",
      "         [0.4963, 0.5066, 0.5285, 0.5176],\n",
      "         [0.4942, 0.5004, 0.5080, 0.5046],\n",
      "         [0.4985, 0.5001, 0.5198, 0.4943],\n",
      "         [0.4898, 0.5058, 0.5126, 0.4900],\n",
      "         [0.4896, 0.5168, 0.5197, 0.5171],\n",
      "         [0.5018, 0.5059, 0.5113, 0.5091]]], device='cuda:0')}, {'pred_obj_logits': tensor([[[ 0.6451, -0.5775, -1.0279,  ...,  0.9803,  0.0699, -0.9476],\n",
      "         [ 0.3424, -0.4500, -0.8483,  ...,  0.7379, -0.2447, -0.8781],\n",
      "         [ 0.5228, -0.4654, -0.9991,  ...,  0.6922,  0.1545, -0.6830],\n",
      "         ...,\n",
      "         [ 0.3637, -0.7101, -0.8519,  ...,  0.9644, -0.0071, -0.8550],\n",
      "         [ 0.6988, -0.7038, -1.3095,  ...,  0.8382,  0.0063, -0.6898],\n",
      "         [ 0.4118, -0.9111, -1.2841,  ...,  1.1611,  0.0954, -0.8359]]],\n",
      "       device='cuda:0'), 'pred_verb_logits': tensor([[[ 0.0282, -1.3129,  0.1735,  ...,  0.8475, -0.0953, -0.2284],\n",
      "         [-0.1162, -1.0740,  0.3348,  ...,  1.4676, -0.2439,  0.0121],\n",
      "         [ 0.0086, -1.0191,  0.0543,  ...,  1.2656, -0.2325,  0.0442],\n",
      "         ...,\n",
      "         [ 0.2472, -0.9969,  0.0495,  ...,  1.2568, -0.3287, -0.1581],\n",
      "         [-0.2074, -1.1024,  0.2130,  ...,  1.0650, -0.2368, -0.0974],\n",
      "         [-0.2293, -1.1374,  0.1104,  ...,  1.2266, -0.1738,  0.0120]]],\n",
      "       device='cuda:0'), 'pred_sub_boxes': tensor([[[0.4998, 0.4673, 0.5111, 0.4844],\n",
      "         [0.4980, 0.4615, 0.5018, 0.5093],\n",
      "         [0.4993, 0.4562, 0.4908, 0.5123],\n",
      "         [0.5080, 0.4728, 0.4925, 0.5028],\n",
      "         [0.4922, 0.4678, 0.4842, 0.5076],\n",
      "         [0.4943, 0.4677, 0.4928, 0.4938],\n",
      "         [0.5000, 0.4620, 0.5026, 0.4934],\n",
      "         [0.4843, 0.4591, 0.4915, 0.5050],\n",
      "         [0.4898, 0.4572, 0.5055, 0.5071],\n",
      "         [0.4909, 0.4591, 0.4986, 0.5052],\n",
      "         [0.4959, 0.4652, 0.4947, 0.5008],\n",
      "         [0.4995, 0.4729, 0.4967, 0.4929],\n",
      "         [0.4949, 0.4549, 0.5033, 0.5241],\n",
      "         [0.4884, 0.4641, 0.4991, 0.4938],\n",
      "         [0.5006, 0.4691, 0.4846, 0.5048],\n",
      "         [0.5028, 0.4599, 0.4990, 0.4997],\n",
      "         [0.4916, 0.4610, 0.4857, 0.5068],\n",
      "         [0.4936, 0.4601, 0.4864, 0.5087],\n",
      "         [0.4816, 0.4634, 0.4869, 0.5122],\n",
      "         [0.5044, 0.4574, 0.4885, 0.5099],\n",
      "         [0.4911, 0.4505, 0.4956, 0.5106],\n",
      "         [0.4906, 0.4723, 0.4961, 0.4853],\n",
      "         [0.4885, 0.4675, 0.4890, 0.5053],\n",
      "         [0.5033, 0.4717, 0.4948, 0.5029],\n",
      "         [0.4797, 0.4738, 0.4864, 0.5084],\n",
      "         [0.5050, 0.4649, 0.4822, 0.5115],\n",
      "         [0.5033, 0.4652, 0.4914, 0.4980],\n",
      "         [0.4963, 0.4597, 0.5007, 0.5021],\n",
      "         [0.4989, 0.4560, 0.4940, 0.5169],\n",
      "         [0.4933, 0.4592, 0.4966, 0.5055],\n",
      "         [0.4767, 0.4669, 0.4815, 0.5096],\n",
      "         [0.5065, 0.4716, 0.4983, 0.4977],\n",
      "         [0.4991, 0.4675, 0.4937, 0.5151],\n",
      "         [0.4964, 0.4811, 0.4952, 0.4970],\n",
      "         [0.4945, 0.4613, 0.4874, 0.5172],\n",
      "         [0.4985, 0.4597, 0.5032, 0.5084],\n",
      "         [0.4890, 0.4650, 0.4823, 0.5111],\n",
      "         [0.4850, 0.4664, 0.4901, 0.5066],\n",
      "         [0.5058, 0.4637, 0.5045, 0.5061],\n",
      "         [0.4971, 0.4621, 0.4899, 0.5085],\n",
      "         [0.4950, 0.4710, 0.4871, 0.5086],\n",
      "         [0.4871, 0.4696, 0.4819, 0.5011],\n",
      "         [0.4999, 0.4603, 0.4960, 0.5021],\n",
      "         [0.4784, 0.4699, 0.4939, 0.5009],\n",
      "         [0.5027, 0.4738, 0.5017, 0.5046],\n",
      "         [0.4933, 0.4640, 0.4832, 0.5076],\n",
      "         [0.5007, 0.4621, 0.4974, 0.5076],\n",
      "         [0.4879, 0.4534, 0.4906, 0.5088],\n",
      "         [0.5025, 0.4861, 0.5010, 0.4906],\n",
      "         [0.5039, 0.4603, 0.4858, 0.4972],\n",
      "         [0.4890, 0.4609, 0.4890, 0.5190],\n",
      "         [0.4816, 0.4570, 0.4942, 0.5021],\n",
      "         [0.4858, 0.4583, 0.4825, 0.5073],\n",
      "         [0.5007, 0.4689, 0.4934, 0.5010],\n",
      "         [0.4880, 0.4560, 0.4797, 0.5159],\n",
      "         [0.4982, 0.4671, 0.5029, 0.5063],\n",
      "         [0.4844, 0.4646, 0.4922, 0.5007],\n",
      "         [0.4913, 0.4704, 0.4914, 0.4987],\n",
      "         [0.4978, 0.4663, 0.4951, 0.5054],\n",
      "         [0.4966, 0.4707, 0.4907, 0.4972],\n",
      "         [0.4940, 0.4585, 0.4942, 0.5037],\n",
      "         [0.4876, 0.4620, 0.4921, 0.5080],\n",
      "         [0.4918, 0.4655, 0.4942, 0.5120],\n",
      "         [0.4874, 0.4643, 0.4955, 0.5094],\n",
      "         [0.5068, 0.4632, 0.4996, 0.4952],\n",
      "         [0.5071, 0.4700, 0.4909, 0.5063],\n",
      "         [0.4826, 0.4717, 0.5034, 0.5006],\n",
      "         [0.5032, 0.4570, 0.4825, 0.5125],\n",
      "         [0.5066, 0.4642, 0.4946, 0.5055],\n",
      "         [0.4871, 0.4627, 0.4863, 0.5042],\n",
      "         [0.4866, 0.4695, 0.4848, 0.5041],\n",
      "         [0.4939, 0.4636, 0.4916, 0.5065],\n",
      "         [0.5018, 0.4729, 0.4905, 0.5043],\n",
      "         [0.4982, 0.4685, 0.4914, 0.4958],\n",
      "         [0.4965, 0.4650, 0.4943, 0.5076],\n",
      "         [0.4986, 0.4677, 0.4838, 0.5013],\n",
      "         [0.4914, 0.4744, 0.4801, 0.4964],\n",
      "         [0.5105, 0.4622, 0.5030, 0.5031],\n",
      "         [0.4984, 0.4566, 0.4968, 0.4980],\n",
      "         [0.4822, 0.4695, 0.4930, 0.4919],\n",
      "         [0.4925, 0.4698, 0.4908, 0.5062],\n",
      "         [0.4986, 0.4546, 0.4931, 0.5110],\n",
      "         [0.4835, 0.4656, 0.4915, 0.5070],\n",
      "         [0.5069, 0.4682, 0.4907, 0.4998],\n",
      "         [0.4913, 0.4713, 0.4915, 0.5096],\n",
      "         [0.4983, 0.4707, 0.4862, 0.5084],\n",
      "         [0.4958, 0.4698, 0.4893, 0.5025],\n",
      "         [0.5036, 0.4631, 0.4904, 0.5082],\n",
      "         [0.4904, 0.4681, 0.4896, 0.5043],\n",
      "         [0.4979, 0.4623, 0.5004, 0.5003],\n",
      "         [0.5007, 0.4622, 0.4903, 0.5045],\n",
      "         [0.4927, 0.4589, 0.4956, 0.5079],\n",
      "         [0.5124, 0.4669, 0.4829, 0.5130],\n",
      "         [0.4925, 0.4614, 0.4903, 0.5073],\n",
      "         [0.4972, 0.4659, 0.5027, 0.5017],\n",
      "         [0.4948, 0.4691, 0.4960, 0.5006],\n",
      "         [0.4883, 0.4601, 0.4972, 0.5051],\n",
      "         [0.5048, 0.4652, 0.4939, 0.4964],\n",
      "         [0.4844, 0.4621, 0.4755, 0.5160],\n",
      "         [0.4997, 0.4666, 0.4980, 0.5009]]], device='cuda:0'), 'pred_obj_boxes': tensor([[[0.4906, 0.5079, 0.5195, 0.4949],\n",
      "         [0.4934, 0.5109, 0.5189, 0.4937],\n",
      "         [0.4945, 0.5159, 0.5310, 0.5023],\n",
      "         [0.4905, 0.4988, 0.5332, 0.5018],\n",
      "         [0.4943, 0.5096, 0.5305, 0.5004],\n",
      "         [0.5000, 0.5039, 0.5259, 0.4957],\n",
      "         [0.4794, 0.5062, 0.5189, 0.4902],\n",
      "         [0.4909, 0.5076, 0.5184, 0.4976],\n",
      "         [0.5021, 0.5044, 0.5162, 0.5077],\n",
      "         [0.5022, 0.5043, 0.5246, 0.4915],\n",
      "         [0.4975, 0.4925, 0.5102, 0.4916],\n",
      "         [0.4785, 0.5068, 0.5189, 0.5017],\n",
      "         [0.4900, 0.4974, 0.5045, 0.4957],\n",
      "         [0.5019, 0.5114, 0.5122, 0.5048],\n",
      "         [0.4916, 0.4984, 0.5159, 0.4806],\n",
      "         [0.4927, 0.5068, 0.5189, 0.4947],\n",
      "         [0.5063, 0.4963, 0.5152, 0.5142],\n",
      "         [0.4999, 0.5049, 0.5164, 0.4888],\n",
      "         [0.4978, 0.5001, 0.5183, 0.4973],\n",
      "         [0.5030, 0.5099, 0.5210, 0.5036],\n",
      "         [0.4963, 0.5062, 0.5295, 0.4991],\n",
      "         [0.5011, 0.4945, 0.5184, 0.4827],\n",
      "         [0.4909, 0.5059, 0.5101, 0.4903],\n",
      "         [0.4969, 0.5004, 0.5167, 0.4922],\n",
      "         [0.4935, 0.5093, 0.5179, 0.5081],\n",
      "         [0.4974, 0.5059, 0.5168, 0.4983],\n",
      "         [0.4918, 0.5051, 0.5238, 0.4993],\n",
      "         [0.4851, 0.4925, 0.5140, 0.4952],\n",
      "         [0.4980, 0.5057, 0.5136, 0.5046],\n",
      "         [0.4923, 0.5087, 0.5116, 0.5003],\n",
      "         [0.4988, 0.5138, 0.5145, 0.4968],\n",
      "         [0.4976, 0.5078, 0.5205, 0.4899],\n",
      "         [0.4989, 0.5061, 0.5169, 0.4989],\n",
      "         [0.5017, 0.4998, 0.5076, 0.5013],\n",
      "         [0.5161, 0.5041, 0.5161, 0.4982],\n",
      "         [0.4982, 0.4940, 0.5119, 0.5048],\n",
      "         [0.4903, 0.5041, 0.5093, 0.5004],\n",
      "         [0.5059, 0.5070, 0.5258, 0.4969],\n",
      "         [0.4988, 0.4992, 0.5207, 0.4921],\n",
      "         [0.5074, 0.5142, 0.5230, 0.5036],\n",
      "         [0.4992, 0.5111, 0.5244, 0.4979],\n",
      "         [0.4934, 0.4964, 0.5265, 0.4843],\n",
      "         [0.4925, 0.5074, 0.5232, 0.4893],\n",
      "         [0.4962, 0.5069, 0.5286, 0.5048],\n",
      "         [0.4909, 0.5088, 0.5202, 0.4979],\n",
      "         [0.4868, 0.5077, 0.5158, 0.4966],\n",
      "         [0.4977, 0.5114, 0.5145, 0.4909],\n",
      "         [0.5049, 0.5019, 0.5154, 0.4942],\n",
      "         [0.4805, 0.5013, 0.5243, 0.5045],\n",
      "         [0.4818, 0.4972, 0.5096, 0.4998],\n",
      "         [0.5143, 0.5048, 0.5081, 0.5023],\n",
      "         [0.4860, 0.4966, 0.5156, 0.4995],\n",
      "         [0.4956, 0.4994, 0.5161, 0.4962],\n",
      "         [0.5077, 0.5094, 0.5185, 0.4868],\n",
      "         [0.4939, 0.5031, 0.5191, 0.5004],\n",
      "         [0.4947, 0.5017, 0.5161, 0.5019],\n",
      "         [0.4875, 0.5074, 0.5132, 0.4951],\n",
      "         [0.4899, 0.4974, 0.5219, 0.5066],\n",
      "         [0.5015, 0.5019, 0.5189, 0.5041],\n",
      "         [0.4949, 0.5024, 0.5186, 0.4893],\n",
      "         [0.4963, 0.5094, 0.5190, 0.4954],\n",
      "         [0.4965, 0.4994, 0.5060, 0.5014],\n",
      "         [0.5022, 0.4997, 0.5067, 0.5081],\n",
      "         [0.5022, 0.4943, 0.5262, 0.5064],\n",
      "         [0.4869, 0.5068, 0.5258, 0.4888],\n",
      "         [0.4930, 0.5033, 0.5179, 0.4999],\n",
      "         [0.4860, 0.5060, 0.5186, 0.4993],\n",
      "         [0.5129, 0.5011, 0.5142, 0.4992],\n",
      "         [0.4929, 0.5025, 0.5129, 0.4903],\n",
      "         [0.4955, 0.5138, 0.5255, 0.4971],\n",
      "         [0.4900, 0.5093, 0.5142, 0.5046],\n",
      "         [0.5003, 0.5075, 0.5052, 0.5039],\n",
      "         [0.4887, 0.4944, 0.5245, 0.5003],\n",
      "         [0.4829, 0.4975, 0.5207, 0.4949],\n",
      "         [0.4840, 0.5030, 0.5160, 0.4974],\n",
      "         [0.4952, 0.5084, 0.5152, 0.4868],\n",
      "         [0.4999, 0.5031, 0.5054, 0.5018],\n",
      "         [0.4866, 0.4897, 0.5241, 0.4965],\n",
      "         [0.4930, 0.5027, 0.5139, 0.5015],\n",
      "         [0.5023, 0.4986, 0.5264, 0.4815],\n",
      "         [0.4964, 0.5075, 0.5150, 0.4889],\n",
      "         [0.5031, 0.5035, 0.5099, 0.5045],\n",
      "         [0.4918, 0.5041, 0.5104, 0.4891],\n",
      "         [0.5000, 0.5004, 0.5266, 0.4968],\n",
      "         [0.4988, 0.4971, 0.5161, 0.5029],\n",
      "         [0.4969, 0.4987, 0.5230, 0.4980],\n",
      "         [0.4952, 0.4977, 0.5180, 0.4943],\n",
      "         [0.4987, 0.4884, 0.5162, 0.4970],\n",
      "         [0.4945, 0.5003, 0.5261, 0.4885],\n",
      "         [0.5014, 0.4957, 0.5049, 0.4949],\n",
      "         [0.4995, 0.5105, 0.5198, 0.4986],\n",
      "         [0.4882, 0.5022, 0.5120, 0.5113],\n",
      "         [0.5032, 0.5083, 0.5173, 0.4915],\n",
      "         [0.4976, 0.4979, 0.5108, 0.5012],\n",
      "         [0.4974, 0.5124, 0.5214, 0.5035],\n",
      "         [0.4927, 0.5009, 0.5121, 0.5048],\n",
      "         [0.5004, 0.5049, 0.5275, 0.4919],\n",
      "         [0.4930, 0.4981, 0.5081, 0.4936],\n",
      "         [0.4918, 0.5073, 0.5168, 0.5094],\n",
      "         [0.4979, 0.5014, 0.5210, 0.4996]]], device='cuda:0')}]}\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "t.append(transforms.Resize(800, interpolation=Image.BICUBIC))\n",
    "transform = transforms.Compose(t)\n",
    "pixel_mean = torch.Tensor([123.675, 116.280, 103.530]).view(-1, 1, 1).cuda()\n",
    "pixel_std = torch.Tensor([58.395, 57.120, 57.375]).view(-1, 1, 1).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_ori = Image.open(image_pth).convert('RGB')\n",
    "    width = image_ori.size[0]\n",
    "    height = image_ori.size[1]\n",
    "    image = transform(image_ori)\n",
    "    image = np.asarray(image)\n",
    "    image_ori = np.asarray(image_ori)\n",
    "    images = torch.from_numpy(image.copy()).permute(2,0,1).cuda()\n",
    "    batch_inputs = [{'image': images, 'height': height, 'width': width}]\n",
    "    \n",
    "    images = [x[\"image\"].to(\"cuda\") for x in batch_inputs]\n",
    "    images = [(x - pixel_mean) / pixel_std for x in images]\n",
    "    images = ImageList.from_tensors(images, 32)\n",
    "\n",
    "    bs, c, h, w = images.tensor.shape\n",
    "    # pos_embed = position_embedding.flatten(2).permute(2, 0, 1)\n",
    "    _query_embed = query_embed.weight.unsqueeze(1).repeat(1, bs, 1)\n",
    "\n",
    "    features = backbone(images.tensor)\n",
    "    encoder_features, pos = hoi_encoder(features)\n",
    "    pos_embed = pos.flatten(2).permute(2, 0, 1)\n",
    "    hopd_out, interaction_decoder_out, memory = hoi_decoder(encoder_features, None, _query_embed, pos_embed)\n",
    "    \n",
    "    outputs_sub_coord = sub_bbox_embed(hopd_out).sigmoid()\n",
    "    outputs_obj_coord = obj_bbox_embed(hopd_out).sigmoid()\n",
    "    outputs_obj_class = obj_class_embed(hopd_out)\n",
    "    outputs_verb_class = verb_class_embed(interaction_decoder_out)\n",
    "\n",
    "    out = {\n",
    "        'pred_obj_logits': outputs_obj_class[-1], \n",
    "        'pred_verb_logits': outputs_verb_class[-1],\n",
    "        'pred_sub_boxes': outputs_sub_coord[-1], \n",
    "        'pred_obj_boxes': outputs_obj_coord[-1]}        \n",
    "                                     \n",
    "    out['aux_outputs'] = _set_aux_loss(\n",
    "        outputs_obj_class, \n",
    "        outputs_verb_class,\n",
    "        outputs_sub_coord,\n",
    "        outputs_obj_coord)\n",
    "    \n",
    "    print(out)\n",
    "    # loss_dict = criterion(out, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_obj_logits': tensor([[[ 0.4069, -0.7388, -1.1195,  ...,  1.2186,  0.0463, -0.8967],\n",
       "          [ 0.1011, -0.4452, -1.0915,  ...,  0.8161, -0.0646, -0.8410],\n",
       "          [ 0.3581, -0.3547, -1.2532,  ...,  0.9195,  0.2502, -0.4877],\n",
       "          ...,\n",
       "          [ 0.3642, -0.6016, -1.1984,  ...,  1.0076,  0.1251, -0.7826],\n",
       "          [ 0.4027, -0.7535, -1.3923,  ...,  1.1560,  0.1017, -0.5479],\n",
       "          [ 0.3033, -0.6127, -1.3077,  ...,  1.3301,  0.4290, -0.6307]]],\n",
       "        device='cuda:0'),\n",
       " 'pred_verb_logits': tensor([[[ 1.0872e-03, -1.1454e+00,  1.7906e-01,  ...,  7.4256e-01,\n",
       "           -3.7168e-02,  6.7809e-02],\n",
       "          [ 4.8286e-02, -8.7118e-01,  3.1757e-01,  ...,  1.0989e+00,\n",
       "           -1.7957e-01,  8.5403e-02],\n",
       "          [ 6.4983e-02, -1.0013e+00,  1.4836e-01,  ...,  1.1264e+00,\n",
       "           -1.1955e-01,  1.7476e-01],\n",
       "          ...,\n",
       "          [ 2.2820e-01, -8.1646e-01,  1.2968e-01,  ...,  1.0931e+00,\n",
       "           -1.5743e-01, -4.7397e-02],\n",
       "          [-7.5525e-02, -9.0131e-01,  1.2192e-01,  ...,  1.0395e+00,\n",
       "           -1.2015e-01, -4.0901e-02],\n",
       "          [-9.1109e-02, -1.0433e+00,  9.7430e-02,  ...,  1.2129e+00,\n",
       "           -1.0719e-01, -5.7496e-02]]], device='cuda:0'),\n",
       " 'pred_sub_boxes': tensor([[[0.5073, 0.4692, 0.5112, 0.4897],\n",
       "          [0.5076, 0.4638, 0.4979, 0.5091],\n",
       "          [0.5043, 0.4538, 0.4898, 0.5103],\n",
       "          [0.5180, 0.4657, 0.4941, 0.5070],\n",
       "          [0.5000, 0.4688, 0.4854, 0.5031],\n",
       "          [0.5103, 0.4660, 0.4865, 0.4980],\n",
       "          [0.5135, 0.4621, 0.4987, 0.4940],\n",
       "          [0.4959, 0.4628, 0.4952, 0.5021],\n",
       "          [0.5006, 0.4624, 0.5018, 0.5004],\n",
       "          [0.4987, 0.4660, 0.4954, 0.5013],\n",
       "          [0.5051, 0.4662, 0.4894, 0.5023],\n",
       "          [0.5092, 0.4711, 0.4992, 0.4889],\n",
       "          [0.5076, 0.4658, 0.5018, 0.5080],\n",
       "          [0.4930, 0.4687, 0.4965, 0.5008],\n",
       "          [0.5080, 0.4768, 0.4831, 0.5049],\n",
       "          [0.5055, 0.4657, 0.4969, 0.5005],\n",
       "          [0.5054, 0.4649, 0.4868, 0.5003],\n",
       "          [0.5083, 0.4619, 0.4876, 0.5054],\n",
       "          [0.4949, 0.4608, 0.4948, 0.5078],\n",
       "          [0.5084, 0.4587, 0.4988, 0.5055],\n",
       "          [0.5002, 0.4524, 0.5040, 0.5101],\n",
       "          [0.5067, 0.4642, 0.5018, 0.5008],\n",
       "          [0.4979, 0.4645, 0.4895, 0.5014],\n",
       "          [0.5054, 0.4693, 0.4962, 0.5031],\n",
       "          [0.4947, 0.4723, 0.4934, 0.5085],\n",
       "          [0.4985, 0.4682, 0.4867, 0.5117],\n",
       "          [0.5067, 0.4628, 0.4954, 0.4979],\n",
       "          [0.4976, 0.4671, 0.4974, 0.5010],\n",
       "          [0.5122, 0.4635, 0.4821, 0.5110],\n",
       "          [0.4974, 0.4630, 0.4993, 0.5045],\n",
       "          [0.4897, 0.4734, 0.4869, 0.5030],\n",
       "          [0.5144, 0.4716, 0.5068, 0.4972],\n",
       "          [0.4965, 0.4677, 0.4964, 0.5135],\n",
       "          [0.5073, 0.4762, 0.4908, 0.5011],\n",
       "          [0.4984, 0.4655, 0.4880, 0.5139],\n",
       "          [0.5098, 0.4536, 0.4949, 0.5089],\n",
       "          [0.4964, 0.4643, 0.4873, 0.5084],\n",
       "          [0.4955, 0.4788, 0.4972, 0.4960],\n",
       "          [0.5103, 0.4658, 0.4978, 0.5007],\n",
       "          [0.5090, 0.4621, 0.4944, 0.5053],\n",
       "          [0.5075, 0.4686, 0.4898, 0.5058],\n",
       "          [0.4983, 0.4701, 0.4911, 0.4983],\n",
       "          [0.5148, 0.4614, 0.4996, 0.5004],\n",
       "          [0.4906, 0.4668, 0.5014, 0.5052],\n",
       "          [0.5074, 0.4729, 0.4925, 0.5030],\n",
       "          [0.4953, 0.4576, 0.4841, 0.5091],\n",
       "          [0.5106, 0.4608, 0.4921, 0.5078],\n",
       "          [0.4991, 0.4648, 0.4920, 0.5081],\n",
       "          [0.5177, 0.4816, 0.4984, 0.4925],\n",
       "          [0.5100, 0.4651, 0.4902, 0.4973],\n",
       "          [0.5053, 0.4596, 0.4876, 0.5108],\n",
       "          [0.4914, 0.4595, 0.4927, 0.5038],\n",
       "          [0.4960, 0.4576, 0.4854, 0.5043],\n",
       "          [0.5020, 0.4683, 0.4946, 0.5018],\n",
       "          [0.4960, 0.4616, 0.4865, 0.5076],\n",
       "          [0.5031, 0.4678, 0.4961, 0.5077],\n",
       "          [0.5056, 0.4668, 0.4935, 0.5019],\n",
       "          [0.5008, 0.4687, 0.4902, 0.4990],\n",
       "          [0.5076, 0.4689, 0.4970, 0.5006],\n",
       "          [0.5118, 0.4769, 0.4923, 0.4958],\n",
       "          [0.5000, 0.4535, 0.4951, 0.5064],\n",
       "          [0.5011, 0.4674, 0.4932, 0.5069],\n",
       "          [0.5026, 0.4650, 0.4959, 0.5065],\n",
       "          [0.4908, 0.4668, 0.4936, 0.5107],\n",
       "          [0.5084, 0.4639, 0.4950, 0.5012],\n",
       "          [0.5091, 0.4703, 0.4948, 0.5030],\n",
       "          [0.5006, 0.4707, 0.5071, 0.5048],\n",
       "          [0.5110, 0.4637, 0.4848, 0.5048],\n",
       "          [0.5182, 0.4647, 0.4905, 0.5057],\n",
       "          [0.5023, 0.4626, 0.4968, 0.5011],\n",
       "          [0.5025, 0.4660, 0.4913, 0.5037],\n",
       "          [0.5075, 0.4657, 0.4941, 0.5075],\n",
       "          [0.5074, 0.4656, 0.4859, 0.5046],\n",
       "          [0.5085, 0.4597, 0.4899, 0.4992],\n",
       "          [0.5035, 0.4668, 0.4933, 0.5048],\n",
       "          [0.5110, 0.4762, 0.4902, 0.5031],\n",
       "          [0.5034, 0.4715, 0.4844, 0.4978],\n",
       "          [0.5143, 0.4586, 0.5029, 0.4984],\n",
       "          [0.5134, 0.4602, 0.4872, 0.4972],\n",
       "          [0.4949, 0.4754, 0.4978, 0.4959],\n",
       "          [0.5070, 0.4666, 0.4961, 0.5032],\n",
       "          [0.5034, 0.4630, 0.4965, 0.5123],\n",
       "          [0.4930, 0.4673, 0.4932, 0.5096],\n",
       "          [0.5082, 0.4627, 0.4822, 0.5028],\n",
       "          [0.5046, 0.4666, 0.4984, 0.5054],\n",
       "          [0.5102, 0.4710, 0.4879, 0.5021],\n",
       "          [0.5054, 0.4739, 0.4908, 0.4927],\n",
       "          [0.5119, 0.4728, 0.4944, 0.5054],\n",
       "          [0.4988, 0.4716, 0.4919, 0.5012],\n",
       "          [0.5023, 0.4643, 0.4975, 0.5008],\n",
       "          [0.5014, 0.4591, 0.4862, 0.5044],\n",
       "          [0.5013, 0.4538, 0.4997, 0.5078],\n",
       "          [0.5160, 0.4698, 0.4903, 0.5057],\n",
       "          [0.4980, 0.4643, 0.4984, 0.5016],\n",
       "          [0.5091, 0.4675, 0.5033, 0.5010],\n",
       "          [0.5050, 0.4739, 0.4952, 0.5009],\n",
       "          [0.5070, 0.4668, 0.4986, 0.5092],\n",
       "          [0.5060, 0.4652, 0.4918, 0.4992],\n",
       "          [0.4930, 0.4692, 0.4788, 0.5122],\n",
       "          [0.5024, 0.4694, 0.5010, 0.5049]]], device='cuda:0'),\n",
       " 'pred_obj_boxes': tensor([[[0.4832, 0.5062, 0.5205, 0.4900],\n",
       "          [0.4966, 0.5104, 0.5140, 0.4885],\n",
       "          [0.4996, 0.5096, 0.5216, 0.4964],\n",
       "          [0.4879, 0.4924, 0.5281, 0.4960],\n",
       "          [0.4863, 0.5045, 0.5183, 0.4973],\n",
       "          [0.5071, 0.5018, 0.5211, 0.4781],\n",
       "          [0.4834, 0.5032, 0.5169, 0.4862],\n",
       "          [0.4847, 0.4928, 0.5144, 0.4905],\n",
       "          [0.4985, 0.5010, 0.5124, 0.4968],\n",
       "          [0.5071, 0.4932, 0.5263, 0.4861],\n",
       "          [0.5027, 0.4894, 0.5144, 0.4852],\n",
       "          [0.4876, 0.5073, 0.5162, 0.4917],\n",
       "          [0.4879, 0.5029, 0.5095, 0.4886],\n",
       "          [0.4982, 0.5097, 0.5086, 0.4941],\n",
       "          [0.5023, 0.5011, 0.5181, 0.4784],\n",
       "          [0.4919, 0.5040, 0.5164, 0.4936],\n",
       "          [0.5025, 0.4964, 0.5111, 0.5062],\n",
       "          [0.4925, 0.5064, 0.5170, 0.4824],\n",
       "          [0.4969, 0.5038, 0.5159, 0.4936],\n",
       "          [0.5005, 0.5060, 0.5179, 0.4956],\n",
       "          [0.4978, 0.5010, 0.5258, 0.4891],\n",
       "          [0.5010, 0.4958, 0.5204, 0.4776],\n",
       "          [0.4936, 0.4959, 0.5116, 0.4917],\n",
       "          [0.4892, 0.5022, 0.5211, 0.4814],\n",
       "          [0.4931, 0.5021, 0.5150, 0.5006],\n",
       "          [0.4925, 0.5030, 0.5106, 0.4915],\n",
       "          [0.4897, 0.5017, 0.5203, 0.4900],\n",
       "          [0.4842, 0.4949, 0.5155, 0.4811],\n",
       "          [0.4986, 0.4930, 0.5087, 0.4952],\n",
       "          [0.4863, 0.5065, 0.5133, 0.4906],\n",
       "          [0.4957, 0.5018, 0.5207, 0.4863],\n",
       "          [0.4911, 0.4960, 0.5202, 0.4862],\n",
       "          [0.4902, 0.5034, 0.5167, 0.4919],\n",
       "          [0.4963, 0.4951, 0.5138, 0.4972],\n",
       "          [0.5108, 0.4952, 0.5159, 0.4908],\n",
       "          [0.4918, 0.4909, 0.5186, 0.5031],\n",
       "          [0.4959, 0.4996, 0.5063, 0.4885],\n",
       "          [0.4961, 0.5025, 0.5232, 0.4892],\n",
       "          [0.4916, 0.4939, 0.5166, 0.4918],\n",
       "          [0.5020, 0.5100, 0.5266, 0.5020],\n",
       "          [0.4900, 0.5074, 0.5195, 0.4921],\n",
       "          [0.4896, 0.4974, 0.5229, 0.4813],\n",
       "          [0.4905, 0.5018, 0.5219, 0.4829],\n",
       "          [0.4999, 0.4991, 0.5220, 0.4939],\n",
       "          [0.4902, 0.5033, 0.5157, 0.4959],\n",
       "          [0.4946, 0.5019, 0.5106, 0.4830],\n",
       "          [0.4899, 0.5061, 0.5230, 0.4968],\n",
       "          [0.4989, 0.5006, 0.5161, 0.4936],\n",
       "          [0.4817, 0.4978, 0.5169, 0.4935],\n",
       "          [0.4795, 0.4883, 0.5147, 0.4974],\n",
       "          [0.5082, 0.5016, 0.5074, 0.4920],\n",
       "          [0.4922, 0.4915, 0.5156, 0.4970],\n",
       "          [0.4833, 0.5021, 0.5226, 0.4930],\n",
       "          [0.5071, 0.5124, 0.5148, 0.4831],\n",
       "          [0.4821, 0.4968, 0.5209, 0.4901],\n",
       "          [0.4963, 0.5025, 0.5158, 0.4924],\n",
       "          [0.4951, 0.5012, 0.5156, 0.4920],\n",
       "          [0.4879, 0.4948, 0.5171, 0.4950],\n",
       "          [0.4881, 0.5025, 0.5185, 0.4953],\n",
       "          [0.4936, 0.4994, 0.5092, 0.4837],\n",
       "          [0.4948, 0.5028, 0.5170, 0.4953],\n",
       "          [0.4901, 0.4979, 0.5034, 0.4958],\n",
       "          [0.5004, 0.5006, 0.5089, 0.4958],\n",
       "          [0.5005, 0.4953, 0.5219, 0.4969],\n",
       "          [0.4915, 0.5067, 0.5178, 0.4857],\n",
       "          [0.4860, 0.5025, 0.5210, 0.4937],\n",
       "          [0.4892, 0.5010, 0.5171, 0.4906],\n",
       "          [0.5143, 0.5029, 0.5131, 0.4820],\n",
       "          [0.4905, 0.4950, 0.5187, 0.4909],\n",
       "          [0.4853, 0.5041, 0.5271, 0.4924],\n",
       "          [0.4881, 0.5009, 0.5195, 0.4913],\n",
       "          [0.5003, 0.5019, 0.5123, 0.5000],\n",
       "          [0.4862, 0.4931, 0.5196, 0.4979],\n",
       "          [0.4851, 0.4992, 0.5209, 0.4877],\n",
       "          [0.4862, 0.4952, 0.5175, 0.4843],\n",
       "          [0.4958, 0.5058, 0.5143, 0.4837],\n",
       "          [0.4963, 0.4983, 0.5080, 0.4964],\n",
       "          [0.4865, 0.4931, 0.5225, 0.4866],\n",
       "          [0.4913, 0.4965, 0.5136, 0.4925],\n",
       "          [0.5004, 0.4991, 0.5214, 0.4829],\n",
       "          [0.4959, 0.5056, 0.5188, 0.4881],\n",
       "          [0.4959, 0.4977, 0.5071, 0.4996],\n",
       "          [0.4949, 0.5023, 0.5149, 0.4841],\n",
       "          [0.5008, 0.4941, 0.5232, 0.4928],\n",
       "          [0.4909, 0.4965, 0.5223, 0.4999],\n",
       "          [0.4980, 0.5052, 0.5173, 0.4926],\n",
       "          [0.4916, 0.5020, 0.5173, 0.4890],\n",
       "          [0.4995, 0.4936, 0.5094, 0.4946],\n",
       "          [0.4914, 0.5018, 0.5233, 0.4848],\n",
       "          [0.4914, 0.4939, 0.5045, 0.4899],\n",
       "          [0.5020, 0.4978, 0.5173, 0.4946],\n",
       "          [0.4898, 0.4973, 0.5157, 0.4998],\n",
       "          [0.4972, 0.5044, 0.5140, 0.4885],\n",
       "          [0.4944, 0.5023, 0.5206, 0.4933],\n",
       "          [0.5000, 0.5169, 0.5143, 0.4941],\n",
       "          [0.4834, 0.5016, 0.5130, 0.4939],\n",
       "          [0.4950, 0.5070, 0.5215, 0.4869],\n",
       "          [0.4920, 0.4983, 0.5102, 0.4918],\n",
       "          [0.4986, 0.4993, 0.5140, 0.4999],\n",
       "          [0.5037, 0.4985, 0.5217, 0.4925]]], device='cuda:0'),\n",
       " 'aux_outputs': [{'pred_obj_logits': tensor([[[ 0.8548, -0.5134, -0.8006,  ...,  0.5911, -0.0461, -0.9973],\n",
       "            [ 0.6713, -0.2550, -0.6937,  ...,  0.4657, -0.3227, -1.1490],\n",
       "            [ 0.9301, -0.4057, -0.7256,  ...,  0.2016,  0.2807, -0.7161],\n",
       "            ...,\n",
       "            [ 0.6548, -0.5633, -0.7406,  ...,  0.5593,  0.0616, -0.9192],\n",
       "            [ 0.9350, -0.6219, -1.1765,  ...,  0.5640,  0.1014, -0.5670],\n",
       "            [ 0.6513, -0.9494, -1.0497,  ...,  0.8280, -0.0679, -0.8674]]],\n",
       "          device='cuda:0'),\n",
       "   'pred_verb_logits': tensor([[[-1.9327e-02, -1.3133e+00,  1.6277e-01,  ...,  8.9138e-01,\n",
       "             -5.9585e-02, -4.4359e-01],\n",
       "            [-1.6991e-01, -1.3017e+00,  2.6719e-01,  ...,  1.4231e+00,\n",
       "             -3.3289e-01, -1.2836e-01],\n",
       "            [-5.8595e-02, -1.1164e+00, -1.1681e-01,  ...,  1.1954e+00,\n",
       "             -2.9487e-01, -1.8405e-01],\n",
       "            ...,\n",
       "            [ 1.7125e-01, -1.2142e+00, -3.0646e-02,  ...,  1.2649e+00,\n",
       "             -4.0233e-01, -4.2666e-01],\n",
       "            [-2.9412e-01, -1.2633e+00, -6.0488e-04,  ...,  1.1879e+00,\n",
       "             -4.8867e-01, -1.9038e-01],\n",
       "            [-2.1670e-01, -1.2447e+00, -4.7901e-02,  ...,  9.9497e-01,\n",
       "             -3.1299e-01, -5.2720e-02]]], device='cuda:0'),\n",
       "   'pred_sub_boxes': tensor([[[0.5023, 0.4747, 0.5043, 0.4864],\n",
       "            [0.4870, 0.4645, 0.5058, 0.5068],\n",
       "            [0.4888, 0.4576, 0.4817, 0.5202],\n",
       "            [0.5013, 0.4748, 0.4890, 0.5036],\n",
       "            [0.4878, 0.4725, 0.4801, 0.5085],\n",
       "            [0.4886, 0.4752, 0.4811, 0.5004],\n",
       "            [0.4966, 0.4652, 0.4992, 0.5017],\n",
       "            [0.4778, 0.4672, 0.4829, 0.5027],\n",
       "            [0.4830, 0.4672, 0.5008, 0.5059],\n",
       "            [0.4917, 0.4688, 0.4846, 0.5090],\n",
       "            [0.4884, 0.4755, 0.4934, 0.5022],\n",
       "            [0.4914, 0.4733, 0.4859, 0.5001],\n",
       "            [0.4821, 0.4648, 0.5006, 0.5250],\n",
       "            [0.4867, 0.4741, 0.4881, 0.5008],\n",
       "            [0.5050, 0.4704, 0.4883, 0.5017],\n",
       "            [0.4927, 0.4636, 0.4885, 0.5021],\n",
       "            [0.4895, 0.4634, 0.4798, 0.5040],\n",
       "            [0.4913, 0.4621, 0.4862, 0.4986],\n",
       "            [0.4776, 0.4702, 0.4803, 0.5162],\n",
       "            [0.4945, 0.4602, 0.4802, 0.5128],\n",
       "            [0.4863, 0.4623, 0.4939, 0.5085],\n",
       "            [0.4967, 0.4710, 0.4870, 0.4869],\n",
       "            [0.4906, 0.4821, 0.4807, 0.5089],\n",
       "            [0.5012, 0.4760, 0.4939, 0.5051],\n",
       "            [0.4788, 0.4863, 0.4836, 0.5090],\n",
       "            [0.4970, 0.4742, 0.4858, 0.5071],\n",
       "            [0.4869, 0.4626, 0.4757, 0.5072],\n",
       "            [0.4924, 0.4660, 0.4979, 0.5036],\n",
       "            [0.4907, 0.4582, 0.4834, 0.5112],\n",
       "            [0.4920, 0.4641, 0.4806, 0.5055],\n",
       "            [0.4736, 0.4751, 0.4736, 0.5144],\n",
       "            [0.5005, 0.4784, 0.4869, 0.4986],\n",
       "            [0.4842, 0.4634, 0.4878, 0.5162],\n",
       "            [0.4839, 0.4764, 0.4969, 0.5005],\n",
       "            [0.4873, 0.4670, 0.4785, 0.5205],\n",
       "            [0.4889, 0.4672, 0.4975, 0.5129],\n",
       "            [0.4824, 0.4659, 0.4801, 0.5208],\n",
       "            [0.4780, 0.4803, 0.4835, 0.5091],\n",
       "            [0.5041, 0.4725, 0.5014, 0.5068],\n",
       "            [0.5049, 0.4736, 0.4909, 0.5088],\n",
       "            [0.4856, 0.4724, 0.4815, 0.5047],\n",
       "            [0.4793, 0.4727, 0.4769, 0.4960],\n",
       "            [0.4959, 0.4659, 0.4860, 0.5037],\n",
       "            [0.4767, 0.4756, 0.4866, 0.4978],\n",
       "            [0.4937, 0.4773, 0.4960, 0.5003],\n",
       "            [0.4923, 0.4726, 0.4789, 0.5080],\n",
       "            [0.4940, 0.4653, 0.4905, 0.5044],\n",
       "            [0.4879, 0.4619, 0.4815, 0.5099],\n",
       "            [0.5003, 0.4918, 0.5002, 0.4963],\n",
       "            [0.5001, 0.4667, 0.4817, 0.4995],\n",
       "            [0.4786, 0.4665, 0.4757, 0.5252],\n",
       "            [0.4817, 0.4662, 0.4868, 0.5040],\n",
       "            [0.4890, 0.4772, 0.4786, 0.5096],\n",
       "            [0.4886, 0.4735, 0.4807, 0.5054],\n",
       "            [0.4801, 0.4606, 0.4819, 0.5153],\n",
       "            [0.4868, 0.4660, 0.5000, 0.5045],\n",
       "            [0.4755, 0.4696, 0.4856, 0.4957],\n",
       "            [0.4857, 0.4892, 0.4805, 0.4939],\n",
       "            [0.4941, 0.4763, 0.4853, 0.5112],\n",
       "            [0.4841, 0.4813, 0.4881, 0.5039],\n",
       "            [0.4886, 0.4724, 0.4847, 0.5085],\n",
       "            [0.4850, 0.4700, 0.5010, 0.5048],\n",
       "            [0.4861, 0.4696, 0.4878, 0.5144],\n",
       "            [0.4843, 0.4516, 0.4918, 0.5221],\n",
       "            [0.4990, 0.4736, 0.4947, 0.4950],\n",
       "            [0.4914, 0.4781, 0.4831, 0.5009],\n",
       "            [0.4737, 0.4807, 0.4960, 0.5061],\n",
       "            [0.4933, 0.4603, 0.4901, 0.5173],\n",
       "            [0.4937, 0.4685, 0.4930, 0.5018],\n",
       "            [0.4828, 0.4598, 0.4764, 0.5014],\n",
       "            [0.4731, 0.4799, 0.4808, 0.5052],\n",
       "            [0.4859, 0.4701, 0.4878, 0.5000],\n",
       "            [0.4960, 0.4760, 0.4816, 0.5100],\n",
       "            [0.4945, 0.4806, 0.4853, 0.4964],\n",
       "            [0.4913, 0.4665, 0.4888, 0.5123],\n",
       "            [0.4851, 0.4670, 0.4858, 0.5041],\n",
       "            [0.4887, 0.4817, 0.4803, 0.4914],\n",
       "            [0.5068, 0.4652, 0.4968, 0.4993],\n",
       "            [0.4924, 0.4714, 0.4856, 0.4970],\n",
       "            [0.4771, 0.4673, 0.4833, 0.5054],\n",
       "            [0.5015, 0.4821, 0.4896, 0.5073],\n",
       "            [0.4835, 0.4641, 0.4862, 0.5125],\n",
       "            [0.4795, 0.4623, 0.4858, 0.5143],\n",
       "            [0.4887, 0.4696, 0.4809, 0.5066],\n",
       "            [0.4856, 0.4791, 0.4836, 0.5088],\n",
       "            [0.4903, 0.4706, 0.4803, 0.5114],\n",
       "            [0.4958, 0.4751, 0.4779, 0.5068],\n",
       "            [0.4948, 0.4599, 0.4777, 0.5055],\n",
       "            [0.4867, 0.4775, 0.4881, 0.5002],\n",
       "            [0.4984, 0.4643, 0.4932, 0.5031],\n",
       "            [0.4911, 0.4630, 0.4832, 0.5103],\n",
       "            [0.4899, 0.4671, 0.4888, 0.5124],\n",
       "            [0.5040, 0.4720, 0.4828, 0.5146],\n",
       "            [0.4819, 0.4682, 0.4843, 0.5001],\n",
       "            [0.4965, 0.4727, 0.4974, 0.5048],\n",
       "            [0.4999, 0.4677, 0.4945, 0.5057],\n",
       "            [0.4871, 0.4628, 0.4897, 0.5068],\n",
       "            [0.4889, 0.4701, 0.4932, 0.5004],\n",
       "            [0.4824, 0.4619, 0.4773, 0.5146],\n",
       "            [0.4958, 0.4673, 0.4927, 0.4996]]], device='cuda:0'),\n",
       "   'pred_obj_boxes': tensor([[[0.4959, 0.5052, 0.5228, 0.4898],\n",
       "            [0.4829, 0.5119, 0.5206, 0.4997],\n",
       "            [0.4906, 0.5200, 0.5244, 0.5003],\n",
       "            [0.4907, 0.5026, 0.5179, 0.5045],\n",
       "            [0.4931, 0.5111, 0.5357, 0.5104],\n",
       "            [0.4969, 0.5028, 0.5263, 0.5001],\n",
       "            [0.4787, 0.5013, 0.5168, 0.4959],\n",
       "            [0.4851, 0.5113, 0.5136, 0.4967],\n",
       "            [0.4983, 0.5106, 0.5125, 0.5093],\n",
       "            [0.4926, 0.5002, 0.5176, 0.4960],\n",
       "            [0.4962, 0.4839, 0.5112, 0.4990],\n",
       "            [0.4833, 0.5061, 0.5155, 0.5059],\n",
       "            [0.4913, 0.4994, 0.5191, 0.4996],\n",
       "            [0.5045, 0.5090, 0.5080, 0.5077],\n",
       "            [0.4979, 0.4958, 0.5185, 0.4855],\n",
       "            [0.4993, 0.5015, 0.5171, 0.4989],\n",
       "            [0.5014, 0.5005, 0.5187, 0.5127],\n",
       "            [0.4943, 0.5077, 0.5147, 0.4939],\n",
       "            [0.4976, 0.4953, 0.5227, 0.5020],\n",
       "            [0.4935, 0.5118, 0.5193, 0.5050],\n",
       "            [0.4914, 0.4987, 0.5255, 0.5055],\n",
       "            [0.4995, 0.4864, 0.5241, 0.4824],\n",
       "            [0.5013, 0.5029, 0.5085, 0.4949],\n",
       "            [0.4965, 0.4985, 0.5071, 0.5012],\n",
       "            [0.5007, 0.5047, 0.5163, 0.5055],\n",
       "            [0.4976, 0.5050, 0.5145, 0.5057],\n",
       "            [0.4910, 0.5037, 0.5293, 0.4989],\n",
       "            [0.4801, 0.4998, 0.5151, 0.5084],\n",
       "            [0.4920, 0.5065, 0.5185, 0.5040],\n",
       "            [0.4877, 0.5091, 0.5052, 0.5031],\n",
       "            [0.4875, 0.5120, 0.5190, 0.5084],\n",
       "            [0.4931, 0.5150, 0.5211, 0.4912],\n",
       "            [0.4955, 0.5055, 0.5197, 0.5015],\n",
       "            [0.4968, 0.5061, 0.5116, 0.5034],\n",
       "            [0.5122, 0.5024, 0.5191, 0.4987],\n",
       "            [0.4988, 0.4930, 0.4989, 0.5103],\n",
       "            [0.4974, 0.5010, 0.5148, 0.5117],\n",
       "            [0.5014, 0.5056, 0.5202, 0.5008],\n",
       "            [0.4985, 0.4977, 0.5176, 0.4967],\n",
       "            [0.5047, 0.5109, 0.5109, 0.5051],\n",
       "            [0.5026, 0.5037, 0.5246, 0.5067],\n",
       "            [0.4900, 0.4822, 0.5248, 0.4769],\n",
       "            [0.4935, 0.5104, 0.5221, 0.4950],\n",
       "            [0.4872, 0.5043, 0.5142, 0.5133],\n",
       "            [0.4900, 0.5123, 0.5217, 0.5037],\n",
       "            [0.4986, 0.5063, 0.5117, 0.5076],\n",
       "            [0.4904, 0.5087, 0.5050, 0.4908],\n",
       "            [0.5066, 0.5093, 0.5127, 0.5036],\n",
       "            [0.4801, 0.5002, 0.5270, 0.4994],\n",
       "            [0.4863, 0.4970, 0.5158, 0.5014],\n",
       "            [0.5099, 0.5014, 0.5147, 0.5156],\n",
       "            [0.4858, 0.5010, 0.5095, 0.5060],\n",
       "            [0.4955, 0.4952, 0.5166, 0.4998],\n",
       "            [0.5105, 0.5065, 0.5183, 0.4896],\n",
       "            [0.4972, 0.5214, 0.5177, 0.5041],\n",
       "            [0.4866, 0.5011, 0.5034, 0.5021],\n",
       "            [0.4832, 0.5079, 0.5096, 0.4977],\n",
       "            [0.4958, 0.4998, 0.5090, 0.5111],\n",
       "            [0.5084, 0.5058, 0.5225, 0.5058],\n",
       "            [0.4983, 0.5063, 0.5187, 0.4934],\n",
       "            [0.4855, 0.5151, 0.5230, 0.4971],\n",
       "            [0.4960, 0.4987, 0.5093, 0.5034],\n",
       "            [0.4994, 0.5001, 0.5130, 0.5053],\n",
       "            [0.4991, 0.4987, 0.5286, 0.5108],\n",
       "            [0.4896, 0.5011, 0.5308, 0.4929],\n",
       "            [0.4884, 0.5032, 0.5169, 0.5093],\n",
       "            [0.4823, 0.5069, 0.5172, 0.5019],\n",
       "            [0.5073, 0.5026, 0.5118, 0.5025],\n",
       "            [0.4872, 0.4984, 0.5113, 0.4934],\n",
       "            [0.4970, 0.5159, 0.5274, 0.5030],\n",
       "            [0.4924, 0.5133, 0.5077, 0.5083],\n",
       "            [0.4936, 0.5039, 0.5049, 0.5026],\n",
       "            [0.4864, 0.4910, 0.5234, 0.4989],\n",
       "            [0.4827, 0.5032, 0.5133, 0.4948],\n",
       "            [0.4836, 0.5032, 0.5080, 0.5037],\n",
       "            [0.4815, 0.5038, 0.5107, 0.4894],\n",
       "            [0.4945, 0.4999, 0.5153, 0.5096],\n",
       "            [0.4872, 0.4894, 0.5272, 0.5044],\n",
       "            [0.4865, 0.5032, 0.5184, 0.5019],\n",
       "            [0.4951, 0.5029, 0.5256, 0.4897],\n",
       "            [0.4935, 0.4992, 0.5195, 0.4902],\n",
       "            [0.4995, 0.5150, 0.5181, 0.5040],\n",
       "            [0.4848, 0.5088, 0.5258, 0.5002],\n",
       "            [0.4971, 0.5031, 0.5184, 0.5015],\n",
       "            [0.5021, 0.5025, 0.5180, 0.5076],\n",
       "            [0.4890, 0.4977, 0.5251, 0.5113],\n",
       "            [0.4906, 0.4919, 0.5150, 0.4883],\n",
       "            [0.4948, 0.4839, 0.5126, 0.4994],\n",
       "            [0.4990, 0.5025, 0.5216, 0.4976],\n",
       "            [0.4952, 0.4983, 0.5131, 0.5016],\n",
       "            [0.4983, 0.5093, 0.5122, 0.5022],\n",
       "            [0.4888, 0.5088, 0.5178, 0.5091],\n",
       "            [0.5038, 0.5046, 0.5230, 0.5066],\n",
       "            [0.5002, 0.4935, 0.5088, 0.5008],\n",
       "            [0.4963, 0.5066, 0.5285, 0.5176],\n",
       "            [0.4942, 0.5004, 0.5080, 0.5046],\n",
       "            [0.4985, 0.5001, 0.5198, 0.4943],\n",
       "            [0.4898, 0.5058, 0.5126, 0.4900],\n",
       "            [0.4896, 0.5168, 0.5197, 0.5171],\n",
       "            [0.5018, 0.5059, 0.5113, 0.5091]]], device='cuda:0')},\n",
       "  {'pred_obj_logits': tensor([[[ 0.6451, -0.5775, -1.0279,  ...,  0.9803,  0.0699, -0.9476],\n",
       "            [ 0.3424, -0.4500, -0.8483,  ...,  0.7379, -0.2447, -0.8781],\n",
       "            [ 0.5228, -0.4654, -0.9991,  ...,  0.6922,  0.1545, -0.6830],\n",
       "            ...,\n",
       "            [ 0.3637, -0.7101, -0.8519,  ...,  0.9644, -0.0071, -0.8550],\n",
       "            [ 0.6988, -0.7038, -1.3095,  ...,  0.8382,  0.0063, -0.6898],\n",
       "            [ 0.4118, -0.9111, -1.2841,  ...,  1.1611,  0.0954, -0.8359]]],\n",
       "          device='cuda:0'),\n",
       "   'pred_verb_logits': tensor([[[ 0.0282, -1.3129,  0.1735,  ...,  0.8475, -0.0953, -0.2284],\n",
       "            [-0.1162, -1.0740,  0.3348,  ...,  1.4676, -0.2439,  0.0121],\n",
       "            [ 0.0086, -1.0191,  0.0543,  ...,  1.2656, -0.2325,  0.0442],\n",
       "            ...,\n",
       "            [ 0.2472, -0.9969,  0.0495,  ...,  1.2568, -0.3287, -0.1581],\n",
       "            [-0.2074, -1.1024,  0.2130,  ...,  1.0650, -0.2368, -0.0974],\n",
       "            [-0.2293, -1.1374,  0.1104,  ...,  1.2266, -0.1738,  0.0120]]],\n",
       "          device='cuda:0'),\n",
       "   'pred_sub_boxes': tensor([[[0.4998, 0.4673, 0.5111, 0.4844],\n",
       "            [0.4980, 0.4615, 0.5018, 0.5093],\n",
       "            [0.4993, 0.4562, 0.4908, 0.5123],\n",
       "            [0.5080, 0.4728, 0.4925, 0.5028],\n",
       "            [0.4922, 0.4678, 0.4842, 0.5076],\n",
       "            [0.4943, 0.4677, 0.4928, 0.4938],\n",
       "            [0.5000, 0.4620, 0.5026, 0.4934],\n",
       "            [0.4843, 0.4591, 0.4915, 0.5050],\n",
       "            [0.4898, 0.4572, 0.5055, 0.5071],\n",
       "            [0.4909, 0.4591, 0.4986, 0.5052],\n",
       "            [0.4959, 0.4652, 0.4947, 0.5008],\n",
       "            [0.4995, 0.4729, 0.4967, 0.4929],\n",
       "            [0.4949, 0.4549, 0.5033, 0.5241],\n",
       "            [0.4884, 0.4641, 0.4991, 0.4938],\n",
       "            [0.5006, 0.4691, 0.4846, 0.5048],\n",
       "            [0.5028, 0.4599, 0.4990, 0.4997],\n",
       "            [0.4916, 0.4610, 0.4857, 0.5068],\n",
       "            [0.4936, 0.4601, 0.4864, 0.5087],\n",
       "            [0.4816, 0.4634, 0.4869, 0.5122],\n",
       "            [0.5044, 0.4574, 0.4885, 0.5099],\n",
       "            [0.4911, 0.4505, 0.4956, 0.5106],\n",
       "            [0.4906, 0.4723, 0.4961, 0.4853],\n",
       "            [0.4885, 0.4675, 0.4890, 0.5053],\n",
       "            [0.5033, 0.4717, 0.4948, 0.5029],\n",
       "            [0.4797, 0.4738, 0.4864, 0.5084],\n",
       "            [0.5050, 0.4649, 0.4822, 0.5115],\n",
       "            [0.5033, 0.4652, 0.4914, 0.4980],\n",
       "            [0.4963, 0.4597, 0.5007, 0.5021],\n",
       "            [0.4989, 0.4560, 0.4940, 0.5169],\n",
       "            [0.4933, 0.4592, 0.4966, 0.5055],\n",
       "            [0.4767, 0.4669, 0.4815, 0.5096],\n",
       "            [0.5065, 0.4716, 0.4983, 0.4977],\n",
       "            [0.4991, 0.4675, 0.4937, 0.5151],\n",
       "            [0.4964, 0.4811, 0.4952, 0.4970],\n",
       "            [0.4945, 0.4613, 0.4874, 0.5172],\n",
       "            [0.4985, 0.4597, 0.5032, 0.5084],\n",
       "            [0.4890, 0.4650, 0.4823, 0.5111],\n",
       "            [0.4850, 0.4664, 0.4901, 0.5066],\n",
       "            [0.5058, 0.4637, 0.5045, 0.5061],\n",
       "            [0.4971, 0.4621, 0.4899, 0.5085],\n",
       "            [0.4950, 0.4710, 0.4871, 0.5086],\n",
       "            [0.4871, 0.4696, 0.4819, 0.5011],\n",
       "            [0.4999, 0.4603, 0.4960, 0.5021],\n",
       "            [0.4784, 0.4699, 0.4939, 0.5009],\n",
       "            [0.5027, 0.4738, 0.5017, 0.5046],\n",
       "            [0.4933, 0.4640, 0.4832, 0.5076],\n",
       "            [0.5007, 0.4621, 0.4974, 0.5076],\n",
       "            [0.4879, 0.4534, 0.4906, 0.5088],\n",
       "            [0.5025, 0.4861, 0.5010, 0.4906],\n",
       "            [0.5039, 0.4603, 0.4858, 0.4972],\n",
       "            [0.4890, 0.4609, 0.4890, 0.5190],\n",
       "            [0.4816, 0.4570, 0.4942, 0.5021],\n",
       "            [0.4858, 0.4583, 0.4825, 0.5073],\n",
       "            [0.5007, 0.4689, 0.4934, 0.5010],\n",
       "            [0.4880, 0.4560, 0.4797, 0.5159],\n",
       "            [0.4982, 0.4671, 0.5029, 0.5063],\n",
       "            [0.4844, 0.4646, 0.4922, 0.5007],\n",
       "            [0.4913, 0.4704, 0.4914, 0.4987],\n",
       "            [0.4978, 0.4663, 0.4951, 0.5054],\n",
       "            [0.4966, 0.4707, 0.4907, 0.4972],\n",
       "            [0.4940, 0.4585, 0.4942, 0.5037],\n",
       "            [0.4876, 0.4620, 0.4921, 0.5080],\n",
       "            [0.4918, 0.4655, 0.4942, 0.5120],\n",
       "            [0.4874, 0.4643, 0.4955, 0.5094],\n",
       "            [0.5068, 0.4632, 0.4996, 0.4952],\n",
       "            [0.5071, 0.4700, 0.4909, 0.5063],\n",
       "            [0.4826, 0.4717, 0.5034, 0.5006],\n",
       "            [0.5032, 0.4570, 0.4825, 0.5125],\n",
       "            [0.5066, 0.4642, 0.4946, 0.5055],\n",
       "            [0.4871, 0.4627, 0.4863, 0.5042],\n",
       "            [0.4866, 0.4695, 0.4848, 0.5041],\n",
       "            [0.4939, 0.4636, 0.4916, 0.5065],\n",
       "            [0.5018, 0.4729, 0.4905, 0.5043],\n",
       "            [0.4982, 0.4685, 0.4914, 0.4958],\n",
       "            [0.4965, 0.4650, 0.4943, 0.5076],\n",
       "            [0.4986, 0.4677, 0.4838, 0.5013],\n",
       "            [0.4914, 0.4744, 0.4801, 0.4964],\n",
       "            [0.5105, 0.4622, 0.5030, 0.5031],\n",
       "            [0.4984, 0.4566, 0.4968, 0.4980],\n",
       "            [0.4822, 0.4695, 0.4930, 0.4919],\n",
       "            [0.4925, 0.4698, 0.4908, 0.5062],\n",
       "            [0.4986, 0.4546, 0.4931, 0.5110],\n",
       "            [0.4835, 0.4656, 0.4915, 0.5070],\n",
       "            [0.5069, 0.4682, 0.4907, 0.4998],\n",
       "            [0.4913, 0.4713, 0.4915, 0.5096],\n",
       "            [0.4983, 0.4707, 0.4862, 0.5084],\n",
       "            [0.4958, 0.4698, 0.4893, 0.5025],\n",
       "            [0.5036, 0.4631, 0.4904, 0.5082],\n",
       "            [0.4904, 0.4681, 0.4896, 0.5043],\n",
       "            [0.4979, 0.4623, 0.5004, 0.5003],\n",
       "            [0.5007, 0.4622, 0.4903, 0.5045],\n",
       "            [0.4927, 0.4589, 0.4956, 0.5079],\n",
       "            [0.5124, 0.4669, 0.4829, 0.5130],\n",
       "            [0.4925, 0.4614, 0.4903, 0.5073],\n",
       "            [0.4972, 0.4659, 0.5027, 0.5017],\n",
       "            [0.4948, 0.4691, 0.4960, 0.5006],\n",
       "            [0.4883, 0.4601, 0.4972, 0.5051],\n",
       "            [0.5048, 0.4652, 0.4939, 0.4964],\n",
       "            [0.4844, 0.4621, 0.4755, 0.5160],\n",
       "            [0.4997, 0.4666, 0.4980, 0.5009]]], device='cuda:0'),\n",
       "   'pred_obj_boxes': tensor([[[0.4906, 0.5079, 0.5195, 0.4949],\n",
       "            [0.4934, 0.5109, 0.5189, 0.4937],\n",
       "            [0.4945, 0.5159, 0.5310, 0.5023],\n",
       "            [0.4905, 0.4988, 0.5332, 0.5018],\n",
       "            [0.4943, 0.5096, 0.5305, 0.5004],\n",
       "            [0.5000, 0.5039, 0.5259, 0.4957],\n",
       "            [0.4794, 0.5062, 0.5189, 0.4902],\n",
       "            [0.4909, 0.5076, 0.5184, 0.4976],\n",
       "            [0.5021, 0.5044, 0.5162, 0.5077],\n",
       "            [0.5022, 0.5043, 0.5246, 0.4915],\n",
       "            [0.4975, 0.4925, 0.5102, 0.4916],\n",
       "            [0.4785, 0.5068, 0.5189, 0.5017],\n",
       "            [0.4900, 0.4974, 0.5045, 0.4957],\n",
       "            [0.5019, 0.5114, 0.5122, 0.5048],\n",
       "            [0.4916, 0.4984, 0.5159, 0.4806],\n",
       "            [0.4927, 0.5068, 0.5189, 0.4947],\n",
       "            [0.5063, 0.4963, 0.5152, 0.5142],\n",
       "            [0.4999, 0.5049, 0.5164, 0.4888],\n",
       "            [0.4978, 0.5001, 0.5183, 0.4973],\n",
       "            [0.5030, 0.5099, 0.5210, 0.5036],\n",
       "            [0.4963, 0.5062, 0.5295, 0.4991],\n",
       "            [0.5011, 0.4945, 0.5184, 0.4827],\n",
       "            [0.4909, 0.5059, 0.5101, 0.4903],\n",
       "            [0.4969, 0.5004, 0.5167, 0.4922],\n",
       "            [0.4935, 0.5093, 0.5179, 0.5081],\n",
       "            [0.4974, 0.5059, 0.5168, 0.4983],\n",
       "            [0.4918, 0.5051, 0.5238, 0.4993],\n",
       "            [0.4851, 0.4925, 0.5140, 0.4952],\n",
       "            [0.4980, 0.5057, 0.5136, 0.5046],\n",
       "            [0.4923, 0.5087, 0.5116, 0.5003],\n",
       "            [0.4988, 0.5138, 0.5145, 0.4968],\n",
       "            [0.4976, 0.5078, 0.5205, 0.4899],\n",
       "            [0.4989, 0.5061, 0.5169, 0.4989],\n",
       "            [0.5017, 0.4998, 0.5076, 0.5013],\n",
       "            [0.5161, 0.5041, 0.5161, 0.4982],\n",
       "            [0.4982, 0.4940, 0.5119, 0.5048],\n",
       "            [0.4903, 0.5041, 0.5093, 0.5004],\n",
       "            [0.5059, 0.5070, 0.5258, 0.4969],\n",
       "            [0.4988, 0.4992, 0.5207, 0.4921],\n",
       "            [0.5074, 0.5142, 0.5230, 0.5036],\n",
       "            [0.4992, 0.5111, 0.5244, 0.4979],\n",
       "            [0.4934, 0.4964, 0.5265, 0.4843],\n",
       "            [0.4925, 0.5074, 0.5232, 0.4893],\n",
       "            [0.4962, 0.5069, 0.5286, 0.5048],\n",
       "            [0.4909, 0.5088, 0.5202, 0.4979],\n",
       "            [0.4868, 0.5077, 0.5158, 0.4966],\n",
       "            [0.4977, 0.5114, 0.5145, 0.4909],\n",
       "            [0.5049, 0.5019, 0.5154, 0.4942],\n",
       "            [0.4805, 0.5013, 0.5243, 0.5045],\n",
       "            [0.4818, 0.4972, 0.5096, 0.4998],\n",
       "            [0.5143, 0.5048, 0.5081, 0.5023],\n",
       "            [0.4860, 0.4966, 0.5156, 0.4995],\n",
       "            [0.4956, 0.4994, 0.5161, 0.4962],\n",
       "            [0.5077, 0.5094, 0.5185, 0.4868],\n",
       "            [0.4939, 0.5031, 0.5191, 0.5004],\n",
       "            [0.4947, 0.5017, 0.5161, 0.5019],\n",
       "            [0.4875, 0.5074, 0.5132, 0.4951],\n",
       "            [0.4899, 0.4974, 0.5219, 0.5066],\n",
       "            [0.5015, 0.5019, 0.5189, 0.5041],\n",
       "            [0.4949, 0.5024, 0.5186, 0.4893],\n",
       "            [0.4963, 0.5094, 0.5190, 0.4954],\n",
       "            [0.4965, 0.4994, 0.5060, 0.5014],\n",
       "            [0.5022, 0.4997, 0.5067, 0.5081],\n",
       "            [0.5022, 0.4943, 0.5262, 0.5064],\n",
       "            [0.4869, 0.5068, 0.5258, 0.4888],\n",
       "            [0.4930, 0.5033, 0.5179, 0.4999],\n",
       "            [0.4860, 0.5060, 0.5186, 0.4993],\n",
       "            [0.5129, 0.5011, 0.5142, 0.4992],\n",
       "            [0.4929, 0.5025, 0.5129, 0.4903],\n",
       "            [0.4955, 0.5138, 0.5255, 0.4971],\n",
       "            [0.4900, 0.5093, 0.5142, 0.5046],\n",
       "            [0.5003, 0.5075, 0.5052, 0.5039],\n",
       "            [0.4887, 0.4944, 0.5245, 0.5003],\n",
       "            [0.4829, 0.4975, 0.5207, 0.4949],\n",
       "            [0.4840, 0.5030, 0.5160, 0.4974],\n",
       "            [0.4952, 0.5084, 0.5152, 0.4868],\n",
       "            [0.4999, 0.5031, 0.5054, 0.5018],\n",
       "            [0.4866, 0.4897, 0.5241, 0.4965],\n",
       "            [0.4930, 0.5027, 0.5139, 0.5015],\n",
       "            [0.5023, 0.4986, 0.5264, 0.4815],\n",
       "            [0.4964, 0.5075, 0.5150, 0.4889],\n",
       "            [0.5031, 0.5035, 0.5099, 0.5045],\n",
       "            [0.4918, 0.5041, 0.5104, 0.4891],\n",
       "            [0.5000, 0.5004, 0.5266, 0.4968],\n",
       "            [0.4988, 0.4971, 0.5161, 0.5029],\n",
       "            [0.4969, 0.4987, 0.5230, 0.4980],\n",
       "            [0.4952, 0.4977, 0.5180, 0.4943],\n",
       "            [0.4987, 0.4884, 0.5162, 0.4970],\n",
       "            [0.4945, 0.5003, 0.5261, 0.4885],\n",
       "            [0.5014, 0.4957, 0.5049, 0.4949],\n",
       "            [0.4995, 0.5105, 0.5198, 0.4986],\n",
       "            [0.4882, 0.5022, 0.5120, 0.5113],\n",
       "            [0.5032, 0.5083, 0.5173, 0.4915],\n",
       "            [0.4976, 0.4979, 0.5108, 0.5012],\n",
       "            [0.4974, 0.5124, 0.5214, 0.5035],\n",
       "            [0.4927, 0.5009, 0.5121, 0.5048],\n",
       "            [0.5004, 0.5049, 0.5275, 0.4919],\n",
       "            [0.4930, 0.4981, 0.5081, 0.4936],\n",
       "            [0.4918, 0.5073, 0.5168, 0.5094],\n",
       "            [0.4979, 0.5014, 0.5210, 0.4996]]], device='cuda:0')}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
